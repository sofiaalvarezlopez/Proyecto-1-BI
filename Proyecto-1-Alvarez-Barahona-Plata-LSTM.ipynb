{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9c6d4b",
   "metadata": {},
   "source": [
    "### María Sofía Álvarez - Brenda Barahona - Álvaro Plata\n",
    "<h1 align='center'>Proyecto 1: Analítica de textos - LSTM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b3c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f18f9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import warnings\n",
    "import datetime\n",
    "import sent2vec\n",
    "import fasttext\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "from gensim.models import FastText\n",
    "from keras.models import load_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "from keras.layers import LSTM, Dense, Embedding, TextVectorization, Input\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33659032",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869d98c9",
   "metadata": {},
   "source": [
    "## Algoritmo elegido: LSTM\n",
    "\n",
    "El tercer algoritmo que usaremos para este problema será LSTM.\n",
    "\n",
    "La LSTM (Long-Short Term Memory) es un tipo de red neuronal recurrente (RNN, por sus siglas en inglés) que se desempeña mejor que las RNN tradicionales en términos de memoria [1]. Una RNN es un tipo de red neuronal que permite a las salidas de capas previas ser utilizadas como entradas, teniendo estados ocultos [2].\n",
    "\n",
    "Las LSTM tienen múltiples capas ocultas. A medida que se pasa a través de una capa, la información relevante se mantiene y la irrelevante se desecha en cada neurona (celda) individual [1]. Asimismo, las LSTM solucionan el problema de desvanecimiento de gradientes que las RNN enfrentan a menudo.\n",
    "\n",
    "Las LSTM cuentan principalmente con 3 compuertas:\n",
    "+ **FORGET Gate:** Esta compuerta es la responsable de decidir qué información se queda y cuál es irrelevante y debe descartarse. Para ello, utiliza la información que viene de la neurona anterior $h_{t-1}$ y la información de la celda actual, $x_t$. Sobre ellas, se corre una función sigmoide, $$S(x) = \\frac{1}{1 + e^{-x}},$$ tal que los datos que tiendan a 0 son descartados por la red [1].\n",
    "+ **INPUT Gate:** Esta compuerta actualiza el estado de la neurona y decide qué información es importante. Como la compuerta FORGET ayuda a descartar la información, la compuerta INPUT ayuda a encontrar la información importante y a almacenar ciertos datos relevantes en memoria. En este caso, la información de la neurona anterior, $h_{t-1}$ es pasada por una función de activación sigmoide, mientras que la información de la neurona actual $x_t$ se pasa por una función de activación de tangete hiperbólica: $$\\tanh(x) = \\frac{1 - e^{-2x}}{1 + e^{-2x}}.$$ Es importante resaltar que la función $\\tanh$ ayuda a regular la red y a reducir el sesgo de la misma [1].\n",
    "+ **OUTPUT Gate:** Tras multiplicar el estado actual de la neurona con lo que se obtiene de la compuerta FORGET, lo cual permite eliminar cierta información si la compuerta FORGET arroja pesos de 0, debe decidirse cual será el estado de la siguiente celda. La información de $h_{t-1}$ y $x_t$ se pasa a través de una función sigmoide, el cual es a su vez pasado por una función de tangente hiperbólica, y ambos resultados se mltiplican para decidir la información que llevará el estado oculto [1]. \n",
    "\n",
    "A continuación, puede verse la gráfica de las funciones $\\tanh$ y sigmoide:\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Muhammad-Hamdan-8/publication/327435257/figure/fig4/AS:742898131812354@1554132125449/Activation-Functions-ReLU-Tanh-Sigmoid.ppm\" />\n",
    "\n",
    "Note que también se encuentra la función de activación ReLU (Regularized Linear Unit), muy popular en las aplicaciones de Machine y Deep Learning.\n",
    "\n",
    "Asimismo, puede verse una representación esquemática (obtenida de [3]) de la estructura de cada una de las compuertas:\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Xuan_Hien_Le2/publication/334268507/figure/fig8/AS:788364231987201@1564972088814/The-structure-of-the-Long-Short-Term-Memory-LSTM-neural-network-Reproduced-from-Yan.png\" width=50% />\n",
    "\n",
    "En la imagen podemos ver las funciones de activación usadas en cada celda LSTM (sigmoide y tangente hiperbólica), así como sus entradas, salidas y compuertas.\n",
    "\n",
    "---\n",
    "Leamos los datos traidos de la fase anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d25c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>problems_described</th>\n",
       "      <th>tokenized_abstracts</th>\n",
       "      <th>non_tokenized_abstracts</th>\n",
       "      <th>non_tokenized_entities</th>\n",
       "      <th>tokenized_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>7957</td>\n",
       "      <td>2</td>\n",
       "      <td>['surgic', 'hydatid', 'liver', 'experi', 'medi...</td>\n",
       "      <td>surgic hydatid liver experi medic record conse...</td>\n",
       "      <td>hydatid liver liver liver extrahepat liver hyd...</td>\n",
       "      <td>['hydatid', 'liver', 'liver', 'liver', 'extrah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>10350</td>\n",
       "      <td>5</td>\n",
       "      <td>['serum', 'tissu', 'magnesium', 'concentr', 'h...</td>\n",
       "      <td>serum tissu magnesium concentr heart failur se...</td>\n",
       "      <td>serum tissu magnesium heart ventricular magnes...</td>\n",
       "      <td>['serum', 'tissu', 'magnesium', 'heart', 'vent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>2654</td>\n",
       "      <td>5</td>\n",
       "      <td>['muscl', 'biopsi', 'diagnosi', 'malign', 'hyp...</td>\n",
       "      <td>muscl biopsi diagnosi malign hyperthermia susc...</td>\n",
       "      <td>muscl biopsi malign hyperthermia muscl biopsi ...</td>\n",
       "      <td>['muscl', 'biopsi', 'malign', 'hyperthermia', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>1160</td>\n",
       "      <td>2</td>\n",
       "      <td>['prospect', 'preval', 'esophag', 'chest', 'pa...</td>\n",
       "      <td>prospect preval esophag chest pain refer elect...</td>\n",
       "      <td>esophag chest cardiac myocardi esophag chest c...</td>\n",
       "      <td>['esophag', 'chest', 'cardiac', 'myocardi', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>355</td>\n",
       "      <td>3</td>\n",
       "      <td>['comparison', 'hybrid', 'uncement', 'total', ...</td>\n",
       "      <td>comparison hybrid uncement total hip replac re...</td>\n",
       "      <td>acetabular cement femor thigh femor cement fem...</td>\n",
       "      <td>['acetabular', 'cement', 'femor', 'thigh', 'fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  problems_described  \\\n",
       "5733        7957                   2   \n",
       "6477       10350                   5   \n",
       "591         2654                   5   \n",
       "6082        1160                   2   \n",
       "6289         355                   3   \n",
       "\n",
       "                                    tokenized_abstracts  \\\n",
       "5733  ['surgic', 'hydatid', 'liver', 'experi', 'medi...   \n",
       "6477  ['serum', 'tissu', 'magnesium', 'concentr', 'h...   \n",
       "591   ['muscl', 'biopsi', 'diagnosi', 'malign', 'hyp...   \n",
       "6082  ['prospect', 'preval', 'esophag', 'chest', 'pa...   \n",
       "6289  ['comparison', 'hybrid', 'uncement', 'total', ...   \n",
       "\n",
       "                                non_tokenized_abstracts  \\\n",
       "5733  surgic hydatid liver experi medic record conse...   \n",
       "6477  serum tissu magnesium concentr heart failur se...   \n",
       "591   muscl biopsi diagnosi malign hyperthermia susc...   \n",
       "6082  prospect preval esophag chest pain refer elect...   \n",
       "6289  comparison hybrid uncement total hip replac re...   \n",
       "\n",
       "                                 non_tokenized_entities  \\\n",
       "5733  hydatid liver liver liver extrahepat liver hyd...   \n",
       "6477  serum tissu magnesium heart ventricular magnes...   \n",
       "591   muscl biopsi malign hyperthermia muscl biopsi ...   \n",
       "6082  esophag chest cardiac myocardi esophag chest c...   \n",
       "6289  acetabular cement femor thigh femor cement fem...   \n",
       "\n",
       "                                     tokenized_entities  \n",
       "5733  ['hydatid', 'liver', 'liver', 'liver', 'extrah...  \n",
       "6477  ['serum', 'tissu', 'magnesium', 'heart', 'vent...  \n",
       "591   ['muscl', 'biopsi', 'malign', 'hyperthermia', ...  \n",
       "6082  ['esophag', 'chest', 'cardiac', 'myocardi', 'e...  \n",
       "6289  ['acetabular', 'cement', 'femor', 'thigh', 'fe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_train = pd.read_csv('train_Data.csv')\n",
    "datos_test = pd.read_csv('test_Data.csv')\n",
    "datos_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d13381",
   "metadata": {},
   "source": [
    "## Vectorización\n",
    "\n",
    "Una vez elegido el modelo, procedemos a hacer la vectorización de los datos que obtuvimos en la fase de preprocesamiento. Como dijimos, el preprocesamiento para los algoritmos basados en secuencias, como las redes neuronales, es diferente. En este caso, optaré por usar dos opciones de embedding. Describo una tercera, pero no la usaré porque es muy costosa computacionalmente.\n",
    "\n",
    "* **BioSentVec:** Módulo basado en las investigaciones de Zhang et. al [4]. Similar a Sent2Vec (algoritmo de embedding de Google), está basado en la librería ```fast_text```de Facebook para embeddings y clasificación de textos. La librería utiliza las base de datos de PubMed y las notas clínicas de MIMIC-III Clinical Database como corpus para entrenar una red que genera vectores de 700 dimensiones. El procedimiento para usar este modelo es largo y tedioso, pero puede encontrarse anexo a este laboratorio. Debido a que la dimensionalidad sigue siendo elevada, para evitar overfitting, solamente se usará sobre los abstracts y no sobre las entities.\n",
    "* **BioWordVec:** Desarrollada por los mismos investigadores de [4], es un embedding muy usado en contextos biomédicos. Como es sobre palabras únicamente, preferimos utilizarlo para las entidades médicas extraídas en el preprocesamiento\n",
    "* **Keras Vectorizer y Keras Embedding:** Al usar redes neuronales con la librería Keras, existe una capa propia de ```Vectorizing``` y ```Embedding```. Esta técnica requiere de muchos más hiperparámetros y no se espera que tenga un mejor rendimiento, ya que no es especialmente diseñada para el contexto médico sino para cualquiera en general. Deberíamos controlar el tamaño de los vectores y la cantidad de neuronas en la capa de embedding, por ejemplo, lo cual es lento (considerando que tenemos los hiperparámetros de LSTM también).\n",
    "\n",
    "Podemos probar esta técnica de vectorización también. Se probará sobre las palabras de entidades puesto que puede tardarse mucho sobre las historias clínicas.\n",
    "\n",
    "Cargamos la librería de BioWordVec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd893f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model successfully loaded\n"
     ]
    }
   ],
   "source": [
    "model_path = 'BioSentVec_PubMed_MIMICIII-bigram_d700.bin'\n",
    "model = sent2vec.Sent2vecModel()\n",
    "try:\n",
    "    model.load_model(model_path)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print('model successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb62c19b",
   "metadata": {},
   "source": [
    "Por la forma en la que funciona la librería, no podemos poner este paso en una Pipeline. Por lo tanto, lo que hacemos es generar los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d1b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_abstracts = model.embed_sentences(datos_train['non_tokenized_abstracts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554a3568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'embedded_abstracts' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store embedded_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0e67d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 700)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_abstracts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae8172",
   "metadata": {},
   "source": [
    "¡Note que la dimensionalidad de estos datos es de 700! Como vimos en el preprocesamiento, esto puede ser mucho para las entidades. Por lo tanto, para ellas, usaremos el embedding de ```sk-learn```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db09a3",
   "metadata": {},
   "source": [
    "## Manejo de desbalanceo de las clases\n",
    "\n",
    "Ahora, uno de los mayores problemas de la clasificación es el contexto desbalanceado. Una opción sería reducir el conjunto de datos hasta que todas las clases queden con un número de abstracts igual al tamaño de la clase de menor cantidad de abstracts. No obstante, por lo general la idea es no reducir el conjunto de datos. Otra opción, como en los algoritmos anteriores, sería usar SMOTE. No obstante, esto es computacionalmente muy costoso para la red.\n",
    "\n",
    "Lo que sí podemos hacer es considerar pesos. Así, el modelo podrá prestar mayor atención a las clases minoritarias. Para ello, usaremos la librería de <code>sk-learn</code> y lo pasaremos como un objeto al modelo que construiremos más adelante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65e19ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "                class_weight = 'balanced',\n",
    "                classes = np.unique(datos_train['problems_described']), \n",
    "                y = datos_train['problems_described'])\n",
    "train_class_weights_ = dict(enumerate(class_weights, start=1))\n",
    "train_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49f3a4",
   "metadata": {},
   "source": [
    "Podemos ver los pesos asociados a cada una de las clases, en orden ascendente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a001630e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.912981455064194,\n",
       " 2: 1.93158953722334,\n",
       " 3: 1.5,\n",
       " 4: 0.9462789551503203,\n",
       " 5: 0.6011271133375078}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7089f639",
   "metadata": {},
   "source": [
    "Como era de esperarse, recordando la gráfica del perfilamiento (mostrada más abajo), la clase con mayor peso es la 2, seguida de la clase 3. La clase mayoritaria (la 5) es la que presenta menores pesos.\n",
    "\n",
    "<img src=\"images/img_preproc.png\" width=40% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f601d",
   "metadata": {},
   "source": [
    "Con esto, ya podemos proceder a realizar el modelamiento. \n",
    "## Modelo LSTM\n",
    "Es importante mencionar que no hay un método estándar para la búsqueda de hiperparámetros en redes neuronales. Para ello, debemos hacer algunos *workarounds*. \n",
    "\n",
    "No obstante, antes de hacer el tuneo de hiperparámetros, en este tipo de modelos resulta más sencillo hacer un modelo base primero. Hagamos un modelo base usando el WordEmbedding de BioSentVec. \n",
    "### Modelo base: Usando BioSentVec\n",
    "Consideremos un modelo base de dos capas LSTM, acompañadas de su capa de dropout (i.e. de pérdida). De acuerdo con [1], es importante que estos modelos estén acompañados de esta capa para evitar overfitting. Finalmente, consideramos una capa densa con función de activación <code>softmax</code>, que es la función de activación que se utiliza en contextos de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d982a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_abstracts_ = embedded_abstracts.reshape(-1, 1, embedded_abstracts.shape[1])\n",
    "Y_train = datos_train['problems_described']\n",
    "Y_train_ = keras.utils.np_utils.to_categorical(Y_train)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8f76bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 5 # Cantidad de clases del problema\n",
    "# ------------------LSTM-----------------------\n",
    "# Inicializamos el modelo\n",
    "lstm_base = Sequential(name='LSTM_basico') \n",
    "# Agregamos una capa LSTM con el tamanio de entrada de los embedded abstracts y 16 neuronas en la capa\n",
    "lstm_base.add(LSTM(units=16, return_sequences=True, \n",
    "                    input_shape=(1, embedded_abstracts_.shape[2])))\n",
    "# Agregamos la primera capa de dropout\n",
    "lstm_base.add(Dropout(0.2))\n",
    "# Agregamos una segunda capa LSTM con 16 neuronas\n",
    "lstm_base.add(LSTM(units=16, return_sequences=False))\n",
    "# Con su respectiva capa de dropout\n",
    "lstm_base.add(Dropout(0.2))\n",
    "# Definimos la capa de salida\n",
    "lstm_base.add(Dense(output, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803c92b",
   "metadata": {},
   "source": [
    "Antes de ver nuestro modelo totalmente construido, conviene discutir un poco lo que acabamos de hacer. Inicializamos el modelo creando un modelo secuencial. Posteriormente, agregamos una capa LSTM con su respectiva capa de dropout. Esta es una capa de regularización, que hace que se aprenda una fracción de los pesos en la red. Para redes grandes, se recomienda un dropout $p=0.5$ , la cual corresponde a la máxima regularización. Esto también lo ajustaremos como hiperparámetro, pero es un buen punto de partida para nuestro primer modelo [5]. Agregamos otra capa de LSTM con su respectiva capa de dropout y, finalmente, diseñamos la capa de salida con 5 neuronas: pues tenemos 5 clases.\n",
    "\n",
    "Revisando la documentación de <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\"/> la capa LSTM</a>, es posible ver que hay muchos posibles hiperparámetros a configurar. No obstante, hay algunos que NO deben ser modificados, de acuerdo con la revisión teórica realizada más arriba, como la función de activación (que debe ser $\\tanh$) y la función de activación recurrente (que debe ser sigmoide). Asimismo, hay otros parámetros que están ajustados para la mayoría de aplicaciones de ML, como el inicializador del kernel (que es globot) y del kernel recurrente (que es ortogonal), por defecto. Asimismo, hay otros hiperparámetros que permiten hacer modificaciones sobre el modelo, como ```go_backwards```. Este puede ser útil para la construcción de redes recurrentes bidireccionales. Así las cosas, vemos que, dados los hiperparámetros de esta capa, en realidad la más fundamental a determinar (y para no tener un gran costo computacional - pues el espacio de búsqueda sería inmenso -) es: \n",
    "* **units:** Indica el número de neuronas de la capa. En el modelo inicial, usamos 16. Pero puede ser cualquier número entero positivo.\n",
    "* El número de capas, aunque no es un hiperparámetro de esta capa, es un hiperparámetro del modelo.\n",
    "\n",
    "Estos hiperparámetros, junto con la tasa de dropout, serán tuneados más adelante. Veamos el resumen del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "620ae19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_basico\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 16)             45888     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 16)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,085\n",
      "Trainable params: 48,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8bd1a0",
   "metadata": {},
   "source": [
    "Ahora, debemos elegir una métrica, una función de pérdida y un optimizador. En cuanto a la función de pérdida, la que se usa con frecuencia en problemas de clasificación es la de entropía cruzada. De hecho, se recomienda no cambiarla, a menos de que se tenga una razón lo suficientemente fuerte para hacerlo, pues es la función de pérdida preferida en el marco de la máxima verosimilitud. Para problemas multiclase, se utiliza entropía cruzada categórica: sparse_categorical_crossentropy [6].\n",
    "\n",
    "En el caso del optimizador, elegimos adam. Por lo general, este es el que mejores resultados presenta, de acuerdo con la literatura. Asimismo, nos quitamos de encima el ajustar un hiperparámetro extra (la tasa de aprendizaje), pues los algoritmos adaptativos como Adam van ajustando esta tasa a medida que entrenan [7]. Últimamente se ha visto que SGD, acompañado de un buen learning rate, puede arrojar resultados excelentes también. No obstante, esto implica el ajuste de un hiperparámetro que, dada la complejidad del problema, puede ser muy costosa computacionalmente.\n",
    "\n",
    "Asimismo, debemos definir la métrica que informa el éxito del modelo. En este caso elegimos la precisión como métrica, pues el usuario médico quiere clasificar tan bien como se pueda los abstracts en las enfermedades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "300c316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_base.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[ keras.metrics.Precision(name='precision')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb257a9",
   "metadata": {},
   "source": [
    "### Control de la complejidad y los tiempos de procesamiento\n",
    "Una forma de controlar la complejidad y los tiempos de procesamiento es mediante el uso de callbacks. Estas son acciones durante las etapas del entrenamiento.\n",
    "\n",
    "De acuerdo con la documentación de Tensorflow, encontramos dos callbacks que consideramos útiles para este laboratorio. Primero, consideramos EarlyStopping. En este caso, ponemos la cantidad monitoreada como la medida que tomamos a la pérdida (val_loss) tal que, si después de 3 épocas no ha mejorado, entonces pare el entrenamiento y la actualización de los pesos. En este caso, monitoreamos sobre el error de validación.\n",
    "\n",
    "Finalmente, ModelCheckpoint permite guardar el modelo con mejor desempeño sobre validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08c23fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto', baseline=None)\n",
    "model_checkpoint = ModelCheckpoint('base_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "callbacks = [early_stopping, model_checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5db5a8",
   "metadata": {},
   "source": [
    "Finalmente, hacemos fit al modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "733b9d8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.3341 - precision: 0.6811\n",
      "Epoch 1: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 2s 2ms/step - loss: 1.3133 - precision: 0.6629 - val_loss: 1.0806 - val_precision: 0.6759\n",
      "Epoch 2/100\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.9649 - precision: 0.6401\n",
      "Epoch 2: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9612 - precision: 0.6411 - val_loss: 1.0182 - val_precision: 0.6458\n",
      "Epoch 3/100\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8991 - precision: 0.6403\n",
      "Epoch 3: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8973 - precision: 0.6394 - val_loss: 0.9781 - val_precision: 0.6479\n",
      "Epoch 4/100\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.8682 - precision: 0.6464\n",
      "Epoch 4: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8661 - precision: 0.6490 - val_loss: 0.9877 - val_precision: 0.6412\n",
      "Epoch 5/100\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.8535 - precision: 0.6562\n",
      "Epoch 5: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8482 - precision: 0.6573 - val_loss: 0.9624 - val_precision: 0.6542\n",
      "Epoch 6/100\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.8317 - precision: 0.6616\n",
      "Epoch 6: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8275 - precision: 0.6645 - val_loss: 0.9472 - val_precision: 0.6470\n",
      "Epoch 7/100\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8036 - precision: 0.6656\n",
      "Epoch 7: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8047 - precision: 0.6653 - val_loss: 0.9641 - val_precision: 0.6456\n",
      "Epoch 8/100\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 0.7994 - precision: 0.6666\n",
      "Epoch 8: val_loss improved from 0.92010 to 0.92000, saving model to base_model.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7956 - precision: 0.6668 - val_loss: 0.9200 - val_precision: 0.6592\n",
      "Epoch 9/100\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7838 - precision: 0.6737\n",
      "Epoch 9: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7839 - precision: 0.6744 - val_loss: 0.9216 - val_precision: 0.6552\n",
      "Epoch 10/100\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7629 - precision: 0.6785\n",
      "Epoch 10: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7644 - precision: 0.6769 - val_loss: 0.9405 - val_precision: 0.6491\n",
      "Epoch 11/100\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 0.7565 - precision: 0.6806\n",
      "Epoch 11: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7587 - precision: 0.6806 - val_loss: 0.9421 - val_precision: 0.6514\n",
      "Epoch 12/100\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7515 - precision: 0.6808\n",
      "Epoch 12: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7490 - precision: 0.6842 - val_loss: 0.9372 - val_precision: 0.6518\n",
      "Epoch 13/100\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.7478 - precision: 0.6780\n",
      "Epoch 13: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7473 - precision: 0.6782 - val_loss: 0.9436 - val_precision: 0.6555\n",
      "Epoch 14/100\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7389 - precision: 0.6824\n",
      "Epoch 14: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7352 - precision: 0.6822 - val_loss: 0.9485 - val_precision: 0.6479\n",
      "Epoch 15/100\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7208 - precision: 0.6875\n",
      "Epoch 15: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7208 - precision: 0.6894 - val_loss: 0.9597 - val_precision: 0.6442\n",
      "Epoch 16/100\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7172 - precision: 0.6863\n",
      "Epoch 16: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.7175 - precision: 0.6866 - val_loss: 0.9587 - val_precision: 0.6400\n",
      "Epoch 17/100\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7093 - precision: 0.6936\n",
      "Epoch 17: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7110 - precision: 0.6937 - val_loss: 0.9888 - val_precision: 0.6377\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6977 - precision: 0.6904\n",
      "Epoch 18: val_loss did not improve from 0.92000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6977 - precision: 0.6904 - val_loss: 0.9667 - val_precision: 0.6407\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_base = lstm_base.fit(embedded_abstracts_, Y_train_, validation_split=0.2, epochs= 100, callbacks=callbacks, class_weight=train_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6fb7a",
   "metadata": {},
   "source": [
    "Podmeos ver los plots de precisión y pérdida para este modelo inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e18f599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1adcb8640>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,7))\n",
    "fig.add_subplot(121)\n",
    "# Precision\n",
    "plt.plot(history_base.epoch, history_base.history['precision'], label = \"precision\")\n",
    "plt.plot(history_base.epoch, history_base.history['val_precision'], label = \"val_precision\")\n",
    "\n",
    "plt.title(\"Precisión\", fontsize=18)\n",
    "plt.xlabel(\"Épocas\", fontsize=15)\n",
    "plt.ylabel(\"Precisión\", fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Pérdida\n",
    "fig.add_subplot(122)\n",
    "\n",
    "plt.plot(history_base.epoch, history_base.history['loss'], label=\"loss\")\n",
    "plt.plot(history_base.epoch, history_base.history['val_loss'], label = \"val_loss\")\n",
    "\n",
    "\n",
    "plt.title(\"Pérdida\", fontsize=18)\n",
    "plt.xlabel(\"Épocas\", fontsize=15)\n",
    "plt.ylabel(\"Pérdida\", fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e14010",
   "metadata": {},
   "source": [
    "De la salida por consola, podemos ver que el modelo paró tempranamente en la época 18. En este caso, suponemos que desde esta época el modelo empezaría a hacer overfitting. De hecho, de la gráfica de pérdida podemos ver que se empieza a llegar a una meseta. Lo que nos sugiere es que el modelo no encuentra forma de optimizar más los parámetros. Así las cosas, nuestro modelo no logra generalizar más sobre el conjunto de datos, o se queda atrapado en la optimización.\n",
    "\n",
    "Asimismo, vemos que la precisión no es muy elevada. Pensamos que esto se debe a la cantidad de neuronas que utilizamos. Intentamos ahora ajustar hiperparámetros a ver si logramos una mejor precisión. Primero, lo intentaremos sobre las vectorizaciones usando el algoritmo biomédico.\n",
    "\n",
    "### Modelo con ajuste de hiperparámetros usando BioSentVec\n",
    "\n",
    "Hay muchos hiperparámetros por afinar en el modelo que en principio podríamos seguir buscando mediante la función de GridSearch. Sin embargo, no es recomendable pues nos encontramos en un universo enorme de hiperparámetros si deseamos hacer una búsqueda exhaustiva. Asimismo, podría usarse la función RandomizedSearchCV. No obstante, esta arroja algunos errores en el cálculo de las métricas y, por tanto, no funciona adecuadamente. Lo que hacemos es, entonces, construir nuestra propia función de búsqueda.\n",
    "\n",
    "Los parámetros que son más importantes de ajustar son el número de neuronas por capa, el número total de capas y la tasa de dropout. Por economía de recursos computacionales, usamos el mismo número de neuronas en todos los casos y la misma tasa de Dropout para todas las capas. Definimos entonces una función que nos permita hacer esto a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca01b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_hiperparametros(config, x_train=embedded_abstracts_, y_train=Y_train_, is_ent=False):\n",
    "    output = 5 # Tenemos 5 neuronas en la capa oculta pues son las 5 clases de salida\n",
    "    # Extraigo los parametros\n",
    "    first_add, second_add, third_add, nn, dropout = config\n",
    "    possible_combinations = list(itertools.product(first_add, second_add, third_add, nn, dropout))\n",
    "    \n",
    "    print('La cantidad de combinaciones es: ', len(possible_combinations))\n",
    "    print('\\n')\n",
    "    hist = []\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "        first_add, second_add, third_add, nn, dropout = possible_combinations[i]\n",
    "        print(f'Combinación {i+1}: \\n')\n",
    "        print('--------------------------------------------------------------------')\n",
    "        # Inicializo la red\n",
    "        clf = Sequential(name=f'Mi_Red_{i+1}')\n",
    "        # Agrego la primera capa obligatoria LSTM\n",
    "        clf.add(LSTM(units=nn, return_sequences=True, input_shape=(1, x_train.shape[2])))\n",
    "        # Agrego la primera capa Dropout\n",
    "        clf.add(Dropout(dropout))\n",
    "        # Agrego capa adicional, de ser necesario, con dropout\n",
    "        if first_add:\n",
    "            clf.add(LSTM(units=nn, return_sequences=True))\n",
    "            clf.add(Dropout(dropout))\n",
    "        # Agrego segunda capa adicional, con dropout\n",
    "        if second_add:\n",
    "            clf.add(LSTM(units=nn, return_sequences=True))\n",
    "            clf.add(Dropout(dropout))\n",
    "        # Agrego tercera capa adicional, con dropout\n",
    "        if third_add:\n",
    "            clf.add(LSTM(units=nn, return_sequences=True))\n",
    "            clf.add(Dropout(dropout))\n",
    "        # Agrego una ultima capa LSTM, con dropout\n",
    "        clf.add(LSTM(units=nn, return_sequences=False))\n",
    "        clf.add(Dropout(dropout))\n",
    "        # Agrego la capa de clasificacion\n",
    "        clf.add(Dense(output, activation='softmax'))\n",
    "        # Compilo el modelo\n",
    "        clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.Precision(name='precision')]) # Valores por defecto\n",
    "        # Agrego un callback para almacenar el mejor modelo\n",
    "        if is_ent:\n",
    "            model_checkpoint = ModelCheckpoint(f'model_ent{i+1}.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "        else:\n",
    "            model_checkpoint = ModelCheckpoint(f'model_{i+1}.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "        # Hago fit\n",
    "        history_base = clf.fit(x_train, y_train, validation_split=0.2, epochs= 70, callbacks=[early_stopping, model_checkpoint], class_weight=train_class_weights)\n",
    "        # Mido la precision\n",
    "        train_precision = clf.evaluate(x_train, y_train, verbose=1)\n",
    "        hist.append(list((f'model_{i+1}.h5', history_base, first_add, second_add, third_add, nn, dropout, train_precision)))\n",
    "        \n",
    "        print(f'Combinación {str(i)} = {possible_combinations[i]} \\n precision train: {train_precision}')\n",
    "        \n",
    "        print('--------------------------------------------------------------------')\n",
    "        print('--------------------------------------------------------------------')\n",
    "        print('--------------------------------------------------------------------')\n",
    "        print('--------------------------------------------------------------------')\n",
    "         \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c578a",
   "metadata": {},
   "source": [
    "Con esto, ya podemos definir nuestra grilla de hiperparámetros.\n",
    "Hablemos un poco de ellos. En este caso, queremos encontrar los mejores hiperparámetros para el número de capas, de neuronas, y la mejor tasa de dropout. Consideramos solo tres capas, así como neuronas entre 8, 16, 32 y 64 para evitar que el modelo haga overfitting. Para el dropout, evaluamos valores entre 0.1, 0.25 y 0.5, siendo 0.5 el máximo dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0be398b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de combinaciones es:  96\n",
      "\n",
      "\n",
      "Combinación 1: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.5706 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.40126, saving model to model_1.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.5577 - precision: 0.0000e+00 - val_loss: 1.4013 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.3109 - precision: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 1.40126 to 1.32364, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3111 - precision: 0.0000e+00 - val_loss: 1.3236 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2681 - precision: 0.0000e+00\n",
      "Epoch 3: val_loss improved from 1.32364 to 1.29586, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2670 - precision: 0.0000e+00 - val_loss: 1.2959 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.2329 - precision: 0.6684\n",
      "Epoch 4: val_loss improved from 1.29586 to 1.27381, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2335 - precision: 0.6490 - val_loss: 1.2738 - val_precision: 0.0000e+00\n",
      "Epoch 5/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1982 - precision: 0.6265\n",
      "Epoch 5: val_loss improved from 1.27381 to 1.24751, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1980 - precision: 0.6340 - val_loss: 1.2475 - val_precision: 0.6851\n",
      "Epoch 6/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1619 - precision: 0.6638\n",
      "Epoch 6: val_loss improved from 1.24751 to 1.18822, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1607 - precision: 0.6675 - val_loss: 1.1882 - val_precision: 0.6986\n",
      "Epoch 7/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1168 - precision: 0.6705\n",
      "Epoch 7: val_loss improved from 1.18822 to 1.17824, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1180 - precision: 0.6651 - val_loss: 1.1782 - val_precision: 0.6339\n",
      "Epoch 8/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0804 - precision: 0.6322\n",
      "Epoch 8: val_loss improved from 1.17824 to 1.15321, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0834 - precision: 0.6330 - val_loss: 1.1532 - val_precision: 0.6449\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0581 - precision: 0.6227\n",
      "Epoch 9: val_loss improved from 1.15321 to 1.13957, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0581 - precision: 0.6234 - val_loss: 1.1396 - val_precision: 0.6055\n",
      "Epoch 10/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0339 - precision: 0.6115\n",
      "Epoch 10: val_loss improved from 1.13957 to 1.13006, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0325 - precision: 0.6126 - val_loss: 1.1301 - val_precision: 0.5955\n",
      "Epoch 11/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0056 - precision: 0.5980\n",
      "Epoch 11: val_loss improved from 1.13006 to 1.11654, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0051 - precision: 0.5983 - val_loss: 1.1165 - val_precision: 0.5856\n",
      "Epoch 12/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9964 - precision: 0.5960\n",
      "Epoch 12: val_loss did not improve from 1.11654\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9981 - precision: 0.5943 - val_loss: 1.1188 - val_precision: 0.5735\n",
      "Epoch 13/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9734 - precision: 0.5984\n",
      "Epoch 13: val_loss improved from 1.11654 to 1.11599, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9732 - precision: 0.5982 - val_loss: 1.1160 - val_precision: 0.5768\n",
      "Epoch 14/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9645 - precision: 0.5934\n",
      "Epoch 14: val_loss improved from 1.11599 to 1.11384, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9633 - precision: 0.5946 - val_loss: 1.1138 - val_precision: 0.5671\n",
      "Epoch 15/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9553 - precision: 0.5959\n",
      "Epoch 15: val_loss did not improve from 1.11384\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9564 - precision: 0.5966 - val_loss: 1.1154 - val_precision: 0.5605\n",
      "Epoch 16/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9346 - precision: 0.6049\n",
      "Epoch 16: val_loss improved from 1.11384 to 1.09953, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9354 - precision: 0.6045 - val_loss: 1.0995 - val_precision: 0.5834\n",
      "Epoch 17/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9398 - precision: 0.5993\n",
      "Epoch 17: val_loss did not improve from 1.09953\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9396 - precision: 0.5994 - val_loss: 1.1177 - val_precision: 0.5764\n",
      "Epoch 18/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9323 - precision: 0.6038\n",
      "Epoch 18: val_loss did not improve from 1.09953\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9298 - precision: 0.6049 - val_loss: 1.1089 - val_precision: 0.5724\n",
      "Epoch 19/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9254 - precision: 0.6044\n",
      "Epoch 19: val_loss did not improve from 1.09953\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9230 - precision: 0.6038 - val_loss: 1.1035 - val_precision: 0.5714\n",
      "Epoch 20/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9104 - precision: 0.6108\n",
      "Epoch 20: val_loss did not improve from 1.09953\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9086 - precision: 0.6104 - val_loss: 1.1118 - val_precision: 0.5741\n",
      "Epoch 21/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8989 - precision: 0.6153\n",
      "Epoch 21: val_loss improved from 1.09953 to 1.09497, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9035 - precision: 0.6127 - val_loss: 1.0950 - val_precision: 0.5772\n",
      "Epoch 22/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8864 - precision: 0.6179\n",
      "Epoch 22: val_loss improved from 1.09497 to 1.08918, saving model to model_1.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8861 - precision: 0.6170 - val_loss: 1.0892 - val_precision: 0.5865\n",
      "Epoch 23/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8730 - precision: 0.6273\n",
      "Epoch 23: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8726 - precision: 0.6274 - val_loss: 1.1089 - val_precision: 0.5800\n",
      "Epoch 24/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8805 - precision: 0.6221\n",
      "Epoch 24: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8804 - precision: 0.6224 - val_loss: 1.0931 - val_precision: 0.5864\n",
      "Epoch 25/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8552 - precision: 0.6329\n",
      "Epoch 25: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8572 - precision: 0.6316 - val_loss: 1.1040 - val_precision: 0.5785\n",
      "Epoch 26/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8614 - precision: 0.6298\n",
      "Epoch 26: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8614 - precision: 0.6298 - val_loss: 1.1028 - val_precision: 0.5865\n",
      "Epoch 27/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8501 - precision: 0.6366\n",
      "Epoch 27: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8485 - precision: 0.6364 - val_loss: 1.0990 - val_precision: 0.5874\n",
      "Epoch 28/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8486 - precision: 0.6330\n",
      "Epoch 28: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8484 - precision: 0.6333 - val_loss: 1.0914 - val_precision: 0.5898\n",
      "Epoch 29/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8374 - precision: 0.6389\n",
      "Epoch 29: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8366 - precision: 0.6398 - val_loss: 1.1004 - val_precision: 0.5853\n",
      "Epoch 30/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8384 - precision: 0.6396\n",
      "Epoch 30: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8356 - precision: 0.6407 - val_loss: 1.0941 - val_precision: 0.5864\n",
      "Epoch 31/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8262 - precision: 0.6417\n",
      "Epoch 31: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8251 - precision: 0.6411 - val_loss: 1.1100 - val_precision: 0.5827\n",
      "Epoch 32/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8255 - precision: 0.6513\n",
      "Epoch 32: val_loss did not improve from 1.08918\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8250 - precision: 0.6509 - val_loss: 1.1079 - val_precision: 0.5836\n",
      "Epoch 32: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9374 - precision: 0.6419\n",
      "Combinación 0 = (True, True, True, 8, 0.1) \n",
      " precision train: [0.9374444484710693, 0.6418855786323547]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 2: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.5825 - precision: 0.5517   \n",
      "Epoch 1: val_loss improved from inf to 1.42737, saving model to model_2.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.5717 - precision: 0.6567 - val_loss: 1.4274 - val_precision: 0.7596\n",
      "Epoch 2/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.3964 - precision: 0.5753\n",
      "Epoch 2: val_loss improved from 1.42737 to 1.34132, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3952 - precision: 0.5787 - val_loss: 1.3413 - val_precision: 0.7427\n",
      "Epoch 3/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.3438 - precision: 0.6176\n",
      "Epoch 3: val_loss improved from 1.34132 to 1.29942, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3431 - precision: 0.6169 - val_loss: 1.2994 - val_precision: 0.7218\n",
      "Epoch 4/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.3020 - precision: 0.6577\n",
      "Epoch 4: val_loss improved from 1.29942 to 1.25789, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2993 - precision: 0.6617 - val_loss: 1.2579 - val_precision: 0.7150\n",
      "Epoch 5/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.2551 - precision: 0.6964\n",
      "Epoch 5: val_loss improved from 1.25789 to 1.23335, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2548 - precision: 0.6952 - val_loss: 1.2333 - val_precision: 0.6776\n",
      "Epoch 6/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.2200 - precision: 0.6942\n",
      "Epoch 6: val_loss improved from 1.23335 to 1.20989, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2239 - precision: 0.6909 - val_loss: 1.2099 - val_precision: 0.7016\n",
      "Epoch 7/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.2069 - precision: 0.7038\n",
      "Epoch 7: val_loss improved from 1.20989 to 1.19506, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2071 - precision: 0.7004 - val_loss: 1.1951 - val_precision: 0.7146\n",
      "Epoch 8/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1864 - precision: 0.7007\n",
      "Epoch 8: val_loss improved from 1.19506 to 1.19203, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1829 - precision: 0.7029 - val_loss: 1.1920 - val_precision: 0.6940\n",
      "Epoch 9/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1760 - precision: 0.7095\n",
      "Epoch 9: val_loss improved from 1.19203 to 1.18013, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1740 - precision: 0.7085 - val_loss: 1.1801 - val_precision: 0.6926\n",
      "Epoch 10/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1651 - precision: 0.7066\n",
      "Epoch 10: val_loss did not improve from 1.18013\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1651 - precision: 0.7066 - val_loss: 1.1804 - val_precision: 0.6848\n",
      "Epoch 11/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1447 - precision: 0.7006\n",
      "Epoch 11: val_loss improved from 1.18013 to 1.17862, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1451 - precision: 0.7007 - val_loss: 1.1786 - val_precision: 0.6883\n",
      "Epoch 12/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1505 - precision: 0.6946\n",
      "Epoch 12: val_loss improved from 1.17862 to 1.17394, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1497 - precision: 0.6978 - val_loss: 1.1739 - val_precision: 0.6917\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1354 - precision: 0.7087\n",
      "Epoch 13: val_loss improved from 1.17394 to 1.16575, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1369 - precision: 0.7054 - val_loss: 1.1657 - val_precision: 0.6888\n",
      "Epoch 14/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1332 - precision: 0.6925\n",
      "Epoch 14: val_loss improved from 1.16575 to 1.16529, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1318 - precision: 0.6922 - val_loss: 1.1653 - val_precision: 0.6827\n",
      "Epoch 15/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1278 - precision: 0.6899\n",
      "Epoch 15: val_loss did not improve from 1.16529\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1240 - precision: 0.6910 - val_loss: 1.1705 - val_precision: 0.6760\n",
      "Epoch 16/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1169 - precision: 0.6940\n",
      "Epoch 16: val_loss did not improve from 1.16529\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1143 - precision: 0.6954 - val_loss: 1.1771 - val_precision: 0.6848\n",
      "Epoch 17/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1119 - precision: 0.6898\n",
      "Epoch 17: val_loss did not improve from 1.16529\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1116 - precision: 0.6899 - val_loss: 1.1699 - val_precision: 0.6871\n",
      "Epoch 18/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1006 - precision: 0.6726\n",
      "Epoch 18: val_loss did not improve from 1.16529\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0991 - precision: 0.6741 - val_loss: 1.1767 - val_precision: 0.6781\n",
      "Epoch 19/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0907 - precision: 0.6525\n",
      "Epoch 19: val_loss did not improve from 1.16529\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0901 - precision: 0.6502 - val_loss: 1.1765 - val_precision: 0.6513\n",
      "Epoch 20/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.0845 - precision: 0.6359\n",
      "Epoch 20: val_loss did not improve from 1.16529\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0845 - precision: 0.6351 - val_loss: 1.1658 - val_precision: 0.6340\n",
      "Epoch 21/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.0789 - precision: 0.6309\n",
      "Epoch 21: val_loss improved from 1.16529 to 1.16444, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0768 - precision: 0.6336 - val_loss: 1.1644 - val_precision: 0.6291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0759 - precision: 0.6206\n",
      "Epoch 22: val_loss improved from 1.16444 to 1.16336, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0762 - precision: 0.6198 - val_loss: 1.1634 - val_precision: 0.6152\n",
      "Epoch 23/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0733 - precision: 0.6196\n",
      "Epoch 23: val_loss did not improve from 1.16336\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0732 - precision: 0.6195 - val_loss: 1.1792 - val_precision: 0.5913\n",
      "Epoch 24/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.0647 - precision: 0.6186\n",
      "Epoch 24: val_loss improved from 1.16336 to 1.15992, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0627 - precision: 0.6210 - val_loss: 1.1599 - val_precision: 0.5784\n",
      "Epoch 25/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0475 - precision: 0.6136\n",
      "Epoch 25: val_loss did not improve from 1.15992\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0484 - precision: 0.6130 - val_loss: 1.1599 - val_precision: 0.5787\n",
      "Epoch 26/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.0442 - precision: 0.6015\n",
      "Epoch 26: val_loss did not improve from 1.15992\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0450 - precision: 0.6021 - val_loss: 1.1674 - val_precision: 0.5813\n",
      "Epoch 27/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0416 - precision: 0.6023\n",
      "Epoch 27: val_loss improved from 1.15992 to 1.15356, saving model to model_2.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0434 - precision: 0.6018 - val_loss: 1.1536 - val_precision: 0.5746\n",
      "Epoch 28/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0370 - precision: 0.6070\n",
      "Epoch 28: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0370 - precision: 0.6070 - val_loss: 1.1603 - val_precision: 0.5718\n",
      "Epoch 29/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0352 - precision: 0.6044\n",
      "Epoch 29: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0352 - precision: 0.6044 - val_loss: 1.1582 - val_precision: 0.5792\n",
      "Epoch 30/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0431 - precision: 0.5965\n",
      "Epoch 30: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0382 - precision: 0.5980 - val_loss: 1.1617 - val_precision: 0.5697\n",
      "Epoch 31/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0335 - precision: 0.6002\n",
      "Epoch 31: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0315 - precision: 0.6014 - val_loss: 1.1650 - val_precision: 0.5716\n",
      "Epoch 32/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.0158 - precision: 0.6051\n",
      "Epoch 32: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0185 - precision: 0.6067 - val_loss: 1.1623 - val_precision: 0.5674\n",
      "Epoch 33/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0128 - precision: 0.6042\n",
      "Epoch 33: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0125 - precision: 0.6046 - val_loss: 1.1580 - val_precision: 0.5658\n",
      "Epoch 34/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0089 - precision: 0.6054\n",
      "Epoch 34: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0072 - precision: 0.6052 - val_loss: 1.1581 - val_precision: 0.5632\n",
      "Epoch 35/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0038 - precision: 0.5976\n",
      "Epoch 35: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0083 - precision: 0.5960 - val_loss: 1.1732 - val_precision: 0.5631\n",
      "Epoch 36/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0093 - precision: 0.6009\n",
      "Epoch 36: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0103 - precision: 0.5999 - val_loss: 1.1675 - val_precision: 0.5536\n",
      "Epoch 37/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.0082 - precision: 0.5997\n",
      "Epoch 37: val_loss did not improve from 1.15356\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0059 - precision: 0.6008 - val_loss: 1.1664 - val_precision: 0.5606\n",
      "Epoch 37: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.0189 - precision: 0.6075\n",
      "Combinación 1 = (True, True, True, 8, 0.25) \n",
      " precision train: [1.0189048051834106, 0.6074591875076294]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 3: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.6086 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.59108, saving model to model_3.h5\n",
      "240/240 [==============================] - 6s 10ms/step - loss: 1.6053 - precision: 0.0000e+00 - val_loss: 1.5911 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.4894 - precision: 0.5796\n",
      "Epoch 2: val_loss improved from 1.59108 to 1.33603, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.4868 - precision: 0.5848 - val_loss: 1.3360 - val_precision: 0.6202\n",
      "Epoch 3/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.3938 - precision: 0.5183\n",
      "Epoch 3: val_loss improved from 1.33603 to 1.31847, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 1.3925 - precision: 0.5176 - val_loss: 1.3185 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.3499 - precision: 0.4923\n",
      "Epoch 4: val_loss improved from 1.31847 to 1.31716, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3515 - precision: 0.4914 - val_loss: 1.3172 - val_precision: 0.0000e+00\n",
      "Epoch 5/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.3391 - precision: 0.4964\n",
      "Epoch 5: val_loss did not improve from 1.31716\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.3380 - precision: 0.4971 - val_loss: 1.3175 - val_precision: 0.0000e+00\n",
      "Epoch 6/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.3372 - precision: 0.4974\n",
      "Epoch 6: val_loss improved from 1.31716 to 1.31029, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.3361 - precision: 0.4987 - val_loss: 1.3103 - val_precision: 0.0000e+00\n",
      "Epoch 7/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.3259 - precision: 0.5125\n",
      "Epoch 7: val_loss improved from 1.31029 to 1.29594, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.3255 - precision: 0.5129 - val_loss: 1.2959 - val_precision: 0.0000e+00\n",
      "Epoch 8/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.3066 - precision: 0.5449\n",
      "Epoch 8: val_loss improved from 1.29594 to 1.29366, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3066 - precision: 0.5449 - val_loss: 1.2937 - val_precision: 0.0000e+00\n",
      "Epoch 9/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.3043 - precision: 0.5299\n",
      "Epoch 9: val_loss did not improve from 1.29366\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3042 - precision: 0.5270 - val_loss: 1.3041 - val_precision: 0.0000e+00\n",
      "Epoch 10/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.2964 - precision: 0.5351\n",
      "Epoch 10: val_loss improved from 1.29366 to 1.27722, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2974 - precision: 0.5331 - val_loss: 1.2772 - val_precision: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.2882 - precision: 0.5747\n",
      "Epoch 11: val_loss improved from 1.27722 to 1.25793, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2898 - precision: 0.5737 - val_loss: 1.2579 - val_precision: 0.7565\n",
      "Epoch 12/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.2698 - precision: 0.5989\n",
      "Epoch 12: val_loss did not improve from 1.25793\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2694 - precision: 0.5978 - val_loss: 1.2597 - val_precision: 0.7344\n",
      "Epoch 13/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.2798 - precision: 0.5699\n",
      "Epoch 13: val_loss improved from 1.25793 to 1.25497, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2778 - precision: 0.5697 - val_loss: 1.2550 - val_precision: 0.7280\n",
      "Epoch 14/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2695 - precision: 0.6053\n",
      "Epoch 14: val_loss improved from 1.25497 to 1.25479, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2683 - precision: 0.6032 - val_loss: 1.2548 - val_precision: 0.7168\n",
      "Epoch 15/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.2724 - precision: 0.5968\n",
      "Epoch 15: val_loss improved from 1.25479 to 1.23838, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2712 - precision: 0.5972 - val_loss: 1.2384 - val_precision: 0.7329\n",
      "Epoch 16/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2448 - precision: 0.5933\n",
      "Epoch 16: val_loss improved from 1.23838 to 1.23012, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2477 - precision: 0.5939 - val_loss: 1.2301 - val_precision: 0.7254\n",
      "Epoch 17/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.2517 - precision: 0.5695\n",
      "Epoch 17: val_loss improved from 1.23012 to 1.22755, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2515 - precision: 0.5711 - val_loss: 1.2276 - val_precision: 0.7222\n",
      "Epoch 18/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.2408 - precision: 0.5944\n",
      "Epoch 18: val_loss improved from 1.22755 to 1.22307, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2407 - precision: 0.5955 - val_loss: 1.2231 - val_precision: 0.7288\n",
      "Epoch 19/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.2373 - precision: 0.5644\n",
      "Epoch 19: val_loss improved from 1.22307 to 1.21737, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2366 - precision: 0.5655 - val_loss: 1.2174 - val_precision: 0.7223\n",
      "Epoch 20/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2278 - precision: 0.5805\n",
      "Epoch 20: val_loss improved from 1.21737 to 1.21033, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2272 - precision: 0.5792 - val_loss: 1.2103 - val_precision: 0.7115\n",
      "Epoch 21/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.2196 - precision: 0.5822\n",
      "Epoch 21: val_loss did not improve from 1.21033\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2212 - precision: 0.5833 - val_loss: 1.2134 - val_precision: 0.6858\n",
      "Epoch 22/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.2131 - precision: 0.5809\n",
      "Epoch 22: val_loss improved from 1.21033 to 1.20341, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2136 - precision: 0.5804 - val_loss: 1.2034 - val_precision: 0.6886\n",
      "Epoch 23/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2224 - precision: 0.5645\n",
      "Epoch 23: val_loss improved from 1.20341 to 1.19447, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2208 - precision: 0.5651 - val_loss: 1.1945 - val_precision: 0.6585\n",
      "Epoch 24/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.2030 - precision: 0.5709\n",
      "Epoch 24: val_loss improved from 1.19447 to 1.19316, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2035 - precision: 0.5701 - val_loss: 1.1932 - val_precision: 0.6362\n",
      "Epoch 25/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.2100 - precision: 0.5646\n",
      "Epoch 25: val_loss improved from 1.19316 to 1.18839, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2123 - precision: 0.5641 - val_loss: 1.1884 - val_precision: 0.6582\n",
      "Epoch 26/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.2009 - precision: 0.5738\n",
      "Epoch 26: val_loss did not improve from 1.18839\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2005 - precision: 0.5735 - val_loss: 1.1904 - val_precision: 0.6466\n",
      "Epoch 27/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.2106 - precision: 0.5723\n",
      "Epoch 27: val_loss did not improve from 1.18839\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2097 - precision: 0.5727 - val_loss: 1.1946 - val_precision: 0.6428\n",
      "Epoch 28/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.2089 - precision: 0.5760\n",
      "Epoch 28: val_loss did not improve from 1.18839\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2071 - precision: 0.5771 - val_loss: 1.1889 - val_precision: 0.6442\n",
      "Epoch 29/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1994 - precision: 0.5657\n",
      "Epoch 29: val_loss improved from 1.18839 to 1.18692, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1977 - precision: 0.5652 - val_loss: 1.1869 - val_precision: 0.6457\n",
      "Epoch 30/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1921 - precision: 0.5713\n",
      "Epoch 30: val_loss improved from 1.18692 to 1.17568, saving model to model_3.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1933 - precision: 0.5700 - val_loss: 1.1757 - val_precision: 0.6714\n",
      "Epoch 31/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1880 - precision: 0.5880\n",
      "Epoch 31: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1880 - precision: 0.5880 - val_loss: 1.1847 - val_precision: 0.6208\n",
      "Epoch 32/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.2011 - precision: 0.5641\n",
      "Epoch 32: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2011 - precision: 0.5641 - val_loss: 1.1867 - val_precision: 0.6118\n",
      "Epoch 33/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1907 - precision: 0.5670\n",
      "Epoch 33: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1875 - precision: 0.5658 - val_loss: 1.1880 - val_precision: 0.6264\n",
      "Epoch 34/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1865 - precision: 0.5748\n",
      "Epoch 34: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1892 - precision: 0.5749 - val_loss: 1.1845 - val_precision: 0.6325\n",
      "Epoch 35/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.1898 - precision: 0.5714\n",
      "Epoch 35: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1899 - precision: 0.5705 - val_loss: 1.1856 - val_precision: 0.6373\n",
      "Epoch 36/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1826 - precision: 0.5863\n",
      "Epoch 36: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1833 - precision: 0.5861 - val_loss: 1.1922 - val_precision: 0.6670\n",
      "Epoch 37/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1920 - precision: 0.5777\n",
      "Epoch 37: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1920 - precision: 0.5777 - val_loss: 1.1805 - val_precision: 0.6552\n",
      "Epoch 38/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1836 - precision: 0.5924\n",
      "Epoch 38: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1831 - precision: 0.5923 - val_loss: 1.1800 - val_precision: 0.6060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.1931 - precision: 0.5652\n",
      "Epoch 39: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1920 - precision: 0.5667 - val_loss: 1.1800 - val_precision: 0.6220\n",
      "Epoch 40/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1547 - precision: 0.5934\n",
      "Epoch 40: val_loss did not improve from 1.17568\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1554 - precision: 0.5926 - val_loss: 1.1886 - val_precision: 0.6238\n",
      "Epoch 40: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.1228 - precision: 0.6473\n",
      "Combinación 2 = (True, True, True, 8, 0.5) \n",
      " precision train: [1.1228073835372925, 0.6473127603530884]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 4: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.4764 - precision: 0.5849\n",
      "Epoch 1: val_loss improved from inf to 1.27056, saving model to model_4.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.4725 - precision: 0.6000 - val_loss: 1.2706 - val_precision: 0.6867\n",
      "Epoch 2/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1364 - precision: 0.5834\n",
      "Epoch 2: val_loss improved from 1.27056 to 1.21193, saving model to model_4.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1371 - precision: 0.5828 - val_loss: 1.2119 - val_precision: 0.5578\n",
      "Epoch 3/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0871 - precision: 0.5888\n",
      "Epoch 3: val_loss improved from 1.21193 to 1.16816, saving model to model_4.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0874 - precision: 0.5873 - val_loss: 1.1682 - val_precision: 0.5529\n",
      "Epoch 4/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0401 - precision: 0.5987\n",
      "Epoch 4: val_loss improved from 1.16816 to 1.11588, saving model to model_4.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0408 - precision: 0.5971 - val_loss: 1.1159 - val_precision: 0.6249\n",
      "Epoch 5/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9755 - precision: 0.6107\n",
      "Epoch 5: val_loss improved from 1.11588 to 1.06402, saving model to model_4.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9752 - precision: 0.6096 - val_loss: 1.0640 - val_precision: 0.6175\n",
      "Epoch 6/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9171 - precision: 0.6198\n",
      "Epoch 6: val_loss improved from 1.06402 to 1.03161, saving model to model_4.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9166 - precision: 0.6212 - val_loss: 1.0316 - val_precision: 0.6205\n",
      "Epoch 7/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9007 - precision: 0.6234\n",
      "Epoch 7: val_loss did not improve from 1.03161\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9038 - precision: 0.6240 - val_loss: 1.0468 - val_precision: 0.6098\n",
      "Epoch 8/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8753 - precision: 0.6364\n",
      "Epoch 8: val_loss did not improve from 1.03161\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8756 - precision: 0.6372 - val_loss: 1.0391 - val_precision: 0.6103\n",
      "Epoch 9/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8504 - precision: 0.6457\n",
      "Epoch 9: val_loss improved from 1.03161 to 1.01188, saving model to model_4.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8496 - precision: 0.6451 - val_loss: 1.0119 - val_precision: 0.6347\n",
      "Epoch 10/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8459 - precision: 0.6533\n",
      "Epoch 10: val_loss did not improve from 1.01188\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8433 - precision: 0.6536 - val_loss: 1.0323 - val_precision: 0.6175\n",
      "Epoch 11/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8257 - precision: 0.6532\n",
      "Epoch 11: val_loss improved from 1.01188 to 0.99999, saving model to model_4.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8294 - precision: 0.6525 - val_loss: 1.0000 - val_precision: 0.6406\n",
      "Epoch 12/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8103 - precision: 0.6629\n",
      "Epoch 12: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8112 - precision: 0.6616 - val_loss: 1.0329 - val_precision: 0.6263\n",
      "Epoch 13/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8137 - precision: 0.6602\n",
      "Epoch 13: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8137 - precision: 0.6602 - val_loss: 1.0153 - val_precision: 0.6337\n",
      "Epoch 14/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7990 - precision: 0.6646\n",
      "Epoch 14: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8003 - precision: 0.6650 - val_loss: 1.0553 - val_precision: 0.6198\n",
      "Epoch 15/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7858 - precision: 0.6756\n",
      "Epoch 15: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7861 - precision: 0.6739 - val_loss: 1.0268 - val_precision: 0.6299\n",
      "Epoch 16/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7790 - precision: 0.6765\n",
      "Epoch 16: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7780 - precision: 0.6766 - val_loss: 1.0406 - val_precision: 0.6172\n",
      "Epoch 17/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7649 - precision: 0.6786\n",
      "Epoch 17: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7617 - precision: 0.6793 - val_loss: 1.0477 - val_precision: 0.6155\n",
      "Epoch 18/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7507 - precision: 0.6862\n",
      "Epoch 18: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7542 - precision: 0.6857 - val_loss: 1.0377 - val_precision: 0.6180\n",
      "Epoch 19/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7453 - precision: 0.6821\n",
      "Epoch 19: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7466 - precision: 0.6810 - val_loss: 1.0800 - val_precision: 0.6042\n",
      "Epoch 20/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7355 - precision: 0.6875\n",
      "Epoch 20: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7367 - precision: 0.6864 - val_loss: 1.0695 - val_precision: 0.6089\n",
      "Epoch 21/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7311 - precision: 0.6892\n",
      "Epoch 21: val_loss did not improve from 0.99999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7323 - precision: 0.6885 - val_loss: 1.0832 - val_precision: 0.6048\n",
      "Epoch 21: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8610 - precision: 0.6820\n",
      "Combinación 3 = (True, True, True, 16, 0.1) \n",
      " precision train: [0.8610241413116455, 0.6819767355918884]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 5: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.5509 - precision: 0.7527  \n",
      "Epoch 1: val_loss improved from inf to 1.28496, saving model to model_5.h5\n",
      "240/240 [==============================] - 6s 10ms/step - loss: 1.5439 - precision: 0.7477 - val_loss: 1.2850 - val_precision: 0.7041\n",
      "Epoch 2/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.2495 - precision: 0.6166\n",
      "Epoch 2: val_loss improved from 1.28496 to 1.24104, saving model to model_5.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.2505 - precision: 0.6121 - val_loss: 1.2410 - val_precision: 0.5524\n",
      "Epoch 3/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1678 - precision: 0.6148\n",
      "Epoch 3: val_loss improved from 1.24104 to 1.18780, saving model to model_5.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1670 - precision: 0.6151 - val_loss: 1.1878 - val_precision: 0.5740\n",
      "Epoch 4/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1217 - precision: 0.6134\n",
      "Epoch 4: val_loss improved from 1.18780 to 1.11401, saving model to model_5.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1188 - precision: 0.6136 - val_loss: 1.1140 - val_precision: 0.6415\n",
      "Epoch 5/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0387 - precision: 0.6164\n",
      "Epoch 5: val_loss improved from 1.11401 to 1.06851, saving model to model_5.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0390 - precision: 0.6161 - val_loss: 1.0685 - val_precision: 0.6123\n",
      "Epoch 6/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9857 - precision: 0.6122\n",
      "Epoch 6: val_loss improved from 1.06851 to 1.06161, saving model to model_5.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9838 - precision: 0.6122 - val_loss: 1.0616 - val_precision: 0.6093\n",
      "Epoch 7/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9576 - precision: 0.6160\n",
      "Epoch 7: val_loss improved from 1.06161 to 1.05449, saving model to model_5.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9556 - precision: 0.6162 - val_loss: 1.0545 - val_precision: 0.6107\n",
      "Epoch 8/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9338 - precision: 0.6229\n",
      "Epoch 8: val_loss improved from 1.05449 to 1.04317, saving model to model_5.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9333 - precision: 0.6226 - val_loss: 1.0432 - val_precision: 0.6129\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9220 - precision: 0.6223\n",
      "Epoch 9: val_loss improved from 1.04317 to 1.03557, saving model to model_5.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9231 - precision: 0.6232 - val_loss: 1.0356 - val_precision: 0.6120\n",
      "Epoch 10/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9146 - precision: 0.6270\n",
      "Epoch 10: val_loss improved from 1.03557 to 1.01834, saving model to model_5.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9142 - precision: 0.6275 - val_loss: 1.0183 - val_precision: 0.6312\n",
      "Epoch 11/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9028 - precision: 0.6327\n",
      "Epoch 11: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9037 - precision: 0.6326 - val_loss: 1.0444 - val_precision: 0.6100\n",
      "Epoch 12/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8809 - precision: 0.6414\n",
      "Epoch 12: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8819 - precision: 0.6410 - val_loss: 1.0218 - val_precision: 0.6200\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8826 - precision: 0.6409\n",
      "Epoch 13: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8822 - precision: 0.6408 - val_loss: 1.0257 - val_precision: 0.6139\n",
      "Epoch 14/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8757 - precision: 0.6445\n",
      "Epoch 14: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8762 - precision: 0.6450 - val_loss: 1.0474 - val_precision: 0.6112\n",
      "Epoch 15/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8718 - precision: 0.6364\n",
      "Epoch 15: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8718 - precision: 0.6364 - val_loss: 1.0462 - val_precision: 0.6052\n",
      "Epoch 16/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8396 - precision: 0.6479\n",
      "Epoch 16: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8422 - precision: 0.6469 - val_loss: 1.0373 - val_precision: 0.6124\n",
      "Epoch 17/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8580 - precision: 0.6439\n",
      "Epoch 17: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8573 - precision: 0.6453 - val_loss: 1.0451 - val_precision: 0.6092\n",
      "Epoch 18/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8441 - precision: 0.6499\n",
      "Epoch 18: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8443 - precision: 0.6484 - val_loss: 1.0540 - val_precision: 0.6081\n",
      "Epoch 19/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8317 - precision: 0.6503\n",
      "Epoch 19: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8314 - precision: 0.6523 - val_loss: 1.0471 - val_precision: 0.6091\n",
      "Epoch 20/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8307 - precision: 0.6510\n",
      "Epoch 20: val_loss did not improve from 1.01834\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8250 - precision: 0.6503 - val_loss: 1.0630 - val_precision: 0.5983\n",
      "Epoch 20: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9314 - precision: 0.6422\n",
      "Combinación 4 = (True, True, True, 16, 0.25) \n",
      " precision train: [0.9313554167747498, 0.6422265768051147]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 6: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.6007 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.49047, saving model to model_6.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.5996 - precision: 0.0000e+00 - val_loss: 1.4905 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.4151 - precision: 0.5478\n",
      "Epoch 2: val_loss improved from 1.49047 to 1.33600, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.4141 - precision: 0.5468 - val_loss: 1.3360 - val_precision: 0.6563\n",
      "Epoch 3/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.3521 - precision: 0.5876\n",
      "Epoch 3: val_loss improved from 1.33600 to 1.27883, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3497 - precision: 0.5882 - val_loss: 1.2788 - val_precision: 0.7014\n",
      "Epoch 4/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.3187 - precision: 0.6369\n",
      "Epoch 4: val_loss improved from 1.27883 to 1.24061, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3148 - precision: 0.6378 - val_loss: 1.2406 - val_precision: 0.6950\n",
      "Epoch 5/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2748 - precision: 0.6753\n",
      "Epoch 5: val_loss improved from 1.24061 to 1.22020, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2787 - precision: 0.6733 - val_loss: 1.2202 - val_precision: 0.7282\n",
      "Epoch 6/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2500 - precision: 0.6860\n",
      "Epoch 6: val_loss improved from 1.22020 to 1.20250, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2502 - precision: 0.6851 - val_loss: 1.2025 - val_precision: 0.7003\n",
      "Epoch 7/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2380 - precision: 0.6927\n",
      "Epoch 7: val_loss improved from 1.20250 to 1.17938, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2356 - precision: 0.6930 - val_loss: 1.1794 - val_precision: 0.6980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.2178 - precision: 0.6927\n",
      "Epoch 8: val_loss improved from 1.17938 to 1.17068, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.2194 - precision: 0.6930 - val_loss: 1.1707 - val_precision: 0.6918\n",
      "Epoch 9/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.2158 - precision: 0.6917\n",
      "Epoch 9: val_loss improved from 1.17068 to 1.16659, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2165 - precision: 0.6910 - val_loss: 1.1666 - val_precision: 0.7046\n",
      "Epoch 10/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2079 - precision: 0.6884\n",
      "Epoch 10: val_loss did not improve from 1.16659\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2062 - precision: 0.6920 - val_loss: 1.1666 - val_precision: 0.6954\n",
      "Epoch 11/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1950 - precision: 0.6973\n",
      "Epoch 11: val_loss improved from 1.16659 to 1.16389, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1950 - precision: 0.6973 - val_loss: 1.1639 - val_precision: 0.6879\n",
      "Epoch 12/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1814 - precision: 0.6992\n",
      "Epoch 12: val_loss improved from 1.16389 to 1.16190, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1829 - precision: 0.7007 - val_loss: 1.1619 - val_precision: 0.6900\n",
      "Epoch 13/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1729 - precision: 0.6938\n",
      "Epoch 13: val_loss improved from 1.16190 to 1.15093, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1737 - precision: 0.6933 - val_loss: 1.1509 - val_precision: 0.6779\n",
      "Epoch 14/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1773 - precision: 0.6909\n",
      "Epoch 14: val_loss did not improve from 1.15093\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1754 - precision: 0.6900 - val_loss: 1.1542 - val_precision: 0.6777\n",
      "Epoch 15/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1659 - precision: 0.6872\n",
      "Epoch 15: val_loss did not improve from 1.15093\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1670 - precision: 0.6868 - val_loss: 1.1527 - val_precision: 0.6932\n",
      "Epoch 16/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.1492 - precision: 0.6840\n",
      "Epoch 16: val_loss improved from 1.15093 to 1.15066, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1486 - precision: 0.6845 - val_loss: 1.1507 - val_precision: 0.6865\n",
      "Epoch 17/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1436 - precision: 0.6834\n",
      "Epoch 17: val_loss improved from 1.15066 to 1.14980, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1438 - precision: 0.6831 - val_loss: 1.1498 - val_precision: 0.6733\n",
      "Epoch 18/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1363 - precision: 0.6575\n",
      "Epoch 18: val_loss improved from 1.14980 to 1.14891, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1363 - precision: 0.6575 - val_loss: 1.1489 - val_precision: 0.6806\n",
      "Epoch 19/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1316 - precision: 0.6519\n",
      "Epoch 19: val_loss improved from 1.14891 to 1.14692, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1327 - precision: 0.6513 - val_loss: 1.1469 - val_precision: 0.6936\n",
      "Epoch 20/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1339 - precision: 0.6498\n",
      "Epoch 20: val_loss did not improve from 1.14692\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1328 - precision: 0.6489 - val_loss: 1.1574 - val_precision: 0.6727\n",
      "Epoch 21/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1346 - precision: 0.6289\n",
      "Epoch 21: val_loss improved from 1.14692 to 1.13635, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1336 - precision: 0.6279 - val_loss: 1.1364 - val_precision: 0.6529\n",
      "Epoch 22/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1102 - precision: 0.6362\n",
      "Epoch 22: val_loss improved from 1.13635 to 1.12988, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1106 - precision: 0.6368 - val_loss: 1.1299 - val_precision: 0.6362\n",
      "Epoch 23/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1095 - precision: 0.6176\n",
      "Epoch 23: val_loss improved from 1.12988 to 1.12596, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1103 - precision: 0.6168 - val_loss: 1.1260 - val_precision: 0.6225\n",
      "Epoch 24/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0956 - precision: 0.6123\n",
      "Epoch 24: val_loss improved from 1.12596 to 1.12446, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0959 - precision: 0.6126 - val_loss: 1.1245 - val_precision: 0.6155\n",
      "Epoch 25/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.0984 - precision: 0.6226\n",
      "Epoch 25: val_loss improved from 1.12446 to 1.11968, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0996 - precision: 0.6206 - val_loss: 1.1197 - val_precision: 0.6032\n",
      "Epoch 26/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0862 - precision: 0.6166\n",
      "Epoch 26: val_loss did not improve from 1.11968\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0832 - precision: 0.6174 - val_loss: 1.1198 - val_precision: 0.6020\n",
      "Epoch 27/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0771 - precision: 0.6086\n",
      "Epoch 27: val_loss improved from 1.11968 to 1.11273, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0763 - precision: 0.6083 - val_loss: 1.1127 - val_precision: 0.6011\n",
      "Epoch 28/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.0747 - precision: 0.6048\n",
      "Epoch 28: val_loss did not improve from 1.11273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0760 - precision: 0.6048 - val_loss: 1.1139 - val_precision: 0.5994\n",
      "Epoch 29/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0762 - precision: 0.6118\n",
      "Epoch 29: val_loss improved from 1.11273 to 1.11248, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0752 - precision: 0.6104 - val_loss: 1.1125 - val_precision: 0.6012\n",
      "Epoch 30/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0551 - precision: 0.6062\n",
      "Epoch 30: val_loss improved from 1.11248 to 1.10527, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0548 - precision: 0.6067 - val_loss: 1.1053 - val_precision: 0.5964\n",
      "Epoch 31/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.0483 - precision: 0.6132\n",
      "Epoch 31: val_loss did not improve from 1.10527\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0472 - precision: 0.6142 - val_loss: 1.1061 - val_precision: 0.5979\n",
      "Epoch 32/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0538 - precision: 0.6132\n",
      "Epoch 32: val_loss improved from 1.10527 to 1.10470, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0556 - precision: 0.6120 - val_loss: 1.1047 - val_precision: 0.5974\n",
      "Epoch 33/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0387 - precision: 0.6159\n",
      "Epoch 33: val_loss did not improve from 1.10470\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0430 - precision: 0.6138 - val_loss: 1.1172 - val_precision: 0.5848\n",
      "Epoch 34/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0380 - precision: 0.6126\n",
      "Epoch 34: val_loss did not improve from 1.10470\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0395 - precision: 0.6110 - val_loss: 1.1106 - val_precision: 0.5899\n",
      "Epoch 35/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.0335 - precision: 0.6197\n",
      "Epoch 35: val_loss did not improve from 1.10470\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0320 - precision: 0.6206 - val_loss: 1.1296 - val_precision: 0.5930\n",
      "Epoch 36/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.0297 - precision: 0.6131\n",
      "Epoch 36: val_loss did not improve from 1.10470\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0310 - precision: 0.6119 - val_loss: 1.1081 - val_precision: 0.5901\n",
      "Epoch 37/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.0197 - precision: 0.6155\n",
      "Epoch 37: val_loss did not improve from 1.10470\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0208 - precision: 0.6154 - val_loss: 1.1055 - val_precision: 0.5969\n",
      "Epoch 38/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.0285 - precision: 0.6099\n",
      "Epoch 38: val_loss improved from 1.10470 to 1.09606, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0254 - precision: 0.6126 - val_loss: 1.0961 - val_precision: 0.5929\n",
      "Epoch 39/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.0176 - precision: 0.6189\n",
      "Epoch 39: val_loss did not improve from 1.09606\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0187 - precision: 0.6188 - val_loss: 1.1053 - val_precision: 0.5972\n",
      "Epoch 40/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.0260 - precision: 0.6150\n",
      "Epoch 40: val_loss did not improve from 1.09606\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0254 - precision: 0.6169 - val_loss: 1.1093 - val_precision: 0.5922\n",
      "Epoch 41/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0123 - precision: 0.6154\n",
      "Epoch 41: val_loss did not improve from 1.09606\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0118 - precision: 0.6151 - val_loss: 1.1019 - val_precision: 0.5960\n",
      "Epoch 42/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0014 - precision: 0.6194\n",
      "Epoch 42: val_loss did not improve from 1.09606\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0009 - precision: 0.6195 - val_loss: 1.1110 - val_precision: 0.5881\n",
      "Epoch 43/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0038 - precision: 0.6269\n",
      "Epoch 43: val_loss improved from 1.09606 to 1.09398, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0051 - precision: 0.6269 - val_loss: 1.0940 - val_precision: 0.5889\n",
      "Epoch 44/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.0109 - precision: 0.6154\n",
      "Epoch 44: val_loss did not improve from 1.09398\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0146 - precision: 0.6149 - val_loss: 1.0967 - val_precision: 0.5873\n",
      "Epoch 45/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.0014 - precision: 0.6220\n",
      "Epoch 45: val_loss did not improve from 1.09398\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0021 - precision: 0.6219 - val_loss: 1.0946 - val_precision: 0.5900\n",
      "Epoch 46/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9952 - precision: 0.6180\n",
      "Epoch 46: val_loss improved from 1.09398 to 1.08786, saving model to model_6.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9994 - precision: 0.6165 - val_loss: 1.0879 - val_precision: 0.5924\n",
      "Epoch 47/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9935 - precision: 0.6123\n",
      "Epoch 47: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9939 - precision: 0.6146 - val_loss: 1.0969 - val_precision: 0.5905\n",
      "Epoch 48/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9833 - precision: 0.6250\n",
      "Epoch 48: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9882 - precision: 0.6234 - val_loss: 1.0927 - val_precision: 0.5856\n",
      "Epoch 49/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9885 - precision: 0.6245\n",
      "Epoch 49: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9897 - precision: 0.6235 - val_loss: 1.0954 - val_precision: 0.5897\n",
      "Epoch 50/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9930 - precision: 0.6173\n",
      "Epoch 50: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9943 - precision: 0.6172 - val_loss: 1.1138 - val_precision: 0.5843\n",
      "Epoch 51/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0045 - precision: 0.6152\n",
      "Epoch 51: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0055 - precision: 0.6147 - val_loss: 1.0910 - val_precision: 0.5924\n",
      "Epoch 52/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9800 - precision: 0.6248\n",
      "Epoch 52: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9800 - precision: 0.6247 - val_loss: 1.0924 - val_precision: 0.5928\n",
      "Epoch 53/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0025 - precision: 0.6148\n",
      "Epoch 53: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0030 - precision: 0.6146 - val_loss: 1.0978 - val_precision: 0.5877\n",
      "Epoch 54/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9801 - precision: 0.6228\n",
      "Epoch 54: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9780 - precision: 0.6230 - val_loss: 1.1048 - val_precision: 0.5890\n",
      "Epoch 55/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0032 - precision: 0.6136\n",
      "Epoch 55: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9987 - precision: 0.6145 - val_loss: 1.0965 - val_precision: 0.5881\n",
      "Epoch 56/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9855 - precision: 0.6259\n",
      "Epoch 56: val_loss did not improve from 1.08786\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9858 - precision: 0.6254 - val_loss: 1.0972 - val_precision: 0.5932\n",
      "Epoch 56: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9782 - precision: 0.6275\n",
      "Combinación 5 = (True, True, True, 16, 0.5) \n",
      " precision train: [0.9782128930091858, 0.6274622678756714]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 7: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.4718 - precision: 0.6947\n",
      "Epoch 1: val_loss improved from inf to 1.32715, saving model to model_7.h5\n",
      "240/240 [==============================] - 6s 9ms/step - loss: 1.4665 - precision: 0.6944 - val_loss: 1.3271 - val_precision: 0.6848\n",
      "Epoch 2/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.2702 - precision: 0.6914\n",
      "Epoch 2: val_loss improved from 1.32715 to 1.25567, saving model to model_7.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.2697 - precision: 0.6924 - val_loss: 1.2557 - val_precision: 0.7018\n",
      "Epoch 3/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1409 - precision: 0.6433\n",
      "Epoch 3: val_loss improved from 1.25567 to 1.17810, saving model to model_7.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1400 - precision: 0.6418 - val_loss: 1.1781 - val_precision: 0.6496\n",
      "Epoch 4/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.0494 - precision: 0.6299\n",
      "Epoch 4: val_loss improved from 1.17810 to 1.11454, saving model to model_7.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0488 - precision: 0.6296 - val_loss: 1.1145 - val_precision: 0.6418\n",
      "Epoch 5/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9692 - precision: 0.6332\n",
      "Epoch 5: val_loss improved from 1.11454 to 1.04847, saving model to model_7.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9700 - precision: 0.6329 - val_loss: 1.0485 - val_precision: 0.6318\n",
      "Epoch 6/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9207 - precision: 0.6222\n",
      "Epoch 6: val_loss improved from 1.04847 to 1.04422, saving model to model_7.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9191 - precision: 0.6225 - val_loss: 1.0442 - val_precision: 0.6134\n",
      "Epoch 7/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8774 - precision: 0.6248\n",
      "Epoch 7: val_loss improved from 1.04422 to 1.04389, saving model to model_7.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8797 - precision: 0.6241 - val_loss: 1.0439 - val_precision: 0.6108\n",
      "Epoch 8/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8594 - precision: 0.6216\n",
      "Epoch 8: val_loss improved from 1.04389 to 1.02792, saving model to model_7.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8586 - precision: 0.6226 - val_loss: 1.0279 - val_precision: 0.6177\n",
      "Epoch 9/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8432 - precision: 0.6341\n",
      "Epoch 9: val_loss did not improve from 1.02792\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8408 - precision: 0.6339 - val_loss: 1.0467 - val_precision: 0.6067\n",
      "Epoch 10/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8294 - precision: 0.6334\n",
      "Epoch 10: val_loss improved from 1.02792 to 1.01598, saving model to model_7.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8258 - precision: 0.6352 - val_loss: 1.0160 - val_precision: 0.6157\n",
      "Epoch 11/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8063 - precision: 0.6411\n",
      "Epoch 11: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8081 - precision: 0.6413 - val_loss: 1.0397 - val_precision: 0.6109\n",
      "Epoch 12/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7975 - precision: 0.6473\n",
      "Epoch 12: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7977 - precision: 0.6470 - val_loss: 1.0332 - val_precision: 0.6133\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7790 - precision: 0.6512\n",
      "Epoch 13: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7821 - precision: 0.6509 - val_loss: 1.0459 - val_precision: 0.6100\n",
      "Epoch 14/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7727 - precision: 0.6590\n",
      "Epoch 14: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7736 - precision: 0.6584 - val_loss: 1.0491 - val_precision: 0.6025\n",
      "Epoch 15/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7565 - precision: 0.6610\n",
      "Epoch 15: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7563 - precision: 0.6608 - val_loss: 1.0699 - val_precision: 0.5985\n",
      "Epoch 16/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7451 - precision: 0.6639\n",
      "Epoch 16: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7432 - precision: 0.6641 - val_loss: 1.0595 - val_precision: 0.6034\n",
      "Epoch 17/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7379 - precision: 0.6708\n",
      "Epoch 17: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7407 - precision: 0.6697 - val_loss: 1.0293 - val_precision: 0.6059\n",
      "Epoch 18/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7274 - precision: 0.6778\n",
      "Epoch 18: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7253 - precision: 0.6774 - val_loss: 1.0591 - val_precision: 0.5967\n",
      "Epoch 19/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7110 - precision: 0.6777\n",
      "Epoch 19: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7102 - precision: 0.6777 - val_loss: 1.0605 - val_precision: 0.6051\n",
      "Epoch 20/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7084 - precision: 0.6857\n",
      "Epoch 20: val_loss did not improve from 1.01598\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7054 - precision: 0.6850 - val_loss: 1.1077 - val_precision: 0.5912\n",
      "Epoch 20: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8832 - precision: 0.6632\n",
      "Combinación 6 = (True, True, True, 32, 0.1) \n",
      " precision train: [0.8832079172134399, 0.6631762385368347]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 8: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.4339 - precision: 0.5361\n",
      "Epoch 1: val_loss improved from inf to 1.31061, saving model to model_8.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.4266 - precision: 0.5416 - val_loss: 1.3106 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.2498 - precision: 0.5784\n",
      "Epoch 2: val_loss improved from 1.31061 to 1.27581, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.2477 - precision: 0.5892 - val_loss: 1.2758 - val_precision: 0.5856\n",
      "Epoch 3/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1961 - precision: 0.6220\n",
      "Epoch 3: val_loss improved from 1.27581 to 1.21028, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1958 - precision: 0.6262 - val_loss: 1.2103 - val_precision: 0.6752\n",
      "Epoch 4/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1452 - precision: 0.6343\n",
      "Epoch 4: val_loss improved from 1.21028 to 1.18164, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1449 - precision: 0.6367 - val_loss: 1.1816 - val_precision: 0.7105\n",
      "Epoch 5/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1079 - precision: 0.5760\n",
      "Epoch 5: val_loss did not improve from 1.18164\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1100 - precision: 0.5750 - val_loss: 1.1919 - val_precision: 0.5263\n",
      "Epoch 6/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.0952 - precision: 0.5739\n",
      "Epoch 6: val_loss did not improve from 1.18164\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0959 - precision: 0.5733 - val_loss: 1.1824 - val_precision: 0.5855\n",
      "Epoch 7/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0656 - precision: 0.5785\n",
      "Epoch 7: val_loss improved from 1.18164 to 1.16543, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0681 - precision: 0.5781 - val_loss: 1.1654 - val_precision: 0.5645\n",
      "Epoch 8/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0492 - precision: 0.6031\n",
      "Epoch 8: val_loss improved from 1.16543 to 1.16058, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0497 - precision: 0.6015 - val_loss: 1.1606 - val_precision: 0.5949\n",
      "Epoch 9/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0260 - precision: 0.6123\n",
      "Epoch 9: val_loss improved from 1.16058 to 1.13294, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0236 - precision: 0.6140 - val_loss: 1.1329 - val_precision: 0.6090\n",
      "Epoch 10/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9916 - precision: 0.6230\n",
      "Epoch 10: val_loss improved from 1.13294 to 1.10136, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9901 - precision: 0.6248 - val_loss: 1.1014 - val_precision: 0.6177\n",
      "Epoch 11/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9481 - precision: 0.6132\n",
      "Epoch 11: val_loss did not improve from 1.10136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9479 - precision: 0.6139 - val_loss: 1.1105 - val_precision: 0.5873\n",
      "Epoch 12/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9198 - precision: 0.6172\n",
      "Epoch 12: val_loss improved from 1.10136 to 1.07603, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9194 - precision: 0.6171 - val_loss: 1.0760 - val_precision: 0.5943\n",
      "Epoch 13/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8921 - precision: 0.6191\n",
      "Epoch 13: val_loss did not improve from 1.07603\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8925 - precision: 0.6183 - val_loss: 1.0913 - val_precision: 0.5872\n",
      "Epoch 14/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8772 - precision: 0.6216\n",
      "Epoch 14: val_loss improved from 1.07603 to 1.06519, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8776 - precision: 0.6209 - val_loss: 1.0652 - val_precision: 0.5917\n",
      "Epoch 15/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8517 - precision: 0.6355\n",
      "Epoch 15: val_loss improved from 1.06519 to 1.05851, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8559 - precision: 0.6351 - val_loss: 1.0585 - val_precision: 0.6031\n",
      "Epoch 16/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8455 - precision: 0.6354\n",
      "Epoch 16: val_loss improved from 1.05851 to 1.05194, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8456 - precision: 0.6347 - val_loss: 1.0519 - val_precision: 0.6054\n",
      "Epoch 17/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8281 - precision: 0.6469\n",
      "Epoch 17: val_loss did not improve from 1.05194\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8262 - precision: 0.6478 - val_loss: 1.0532 - val_precision: 0.6096\n",
      "Epoch 18/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8172 - precision: 0.6497\n",
      "Epoch 18: val_loss did not improve from 1.05194\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8194 - precision: 0.6496 - val_loss: 1.0831 - val_precision: 0.5863\n",
      "Epoch 19/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8063 - precision: 0.6519\n",
      "Epoch 19: val_loss did not improve from 1.05194\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8063 - precision: 0.6533 - val_loss: 1.0662 - val_precision: 0.6103\n",
      "Epoch 20/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7882 - precision: 0.6582\n",
      "Epoch 20: val_loss did not improve from 1.05194\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7888 - precision: 0.6579 - val_loss: 1.0600 - val_precision: 0.6057\n",
      "Epoch 21/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7741 - precision: 0.6568\n",
      "Epoch 21: val_loss did not improve from 1.05194\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7761 - precision: 0.6560 - val_loss: 1.0859 - val_precision: 0.5974\n",
      "Epoch 22/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7610 - precision: 0.6626\n",
      "Epoch 22: val_loss did not improve from 1.05194\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7614 - precision: 0.6617 - val_loss: 1.0624 - val_precision: 0.6016\n",
      "Epoch 23/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7439 - precision: 0.6698\n",
      "Epoch 23: val_loss did not improve from 1.05194\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7441 - precision: 0.6707 - val_loss: 1.0545 - val_precision: 0.6008\n",
      "Epoch 24/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7435 - precision: 0.6707\n",
      "Epoch 24: val_loss improved from 1.05194 to 1.05188, saving model to model_8.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7440 - precision: 0.6704 - val_loss: 1.0519 - val_precision: 0.5993\n",
      "Epoch 25/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7373 - precision: 0.6767\n",
      "Epoch 25: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7338 - precision: 0.6785 - val_loss: 1.0520 - val_precision: 0.6030\n",
      "Epoch 26/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7196 - precision: 0.6795\n",
      "Epoch 26: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7195 - precision: 0.6794 - val_loss: 1.0748 - val_precision: 0.5942\n",
      "Epoch 27/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7146 - precision: 0.6793\n",
      "Epoch 27: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7131 - precision: 0.6795 - val_loss: 1.0858 - val_precision: 0.6018\n",
      "Epoch 28/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7112 - precision: 0.6826\n",
      "Epoch 28: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7118 - precision: 0.6823 - val_loss: 1.0904 - val_precision: 0.5876\n",
      "Epoch 29/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6962 - precision: 0.6890\n",
      "Epoch 29: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6951 - precision: 0.6897 - val_loss: 1.0999 - val_precision: 0.5947\n",
      "Epoch 30/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6811 - precision: 0.6966\n",
      "Epoch 30: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6823 - precision: 0.6961 - val_loss: 1.0910 - val_precision: 0.5893\n",
      "Epoch 31/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6854 - precision: 0.6917\n",
      "Epoch 31: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6848 - precision: 0.6929 - val_loss: 1.0925 - val_precision: 0.5935\n",
      "Epoch 32/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.6714 - precision: 0.7010\n",
      "Epoch 32: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6729 - precision: 0.7004 - val_loss: 1.1011 - val_precision: 0.5954\n",
      "Epoch 33/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.6757 - precision: 0.6970\n",
      "Epoch 33: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6756 - precision: 0.6971 - val_loss: 1.1062 - val_precision: 0.5875\n",
      "Epoch 34/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6693 - precision: 0.7014\n",
      "Epoch 34: val_loss did not improve from 1.05188\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6683 - precision: 0.7020 - val_loss: 1.1106 - val_precision: 0.5945\n",
      "Epoch 34: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8066 - precision: 0.7000\n",
      "Combinación 7 = (True, True, True, 32, 0.25) \n",
      " precision train: [0.8065682053565979, 0.6999889612197876]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 9: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.5915 - precision: 0.6226    \n",
      "Epoch 1: val_loss improved from inf to 1.38320, saving model to model_9.h5\n",
      "240/240 [==============================] - 7s 11ms/step - loss: 1.5787 - precision: 0.6788 - val_loss: 1.3832 - val_precision: 0.6863\n",
      "Epoch 2/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.3639 - precision: 0.6801\n",
      "Epoch 2: val_loss improved from 1.38320 to 1.20149, saving model to model_9.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.3622 - precision: 0.6811 - val_loss: 1.2015 - val_precision: 0.7093\n",
      "Epoch 3/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.2133 - precision: 0.6389\n",
      "Epoch 3: val_loss improved from 1.20149 to 1.12812, saving model to model_9.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.2154 - precision: 0.6365 - val_loss: 1.1281 - val_precision: 0.6369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1358 - precision: 0.6293\n",
      "Epoch 4: val_loss improved from 1.12812 to 1.11219, saving model to model_9.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1335 - precision: 0.6296 - val_loss: 1.1122 - val_precision: 0.6240\n",
      "Epoch 5/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0718 - precision: 0.6255\n",
      "Epoch 5: val_loss improved from 1.11219 to 1.07592, saving model to model_9.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0713 - precision: 0.6259 - val_loss: 1.0759 - val_precision: 0.6204\n",
      "Epoch 6/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0251 - precision: 0.6057\n",
      "Epoch 6: val_loss improved from 1.07592 to 1.06088, saving model to model_9.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0262 - precision: 0.6048 - val_loss: 1.0609 - val_precision: 0.5957\n",
      "Epoch 7/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0025 - precision: 0.5997\n",
      "Epoch 7: val_loss improved from 1.06088 to 1.04841, saving model to model_9.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0058 - precision: 0.5990 - val_loss: 1.0484 - val_precision: 0.6004\n",
      "Epoch 8/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9844 - precision: 0.5998\n",
      "Epoch 8: val_loss did not improve from 1.04841\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9837 - precision: 0.5997 - val_loss: 1.0572 - val_precision: 0.5935\n",
      "Epoch 9/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9640 - precision: 0.6012\n",
      "Epoch 9: val_loss improved from 1.04841 to 1.03728, saving model to model_9.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9663 - precision: 0.6013 - val_loss: 1.0373 - val_precision: 0.5993\n",
      "Epoch 10/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9570 - precision: 0.6092\n",
      "Epoch 10: val_loss did not improve from 1.03728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9565 - precision: 0.6092 - val_loss: 1.0573 - val_precision: 0.5985\n",
      "Epoch 11/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9513 - precision: 0.6050\n",
      "Epoch 11: val_loss did not improve from 1.03728\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9513 - precision: 0.6050 - val_loss: 1.0447 - val_precision: 0.5980\n",
      "Epoch 12/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9287 - precision: 0.6171\n",
      "Epoch 12: val_loss did not improve from 1.03728\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9278 - precision: 0.6178 - val_loss: 1.0466 - val_precision: 0.5999\n",
      "Epoch 13/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9354 - precision: 0.6131\n",
      "Epoch 13: val_loss did not improve from 1.03728\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9359 - precision: 0.6132 - val_loss: 1.0458 - val_precision: 0.5979\n",
      "Epoch 14/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9275 - precision: 0.6114\n",
      "Epoch 14: val_loss did not improve from 1.03728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9314 - precision: 0.6110 - val_loss: 1.0431 - val_precision: 0.6003\n",
      "Epoch 15/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9184 - precision: 0.6203\n",
      "Epoch 15: val_loss did not improve from 1.03728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9216 - precision: 0.6192 - val_loss: 1.0462 - val_precision: 0.5987\n",
      "Epoch 16/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9166 - precision: 0.6176\n",
      "Epoch 16: val_loss improved from 1.03728 to 1.03342, saving model to model_9.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9139 - precision: 0.6196 - val_loss: 1.0334 - val_precision: 0.5989\n",
      "Epoch 17/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9001 - precision: 0.6203\n",
      "Epoch 17: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9060 - precision: 0.6203 - val_loss: 1.0508 - val_precision: 0.5981\n",
      "Epoch 18/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9036 - precision: 0.6231\n",
      "Epoch 18: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9080 - precision: 0.6225 - val_loss: 1.0494 - val_precision: 0.5995\n",
      "Epoch 19/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8939 - precision: 0.6242\n",
      "Epoch 19: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8937 - precision: 0.6247 - val_loss: 1.0411 - val_precision: 0.6044\n",
      "Epoch 20/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9031 - precision: 0.6255\n",
      "Epoch 20: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9026 - precision: 0.6258 - val_loss: 1.0533 - val_precision: 0.5910\n",
      "Epoch 21/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8987 - precision: 0.6215\n",
      "Epoch 21: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8981 - precision: 0.6217 - val_loss: 1.0496 - val_precision: 0.5959\n",
      "Epoch 22/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8844 - precision: 0.6284\n",
      "Epoch 22: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8849 - precision: 0.6292 - val_loss: 1.0596 - val_precision: 0.5923\n",
      "Epoch 23/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8778 - precision: 0.6317\n",
      "Epoch 23: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8800 - precision: 0.6294 - val_loss: 1.0544 - val_precision: 0.5986\n",
      "Epoch 24/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8825 - precision: 0.6304\n",
      "Epoch 24: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8828 - precision: 0.6303 - val_loss: 1.0490 - val_precision: 0.5988\n",
      "Epoch 25/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8806 - precision: 0.6301\n",
      "Epoch 25: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8781 - precision: 0.6298 - val_loss: 1.0694 - val_precision: 0.5895\n",
      "Epoch 26/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8768 - precision: 0.6291\n",
      "Epoch 26: val_loss did not improve from 1.03342\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8746 - precision: 0.6312 - val_loss: 1.0610 - val_precision: 0.5987\n",
      "Epoch 26: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9394 - precision: 0.6300\n",
      "Combinación 8 = (True, True, True, 32, 0.5) \n",
      " precision train: [0.9393835663795471, 0.6300268173217773]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 10: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.3597 - precision: 0.6646\n",
      "Epoch 1: val_loss improved from inf to 1.17617, saving model to model_10.h5\n",
      "240/240 [==============================] - 6s 9ms/step - loss: 1.3508 - precision: 0.6693 - val_loss: 1.1762 - val_precision: 0.7034\n",
      "Epoch 2/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0285 - precision: 0.6199\n",
      "Epoch 2: val_loss improved from 1.17617 to 1.08344, saving model to model_10.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0252 - precision: 0.6185 - val_loss: 1.0834 - val_precision: 0.6136\n",
      "Epoch 3/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9213 - precision: 0.6155\n",
      "Epoch 3: val_loss improved from 1.08344 to 1.01754, saving model to model_10.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9208 - precision: 0.6155 - val_loss: 1.0175 - val_precision: 0.6318\n",
      "Epoch 4/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8754 - precision: 0.6217\n",
      "Epoch 4: val_loss improved from 1.01754 to 1.00213, saving model to model_10.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8763 - precision: 0.6231 - val_loss: 1.0021 - val_precision: 0.6288\n",
      "Epoch 5/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8375 - precision: 0.6266\n",
      "Epoch 5: val_loss improved from 1.00213 to 0.98130, saving model to model_10.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8424 - precision: 0.6258 - val_loss: 0.9813 - val_precision: 0.6326\n",
      "Epoch 6/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8144 - precision: 0.6323\n",
      "Epoch 6: val_loss did not improve from 0.98130\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8113 - precision: 0.6335 - val_loss: 1.0130 - val_precision: 0.6142\n",
      "Epoch 7/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7869 - precision: 0.6368\n",
      "Epoch 7: val_loss improved from 0.98130 to 0.97443, saving model to model_10.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7885 - precision: 0.6365 - val_loss: 0.9744 - val_precision: 0.6215\n",
      "Epoch 8/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7652 - precision: 0.6468\n",
      "Epoch 8: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7706 - precision: 0.6459 - val_loss: 0.9774 - val_precision: 0.6292\n",
      "Epoch 9/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7490 - precision: 0.6560\n",
      "Epoch 9: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7496 - precision: 0.6543 - val_loss: 0.9928 - val_precision: 0.6234\n",
      "Epoch 10/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7348 - precision: 0.6554\n",
      "Epoch 10: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7352 - precision: 0.6560 - val_loss: 0.9979 - val_precision: 0.6166\n",
      "Epoch 11/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7164 - precision: 0.6629\n",
      "Epoch 11: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7170 - precision: 0.6623 - val_loss: 1.0063 - val_precision: 0.6283\n",
      "Epoch 12/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7002 - precision: 0.6671\n",
      "Epoch 12: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6996 - precision: 0.6669 - val_loss: 1.0065 - val_precision: 0.6180\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6785 - precision: 0.6766\n",
      "Epoch 13: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6816 - precision: 0.6765 - val_loss: 1.0184 - val_precision: 0.6160\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6652 - precision: 0.6777\n",
      "Epoch 14: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6663 - precision: 0.6771 - val_loss: 1.0277 - val_precision: 0.6135\n",
      "Epoch 15/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6592 - precision: 0.6856\n",
      "Epoch 15: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6592 - precision: 0.6856 - val_loss: 1.0322 - val_precision: 0.6167\n",
      "Epoch 16/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6406 - precision: 0.6878\n",
      "Epoch 16: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6405 - precision: 0.6889 - val_loss: 1.0476 - val_precision: 0.6042\n",
      "Epoch 17/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6241 - precision: 0.6960\n",
      "Epoch 17: val_loss did not improve from 0.97443\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6239 - precision: 0.6962 - val_loss: 1.0754 - val_precision: 0.6065\n",
      "Epoch 17: early stopping\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.7806 - precision: 0.6934\n",
      "Combinación 9 = (True, True, True, 64, 0.1) \n",
      " precision train: [0.7805542349815369, 0.6934322714805603]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 11: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.4093 - precision: 0.6137\n",
      "Epoch 1: val_loss improved from inf to 1.28280, saving model to model_11.h5\n",
      "240/240 [==============================] - 6s 9ms/step - loss: 1.4043 - precision: 0.6203 - val_loss: 1.2828 - val_precision: 0.7243\n",
      "Epoch 2/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1873 - precision: 0.6677\n",
      "Epoch 2: val_loss improved from 1.28280 to 1.17269, saving model to model_11.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1869 - precision: 0.6684 - val_loss: 1.1727 - val_precision: 0.6372\n",
      "Epoch 3/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0477 - precision: 0.6138\n",
      "Epoch 3: val_loss improved from 1.17269 to 1.06854, saving model to model_11.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0455 - precision: 0.6118 - val_loss: 1.0685 - val_precision: 0.6142\n",
      "Epoch 4/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9642 - precision: 0.6086\n",
      "Epoch 4: val_loss improved from 1.06854 to 1.05423, saving model to model_11.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9646 - precision: 0.6092 - val_loss: 1.0542 - val_precision: 0.6113\n",
      "Epoch 5/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9044 - precision: 0.6278\n",
      "Epoch 5: val_loss improved from 1.05423 to 1.05337, saving model to model_11.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9048 - precision: 0.6269 - val_loss: 1.0534 - val_precision: 0.6104\n",
      "Epoch 6/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8840 - precision: 0.6285\n",
      "Epoch 6: val_loss improved from 1.05337 to 1.00164, saving model to model_11.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8838 - precision: 0.6287 - val_loss: 1.0016 - val_precision: 0.6288\n",
      "Epoch 7/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8599 - precision: 0.6339\n",
      "Epoch 7: val_loss did not improve from 1.00164\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8583 - precision: 0.6326 - val_loss: 1.0478 - val_precision: 0.6032\n",
      "Epoch 8/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8363 - precision: 0.6387\n",
      "Epoch 8: val_loss did not improve from 1.00164\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8360 - precision: 0.6392 - val_loss: 1.0206 - val_precision: 0.6151\n",
      "Epoch 9/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8172 - precision: 0.6385\n",
      "Epoch 9: val_loss did not improve from 1.00164\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8191 - precision: 0.6370 - val_loss: 1.0165 - val_precision: 0.6175\n",
      "Epoch 10/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7914 - precision: 0.6483\n",
      "Epoch 10: val_loss did not improve from 1.00164\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7961 - precision: 0.6457 - val_loss: 1.0257 - val_precision: 0.6193\n",
      "Epoch 11/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7934 - precision: 0.6499\n",
      "Epoch 11: val_loss did not improve from 1.00164\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7906 - precision: 0.6514 - val_loss: 1.0191 - val_precision: 0.6111\n",
      "Epoch 12/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7652 - precision: 0.6547\n",
      "Epoch 12: val_loss did not improve from 1.00164\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7658 - precision: 0.6544 - val_loss: 1.0129 - val_precision: 0.6148\n",
      "Epoch 13/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7590 - precision: 0.6597\n",
      "Epoch 13: val_loss did not improve from 1.00164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7588 - precision: 0.6589 - val_loss: 1.0358 - val_precision: 0.6104\n",
      "Epoch 14/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7384 - precision: 0.6659\n",
      "Epoch 14: val_loss did not improve from 1.00164\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7384 - precision: 0.6659 - val_loss: 1.0154 - val_precision: 0.6235\n",
      "Epoch 15/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7296 - precision: 0.6706\n",
      "Epoch 15: val_loss did not improve from 1.00164\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7294 - precision: 0.6702 - val_loss: 1.0089 - val_precision: 0.6213\n",
      "Epoch 16/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7116 - precision: 0.6741\n",
      "Epoch 16: val_loss did not improve from 1.00164\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7108 - precision: 0.6745 - val_loss: 1.0101 - val_precision: 0.6239\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.8224 - precision: 0.6843\n",
      "Combinación 10 = (True, True, True, 64, 0.25) \n",
      " precision train: [0.8223743438720703, 0.6842845678329468]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 12: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.4873 - precision: 0.5893\n",
      "Epoch 1: val_loss improved from inf to 1.27697, saving model to model_12.h5\n",
      "240/240 [==============================] - 7s 9ms/step - loss: 1.4811 - precision: 0.5871 - val_loss: 1.2770 - val_precision: 0.7254\n",
      "Epoch 2/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.2021 - precision: 0.6632\n",
      "Epoch 2: val_loss improved from 1.27697 to 1.10927, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.2017 - precision: 0.6632 - val_loss: 1.1093 - val_precision: 0.6724\n",
      "Epoch 3/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0608 - precision: 0.6091\n",
      "Epoch 3: val_loss improved from 1.10927 to 1.07068, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0590 - precision: 0.6093 - val_loss: 1.0707 - val_precision: 0.6105\n",
      "Epoch 4/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0062 - precision: 0.6052\n",
      "Epoch 4: val_loss improved from 1.07068 to 1.05566, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0070 - precision: 0.6055 - val_loss: 1.0557 - val_precision: 0.6028\n",
      "Epoch 5/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9842 - precision: 0.6095\n",
      "Epoch 5: val_loss improved from 1.05566 to 1.05477, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9836 - precision: 0.6083 - val_loss: 1.0548 - val_precision: 0.6094\n",
      "Epoch 6/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9571 - precision: 0.6173\n",
      "Epoch 6: val_loss improved from 1.05477 to 1.05055, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9577 - precision: 0.6175 - val_loss: 1.0505 - val_precision: 0.6137\n",
      "Epoch 7/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9374 - precision: 0.6246\n",
      "Epoch 7: val_loss improved from 1.05055 to 1.04878, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9392 - precision: 0.6244 - val_loss: 1.0488 - val_precision: 0.6168\n",
      "Epoch 8/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9307 - precision: 0.6215\n",
      "Epoch 8: val_loss did not improve from 1.04878\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9273 - precision: 0.6220 - val_loss: 1.0572 - val_precision: 0.6034\n",
      "Epoch 9/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9035 - precision: 0.6211\n",
      "Epoch 9: val_loss improved from 1.04878 to 1.04026, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9059 - precision: 0.6205 - val_loss: 1.0403 - val_precision: 0.6043\n",
      "Epoch 10/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8995 - precision: 0.6313\n",
      "Epoch 10: val_loss improved from 1.04026 to 1.04008, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8997 - precision: 0.6319 - val_loss: 1.0401 - val_precision: 0.6121\n",
      "Epoch 11/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8808 - precision: 0.6324\n",
      "Epoch 11: val_loss did not improve from 1.04008\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8841 - precision: 0.6331 - val_loss: 1.0445 - val_precision: 0.6097\n",
      "Epoch 12/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8800 - precision: 0.6262\n",
      "Epoch 12: val_loss did not improve from 1.04008\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8791 - precision: 0.6262 - val_loss: 1.0444 - val_precision: 0.6075\n",
      "Epoch 13/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8582 - precision: 0.6352\n",
      "Epoch 13: val_loss improved from 1.04008 to 1.03440, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8627 - precision: 0.6322 - val_loss: 1.0344 - val_precision: 0.6051\n",
      "Epoch 14/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8572 - precision: 0.6334\n",
      "Epoch 14: val_loss did not improve from 1.03440\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8560 - precision: 0.6333 - val_loss: 1.0385 - val_precision: 0.6024\n",
      "Epoch 15/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8443 - precision: 0.6360\n",
      "Epoch 15: val_loss did not improve from 1.03440\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8423 - precision: 0.6357 - val_loss: 1.0465 - val_precision: 0.6040\n",
      "Epoch 16/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8553 - precision: 0.6348\n",
      "Epoch 16: val_loss improved from 1.03440 to 1.03395, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8518 - precision: 0.6352 - val_loss: 1.0339 - val_precision: 0.6091\n",
      "Epoch 17/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8328 - precision: 0.6358\n",
      "Epoch 17: val_loss improved from 1.03395 to 1.01699, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8325 - precision: 0.6361 - val_loss: 1.0170 - val_precision: 0.6121\n",
      "Epoch 18/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8166 - precision: 0.6416\n",
      "Epoch 18: val_loss did not improve from 1.01699\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8179 - precision: 0.6405 - val_loss: 1.0350 - val_precision: 0.6018\n",
      "Epoch 19/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8163 - precision: 0.6428\n",
      "Epoch 19: val_loss improved from 1.01699 to 1.01113, saving model to model_12.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8133 - precision: 0.6426 - val_loss: 1.0111 - val_precision: 0.6108\n",
      "Epoch 20/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8000 - precision: 0.6474\n",
      "Epoch 20: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8044 - precision: 0.6471 - val_loss: 1.0351 - val_precision: 0.6060\n",
      "Epoch 21/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8080 - precision: 0.6440\n",
      "Epoch 21: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8086 - precision: 0.6440 - val_loss: 1.0403 - val_precision: 0.6040\n",
      "Epoch 22/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7856 - precision: 0.6527\n",
      "Epoch 22: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7868 - precision: 0.6518 - val_loss: 1.0519 - val_precision: 0.6014\n",
      "Epoch 23/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7821 - precision: 0.6488\n",
      "Epoch 23: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7828 - precision: 0.6474 - val_loss: 1.0116 - val_precision: 0.6140\n",
      "Epoch 24/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7832 - precision: 0.6532\n",
      "Epoch 24: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7830 - precision: 0.6543 - val_loss: 1.0423 - val_precision: 0.6062\n",
      "Epoch 25/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7701 - precision: 0.6576\n",
      "Epoch 25: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7704 - precision: 0.6570 - val_loss: 1.0361 - val_precision: 0.6097\n",
      "Epoch 26/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7530 - precision: 0.6640\n",
      "Epoch 26: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7537 - precision: 0.6634 - val_loss: 1.0638 - val_precision: 0.6023\n",
      "Epoch 27/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7733 - precision: 0.6524\n",
      "Epoch 27: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7727 - precision: 0.6529 - val_loss: 1.0484 - val_precision: 0.6001\n",
      "Epoch 28/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7601 - precision: 0.6619\n",
      "Epoch 28: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7590 - precision: 0.6625 - val_loss: 1.0488 - val_precision: 0.6024\n",
      "Epoch 29/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7499 - precision: 0.6646\n",
      "Epoch 29: val_loss did not improve from 1.01113\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7501 - precision: 0.6648 - val_loss: 1.0390 - val_precision: 0.6080\n",
      "Epoch 29: early stopping\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.8493 - precision: 0.6687\n",
      "Combinación 11 = (True, True, True, 64, 0.5) \n",
      " precision train: [0.8493091464042664, 0.6687363386154175]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 13: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.5337 - precision: 1.0000    \n",
      "Epoch 1: val_loss improved from inf to 1.35592, saving model to model_13.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5337 - precision: 1.0000 - val_loss: 1.3559 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1875 - precision: 0.5738\n",
      "Epoch 2: val_loss improved from 1.35592 to 1.15937, saving model to model_13.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1844 - precision: 0.5811 - val_loss: 1.1594 - val_precision: 0.6388\n",
      "Epoch 3/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0501 - precision: 0.5968\n",
      "Epoch 3: val_loss improved from 1.15937 to 1.08741, saving model to model_13.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0492 - precision: 0.5976 - val_loss: 1.0874 - val_precision: 0.6140\n",
      "Epoch 4/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9949 - precision: 0.5931\n",
      "Epoch 4: val_loss improved from 1.08741 to 1.07035, saving model to model_13.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9912 - precision: 0.5927 - val_loss: 1.0704 - val_precision: 0.6034\n",
      "Epoch 5/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.9666 - precision: 0.6040\n",
      "Epoch 5: val_loss improved from 1.07035 to 1.06831, saving model to model_13.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9679 - precision: 0.6022 - val_loss: 1.0683 - val_precision: 0.6015\n",
      "Epoch 6/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9489 - precision: 0.6019\n",
      "Epoch 6: val_loss improved from 1.06831 to 1.04753, saving model to model_13.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9482 - precision: 0.6019 - val_loss: 1.0475 - val_precision: 0.6074\n",
      "Epoch 7/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9228 - precision: 0.6153\n",
      "Epoch 7: val_loss improved from 1.04753 to 1.02814, saving model to model_13.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9245 - precision: 0.6153 - val_loss: 1.0281 - val_precision: 0.6254\n",
      "Epoch 8/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9053 - precision: 0.6239\n",
      "Epoch 8: val_loss did not improve from 1.02814\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9056 - precision: 0.6235 - val_loss: 1.0411 - val_precision: 0.6094\n",
      "Epoch 9/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8981 - precision: 0.6299\n",
      "Epoch 9: val_loss improved from 1.02814 to 1.02227, saving model to model_13.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8994 - precision: 0.6295 - val_loss: 1.0223 - val_precision: 0.6242\n",
      "Epoch 10/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8803 - precision: 0.6351\n",
      "Epoch 10: val_loss did not improve from 1.02227\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8862 - precision: 0.6330 - val_loss: 1.0297 - val_precision: 0.6188\n",
      "Epoch 11/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8748 - precision: 0.6394\n",
      "Epoch 11: val_loss did not improve from 1.02227\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8697 - precision: 0.6413 - val_loss: 1.0281 - val_precision: 0.6242\n",
      "Epoch 12/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8686 - precision: 0.6390\n",
      "Epoch 12: val_loss did not improve from 1.02227\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8671 - precision: 0.6396 - val_loss: 1.0381 - val_precision: 0.6147\n",
      "Epoch 13/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8460 - precision: 0.6495\n",
      "Epoch 13: val_loss improved from 1.02227 to 1.01892, saving model to model_13.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8503 - precision: 0.6482 - val_loss: 1.0189 - val_precision: 0.6279\n",
      "Epoch 14/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8435 - precision: 0.6547\n",
      "Epoch 14: val_loss did not improve from 1.01892\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8428 - precision: 0.6550 - val_loss: 1.0293 - val_precision: 0.6240\n",
      "Epoch 15/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8258 - precision: 0.6511\n",
      "Epoch 15: val_loss improved from 1.01892 to 1.01828, saving model to model_13.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8286 - precision: 0.6516 - val_loss: 1.0183 - val_precision: 0.6307\n",
      "Epoch 16/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8228 - precision: 0.6576\n",
      "Epoch 16: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8206 - precision: 0.6594 - val_loss: 1.0257 - val_precision: 0.6280\n",
      "Epoch 17/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8178 - precision: 0.6624\n",
      "Epoch 17: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8192 - precision: 0.6614 - val_loss: 1.0414 - val_precision: 0.6219\n",
      "Epoch 18/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8219 - precision: 0.6634\n",
      "Epoch 18: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8168 - precision: 0.6643 - val_loss: 1.0213 - val_precision: 0.6298\n",
      "Epoch 19/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8049 - precision: 0.6667\n",
      "Epoch 19: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8040 - precision: 0.6657 - val_loss: 1.0310 - val_precision: 0.6267\n",
      "Epoch 20/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8028 - precision: 0.6679\n",
      "Epoch 20: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8015 - precision: 0.6700 - val_loss: 1.0395 - val_precision: 0.6222\n",
      "Epoch 21/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7901 - precision: 0.6712\n",
      "Epoch 21: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7887 - precision: 0.6724 - val_loss: 1.0518 - val_precision: 0.6165\n",
      "Epoch 22/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7857 - precision: 0.6793\n",
      "Epoch 22: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7877 - precision: 0.6762 - val_loss: 1.0497 - val_precision: 0.6160\n",
      "Epoch 23/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7817 - precision: 0.6773\n",
      "Epoch 23: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7807 - precision: 0.6766 - val_loss: 1.0406 - val_precision: 0.6257\n",
      "Epoch 24/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7816 - precision: 0.6747\n",
      "Epoch 24: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7828 - precision: 0.6742 - val_loss: 1.0455 - val_precision: 0.6215\n",
      "Epoch 25/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7715 - precision: 0.6812\n",
      "Epoch 25: val_loss did not improve from 1.01828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7709 - precision: 0.6806 - val_loss: 1.0626 - val_precision: 0.6074\n",
      "Epoch 25: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8854 - precision: 0.6731\n",
      "Combinación 12 = (True, True, False, 8, 0.1) \n",
      " precision train: [0.8854482173919678, 0.6731049418449402]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 14: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.5715 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.41159, saving model to model_14.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5685 - precision: 0.0000e+00 - val_loss: 1.4116 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.3203 - precision: 0.6258\n",
      "Epoch 2: val_loss improved from 1.41159 to 1.27036, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3181 - precision: 0.6328 - val_loss: 1.2704 - val_precision: 0.7316\n",
      "Epoch 3/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2225 - precision: 0.6569\n",
      "Epoch 3: val_loss improved from 1.27036 to 1.21344, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2214 - precision: 0.6495 - val_loss: 1.2134 - val_precision: 0.6772\n",
      "Epoch 4/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1783 - precision: 0.6107\n",
      "Epoch 4: val_loss improved from 1.21344 to 1.17677, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1762 - precision: 0.6132 - val_loss: 1.1768 - val_precision: 0.6316\n",
      "Epoch 5/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1385 - precision: 0.6107\n",
      "Epoch 5: val_loss did not improve from 1.17677\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1391 - precision: 0.6121 - val_loss: 1.1788 - val_precision: 0.6540\n",
      "Epoch 6/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.1125 - precision: 0.6038\n",
      "Epoch 6: val_loss improved from 1.17677 to 1.15097, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1177 - precision: 0.6056 - val_loss: 1.1510 - val_precision: 0.6320\n",
      "Epoch 7/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.1007 - precision: 0.6068\n",
      "Epoch 7: val_loss did not improve from 1.15097\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1006 - precision: 0.6072 - val_loss: 1.1523 - val_precision: 0.6423\n",
      "Epoch 8/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.0936 - precision: 0.6105\n",
      "Epoch 8: val_loss improved from 1.15097 to 1.14102, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0955 - precision: 0.6055 - val_loss: 1.1410 - val_precision: 0.6529\n",
      "Epoch 9/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0816 - precision: 0.6096\n",
      "Epoch 9: val_loss improved from 1.14102 to 1.13031, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0830 - precision: 0.6125 - val_loss: 1.1303 - val_precision: 0.6447\n",
      "Epoch 10/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0543 - precision: 0.6177\n",
      "Epoch 10: val_loss improved from 1.13031 to 1.11726, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0557 - precision: 0.6179 - val_loss: 1.1173 - val_precision: 0.6689\n",
      "Epoch 11/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0380 - precision: 0.6307\n",
      "Epoch 11: val_loss improved from 1.11726 to 1.10248, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0394 - precision: 0.6306 - val_loss: 1.1025 - val_precision: 0.6445\n",
      "Epoch 12/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.0120 - precision: 0.6416\n",
      "Epoch 12: val_loss improved from 1.10248 to 1.08710, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0143 - precision: 0.6417 - val_loss: 1.0871 - val_precision: 0.6586\n",
      "Epoch 13/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0096 - precision: 0.6371\n",
      "Epoch 13: val_loss improved from 1.08710 to 1.06938, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0106 - precision: 0.6354 - val_loss: 1.0694 - val_precision: 0.6562\n",
      "Epoch 14/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0065 - precision: 0.6230\n",
      "Epoch 14: val_loss improved from 1.06938 to 1.06765, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0057 - precision: 0.6232 - val_loss: 1.0677 - val_precision: 0.6468\n",
      "Epoch 15/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9869 - precision: 0.6304\n",
      "Epoch 15: val_loss improved from 1.06765 to 1.05226, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9893 - precision: 0.6304 - val_loss: 1.0523 - val_precision: 0.6569\n",
      "Epoch 16/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9781 - precision: 0.6268\n",
      "Epoch 16: val_loss improved from 1.05226 to 1.04630, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9806 - precision: 0.6272 - val_loss: 1.0463 - val_precision: 0.6562\n",
      "Epoch 17/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9704 - precision: 0.6336\n",
      "Epoch 17: val_loss did not improve from 1.04630\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9693 - precision: 0.6338 - val_loss: 1.0470 - val_precision: 0.6393\n",
      "Epoch 18/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9604 - precision: 0.6330\n",
      "Epoch 18: val_loss did not improve from 1.04630\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9612 - precision: 0.6319 - val_loss: 1.0483 - val_precision: 0.6329\n",
      "Epoch 19/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9487 - precision: 0.6322\n",
      "Epoch 19: val_loss improved from 1.04630 to 1.04362, saving model to model_14.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9525 - precision: 0.6295 - val_loss: 1.0436 - val_precision: 0.6415\n",
      "Epoch 20/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9437 - precision: 0.6384\n",
      "Epoch 20: val_loss improved from 1.04362 to 1.04173, saving model to model_14.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 6ms/step - loss: 0.9437 - precision: 0.6384 - val_loss: 1.0417 - val_precision: 0.6399\n",
      "Epoch 21/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9400 - precision: 0.6362\n",
      "Epoch 21: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9395 - precision: 0.6367 - val_loss: 1.0519 - val_precision: 0.6284\n",
      "Epoch 22/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9159 - precision: 0.6463\n",
      "Epoch 22: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9148 - precision: 0.6469 - val_loss: 1.0596 - val_precision: 0.6232\n",
      "Epoch 23/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9196 - precision: 0.6316\n",
      "Epoch 23: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9199 - precision: 0.6315 - val_loss: 1.0491 - val_precision: 0.6249\n",
      "Epoch 24/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9229 - precision: 0.6390\n",
      "Epoch 24: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9223 - precision: 0.6414 - val_loss: 1.0497 - val_precision: 0.6201\n",
      "Epoch 25/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9141 - precision: 0.6338\n",
      "Epoch 25: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9183 - precision: 0.6353 - val_loss: 1.0431 - val_precision: 0.6267\n",
      "Epoch 26/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9161 - precision: 0.6426\n",
      "Epoch 26: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9146 - precision: 0.6437 - val_loss: 1.0559 - val_precision: 0.6226\n",
      "Epoch 27/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9038 - precision: 0.6391\n",
      "Epoch 27: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9093 - precision: 0.6374 - val_loss: 1.0418 - val_precision: 0.6296\n",
      "Epoch 28/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9066 - precision: 0.6433\n",
      "Epoch 28: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9057 - precision: 0.6420 - val_loss: 1.0583 - val_precision: 0.6156\n",
      "Epoch 29/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9000 - precision: 0.6430\n",
      "Epoch 29: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9015 - precision: 0.6431 - val_loss: 1.0661 - val_precision: 0.6160\n",
      "Epoch 30/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8979 - precision: 0.6372\n",
      "Epoch 30: val_loss did not improve from 1.04173\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8992 - precision: 0.6370 - val_loss: 1.0582 - val_precision: 0.6205\n",
      "Epoch 30: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9362 - precision: 0.6548\n",
      "Combinación 13 = (True, True, False, 8, 0.25) \n",
      " precision train: [0.9361562132835388, 0.6548336148262024]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 15: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.5936 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.51181, saving model to model_15.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5936 - precision: 0.0000e+00 - val_loss: 1.5118 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.4680 - precision: 0.6282\n",
      "Epoch 2: val_loss improved from 1.51181 to 1.35742, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.4676 - precision: 0.6234 - val_loss: 1.3574 - val_precision: 0.6626\n",
      "Epoch 3/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.4056 - precision: 0.6177\n",
      "Epoch 3: val_loss improved from 1.35742 to 1.33283, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.4067 - precision: 0.6149 - val_loss: 1.3328 - val_precision: 0.6324\n",
      "Epoch 4/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.3784 - precision: 0.6379\n",
      "Epoch 4: val_loss improved from 1.33283 to 1.29971, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.3782 - precision: 0.6401 - val_loss: 1.2997 - val_precision: 0.6687\n",
      "Epoch 5/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.3557 - precision: 0.6592\n",
      "Epoch 5: val_loss improved from 1.29971 to 1.27485, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3588 - precision: 0.6563 - val_loss: 1.2748 - val_precision: 0.7136\n",
      "Epoch 6/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.3336 - precision: 0.6552\n",
      "Epoch 6: val_loss improved from 1.27485 to 1.24395, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3330 - precision: 0.6567 - val_loss: 1.2439 - val_precision: 0.6916\n",
      "Epoch 7/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.3120 - precision: 0.6565\n",
      "Epoch 7: val_loss improved from 1.24395 to 1.22889, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3120 - precision: 0.6571 - val_loss: 1.2289 - val_precision: 0.7264\n",
      "Epoch 8/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.2829 - precision: 0.6655\n",
      "Epoch 8: val_loss improved from 1.22889 to 1.21917, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2834 - precision: 0.6687 - val_loss: 1.2192 - val_precision: 0.7194\n",
      "Epoch 9/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.2738 - precision: 0.6654\n",
      "Epoch 9: val_loss improved from 1.21917 to 1.21094, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2756 - precision: 0.6632 - val_loss: 1.2109 - val_precision: 0.7057\n",
      "Epoch 10/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2624 - precision: 0.6654\n",
      "Epoch 10: val_loss improved from 1.21094 to 1.20595, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2604 - precision: 0.6639 - val_loss: 1.2060 - val_precision: 0.7048\n",
      "Epoch 11/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.2566 - precision: 0.6679\n",
      "Epoch 11: val_loss improved from 1.20595 to 1.20539, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2552 - precision: 0.6685 - val_loss: 1.2054 - val_precision: 0.7072\n",
      "Epoch 12/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.2472 - precision: 0.6672\n",
      "Epoch 12: val_loss improved from 1.20539 to 1.20137, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2456 - precision: 0.6654 - val_loss: 1.2014 - val_precision: 0.7065\n",
      "Epoch 13/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2454 - precision: 0.6722\n",
      "Epoch 13: val_loss did not improve from 1.20137\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2432 - precision: 0.6726 - val_loss: 1.2051 - val_precision: 0.6941\n",
      "Epoch 14/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.2478 - precision: 0.6603\n",
      "Epoch 14: val_loss improved from 1.20137 to 1.19654, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2471 - precision: 0.6603 - val_loss: 1.1965 - val_precision: 0.7001\n",
      "Epoch 15/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2183 - precision: 0.6713\n",
      "Epoch 15: val_loss did not improve from 1.19654\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2181 - precision: 0.6725 - val_loss: 1.1985 - val_precision: 0.6983\n",
      "Epoch 16/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.2224 - precision: 0.6672\n",
      "Epoch 16: val_loss did not improve from 1.19654\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2240 - precision: 0.6682 - val_loss: 1.2002 - val_precision: 0.7205\n",
      "Epoch 17/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2208 - precision: 0.6793\n",
      "Epoch 17: val_loss improved from 1.19654 to 1.18608, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2228 - precision: 0.6763 - val_loss: 1.1861 - val_precision: 0.7182\n",
      "Epoch 18/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2165 - precision: 0.6654\n",
      "Epoch 18: val_loss improved from 1.18608 to 1.17997, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2184 - precision: 0.6655 - val_loss: 1.1800 - val_precision: 0.7116\n",
      "Epoch 19/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.2202 - precision: 0.6576\n",
      "Epoch 19: val_loss improved from 1.17997 to 1.17776, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2180 - precision: 0.6570 - val_loss: 1.1778 - val_precision: 0.7040\n",
      "Epoch 20/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2056 - precision: 0.6667\n",
      "Epoch 20: val_loss improved from 1.17776 to 1.17367, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2050 - precision: 0.6655 - val_loss: 1.1737 - val_precision: 0.7016\n",
      "Epoch 21/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.2146 - precision: 0.6571\n",
      "Epoch 21: val_loss did not improve from 1.17367\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2148 - precision: 0.6577 - val_loss: 1.1743 - val_precision: 0.7087\n",
      "Epoch 22/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.2018 - precision: 0.6444\n",
      "Epoch 22: val_loss improved from 1.17367 to 1.17350, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2056 - precision: 0.6445 - val_loss: 1.1735 - val_precision: 0.7093\n",
      "Epoch 23/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1931 - precision: 0.6566\n",
      "Epoch 23: val_loss did not improve from 1.17350\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1927 - precision: 0.6567 - val_loss: 1.1753 - val_precision: 0.7087\n",
      "Epoch 24/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1932 - precision: 0.6474\n",
      "Epoch 24: val_loss improved from 1.17350 to 1.16720, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1913 - precision: 0.6485 - val_loss: 1.1672 - val_precision: 0.7099\n",
      "Epoch 25/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2022 - precision: 0.6442\n",
      "Epoch 25: val_loss improved from 1.16720 to 1.16336, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1982 - precision: 0.6450 - val_loss: 1.1634 - val_precision: 0.6999\n",
      "Epoch 26/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1854 - precision: 0.6456\n",
      "Epoch 26: val_loss improved from 1.16336 to 1.15771, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1873 - precision: 0.6425 - val_loss: 1.1577 - val_precision: 0.7120\n",
      "Epoch 27/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1807 - precision: 0.6486\n",
      "Epoch 27: val_loss did not improve from 1.15771\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1809 - precision: 0.6489 - val_loss: 1.1597 - val_precision: 0.6977\n",
      "Epoch 28/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1902 - precision: 0.6270\n",
      "Epoch 28: val_loss did not improve from 1.15771\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1865 - precision: 0.6287 - val_loss: 1.1590 - val_precision: 0.7059\n",
      "Epoch 29/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1760 - precision: 0.6386\n",
      "Epoch 29: val_loss did not improve from 1.15771\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1736 - precision: 0.6406 - val_loss: 1.1614 - val_precision: 0.6730\n",
      "Epoch 30/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.1742 - precision: 0.6344\n",
      "Epoch 30: val_loss improved from 1.15771 to 1.15177, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1749 - precision: 0.6360 - val_loss: 1.1518 - val_precision: 0.6785\n",
      "Epoch 31/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1738 - precision: 0.6300\n",
      "Epoch 31: val_loss improved from 1.15177 to 1.14620, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1732 - precision: 0.6304 - val_loss: 1.1462 - val_precision: 0.6718\n",
      "Epoch 32/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1579 - precision: 0.6426\n",
      "Epoch 32: val_loss did not improve from 1.14620\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1574 - precision: 0.6435 - val_loss: 1.1469 - val_precision: 0.6723\n",
      "Epoch 33/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1700 - precision: 0.6326\n",
      "Epoch 33: val_loss did not improve from 1.14620\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1696 - precision: 0.6329 - val_loss: 1.1506 - val_precision: 0.6567\n",
      "Epoch 34/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1718 - precision: 0.6385\n",
      "Epoch 34: val_loss improved from 1.14620 to 1.14448, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1694 - precision: 0.6374 - val_loss: 1.1445 - val_precision: 0.6548\n",
      "Epoch 35/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1711 - precision: 0.6273\n",
      "Epoch 35: val_loss did not improve from 1.14448\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1686 - precision: 0.6274 - val_loss: 1.1452 - val_precision: 0.6625\n",
      "Epoch 36/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1564 - precision: 0.6217\n",
      "Epoch 36: val_loss improved from 1.14448 to 1.13833, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1596 - precision: 0.6210 - val_loss: 1.1383 - val_precision: 0.6663\n",
      "Epoch 37/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1591 - precision: 0.6405\n",
      "Epoch 37: val_loss did not improve from 1.13833\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1582 - precision: 0.6390 - val_loss: 1.1498 - val_precision: 0.6436\n",
      "Epoch 38/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1673 - precision: 0.6234\n",
      "Epoch 38: val_loss improved from 1.13833 to 1.13566, saving model to model_15.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1699 - precision: 0.6226 - val_loss: 1.1357 - val_precision: 0.6531\n",
      "Epoch 39/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.1466 - precision: 0.6324\n",
      "Epoch 39: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1466 - precision: 0.6297 - val_loss: 1.1427 - val_precision: 0.6580\n",
      "Epoch 40/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1565 - precision: 0.6226\n",
      "Epoch 40: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1563 - precision: 0.6229 - val_loss: 1.1413 - val_precision: 0.6473\n",
      "Epoch 41/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1475 - precision: 0.6304\n",
      "Epoch 41: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1453 - precision: 0.6299 - val_loss: 1.1463 - val_precision: 0.6550\n",
      "Epoch 42/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1454 - precision: 0.6385\n",
      "Epoch 42: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1458 - precision: 0.6371 - val_loss: 1.1369 - val_precision: 0.6516\n",
      "Epoch 43/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1536 - precision: 0.6215\n",
      "Epoch 43: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1554 - precision: 0.6230 - val_loss: 1.1379 - val_precision: 0.6512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1350 - precision: 0.6287\n",
      "Epoch 44: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1368 - precision: 0.6284 - val_loss: 1.1364 - val_precision: 0.6501\n",
      "Epoch 45/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1387 - precision: 0.6268\n",
      "Epoch 45: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1371 - precision: 0.6286 - val_loss: 1.1416 - val_precision: 0.6364\n",
      "Epoch 46/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1377 - precision: 0.6265\n",
      "Epoch 46: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1395 - precision: 0.6246 - val_loss: 1.1392 - val_precision: 0.6464\n",
      "Epoch 47/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1412 - precision: 0.6181\n",
      "Epoch 47: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1388 - precision: 0.6196 - val_loss: 1.1386 - val_precision: 0.6428\n",
      "Epoch 48/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1430 - precision: 0.6365\n",
      "Epoch 48: val_loss did not improve from 1.13566\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1439 - precision: 0.6352 - val_loss: 1.1444 - val_precision: 0.6368\n",
      "Epoch 48: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.0515 - precision: 0.6738\n",
      "Combinación 14 = (True, True, False, 8, 0.5) \n",
      " precision train: [1.0515143871307373, 0.6737931966781616]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 16: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.4192 - precision: 0.6901\n",
      "Epoch 1: val_loss improved from inf to 1.16389, saving model to model_16.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.4141 - precision: 0.6872 - val_loss: 1.1639 - val_precision: 0.6692\n",
      "Epoch 2/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1055 - precision: 0.6784\n",
      "Epoch 2: val_loss improved from 1.16389 to 1.09648, saving model to model_16.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1013 - precision: 0.6779 - val_loss: 1.0965 - val_precision: 0.6533\n",
      "Epoch 3/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.0083 - precision: 0.6420\n",
      "Epoch 3: val_loss improved from 1.09648 to 1.06441, saving model to model_16.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0106 - precision: 0.6410 - val_loss: 1.0644 - val_precision: 0.6530\n",
      "Epoch 4/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9471 - precision: 0.6285\n",
      "Epoch 4: val_loss improved from 1.06441 to 1.04904, saving model to model_16.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9483 - precision: 0.6275 - val_loss: 1.0490 - val_precision: 0.6325\n",
      "Epoch 5/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.9195 - precision: 0.6214\n",
      "Epoch 5: val_loss improved from 1.04904 to 1.02828, saving model to model_16.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9237 - precision: 0.6208 - val_loss: 1.0283 - val_precision: 0.6341\n",
      "Epoch 6/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8998 - precision: 0.6282\n",
      "Epoch 6: val_loss did not improve from 1.02828\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9000 - precision: 0.6278 - val_loss: 1.0342 - val_precision: 0.6284\n",
      "Epoch 7/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8821 - precision: 0.6317\n",
      "Epoch 7: val_loss improved from 1.02828 to 1.02006, saving model to model_16.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8834 - precision: 0.6321 - val_loss: 1.0201 - val_precision: 0.6296\n",
      "Epoch 8/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8642 - precision: 0.6362\n",
      "Epoch 8: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8649 - precision: 0.6373 - val_loss: 1.0487 - val_precision: 0.6149\n",
      "Epoch 9/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8455 - precision: 0.6408\n",
      "Epoch 9: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8468 - precision: 0.6415 - val_loss: 1.0325 - val_precision: 0.6154\n",
      "Epoch 10/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.8332 - precision: 0.6539\n",
      "Epoch 10: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8367 - precision: 0.6493 - val_loss: 1.0552 - val_precision: 0.6091\n",
      "Epoch 11/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8253 - precision: 0.6572\n",
      "Epoch 11: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8205 - precision: 0.6553 - val_loss: 1.0263 - val_precision: 0.6247\n",
      "Epoch 12/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.8102 - precision: 0.6566\n",
      "Epoch 12: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8109 - precision: 0.6562 - val_loss: 1.0384 - val_precision: 0.6156\n",
      "Epoch 13/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7947 - precision: 0.6612\n",
      "Epoch 13: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7933 - precision: 0.6626 - val_loss: 1.0393 - val_precision: 0.6196\n",
      "Epoch 14/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7932 - precision: 0.6641\n",
      "Epoch 14: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7957 - precision: 0.6638 - val_loss: 1.0349 - val_precision: 0.6204\n",
      "Epoch 15/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7849 - precision: 0.6685\n",
      "Epoch 15: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7849 - precision: 0.6685 - val_loss: 1.0549 - val_precision: 0.6117\n",
      "Epoch 16/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7719 - precision: 0.6717\n",
      "Epoch 16: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7719 - precision: 0.6717 - val_loss: 1.0629 - val_precision: 0.6189\n",
      "Epoch 17/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7706 - precision: 0.6720\n",
      "Epoch 17: val_loss did not improve from 1.02006\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7685 - precision: 0.6725 - val_loss: 1.0670 - val_precision: 0.6045\n",
      "Epoch 17: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8929 - precision: 0.6628\n",
      "Combinación 15 = (True, True, False, 16, 0.1) \n",
      " precision train: [0.8928824067115784, 0.6628172397613525]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 17: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.4737 - precision: 0.6180\n",
      "Epoch 1: val_loss improved from inf to 1.30792, saving model to model_17.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.4665 - precision: 0.6241 - val_loss: 1.3079 - val_precision: 0.6437\n",
      "Epoch 2/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.2640 - precision: 0.6365\n",
      "Epoch 2: val_loss improved from 1.30792 to 1.24222, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2637 - precision: 0.6377 - val_loss: 1.2422 - val_precision: 0.7133\n",
      "Epoch 3/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1627 - precision: 0.6260\n",
      "Epoch 3: val_loss improved from 1.24222 to 1.18338, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1598 - precision: 0.6278 - val_loss: 1.1834 - val_precision: 0.6342\n",
      "Epoch 4/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0984 - precision: 0.6307\n",
      "Epoch 4: val_loss improved from 1.18338 to 1.16823, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0964 - precision: 0.6321 - val_loss: 1.1682 - val_precision: 0.6422\n",
      "Epoch 5/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0809 - precision: 0.6324\n",
      "Epoch 5: val_loss improved from 1.16823 to 1.12866, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0809 - precision: 0.6324 - val_loss: 1.1287 - val_precision: 0.6586\n",
      "Epoch 6/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0468 - precision: 0.6430\n",
      "Epoch 6: val_loss improved from 1.12866 to 1.11960, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0465 - precision: 0.6430 - val_loss: 1.1196 - val_precision: 0.6485\n",
      "Epoch 7/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0118 - precision: 0.6527\n",
      "Epoch 7: val_loss improved from 1.11960 to 1.07679, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0122 - precision: 0.6528 - val_loss: 1.0768 - val_precision: 0.6675\n",
      "Epoch 8/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9810 - precision: 0.6550\n",
      "Epoch 8: val_loss improved from 1.07679 to 1.04884, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9781 - precision: 0.6526 - val_loss: 1.0488 - val_precision: 0.6540\n",
      "Epoch 9/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9462 - precision: 0.6333\n",
      "Epoch 9: val_loss improved from 1.04884 to 1.04084, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9452 - precision: 0.6330 - val_loss: 1.0408 - val_precision: 0.6149\n",
      "Epoch 10/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.9205 - precision: 0.6246\n",
      "Epoch 10: val_loss improved from 1.04084 to 1.03577, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9234 - precision: 0.6250 - val_loss: 1.0358 - val_precision: 0.6112\n",
      "Epoch 11/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9128 - precision: 0.6215\n",
      "Epoch 11: val_loss improved from 1.03577 to 1.03419, saving model to model_17.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9130 - precision: 0.6224 - val_loss: 1.0342 - val_precision: 0.6142\n",
      "Epoch 12/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9019 - precision: 0.6253\n",
      "Epoch 12: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9018 - precision: 0.6250 - val_loss: 1.0382 - val_precision: 0.6129\n",
      "Epoch 13/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8816 - precision: 0.6324\n",
      "Epoch 13: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8792 - precision: 0.6341 - val_loss: 1.0486 - val_precision: 0.6044\n",
      "Epoch 14/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8731 - precision: 0.6345\n",
      "Epoch 14: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8731 - precision: 0.6345 - val_loss: 1.0402 - val_precision: 0.6095\n",
      "Epoch 15/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8755 - precision: 0.6375\n",
      "Epoch 15: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8745 - precision: 0.6363 - val_loss: 1.0384 - val_precision: 0.6039\n",
      "Epoch 16/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8533 - precision: 0.6399\n",
      "Epoch 16: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8538 - precision: 0.6405 - val_loss: 1.0358 - val_precision: 0.6108\n",
      "Epoch 17/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8488 - precision: 0.6417\n",
      "Epoch 17: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8480 - precision: 0.6428 - val_loss: 1.0646 - val_precision: 0.6057\n",
      "Epoch 18/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8345 - precision: 0.6481\n",
      "Epoch 18: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8349 - precision: 0.6475 - val_loss: 1.0560 - val_precision: 0.6102\n",
      "Epoch 19/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8338 - precision: 0.6541\n",
      "Epoch 19: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8301 - precision: 0.6549 - val_loss: 1.0546 - val_precision: 0.6012\n",
      "Epoch 20/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8293 - precision: 0.6510\n",
      "Epoch 20: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8287 - precision: 0.6491 - val_loss: 1.0680 - val_precision: 0.5942\n",
      "Epoch 21/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.8183 - precision: 0.6598\n",
      "Epoch 21: val_loss did not improve from 1.03419\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8155 - precision: 0.6609 - val_loss: 1.0665 - val_precision: 0.6040\n",
      "Epoch 21: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9195 - precision: 0.6505\n",
      "Combinación 16 = (True, True, False, 16, 0.25) \n",
      " precision train: [0.919477105140686, 0.6504517793655396]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 18: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.5846 - precision: 1.0000    \n",
      "Epoch 1: val_loss improved from inf to 1.39064, saving model to model_18.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.5819 - precision: 1.0000 - val_loss: 1.3906 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.3208 - precision: 0.5868\n",
      "Epoch 2: val_loss improved from 1.39064 to 1.18645, saving model to model_18.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3193 - precision: 0.5872 - val_loss: 1.1864 - val_precision: 0.6460\n",
      "Epoch 3/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.2190 - precision: 0.6015\n",
      "Epoch 3: val_loss improved from 1.18645 to 1.14352, saving model to model_18.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.2190 - precision: 0.6015 - val_loss: 1.1435 - val_precision: 0.6346\n",
      "Epoch 4/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1808 - precision: 0.6060\n",
      "Epoch 4: val_loss improved from 1.14352 to 1.12246, saving model to model_18.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1764 - precision: 0.6085 - val_loss: 1.1225 - val_precision: 0.6322\n",
      "Epoch 5/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1373 - precision: 0.6150\n",
      "Epoch 5: val_loss improved from 1.12246 to 1.09388, saving model to model_18.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1389 - precision: 0.6154 - val_loss: 1.0939 - val_precision: 0.6328\n",
      "Epoch 6/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1251 - precision: 0.6125\n",
      "Epoch 6: val_loss improved from 1.09388 to 1.07273, saving model to model_18.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1239 - precision: 0.6127 - val_loss: 1.0727 - val_precision: 0.6333\n",
      "Epoch 7/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.0974 - precision: 0.6105\n",
      "Epoch 7: val_loss improved from 1.07273 to 1.05109, saving model to model_18.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0992 - precision: 0.6065 - val_loss: 1.0511 - val_precision: 0.6266\n",
      "Epoch 8/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.0720 - precision: 0.6161\n",
      "Epoch 8: val_loss improved from 1.05109 to 1.04478, saving model to model_18.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0710 - precision: 0.6155 - val_loss: 1.0448 - val_precision: 0.6159\n",
      "Epoch 9/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0510 - precision: 0.6105\n",
      "Epoch 9: val_loss improved from 1.04478 to 1.03818, saving model to model_18.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0525 - precision: 0.6092 - val_loss: 1.0382 - val_precision: 0.6145\n",
      "Epoch 10/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0508 - precision: 0.6031\n",
      "Epoch 10: val_loss did not improve from 1.03818\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0501 - precision: 0.6033 - val_loss: 1.0394 - val_precision: 0.6106\n",
      "Epoch 11/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.0284 - precision: 0.6116\n",
      "Epoch 11: val_loss improved from 1.03818 to 1.03677, saving model to model_18.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0282 - precision: 0.6123 - val_loss: 1.0368 - val_precision: 0.6148\n",
      "Epoch 12/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0157 - precision: 0.6179\n",
      "Epoch 12: val_loss did not improve from 1.03677\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0193 - precision: 0.6165 - val_loss: 1.0381 - val_precision: 0.6153\n",
      "Epoch 13/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0279 - precision: 0.6035\n",
      "Epoch 13: val_loss did not improve from 1.03677\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0267 - precision: 0.6032 - val_loss: 1.0416 - val_precision: 0.6106\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0155 - precision: 0.6079\n",
      "Epoch 14: val_loss improved from 1.03677 to 1.03311, saving model to model_18.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0157 - precision: 0.6077 - val_loss: 1.0331 - val_precision: 0.6152\n",
      "Epoch 15/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0091 - precision: 0.6155\n",
      "Epoch 15: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0118 - precision: 0.6156 - val_loss: 1.0469 - val_precision: 0.6129\n",
      "Epoch 16/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.0081 - precision: 0.6190\n",
      "Epoch 16: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0074 - precision: 0.6190 - val_loss: 1.0498 - val_precision: 0.6048\n",
      "Epoch 17/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9932 - precision: 0.6169\n",
      "Epoch 17: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9956 - precision: 0.6166 - val_loss: 1.0382 - val_precision: 0.6106\n",
      "Epoch 18/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9832 - precision: 0.6192\n",
      "Epoch 18: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9839 - precision: 0.6188 - val_loss: 1.0474 - val_precision: 0.6131\n",
      "Epoch 19/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9954 - precision: 0.6191\n",
      "Epoch 19: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9954 - precision: 0.6191 - val_loss: 1.0334 - val_precision: 0.6088\n",
      "Epoch 20/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9720 - precision: 0.6203\n",
      "Epoch 20: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9730 - precision: 0.6204 - val_loss: 1.0443 - val_precision: 0.6055\n",
      "Epoch 21/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9666 - precision: 0.6257\n",
      "Epoch 21: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9635 - precision: 0.6270 - val_loss: 1.0609 - val_precision: 0.6046\n",
      "Epoch 22/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9805 - precision: 0.6195\n",
      "Epoch 22: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9811 - precision: 0.6196 - val_loss: 1.0484 - val_precision: 0.6088\n",
      "Epoch 23/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9832 - precision: 0.6246\n",
      "Epoch 23: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9830 - precision: 0.6248 - val_loss: 1.0386 - val_precision: 0.6117\n",
      "Epoch 24/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9560 - precision: 0.6265\n",
      "Epoch 24: val_loss did not improve from 1.03311\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9560 - precision: 0.6265 - val_loss: 1.0454 - val_precision: 0.6051\n",
      "Epoch 24: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9644 - precision: 0.6272\n",
      "Combinación 17 = (True, True, False, 16, 0.5) \n",
      " precision train: [0.964382529258728, 0.6272042989730835]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 19: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.3430 - precision: 0.6483\n",
      "Epoch 1: val_loss improved from inf to 1.15084, saving model to model_19.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.3417 - precision: 0.6438 - val_loss: 1.1508 - val_precision: 0.6396\n",
      "Epoch 2/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0382 - precision: 0.6258\n",
      "Epoch 2: val_loss improved from 1.15084 to 1.05471, saving model to model_19.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0382 - precision: 0.6258 - val_loss: 1.0547 - val_precision: 0.6272\n",
      "Epoch 3/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9165 - precision: 0.6187\n",
      "Epoch 3: val_loss improved from 1.05471 to 1.04083, saving model to model_19.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9229 - precision: 0.6192 - val_loss: 1.0408 - val_precision: 0.6155\n",
      "Epoch 4/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8730 - precision: 0.6323\n",
      "Epoch 4: val_loss improved from 1.04083 to 1.01151, saving model to model_19.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8749 - precision: 0.6336 - val_loss: 1.0115 - val_precision: 0.6227\n",
      "Epoch 5/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8430 - precision: 0.6313\n",
      "Epoch 5: val_loss did not improve from 1.01151\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8495 - precision: 0.6304 - val_loss: 1.0123 - val_precision: 0.6207\n",
      "Epoch 6/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8286 - precision: 0.6394\n",
      "Epoch 6: val_loss improved from 1.01151 to 1.00532, saving model to model_19.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8246 - precision: 0.6427 - val_loss: 1.0053 - val_precision: 0.6218\n",
      "Epoch 7/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7996 - precision: 0.6456\n",
      "Epoch 7: val_loss improved from 1.00532 to 0.97653, saving model to model_19.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7996 - precision: 0.6456 - val_loss: 0.9765 - val_precision: 0.6316\n",
      "Epoch 8/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7747 - precision: 0.6568\n",
      "Epoch 8: val_loss did not improve from 0.97653\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7756 - precision: 0.6561 - val_loss: 0.9820 - val_precision: 0.6278\n",
      "Epoch 9/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7587 - precision: 0.6602\n",
      "Epoch 9: val_loss did not improve from 0.97653\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7577 - precision: 0.6606 - val_loss: 0.9853 - val_precision: 0.6377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7372 - precision: 0.6729\n",
      "Epoch 10: val_loss did not improve from 0.97653\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7362 - precision: 0.6734 - val_loss: 1.0106 - val_precision: 0.6200\n",
      "Epoch 11/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7173 - precision: 0.6754\n",
      "Epoch 11: val_loss did not improve from 0.97653\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7162 - precision: 0.6765 - val_loss: 0.9798 - val_precision: 0.6331\n",
      "Epoch 12/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.6967 - precision: 0.6806\n",
      "Epoch 12: val_loss did not improve from 0.97653\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7010 - precision: 0.6811 - val_loss: 1.0004 - val_precision: 0.6258\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.6879 - precision: 0.6878\n",
      "Epoch 13: val_loss did not improve from 0.97653\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6855 - precision: 0.6886 - val_loss: 1.0418 - val_precision: 0.6217\n",
      "Epoch 14/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6829 - precision: 0.6913\n",
      "Epoch 14: val_loss improved from 0.97653 to 0.97273, saving model to model_19.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6821 - precision: 0.6912 - val_loss: 0.9727 - val_precision: 0.6350\n",
      "Epoch 15/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.6624 - precision: 0.6994\n",
      "Epoch 15: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6620 - precision: 0.6978 - val_loss: 0.9931 - val_precision: 0.6307\n",
      "Epoch 16/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6501 - precision: 0.6995\n",
      "Epoch 16: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6509 - precision: 0.6996 - val_loss: 1.0240 - val_precision: 0.6304\n",
      "Epoch 17/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6319 - precision: 0.7062\n",
      "Epoch 17: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6322 - precision: 0.7068 - val_loss: 1.0138 - val_precision: 0.6270\n",
      "Epoch 18/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.6260 - precision: 0.7102\n",
      "Epoch 18: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6255 - precision: 0.7074 - val_loss: 1.0476 - val_precision: 0.6202\n",
      "Epoch 19/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.6152 - precision: 0.7164\n",
      "Epoch 19: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6145 - precision: 0.7178 - val_loss: 1.0680 - val_precision: 0.6175\n",
      "Epoch 20/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6081 - precision: 0.7139\n",
      "Epoch 20: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6093 - precision: 0.7133 - val_loss: 1.0654 - val_precision: 0.6078\n",
      "Epoch 21/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.5948 - precision: 0.7204\n",
      "Epoch 21: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5955 - precision: 0.7199 - val_loss: 1.0556 - val_precision: 0.6152\n",
      "Epoch 22/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.5904 - precision: 0.7261\n",
      "Epoch 22: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5896 - precision: 0.7259 - val_loss: 1.0959 - val_precision: 0.6073\n",
      "Epoch 23/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.5769 - precision: 0.7238\n",
      "Epoch 23: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5787 - precision: 0.7230 - val_loss: 1.0782 - val_precision: 0.6159\n",
      "Epoch 24/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.5686 - precision: 0.7318\n",
      "Epoch 24: val_loss did not improve from 0.97273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5701 - precision: 0.7320 - val_loss: 1.1104 - val_precision: 0.6002\n",
      "Epoch 24: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7490 - precision: 0.7091\n",
      "Combinación 18 = (True, True, False, 32, 0.1) \n",
      " precision train: [0.7489979267120361, 0.7090849280357361]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 20: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.3891 - precision: 0.6556\n",
      "Epoch 1: val_loss improved from inf to 1.12037, saving model to model_20.h5\n",
      "240/240 [==============================] - 8s 12ms/step - loss: 1.3767 - precision: 0.6582 - val_loss: 1.1204 - val_precision: 0.6560\n",
      "Epoch 2/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9993 - precision: 0.6080\n",
      "Epoch 2: val_loss improved from 1.12037 to 1.03988, saving model to model_20.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9974 - precision: 0.6088 - val_loss: 1.0399 - val_precision: 0.6165\n",
      "Epoch 3/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9283 - precision: 0.6108\n",
      "Epoch 3: val_loss improved from 1.03988 to 1.01504, saving model to model_20.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9283 - precision: 0.6108 - val_loss: 1.0150 - val_precision: 0.6183\n",
      "Epoch 4/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9004 - precision: 0.6180\n",
      "Epoch 4: val_loss improved from 1.01504 to 1.00385, saving model to model_20.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9004 - precision: 0.6180 - val_loss: 1.0038 - val_precision: 0.6215\n",
      "Epoch 5/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8776 - precision: 0.6241\n",
      "Epoch 5: val_loss improved from 1.00385 to 0.99741, saving model to model_20.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8768 - precision: 0.6259 - val_loss: 0.9974 - val_precision: 0.6221\n",
      "Epoch 6/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8565 - precision: 0.6321\n",
      "Epoch 6: val_loss improved from 0.99741 to 0.99416, saving model to model_20.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8565 - precision: 0.6305 - val_loss: 0.9942 - val_precision: 0.6260\n",
      "Epoch 7/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8411 - precision: 0.6378\n",
      "Epoch 7: val_loss improved from 0.99416 to 0.98996, saving model to model_20.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8408 - precision: 0.6373 - val_loss: 0.9900 - val_precision: 0.6206\n",
      "Epoch 8/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8242 - precision: 0.6431\n",
      "Epoch 8: val_loss did not improve from 0.98996\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8242 - precision: 0.6431 - val_loss: 0.9942 - val_precision: 0.6205\n",
      "Epoch 9/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8197 - precision: 0.6454\n",
      "Epoch 9: val_loss did not improve from 0.98996\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8198 - precision: 0.6451 - val_loss: 0.9907 - val_precision: 0.6271\n",
      "Epoch 10/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7988 - precision: 0.6514\n",
      "Epoch 10: val_loss did not improve from 0.98996\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8009 - precision: 0.6530 - val_loss: 0.9933 - val_precision: 0.6253\n",
      "Epoch 11/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7980 - precision: 0.6489\n",
      "Epoch 11: val_loss did not improve from 0.98996\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7942 - precision: 0.6506 - val_loss: 1.0022 - val_precision: 0.6255\n",
      "Epoch 12/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7782 - precision: 0.6540\n",
      "Epoch 12: val_loss improved from 0.98996 to 0.97927, saving model to model_20.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7800 - precision: 0.6543 - val_loss: 0.9793 - val_precision: 0.6375\n",
      "Epoch 13/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7738 - precision: 0.6591\n",
      "Epoch 13: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7741 - precision: 0.6595 - val_loss: 1.0087 - val_precision: 0.6222\n",
      "Epoch 14/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7658 - precision: 0.6640\n",
      "Epoch 14: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7645 - precision: 0.6643 - val_loss: 0.9950 - val_precision: 0.6320\n",
      "Epoch 15/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7569 - precision: 0.6666\n",
      "Epoch 15: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7587 - precision: 0.6655 - val_loss: 1.0361 - val_precision: 0.6117\n",
      "Epoch 16/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7541 - precision: 0.6637\n",
      "Epoch 16: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7493 - precision: 0.6654 - val_loss: 1.0326 - val_precision: 0.6153\n",
      "Epoch 17/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7347 - precision: 0.6765\n",
      "Epoch 17: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7312 - precision: 0.6781 - val_loss: 1.0362 - val_precision: 0.6149\n",
      "Epoch 18/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7334 - precision: 0.6777\n",
      "Epoch 18: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7328 - precision: 0.6773 - val_loss: 1.0280 - val_precision: 0.6197\n",
      "Epoch 19/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7190 - precision: 0.6846\n",
      "Epoch 19: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7136 - precision: 0.6857 - val_loss: 1.0290 - val_precision: 0.6207\n",
      "Epoch 20/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7094 - precision: 0.6881\n",
      "Epoch 20: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7094 - precision: 0.6881 - val_loss: 1.0325 - val_precision: 0.6207\n",
      "Epoch 21/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7108 - precision: 0.6869\n",
      "Epoch 21: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7101 - precision: 0.6866 - val_loss: 1.0000 - val_precision: 0.6203\n",
      "Epoch 22/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.6912 - precision: 0.6900\n",
      "Epoch 22: val_loss did not improve from 0.97927\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6940 - precision: 0.6888 - val_loss: 1.0391 - val_precision: 0.6137\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8188 - precision: 0.6866\n",
      "Combinación 19 = (True, True, False, 32, 0.25) \n",
      " precision train: [0.8187582492828369, 0.6865880489349365]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 21: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.5025 - precision: 0.6608\n",
      "Epoch 1: val_loss improved from inf to 1.25807, saving model to model_21.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5025 - precision: 0.6608 - val_loss: 1.2581 - val_precision: 0.7025\n",
      "Epoch 2/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.2019 - precision: 0.6130\n",
      "Epoch 2: val_loss improved from 1.25807 to 1.15045, saving model to model_21.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2016 - precision: 0.6149 - val_loss: 1.1504 - val_precision: 0.6505\n",
      "Epoch 3/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1081 - precision: 0.6347\n",
      "Epoch 3: val_loss improved from 1.15045 to 1.11327, saving model to model_21.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1093 - precision: 0.6317 - val_loss: 1.1133 - val_precision: 0.6366\n",
      "Epoch 4/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.0583 - precision: 0.6301\n",
      "Epoch 4: val_loss improved from 1.11327 to 1.05942, saving model to model_21.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0607 - precision: 0.6269 - val_loss: 1.0594 - val_precision: 0.6687\n",
      "Epoch 5/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0164 - precision: 0.6208\n",
      "Epoch 5: val_loss improved from 1.05942 to 1.05162, saving model to model_21.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0171 - precision: 0.6216 - val_loss: 1.0516 - val_precision: 0.6248\n",
      "Epoch 6/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9864 - precision: 0.6132\n",
      "Epoch 6: val_loss improved from 1.05162 to 1.04227, saving model to model_21.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9866 - precision: 0.6144 - val_loss: 1.0423 - val_precision: 0.6118\n",
      "Epoch 7/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9730 - precision: 0.6121\n",
      "Epoch 7: val_loss improved from 1.04227 to 1.03214, saving model to model_21.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9718 - precision: 0.6112 - val_loss: 1.0321 - val_precision: 0.6241\n",
      "Epoch 8/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9629 - precision: 0.6149\n",
      "Epoch 8: val_loss improved from 1.03214 to 1.03206, saving model to model_21.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9606 - precision: 0.6148 - val_loss: 1.0321 - val_precision: 0.6126\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9448 - precision: 0.6207\n",
      "Epoch 9: val_loss improved from 1.03206 to 1.02602, saving model to model_21.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9453 - precision: 0.6208 - val_loss: 1.0260 - val_precision: 0.6237\n",
      "Epoch 10/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9379 - precision: 0.6205\n",
      "Epoch 10: val_loss did not improve from 1.02602\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9375 - precision: 0.6208 - val_loss: 1.0303 - val_precision: 0.6162\n",
      "Epoch 11/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9254 - precision: 0.6227\n",
      "Epoch 11: val_loss did not improve from 1.02602\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9296 - precision: 0.6225 - val_loss: 1.0274 - val_precision: 0.6125\n",
      "Epoch 12/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9126 - precision: 0.6268\n",
      "Epoch 12: val_loss improved from 1.02602 to 1.01118, saving model to model_21.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9163 - precision: 0.6268 - val_loss: 1.0112 - val_precision: 0.6259\n",
      "Epoch 13/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9172 - precision: 0.6267\n",
      "Epoch 13: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9145 - precision: 0.6255 - val_loss: 1.0287 - val_precision: 0.6138\n",
      "Epoch 14/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9059 - precision: 0.6300\n",
      "Epoch 14: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9059 - precision: 0.6300 - val_loss: 1.0530 - val_precision: 0.6059\n",
      "Epoch 15/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9067 - precision: 0.6271\n",
      "Epoch 15: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9014 - precision: 0.6280 - val_loss: 1.0442 - val_precision: 0.6074\n",
      "Epoch 16/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8954 - precision: 0.6327\n",
      "Epoch 16: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8960 - precision: 0.6327 - val_loss: 1.0361 - val_precision: 0.6130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8849 - precision: 0.6342\n",
      "Epoch 17: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8846 - precision: 0.6338 - val_loss: 1.0347 - val_precision: 0.6108\n",
      "Epoch 18/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8842 - precision: 0.6323\n",
      "Epoch 18: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8851 - precision: 0.6317 - val_loss: 1.0394 - val_precision: 0.6134\n",
      "Epoch 19/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8839 - precision: 0.6388\n",
      "Epoch 19: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8823 - precision: 0.6371 - val_loss: 1.0186 - val_precision: 0.6351\n",
      "Epoch 20/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8784 - precision: 0.6379\n",
      "Epoch 20: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8760 - precision: 0.6387 - val_loss: 1.0251 - val_precision: 0.6223\n",
      "Epoch 21/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8658 - precision: 0.6380\n",
      "Epoch 21: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8656 - precision: 0.6386 - val_loss: 1.0295 - val_precision: 0.6157\n",
      "Epoch 22/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8604 - precision: 0.6450\n",
      "Epoch 22: val_loss did not improve from 1.01118\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8621 - precision: 0.6420 - val_loss: 1.0429 - val_precision: 0.6112\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9289 - precision: 0.6396\n",
      "Combinación 20 = (True, True, False, 32, 0.5) \n",
      " precision train: [0.9288646578788757, 0.6395660638809204]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 22: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.2374 - precision: 0.6080\n",
      "Epoch 1: val_loss improved from inf to 1.05657, saving model to model_22.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.2374 - precision: 0.6080 - val_loss: 1.0566 - val_precision: 0.6177\n",
      "Epoch 2/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9125 - precision: 0.6084\n",
      "Epoch 2: val_loss improved from 1.05657 to 0.99228, saving model to model_22.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9123 - precision: 0.6079 - val_loss: 0.9923 - val_precision: 0.6304\n",
      "Epoch 3/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8654 - precision: 0.6193\n",
      "Epoch 3: val_loss did not improve from 0.99228\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8613 - precision: 0.6222 - val_loss: 1.0025 - val_precision: 0.6180\n",
      "Epoch 4/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8293 - precision: 0.6269\n",
      "Epoch 4: val_loss improved from 0.99228 to 0.98840, saving model to model_22.h5\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.8302 - precision: 0.6272 - val_loss: 0.9884 - val_precision: 0.6226\n",
      "Epoch 5/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8006 - precision: 0.6398\n",
      "Epoch 5: val_loss did not improve from 0.98840\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8001 - precision: 0.6398 - val_loss: 0.9936 - val_precision: 0.6267\n",
      "Epoch 6/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7768 - precision: 0.6481\n",
      "Epoch 6: val_loss improved from 0.98840 to 0.95092, saving model to model_22.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7769 - precision: 0.6482 - val_loss: 0.9509 - val_precision: 0.6341\n",
      "Epoch 7/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7512 - precision: 0.6599\n",
      "Epoch 7: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7503 - precision: 0.6599 - val_loss: 0.9550 - val_precision: 0.6378\n",
      "Epoch 8/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7290 - precision: 0.6651\n",
      "Epoch 8: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7287 - precision: 0.6644 - val_loss: 0.9741 - val_precision: 0.6332\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7137 - precision: 0.6709\n",
      "Epoch 9: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7112 - precision: 0.6707 - val_loss: 0.9655 - val_precision: 0.6397\n",
      "Epoch 10/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.6945 - precision: 0.6700\n",
      "Epoch 10: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6969 - precision: 0.6697 - val_loss: 0.9584 - val_precision: 0.6442\n",
      "Epoch 11/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6798 - precision: 0.6797\n",
      "Epoch 11: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6793 - precision: 0.6798 - val_loss: 1.0082 - val_precision: 0.6202\n",
      "Epoch 12/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6570 - precision: 0.6835\n",
      "Epoch 12: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6574 - precision: 0.6834 - val_loss: 0.9764 - val_precision: 0.6412\n",
      "Epoch 13/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.6412 - precision: 0.6907\n",
      "Epoch 13: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6418 - precision: 0.6905 - val_loss: 1.0075 - val_precision: 0.6252\n",
      "Epoch 14/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.6281 - precision: 0.6999\n",
      "Epoch 14: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6289 - precision: 0.6987 - val_loss: 1.0039 - val_precision: 0.6333\n",
      "Epoch 15/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.6162 - precision: 0.6975\n",
      "Epoch 15: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6161 - precision: 0.6981 - val_loss: 0.9871 - val_precision: 0.6405\n",
      "Epoch 16/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.5934 - precision: 0.7063\n",
      "Epoch 16: val_loss did not improve from 0.95092\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5915 - precision: 0.7072 - val_loss: 1.0491 - val_precision: 0.6236\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7090 - precision: 0.7198\n",
      "Combinación 21 = (True, True, False, 64, 0.1) \n",
      " precision train: [0.7090219855308533, 0.7198400497436523]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 23: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2984 - precision: 0.6233\n",
      "Epoch 1: val_loss improved from inf to 1.08598, saving model to model_23.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.2855 - precision: 0.6193 - val_loss: 1.0860 - val_precision: 0.6057\n",
      "Epoch 2/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9500 - precision: 0.6076\n",
      "Epoch 2: val_loss improved from 1.08598 to 1.02798, saving model to model_23.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9496 - precision: 0.6071 - val_loss: 1.0280 - val_precision: 0.6262\n",
      "Epoch 3/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9025 - precision: 0.6179\n",
      "Epoch 3: val_loss improved from 1.02798 to 1.00426, saving model to model_23.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8991 - precision: 0.6182 - val_loss: 1.0043 - val_precision: 0.6226\n",
      "Epoch 4/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8632 - precision: 0.6269\n",
      "Epoch 4: val_loss improved from 1.00426 to 0.98274, saving model to model_23.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8641 - precision: 0.6260 - val_loss: 0.9827 - val_precision: 0.6336\n",
      "Epoch 5/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8472 - precision: 0.6328\n",
      "Epoch 5: val_loss did not improve from 0.98274\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8463 - precision: 0.6335 - val_loss: 0.9996 - val_precision: 0.6206\n",
      "Epoch 6/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8191 - precision: 0.6385\n",
      "Epoch 6: val_loss improved from 0.98274 to 0.94839, saving model to model_23.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8160 - precision: 0.6386 - val_loss: 0.9484 - val_precision: 0.6443\n",
      "Epoch 7/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8019 - precision: 0.6439\n",
      "Epoch 7: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7995 - precision: 0.6443 - val_loss: 0.9824 - val_precision: 0.6233\n",
      "Epoch 8/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7779 - precision: 0.6489\n",
      "Epoch 8: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7791 - precision: 0.6476 - val_loss: 1.0019 - val_precision: 0.6257\n",
      "Epoch 9/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7587 - precision: 0.6593\n",
      "Epoch 9: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7586 - precision: 0.6593 - val_loss: 0.9746 - val_precision: 0.6260\n",
      "Epoch 10/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7477 - precision: 0.6655\n",
      "Epoch 10: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7447 - precision: 0.6657 - val_loss: 0.9814 - val_precision: 0.6220\n",
      "Epoch 11/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7298 - precision: 0.6693\n",
      "Epoch 11: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7300 - precision: 0.6690 - val_loss: 0.9628 - val_precision: 0.6379\n",
      "Epoch 12/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7164 - precision: 0.6752\n",
      "Epoch 12: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7158 - precision: 0.6762 - val_loss: 0.9721 - val_precision: 0.6321\n",
      "Epoch 13/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6959 - precision: 0.6790\n",
      "Epoch 13: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6957 - precision: 0.6806 - val_loss: 0.9968 - val_precision: 0.6231\n",
      "Epoch 14/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6865 - precision: 0.6863\n",
      "Epoch 14: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6856 - precision: 0.6873 - val_loss: 0.9890 - val_precision: 0.6280\n",
      "Epoch 15/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6637 - precision: 0.6903\n",
      "Epoch 15: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6634 - precision: 0.6916 - val_loss: 0.9761 - val_precision: 0.6301\n",
      "Epoch 16/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.6665 - precision: 0.6850\n",
      "Epoch 16: val_loss did not improve from 0.94839\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6653 - precision: 0.6860 - val_loss: 0.9625 - val_precision: 0.6395\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7559 - precision: 0.7120\n",
      "Combinación 22 = (True, True, False, 64, 0.25) \n",
      " precision train: [0.7558944225311279, 0.7119775414466858]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 24: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.4235 - precision: 0.6595\n",
      "Epoch 1: val_loss improved from inf to 1.16691, saving model to model_24.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.4189 - precision: 0.6593 - val_loss: 1.1669 - val_precision: 0.6828\n",
      "Epoch 2/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.0850 - precision: 0.6333\n",
      "Epoch 2: val_loss improved from 1.16691 to 1.04568, saving model to model_24.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0816 - precision: 0.6343 - val_loss: 1.0457 - val_precision: 0.6262\n",
      "Epoch 3/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9679 - precision: 0.6176\n",
      "Epoch 3: val_loss improved from 1.04568 to 1.02877, saving model to model_24.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9707 - precision: 0.6167 - val_loss: 1.0288 - val_precision: 0.6200\n",
      "Epoch 4/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9379 - precision: 0.6216\n",
      "Epoch 4: val_loss improved from 1.02877 to 1.00167, saving model to model_24.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9376 - precision: 0.6223 - val_loss: 1.0017 - val_precision: 0.6353\n",
      "Epoch 5/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9154 - precision: 0.6258\n",
      "Epoch 5: val_loss improved from 1.00167 to 0.99989, saving model to model_24.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9144 - precision: 0.6262 - val_loss: 0.9999 - val_precision: 0.6248\n",
      "Epoch 6/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8911 - precision: 0.6275\n",
      "Epoch 6: val_loss improved from 0.99989 to 0.99876, saving model to model_24.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8913 - precision: 0.6270 - val_loss: 0.9988 - val_precision: 0.6244\n",
      "Epoch 7/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8752 - precision: 0.6304\n",
      "Epoch 7: val_loss did not improve from 0.99876\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8752 - precision: 0.6310 - val_loss: 1.0191 - val_precision: 0.6178\n",
      "Epoch 8/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8668 - precision: 0.6312\n",
      "Epoch 8: val_loss improved from 0.99876 to 0.98727, saving model to model_24.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8655 - precision: 0.6322 - val_loss: 0.9873 - val_precision: 0.6301\n",
      "Epoch 9/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8536 - precision: 0.6320\n",
      "Epoch 9: val_loss did not improve from 0.98727\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8525 - precision: 0.6321 - val_loss: 0.9940 - val_precision: 0.6274\n",
      "Epoch 10/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8418 - precision: 0.6437\n",
      "Epoch 10: val_loss did not improve from 0.98727\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8413 - precision: 0.6432 - val_loss: 0.9909 - val_precision: 0.6245\n",
      "Epoch 11/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8324 - precision: 0.6406\n",
      "Epoch 11: val_loss did not improve from 0.98727\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8335 - precision: 0.6386 - val_loss: 1.0000 - val_precision: 0.6172\n",
      "Epoch 12/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8304 - precision: 0.6307\n",
      "Epoch 12: val_loss did not improve from 0.98727\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8310 - precision: 0.6303 - val_loss: 0.9963 - val_precision: 0.6209\n",
      "Epoch 13/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8102 - precision: 0.6449\n",
      "Epoch 13: val_loss improved from 0.98727 to 0.98592, saving model to model_24.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8091 - precision: 0.6463 - val_loss: 0.9859 - val_precision: 0.6217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7996 - precision: 0.6479\n",
      "Epoch 14: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7995 - precision: 0.6481 - val_loss: 1.0237 - val_precision: 0.6093\n",
      "Epoch 15/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7995 - precision: 0.6476\n",
      "Epoch 15: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8002 - precision: 0.6470 - val_loss: 1.0043 - val_precision: 0.6186\n",
      "Epoch 16/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7869 - precision: 0.6483\n",
      "Epoch 16: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7838 - precision: 0.6497 - val_loss: 1.0136 - val_precision: 0.6140\n",
      "Epoch 17/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7782 - precision: 0.6563\n",
      "Epoch 17: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7781 - precision: 0.6558 - val_loss: 1.0135 - val_precision: 0.6117\n",
      "Epoch 18/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7730 - precision: 0.6592\n",
      "Epoch 18: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7733 - precision: 0.6584 - val_loss: 1.0011 - val_precision: 0.6173\n",
      "Epoch 19/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7693 - precision: 0.6576\n",
      "Epoch 19: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7684 - precision: 0.6583 - val_loss: 1.0114 - val_precision: 0.6215\n",
      "Epoch 20/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7636 - precision: 0.6553\n",
      "Epoch 20: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7636 - precision: 0.6558 - val_loss: 1.0034 - val_precision: 0.6204\n",
      "Epoch 21/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7503 - precision: 0.6647\n",
      "Epoch 21: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7517 - precision: 0.6652 - val_loss: 1.0187 - val_precision: 0.6138\n",
      "Epoch 22/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7440 - precision: 0.6652\n",
      "Epoch 22: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7445 - precision: 0.6639 - val_loss: 1.0144 - val_precision: 0.6204\n",
      "Epoch 23/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7522 - precision: 0.6667\n",
      "Epoch 23: val_loss did not improve from 0.98592\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7535 - precision: 0.6667 - val_loss: 1.0271 - val_precision: 0.6200\n",
      "Epoch 23: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8454 - precision: 0.6663\n",
      "Combinación 23 = (True, True, False, 64, 0.5) \n",
      " precision train: [0.8454352021217346, 0.6662713289260864]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 25: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.5333 - precision: 0.5000   \n",
      "Epoch 1: val_loss improved from inf to 1.39642, saving model to model_25.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5333 - precision: 0.5000 - val_loss: 1.3964 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.3151 - precision: 0.6018\n",
      "Epoch 2: val_loss improved from 1.39642 to 1.32405, saving model to model_25.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3123 - precision: 0.6000 - val_loss: 1.3241 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.2507 - precision: 0.6843\n",
      "Epoch 3: val_loss improved from 1.32405 to 1.27841, saving model to model_25.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2487 - precision: 0.6895 - val_loss: 1.2784 - val_precision: 0.7671\n",
      "Epoch 4/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1893 - precision: 0.6731\n",
      "Epoch 4: val_loss improved from 1.27841 to 1.20371, saving model to model_25.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1851 - precision: 0.6743 - val_loss: 1.2037 - val_precision: 0.6880\n",
      "Epoch 5/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1077 - precision: 0.6557\n",
      "Epoch 5: val_loss improved from 1.20371 to 1.15543, saving model to model_25.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1057 - precision: 0.6589 - val_loss: 1.1554 - val_precision: 0.6664\n",
      "Epoch 6/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.0407 - precision: 0.6579\n",
      "Epoch 6: val_loss improved from 1.15543 to 1.10951, saving model to model_25.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0449 - precision: 0.6583 - val_loss: 1.1095 - val_precision: 0.6717\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0060 - precision: 0.6635\n",
      "Epoch 7: val_loss improved from 1.10951 to 1.09421, saving model to model_25.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0066 - precision: 0.6624 - val_loss: 1.0942 - val_precision: 0.6574\n",
      "Epoch 8/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9834 - precision: 0.6470\n",
      "Epoch 8: val_loss did not improve from 1.09421\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9842 - precision: 0.6450 - val_loss: 1.1006 - val_precision: 0.6318\n",
      "Epoch 9/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9567 - precision: 0.6460\n",
      "Epoch 9: val_loss improved from 1.09421 to 1.08556, saving model to model_25.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9538 - precision: 0.6463 - val_loss: 1.0856 - val_precision: 0.6274\n",
      "Epoch 10/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9331 - precision: 0.6384\n",
      "Epoch 10: val_loss improved from 1.08556 to 1.07501, saving model to model_25.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9323 - precision: 0.6365 - val_loss: 1.0750 - val_precision: 0.6158\n",
      "Epoch 11/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9138 - precision: 0.6403\n",
      "Epoch 11: val_loss did not improve from 1.07501\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9139 - precision: 0.6386 - val_loss: 1.0760 - val_precision: 0.6182\n",
      "Epoch 12/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9071 - precision: 0.6430\n",
      "Epoch 12: val_loss improved from 1.07501 to 1.04728, saving model to model_25.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9091 - precision: 0.6410 - val_loss: 1.0473 - val_precision: 0.6243\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8965 - precision: 0.6443\n",
      "Epoch 13: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8949 - precision: 0.6458 - val_loss: 1.0482 - val_precision: 0.6161\n",
      "Epoch 14/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8824 - precision: 0.6470\n",
      "Epoch 14: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8825 - precision: 0.6462 - val_loss: 1.0552 - val_precision: 0.6177\n",
      "Epoch 15/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8690 - precision: 0.6493\n",
      "Epoch 15: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8679 - precision: 0.6516 - val_loss: 1.0528 - val_precision: 0.6183\n",
      "Epoch 16/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8634 - precision: 0.6461\n",
      "Epoch 16: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8655 - precision: 0.6465 - val_loss: 1.0845 - val_precision: 0.6036\n",
      "Epoch 17/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8477 - precision: 0.6531\n",
      "Epoch 17: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8445 - precision: 0.6525 - val_loss: 1.0649 - val_precision: 0.6111\n",
      "Epoch 18/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8418 - precision: 0.6556\n",
      "Epoch 18: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8412 - precision: 0.6561 - val_loss: 1.0596 - val_precision: 0.6166\n",
      "Epoch 19/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8311 - precision: 0.6592\n",
      "Epoch 19: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8319 - precision: 0.6589 - val_loss: 1.0756 - val_precision: 0.6054\n",
      "Epoch 20/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8205 - precision: 0.6566\n",
      "Epoch 20: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8214 - precision: 0.6564 - val_loss: 1.0653 - val_precision: 0.6121\n",
      "Epoch 21/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8177 - precision: 0.6614\n",
      "Epoch 21: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8166 - precision: 0.6618 - val_loss: 1.0643 - val_precision: 0.6094\n",
      "Epoch 22/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8176 - precision: 0.6634\n",
      "Epoch 22: val_loss did not improve from 1.04728\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8183 - precision: 0.6635 - val_loss: 1.0710 - val_precision: 0.6076\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9110 - precision: 0.6598\n",
      "Combinación 24 = (True, False, True, 8, 0.1) \n",
      " precision train: [0.9110291600227356, 0.6597520709037781]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 26: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.5579 - precision: 0.5000  \n",
      "Epoch 1: val_loss improved from inf to 1.38449, saving model to model_26.h5\n",
      "240/240 [==============================] - 7s 7ms/step - loss: 1.5542 - precision: 0.5526 - val_loss: 1.3845 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.3279 - precision: 0.5444\n",
      "Epoch 2: val_loss improved from 1.38449 to 1.31468, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3319 - precision: 0.5443 - val_loss: 1.3147 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.2826 - precision: 0.5339\n",
      "Epoch 3: val_loss improved from 1.31468 to 1.29748, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2815 - precision: 0.5403 - val_loss: 1.2975 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2575 - precision: 0.5845\n",
      "Epoch 4: val_loss improved from 1.29748 to 1.26790, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2573 - precision: 0.5810 - val_loss: 1.2679 - val_precision: 0.8387\n",
      "Epoch 5/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.2304 - precision: 0.6349\n",
      "Epoch 5: val_loss improved from 1.26790 to 1.24317, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2306 - precision: 0.6349 - val_loss: 1.2432 - val_precision: 0.7250\n",
      "Epoch 6/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.2097 - precision: 0.6497\n",
      "Epoch 6: val_loss improved from 1.24317 to 1.21746, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2106 - precision: 0.6491 - val_loss: 1.2175 - val_precision: 0.7027\n",
      "Epoch 7/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1980 - precision: 0.6583\n",
      "Epoch 7: val_loss improved from 1.21746 to 1.19022, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1962 - precision: 0.6599 - val_loss: 1.1902 - val_precision: 0.7009\n",
      "Epoch 8/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1735 - precision: 0.6746\n",
      "Epoch 8: val_loss improved from 1.19022 to 1.18851, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1742 - precision: 0.6753 - val_loss: 1.1885 - val_precision: 0.6912\n",
      "Epoch 9/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1535 - precision: 0.6735\n",
      "Epoch 9: val_loss improved from 1.18851 to 1.16292, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1547 - precision: 0.6763 - val_loss: 1.1629 - val_precision: 0.7102\n",
      "Epoch 10/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.1261 - precision: 0.6593\n",
      "Epoch 10: val_loss improved from 1.16292 to 1.15581, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1260 - precision: 0.6600 - val_loss: 1.1558 - val_precision: 0.7017\n",
      "Epoch 11/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1203 - precision: 0.6405\n",
      "Epoch 11: val_loss improved from 1.15581 to 1.13956, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1206 - precision: 0.6419 - val_loss: 1.1396 - val_precision: 0.6827\n",
      "Epoch 12/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.0993 - precision: 0.6429\n",
      "Epoch 12: val_loss improved from 1.13956 to 1.12546, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0981 - precision: 0.6454 - val_loss: 1.1255 - val_precision: 0.6655\n",
      "Epoch 13/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0879 - precision: 0.6306\n",
      "Epoch 13: val_loss improved from 1.12546 to 1.11994, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0894 - precision: 0.6307 - val_loss: 1.1199 - val_precision: 0.6602\n",
      "Epoch 14/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0795 - precision: 0.6239\n",
      "Epoch 14: val_loss improved from 1.11994 to 1.11168, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0833 - precision: 0.6231 - val_loss: 1.1117 - val_precision: 0.6576\n",
      "Epoch 15/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0500 - precision: 0.6261\n",
      "Epoch 15: val_loss did not improve from 1.11168\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0510 - precision: 0.6253 - val_loss: 1.1152 - val_precision: 0.6346\n",
      "Epoch 16/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0438 - precision: 0.6153\n",
      "Epoch 16: val_loss improved from 1.11168 to 1.10377, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0444 - precision: 0.6144 - val_loss: 1.1038 - val_precision: 0.6429\n",
      "Epoch 17/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.0354 - precision: 0.6195\n",
      "Epoch 17: val_loss did not improve from 1.10377\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0369 - precision: 0.6185 - val_loss: 1.1178 - val_precision: 0.6135\n",
      "Epoch 18/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.0238 - precision: 0.6169\n",
      "Epoch 18: val_loss improved from 1.10377 to 1.09910, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0272 - precision: 0.6154 - val_loss: 1.0991 - val_precision: 0.6062\n",
      "Epoch 19/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.0132 - precision: 0.6164\n",
      "Epoch 19: val_loss did not improve from 1.09910\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0144 - precision: 0.6163 - val_loss: 1.1021 - val_precision: 0.6040\n",
      "Epoch 20/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0107 - precision: 0.6122\n",
      "Epoch 20: val_loss improved from 1.09910 to 1.09904, saving model to model_26.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0099 - precision: 0.6131 - val_loss: 1.0990 - val_precision: 0.5981\n",
      "Epoch 21/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0006 - precision: 0.6079\n",
      "Epoch 21: val_loss improved from 1.09904 to 1.09536, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0027 - precision: 0.6094 - val_loss: 1.0954 - val_precision: 0.5909\n",
      "Epoch 22/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0103 - precision: 0.6059\n",
      "Epoch 22: val_loss improved from 1.09536 to 1.08973, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0101 - precision: 0.6078 - val_loss: 1.0897 - val_precision: 0.5991\n",
      "Epoch 23/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9881 - precision: 0.6147\n",
      "Epoch 23: val_loss did not improve from 1.08973\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9845 - precision: 0.6152 - val_loss: 1.0898 - val_precision: 0.5908\n",
      "Epoch 24/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9877 - precision: 0.6121\n",
      "Epoch 24: val_loss improved from 1.08973 to 1.07700, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9868 - precision: 0.6111 - val_loss: 1.0770 - val_precision: 0.5944\n",
      "Epoch 25/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9753 - precision: 0.6214\n",
      "Epoch 25: val_loss did not improve from 1.07700\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9752 - precision: 0.6219 - val_loss: 1.0966 - val_precision: 0.5788\n",
      "Epoch 26/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9789 - precision: 0.6088\n",
      "Epoch 26: val_loss did not improve from 1.07700\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9760 - precision: 0.6089 - val_loss: 1.0910 - val_precision: 0.5838\n",
      "Epoch 27/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9728 - precision: 0.6043\n",
      "Epoch 27: val_loss did not improve from 1.07700\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9747 - precision: 0.6039 - val_loss: 1.0814 - val_precision: 0.5906\n",
      "Epoch 28/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9594 - precision: 0.6198\n",
      "Epoch 28: val_loss did not improve from 1.07700\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9539 - precision: 0.6184 - val_loss: 1.0782 - val_precision: 0.5818\n",
      "Epoch 29/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9565 - precision: 0.6119\n",
      "Epoch 29: val_loss did not improve from 1.07700\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9585 - precision: 0.6111 - val_loss: 1.0840 - val_precision: 0.5762\n",
      "Epoch 30/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9499 - precision: 0.6188\n",
      "Epoch 30: val_loss did not improve from 1.07700\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9485 - precision: 0.6193 - val_loss: 1.0816 - val_precision: 0.5854\n",
      "Epoch 31/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9582 - precision: 0.6203\n",
      "Epoch 31: val_loss did not improve from 1.07700\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9595 - precision: 0.6199 - val_loss: 1.0936 - val_precision: 0.5802\n",
      "Epoch 32/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9506 - precision: 0.6130\n",
      "Epoch 32: val_loss did not improve from 1.07700\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9521 - precision: 0.6142 - val_loss: 1.0907 - val_precision: 0.5761\n",
      "Epoch 33/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9411 - precision: 0.6204\n",
      "Epoch 33: val_loss improved from 1.07700 to 1.07187, saving model to model_26.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9421 - precision: 0.6202 - val_loss: 1.0719 - val_precision: 0.5814\n",
      "Epoch 34/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9385 - precision: 0.6164\n",
      "Epoch 34: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9410 - precision: 0.6171 - val_loss: 1.0761 - val_precision: 0.5775\n",
      "Epoch 35/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9348 - precision: 0.6182\n",
      "Epoch 35: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9333 - precision: 0.6189 - val_loss: 1.1005 - val_precision: 0.5723\n",
      "Epoch 36/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9265 - precision: 0.6207\n",
      "Epoch 36: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9258 - precision: 0.6213 - val_loss: 1.0930 - val_precision: 0.5839\n",
      "Epoch 37/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9271 - precision: 0.6108\n",
      "Epoch 37: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9312 - precision: 0.6109 - val_loss: 1.0777 - val_precision: 0.5778\n",
      "Epoch 38/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9239 - precision: 0.6218\n",
      "Epoch 38: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9233 - precision: 0.6218 - val_loss: 1.0937 - val_precision: 0.5785\n",
      "Epoch 39/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9199 - precision: 0.6229\n",
      "Epoch 39: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9198 - precision: 0.6223 - val_loss: 1.0767 - val_precision: 0.5876\n",
      "Epoch 40/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9152 - precision: 0.6265\n",
      "Epoch 40: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9166 - precision: 0.6252 - val_loss: 1.0970 - val_precision: 0.5749\n",
      "Epoch 41/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9208 - precision: 0.6266\n",
      "Epoch 41: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9181 - precision: 0.6264 - val_loss: 1.0984 - val_precision: 0.5811\n",
      "Epoch 42/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9239 - precision: 0.6196\n",
      "Epoch 42: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9216 - precision: 0.6187 - val_loss: 1.0859 - val_precision: 0.5761\n",
      "Epoch 43/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.9026 - precision: 0.6233\n",
      "Epoch 43: val_loss did not improve from 1.07187\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9034 - precision: 0.6267 - val_loss: 1.0999 - val_precision: 0.5779\n",
      "Epoch 43: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9455 - precision: 0.6321\n",
      "Combinación 25 = (True, False, True, 8, 0.25) \n",
      " precision train: [0.945455014705658, 0.6320865750312805]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 27: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.6086 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.59768, saving model to model_27.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.6054 - precision: 0.0000e+00 - val_loss: 1.5977 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.5252 - precision: 0.6056\n",
      "Epoch 2: val_loss improved from 1.59768 to 1.38528, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.5184 - precision: 0.6021 - val_loss: 1.3853 - val_precision: 0.7363\n",
      "Epoch 3/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.4261 - precision: 0.6136\n",
      "Epoch 3: val_loss improved from 1.38528 to 1.33499, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.4223 - precision: 0.6151 - val_loss: 1.3350 - val_precision: 0.7264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.3877 - precision: 0.6482\n",
      "Epoch 4: val_loss improved from 1.33499 to 1.28357, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3857 - precision: 0.6495 - val_loss: 1.2836 - val_precision: 0.7077\n",
      "Epoch 5/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.3449 - precision: 0.6290\n",
      "Epoch 5: val_loss improved from 1.28357 to 1.26077, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3449 - precision: 0.6262 - val_loss: 1.2608 - val_precision: 0.7108\n",
      "Epoch 6/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.3309 - precision: 0.6139\n",
      "Epoch 6: val_loss improved from 1.26077 to 1.24183, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3306 - precision: 0.6132 - val_loss: 1.2418 - val_precision: 0.7229\n",
      "Epoch 7/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.2939 - precision: 0.6620\n",
      "Epoch 7: val_loss improved from 1.24183 to 1.23470, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2933 - precision: 0.6662 - val_loss: 1.2347 - val_precision: 0.6998\n",
      "Epoch 8/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.2905 - precision: 0.6460\n",
      "Epoch 8: val_loss improved from 1.23470 to 1.22312, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2893 - precision: 0.6450 - val_loss: 1.2231 - val_precision: 0.7028\n",
      "Epoch 9/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.2716 - precision: 0.6549\n",
      "Epoch 9: val_loss did not improve from 1.22312\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2728 - precision: 0.6517 - val_loss: 1.2274 - val_precision: 0.7203\n",
      "Epoch 10/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.2638 - precision: 0.6342\n",
      "Epoch 10: val_loss improved from 1.22312 to 1.21084, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2630 - precision: 0.6322 - val_loss: 1.2108 - val_precision: 0.7155\n",
      "Epoch 11/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2494 - precision: 0.6235\n",
      "Epoch 11: val_loss improved from 1.21084 to 1.20684, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2493 - precision: 0.6216 - val_loss: 1.2068 - val_precision: 0.7167\n",
      "Epoch 12/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2378 - precision: 0.6297\n",
      "Epoch 12: val_loss improved from 1.20684 to 1.20016, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2420 - precision: 0.6251 - val_loss: 1.2002 - val_precision: 0.6841\n",
      "Epoch 13/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.2384 - precision: 0.6022\n",
      "Epoch 13: val_loss improved from 1.20016 to 1.19570, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2402 - precision: 0.6041 - val_loss: 1.1957 - val_precision: 0.6726\n",
      "Epoch 14/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.2296 - precision: 0.6161\n",
      "Epoch 14: val_loss improved from 1.19570 to 1.19364, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2286 - precision: 0.6149 - val_loss: 1.1936 - val_precision: 0.6625\n",
      "Epoch 15/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2326 - precision: 0.5861\n",
      "Epoch 15: val_loss did not improve from 1.19364\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2317 - precision: 0.5890 - val_loss: 1.1949 - val_precision: 0.6461\n",
      "Epoch 16/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.2410 - precision: 0.6108\n",
      "Epoch 16: val_loss improved from 1.19364 to 1.18721, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2359 - precision: 0.6157 - val_loss: 1.1872 - val_precision: 0.6629\n",
      "Epoch 17/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2168 - precision: 0.6200\n",
      "Epoch 17: val_loss improved from 1.18721 to 1.18462, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2138 - precision: 0.6160 - val_loss: 1.1846 - val_precision: 0.6491\n",
      "Epoch 18/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.2157 - precision: 0.5907\n",
      "Epoch 18: val_loss improved from 1.18462 to 1.18406, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2129 - precision: 0.5935 - val_loss: 1.1841 - val_precision: 0.6617\n",
      "Epoch 19/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2191 - precision: 0.5929\n",
      "Epoch 19: val_loss did not improve from 1.18406\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2161 - precision: 0.5934 - val_loss: 1.1891 - val_precision: 0.6560\n",
      "Epoch 20/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.2199 - precision: 0.5792\n",
      "Epoch 20: val_loss did not improve from 1.18406\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2159 - precision: 0.5831 - val_loss: 1.1866 - val_precision: 0.6671\n",
      "Epoch 21/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2091 - precision: 0.5977\n",
      "Epoch 21: val_loss did not improve from 1.18406\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2103 - precision: 0.6007 - val_loss: 1.1847 - val_precision: 0.6504\n",
      "Epoch 22/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2015 - precision: 0.5961\n",
      "Epoch 22: val_loss did not improve from 1.18406\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2047 - precision: 0.5952 - val_loss: 1.1926 - val_precision: 0.6471\n",
      "Epoch 23/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.1994 - precision: 0.5944\n",
      "Epoch 23: val_loss did not improve from 1.18406\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2011 - precision: 0.5918 - val_loss: 1.1883 - val_precision: 0.6357\n",
      "Epoch 24/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.1981 - precision: 0.5965\n",
      "Epoch 24: val_loss did not improve from 1.18406\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2004 - precision: 0.5940 - val_loss: 1.1880 - val_precision: 0.6496\n",
      "Epoch 25/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1957 - precision: 0.5964\n",
      "Epoch 25: val_loss did not improve from 1.18406\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1958 - precision: 0.5934 - val_loss: 1.1844 - val_precision: 0.6420\n",
      "Epoch 26/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.1967 - precision: 0.5909\n",
      "Epoch 26: val_loss improved from 1.18406 to 1.18302, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1939 - precision: 0.5919 - val_loss: 1.1830 - val_precision: 0.6328\n",
      "Epoch 27/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1907 - precision: 0.5907\n",
      "Epoch 27: val_loss did not improve from 1.18302\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1943 - precision: 0.5914 - val_loss: 1.1879 - val_precision: 0.6542\n",
      "Epoch 28/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1910 - precision: 0.5866\n",
      "Epoch 28: val_loss improved from 1.18302 to 1.18126, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1910 - precision: 0.5866 - val_loss: 1.1813 - val_precision: 0.6528\n",
      "Epoch 29/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1875 - precision: 0.5860\n",
      "Epoch 29: val_loss improved from 1.18126 to 1.18088, saving model to model_27.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1896 - precision: 0.5869 - val_loss: 1.1809 - val_precision: 0.6501\n",
      "Epoch 30/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1900 - precision: 0.5958\n",
      "Epoch 30: val_loss did not improve from 1.18088\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1900 - precision: 0.5958 - val_loss: 1.1962 - val_precision: 0.6459\n",
      "Epoch 31/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1828 - precision: 0.6021\n",
      "Epoch 31: val_loss did not improve from 1.18088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1828 - precision: 0.6021 - val_loss: 1.1915 - val_precision: 0.6224\n",
      "Epoch 32/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1826 - precision: 0.5842\n",
      "Epoch 32: val_loss did not improve from 1.18088\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1822 - precision: 0.5877 - val_loss: 1.1823 - val_precision: 0.6461\n",
      "Epoch 33/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1779 - precision: 0.5815\n",
      "Epoch 33: val_loss did not improve from 1.18088\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1778 - precision: 0.5815 - val_loss: 1.1881 - val_precision: 0.6406\n",
      "Epoch 34/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1782 - precision: 0.5857\n",
      "Epoch 34: val_loss did not improve from 1.18088\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1784 - precision: 0.5850 - val_loss: 1.1944 - val_precision: 0.6401\n",
      "Epoch 35/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.1914 - precision: 0.5854\n",
      "Epoch 35: val_loss did not improve from 1.18088\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1893 - precision: 0.5858 - val_loss: 1.1862 - val_precision: 0.6142\n",
      "Epoch 36/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.1726 - precision: 0.5879\n",
      "Epoch 36: val_loss did not improve from 1.18088\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1715 - precision: 0.5878 - val_loss: 1.1860 - val_precision: 0.6404\n",
      "Epoch 37/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1680 - precision: 0.6043\n",
      "Epoch 37: val_loss did not improve from 1.18088\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1700 - precision: 0.5994 - val_loss: 1.1970 - val_precision: 0.6353\n",
      "Epoch 38/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1677 - precision: 0.5997\n",
      "Epoch 38: val_loss did not improve from 1.18088\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1696 - precision: 0.5964 - val_loss: 1.1898 - val_precision: 0.6205\n",
      "Epoch 39/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1739 - precision: 0.5938\n",
      "Epoch 39: val_loss did not improve from 1.18088\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1752 - precision: 0.5886 - val_loss: 1.1879 - val_precision: 0.6272\n",
      "Epoch 39: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 1.1313 - precision: 0.6432\n",
      "Combinación 26 = (True, False, True, 8, 0.5) \n",
      " precision train: [1.1312901973724365, 0.643203854560852]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 28: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.4197 - precision: 0.6369\n",
      "Epoch 1: val_loss improved from inf to 1.15217, saving model to model_28.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.4016 - precision: 0.6294 - val_loss: 1.1522 - val_precision: 0.6560\n",
      "Epoch 2/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0293 - precision: 0.6148\n",
      "Epoch 2: val_loss improved from 1.15217 to 1.06205, saving model to model_28.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0264 - precision: 0.6157 - val_loss: 1.0620 - val_precision: 0.6243\n",
      "Epoch 3/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9564 - precision: 0.6154\n",
      "Epoch 3: val_loss improved from 1.06205 to 1.05125, saving model to model_28.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9579 - precision: 0.6144 - val_loss: 1.0512 - val_precision: 0.6216\n",
      "Epoch 4/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9366 - precision: 0.6215\n",
      "Epoch 4: val_loss improved from 1.05125 to 1.02643, saving model to model_28.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9356 - precision: 0.6207 - val_loss: 1.0264 - val_precision: 0.6236\n",
      "Epoch 5/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9049 - precision: 0.6336\n",
      "Epoch 5: val_loss did not improve from 1.02643\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9062 - precision: 0.6333 - val_loss: 1.0330 - val_precision: 0.6157\n",
      "Epoch 6/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8857 - precision: 0.6368\n",
      "Epoch 6: val_loss improved from 1.02643 to 1.02172, saving model to model_28.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8889 - precision: 0.6360 - val_loss: 1.0217 - val_precision: 0.6180\n",
      "Epoch 7/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8672 - precision: 0.6425\n",
      "Epoch 7: val_loss did not improve from 1.02172\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8682 - precision: 0.6422 - val_loss: 1.0256 - val_precision: 0.6167\n",
      "Epoch 8/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8508 - precision: 0.6445\n",
      "Epoch 8: val_loss did not improve from 1.02172\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8485 - precision: 0.6461 - val_loss: 1.0314 - val_precision: 0.6120\n",
      "Epoch 9/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8281 - precision: 0.6560\n",
      "Epoch 9: val_loss did not improve from 1.02172\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8271 - precision: 0.6551 - val_loss: 1.0240 - val_precision: 0.6184\n",
      "Epoch 10/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8106 - precision: 0.6529\n",
      "Epoch 10: val_loss did not improve from 1.02172\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8106 - precision: 0.6529 - val_loss: 1.0394 - val_precision: 0.6128\n",
      "Epoch 11/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7937 - precision: 0.6644\n",
      "Epoch 11: val_loss improved from 1.02172 to 1.01010, saving model to model_28.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7951 - precision: 0.6637 - val_loss: 1.0101 - val_precision: 0.6252\n",
      "Epoch 12/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7737 - precision: 0.6693\n",
      "Epoch 12: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7777 - precision: 0.6681 - val_loss: 1.0192 - val_precision: 0.6239\n",
      "Epoch 13/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7690 - precision: 0.6723\n",
      "Epoch 13: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7690 - precision: 0.6722 - val_loss: 1.0129 - val_precision: 0.6197\n",
      "Epoch 14/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7612 - precision: 0.6733\n",
      "Epoch 14: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7639 - precision: 0.6736 - val_loss: 1.0355 - val_precision: 0.6135\n",
      "Epoch 15/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7506 - precision: 0.6771\n",
      "Epoch 15: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7470 - precision: 0.6783 - val_loss: 1.0354 - val_precision: 0.6211\n",
      "Epoch 16/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7378 - precision: 0.6793\n",
      "Epoch 16: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7341 - precision: 0.6818 - val_loss: 1.0519 - val_precision: 0.6182\n",
      "Epoch 17/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7221 - precision: 0.6816\n",
      "Epoch 17: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7221 - precision: 0.6818 - val_loss: 1.0336 - val_precision: 0.6187\n",
      "Epoch 18/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7122 - precision: 0.6896\n",
      "Epoch 18: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7121 - precision: 0.6899 - val_loss: 1.0259 - val_precision: 0.6170\n",
      "Epoch 19/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7000 - precision: 0.6904\n",
      "Epoch 19: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7001 - precision: 0.6909 - val_loss: 1.0290 - val_precision: 0.6204\n",
      "Epoch 20/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.6984 - precision: 0.6903\n",
      "Epoch 20: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6976 - precision: 0.6917 - val_loss: 1.0516 - val_precision: 0.6143\n",
      "Epoch 21/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.6830 - precision: 0.6975\n",
      "Epoch 21: val_loss did not improve from 1.01010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6814 - precision: 0.6984 - val_loss: 1.0741 - val_precision: 0.6085\n",
      "Epoch 21: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8304 - precision: 0.6874\n",
      "Combinación 27 = (True, False, True, 16, 0.1) \n",
      " precision train: [0.8304125070571899, 0.6874014139175415]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 29: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.4852 - precision: 0.5513 \n",
      "Epoch 1: val_loss improved from inf to 1.30102, saving model to model_29.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.4666 - precision: 0.6435 - val_loss: 1.3010 - val_precision: 0.7669\n",
      "Epoch 2/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.1461 - precision: 0.6131\n",
      "Epoch 2: val_loss improved from 1.30102 to 1.13500, saving model to model_29.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1437 - precision: 0.6141 - val_loss: 1.1350 - val_precision: 0.6568\n",
      "Epoch 3/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0238 - precision: 0.6050\n",
      "Epoch 3: val_loss improved from 1.13500 to 1.09047, saving model to model_29.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0247 - precision: 0.6042 - val_loss: 1.0905 - val_precision: 0.6002\n",
      "Epoch 4/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9917 - precision: 0.6024\n",
      "Epoch 4: val_loss improved from 1.09047 to 1.05270, saving model to model_29.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9898 - precision: 0.6018 - val_loss: 1.0527 - val_precision: 0.6113\n",
      "Epoch 5/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9675 - precision: 0.6041\n",
      "Epoch 5: val_loss improved from 1.05270 to 1.03862, saving model to model_29.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9656 - precision: 0.6058 - val_loss: 1.0386 - val_precision: 0.6183\n",
      "Epoch 6/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9388 - precision: 0.6173\n",
      "Epoch 6: val_loss did not improve from 1.03862\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9380 - precision: 0.6182 - val_loss: 1.0470 - val_precision: 0.6110\n",
      "Epoch 7/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9342 - precision: 0.6271\n",
      "Epoch 7: val_loss improved from 1.03862 to 1.02248, saving model to model_29.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9359 - precision: 0.6257 - val_loss: 1.0225 - val_precision: 0.6254\n",
      "Epoch 8/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9128 - precision: 0.6252\n",
      "Epoch 8: val_loss did not improve from 1.02248\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9146 - precision: 0.6254 - val_loss: 1.0400 - val_precision: 0.6156\n",
      "Epoch 9/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9100 - precision: 0.6317\n",
      "Epoch 9: val_loss improved from 1.02248 to 1.01251, saving model to model_29.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9099 - precision: 0.6318 - val_loss: 1.0125 - val_precision: 0.6375\n",
      "Epoch 10/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9025 - precision: 0.6355\n",
      "Epoch 10: val_loss did not improve from 1.01251\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9017 - precision: 0.6363 - val_loss: 1.0291 - val_precision: 0.6252\n",
      "Epoch 11/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8827 - precision: 0.6380\n",
      "Epoch 11: val_loss did not improve from 1.01251\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8850 - precision: 0.6376 - val_loss: 1.0375 - val_precision: 0.6177\n",
      "Epoch 12/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8809 - precision: 0.6460\n",
      "Epoch 12: val_loss did not improve from 1.01251\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8802 - precision: 0.6469 - val_loss: 1.0358 - val_precision: 0.6200\n",
      "Epoch 13/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8617 - precision: 0.6437\n",
      "Epoch 13: val_loss did not improve from 1.01251\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8602 - precision: 0.6443 - val_loss: 1.0453 - val_precision: 0.6144\n",
      "Epoch 14/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8609 - precision: 0.6465\n",
      "Epoch 14: val_loss did not improve from 1.01251\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8609 - precision: 0.6465 - val_loss: 1.0169 - val_precision: 0.6314\n",
      "Epoch 15/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8429 - precision: 0.6534\n",
      "Epoch 15: val_loss improved from 1.01251 to 1.01074, saving model to model_29.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8429 - precision: 0.6534 - val_loss: 1.0107 - val_precision: 0.6344\n",
      "Epoch 16/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8446 - precision: 0.6571\n",
      "Epoch 16: val_loss did not improve from 1.01074\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8447 - precision: 0.6562 - val_loss: 1.0476 - val_precision: 0.6149\n",
      "Epoch 17/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8293 - precision: 0.6588\n",
      "Epoch 17: val_loss did not improve from 1.01074\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8293 - precision: 0.6588 - val_loss: 1.0422 - val_precision: 0.6163\n",
      "Epoch 18/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8198 - precision: 0.6645\n",
      "Epoch 18: val_loss did not improve from 1.01074\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8211 - precision: 0.6636 - val_loss: 1.0532 - val_precision: 0.6122\n",
      "Epoch 19/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8190 - precision: 0.6614\n",
      "Epoch 19: val_loss did not improve from 1.01074\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8158 - precision: 0.6622 - val_loss: 1.0544 - val_precision: 0.6100\n",
      "Epoch 20/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8194 - precision: 0.6590\n",
      "Epoch 20: val_loss did not improve from 1.01074\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8194 - precision: 0.6590 - val_loss: 1.0403 - val_precision: 0.6237\n",
      "Epoch 21/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8118 - precision: 0.6639\n",
      "Epoch 21: val_loss did not improve from 1.01074\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8107 - precision: 0.6648 - val_loss: 1.0740 - val_precision: 0.6028\n",
      "Epoch 22/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8200 - precision: 0.6624\n",
      "Epoch 22: val_loss did not improve from 1.01074\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8177 - precision: 0.6623 - val_loss: 1.0695 - val_precision: 0.6048\n",
      "Epoch 23/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8027 - precision: 0.6663\n",
      "Epoch 23: val_loss did not improve from 1.01074\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8030 - precision: 0.6659 - val_loss: 1.0479 - val_precision: 0.6179\n",
      "Epoch 24/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7971 - precision: 0.6696\n",
      "Epoch 24: val_loss did not improve from 1.01074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7986 - precision: 0.6691 - val_loss: 1.0458 - val_precision: 0.6190\n",
      "Epoch 25/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7815 - precision: 0.6773\n",
      "Epoch 25: val_loss did not improve from 1.01074\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7814 - precision: 0.6772 - val_loss: 1.0773 - val_precision: 0.6080\n",
      "Epoch 25: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8913 - precision: 0.6654\n",
      "Combinación 28 = (True, False, True, 16, 0.25) \n",
      " precision train: [0.891322910785675, 0.665351927280426]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 30: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.5560 - precision: 0.5909 \n",
      "Epoch 1: val_loss improved from inf to 1.35001, saving model to model_30.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5452 - precision: 0.5961 - val_loss: 1.3500 - val_precision: 0.6972\n",
      "Epoch 2/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.3338 - precision: 0.5700\n",
      "Epoch 2: val_loss improved from 1.35001 to 1.30700, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3306 - precision: 0.5695 - val_loss: 1.3070 - val_precision: 0.7350\n",
      "Epoch 3/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.2847 - precision: 0.5886\n",
      "Epoch 3: val_loss improved from 1.30700 to 1.26476, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2857 - precision: 0.5874 - val_loss: 1.2648 - val_precision: 0.7483\n",
      "Epoch 4/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.2642 - precision: 0.5710\n",
      "Epoch 4: val_loss improved from 1.26476 to 1.23314, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2641 - precision: 0.5702 - val_loss: 1.2331 - val_precision: 0.7296\n",
      "Epoch 5/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2320 - precision: 0.6418\n",
      "Epoch 5: val_loss improved from 1.23314 to 1.21415, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2366 - precision: 0.6411 - val_loss: 1.2142 - val_precision: 0.7115\n",
      "Epoch 6/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.2140 - precision: 0.6377\n",
      "Epoch 6: val_loss improved from 1.21415 to 1.18470, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2142 - precision: 0.6359 - val_loss: 1.1847 - val_precision: 0.6896\n",
      "Epoch 7/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1888 - precision: 0.6300\n",
      "Epoch 7: val_loss improved from 1.18470 to 1.16717, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1887 - precision: 0.6300 - val_loss: 1.1672 - val_precision: 0.6936\n",
      "Epoch 8/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1713 - precision: 0.6469\n",
      "Epoch 8: val_loss improved from 1.16717 to 1.15466, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1720 - precision: 0.6470 - val_loss: 1.1547 - val_precision: 0.6882\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1526 - precision: 0.6378\n",
      "Epoch 9: val_loss improved from 1.15466 to 1.14411, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1504 - precision: 0.6390 - val_loss: 1.1441 - val_precision: 0.6465\n",
      "Epoch 10/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1504 - precision: 0.6321\n",
      "Epoch 10: val_loss improved from 1.14411 to 1.12263, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1504 - precision: 0.6350 - val_loss: 1.1226 - val_precision: 0.6635\n",
      "Epoch 11/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.1349 - precision: 0.6396\n",
      "Epoch 11: val_loss did not improve from 1.12263\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1352 - precision: 0.6360 - val_loss: 1.1260 - val_precision: 0.6582\n",
      "Epoch 12/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.1112 - precision: 0.6356\n",
      "Epoch 12: val_loss improved from 1.12263 to 1.10955, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1132 - precision: 0.6316 - val_loss: 1.1095 - val_precision: 0.6591\n",
      "Epoch 13/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1019 - precision: 0.6423\n",
      "Epoch 13: val_loss improved from 1.10955 to 1.10875, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1009 - precision: 0.6430 - val_loss: 1.1088 - val_precision: 0.6509\n",
      "Epoch 14/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0917 - precision: 0.6237\n",
      "Epoch 14: val_loss improved from 1.10875 to 1.09944, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0915 - precision: 0.6242 - val_loss: 1.0994 - val_precision: 0.6574\n",
      "Epoch 15/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.0966 - precision: 0.6241\n",
      "Epoch 15: val_loss improved from 1.09944 to 1.09086, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0919 - precision: 0.6246 - val_loss: 1.0909 - val_precision: 0.6527\n",
      "Epoch 16/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.0683 - precision: 0.6187\n",
      "Epoch 16: val_loss improved from 1.09086 to 1.08400, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0721 - precision: 0.6200 - val_loss: 1.0840 - val_precision: 0.6527\n",
      "Epoch 17/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0735 - precision: 0.6011\n",
      "Epoch 17: val_loss did not improve from 1.08400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0721 - precision: 0.6014 - val_loss: 1.0885 - val_precision: 0.6378\n",
      "Epoch 18/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0574 - precision: 0.6268\n",
      "Epoch 18: val_loss did not improve from 1.08400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0578 - precision: 0.6263 - val_loss: 1.0891 - val_precision: 0.6492\n",
      "Epoch 19/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.0530 - precision: 0.6099\n",
      "Epoch 19: val_loss did not improve from 1.08400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0511 - precision: 0.6130 - val_loss: 1.0923 - val_precision: 0.6374\n",
      "Epoch 20/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0451 - precision: 0.6107\n",
      "Epoch 20: val_loss improved from 1.08400 to 1.07877, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0443 - precision: 0.6110 - val_loss: 1.0788 - val_precision: 0.6372\n",
      "Epoch 21/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.0353 - precision: 0.6110\n",
      "Epoch 21: val_loss improved from 1.07877 to 1.07652, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0389 - precision: 0.6102 - val_loss: 1.0765 - val_precision: 0.6233\n",
      "Epoch 22/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0335 - precision: 0.6175\n",
      "Epoch 22: val_loss did not improve from 1.07652\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0340 - precision: 0.6167 - val_loss: 1.0834 - val_precision: 0.6040\n",
      "Epoch 23/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0293 - precision: 0.6191\n",
      "Epoch 23: val_loss improved from 1.07652 to 1.07104, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0283 - precision: 0.6200 - val_loss: 1.0710 - val_precision: 0.6179\n",
      "Epoch 24/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0247 - precision: 0.6093\n",
      "Epoch 24: val_loss did not improve from 1.07104\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0243 - precision: 0.6089 - val_loss: 1.0804 - val_precision: 0.6015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0090 - precision: 0.6135\n",
      "Epoch 25: val_loss did not improve from 1.07104\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0089 - precision: 0.6133 - val_loss: 1.0793 - val_precision: 0.6025\n",
      "Epoch 26/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0213 - precision: 0.6099\n",
      "Epoch 26: val_loss did not improve from 1.07104\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0244 - precision: 0.6091 - val_loss: 1.0804 - val_precision: 0.6091\n",
      "Epoch 27/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.0051 - precision: 0.6139\n",
      "Epoch 27: val_loss did not improve from 1.07104\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0062 - precision: 0.6143 - val_loss: 1.0750 - val_precision: 0.6083\n",
      "Epoch 28/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0053 - precision: 0.6121\n",
      "Epoch 28: val_loss did not improve from 1.07104\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0053 - precision: 0.6121 - val_loss: 1.0894 - val_precision: 0.6030\n",
      "Epoch 29/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9989 - precision: 0.6191\n",
      "Epoch 29: val_loss did not improve from 1.07104\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0002 - precision: 0.6182 - val_loss: 1.0784 - val_precision: 0.6046\n",
      "Epoch 30/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9975 - precision: 0.6171\n",
      "Epoch 30: val_loss improved from 1.07104 to 1.07099, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9980 - precision: 0.6159 - val_loss: 1.0710 - val_precision: 0.6007\n",
      "Epoch 31/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9982 - precision: 0.6159\n",
      "Epoch 31: val_loss improved from 1.07099 to 1.07075, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9971 - precision: 0.6166 - val_loss: 1.0707 - val_precision: 0.6058\n",
      "Epoch 32/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9835 - precision: 0.6182\n",
      "Epoch 32: val_loss did not improve from 1.07075\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9829 - precision: 0.6176 - val_loss: 1.0902 - val_precision: 0.5941\n",
      "Epoch 33/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9825 - precision: 0.6190\n",
      "Epoch 33: val_loss did not improve from 1.07075\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9814 - precision: 0.6200 - val_loss: 1.0865 - val_precision: 0.5946\n",
      "Epoch 34/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9763 - precision: 0.6167\n",
      "Epoch 34: val_loss improved from 1.07075 to 1.06738, saving model to model_30.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9761 - precision: 0.6180 - val_loss: 1.0674 - val_precision: 0.6025\n",
      "Epoch 35/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9731 - precision: 0.6160\n",
      "Epoch 35: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9739 - precision: 0.6153 - val_loss: 1.0746 - val_precision: 0.6006\n",
      "Epoch 36/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9694 - precision: 0.6309\n",
      "Epoch 36: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9679 - precision: 0.6320 - val_loss: 1.0736 - val_precision: 0.6016\n",
      "Epoch 37/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9816 - precision: 0.6194\n",
      "Epoch 37: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9802 - precision: 0.6199 - val_loss: 1.0883 - val_precision: 0.5923\n",
      "Epoch 38/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9655 - precision: 0.6285\n",
      "Epoch 38: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9659 - precision: 0.6296 - val_loss: 1.0860 - val_precision: 0.5967\n",
      "Epoch 39/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9718 - precision: 0.6219\n",
      "Epoch 39: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9700 - precision: 0.6224 - val_loss: 1.0932 - val_precision: 0.5912\n",
      "Epoch 40/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9670 - precision: 0.6190\n",
      "Epoch 40: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9676 - precision: 0.6179 - val_loss: 1.0801 - val_precision: 0.5978\n",
      "Epoch 41/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9581 - precision: 0.6290\n",
      "Epoch 41: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9584 - precision: 0.6281 - val_loss: 1.0848 - val_precision: 0.5960\n",
      "Epoch 42/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9651 - precision: 0.6239\n",
      "Epoch 42: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9665 - precision: 0.6215 - val_loss: 1.0828 - val_precision: 0.5945\n",
      "Epoch 43/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9587 - precision: 0.6314\n",
      "Epoch 43: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9589 - precision: 0.6316 - val_loss: 1.0921 - val_precision: 0.5915\n",
      "Epoch 44/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9492 - precision: 0.6284\n",
      "Epoch 44: val_loss did not improve from 1.06738\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9492 - precision: 0.6285 - val_loss: 1.0825 - val_precision: 0.6000\n",
      "Epoch 44: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9644 - precision: 0.6386\n",
      "Combinación 29 = (True, False, True, 16, 0.5) \n",
      " precision train: [0.9644315838813782, 0.6385817527770996]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 31: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.3225 - precision: 0.6051\n",
      "Epoch 1: val_loss improved from inf to 1.07861, saving model to model_31.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.3053 - precision: 0.6078 - val_loss: 1.0786 - val_precision: 0.6210\n",
      "Epoch 2/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9426 - precision: 0.6026\n",
      "Epoch 2: val_loss improved from 1.07861 to 1.04250, saving model to model_31.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9413 - precision: 0.6028 - val_loss: 1.0425 - val_precision: 0.6111\n",
      "Epoch 3/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9016 - precision: 0.6136\n",
      "Epoch 3: val_loss improved from 1.04250 to 1.01789, saving model to model_31.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8990 - precision: 0.6139 - val_loss: 1.0179 - val_precision: 0.6137\n",
      "Epoch 4/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8722 - precision: 0.6226\n",
      "Epoch 4: val_loss did not improve from 1.01789\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8722 - precision: 0.6226 - val_loss: 1.0189 - val_precision: 0.6123\n",
      "Epoch 5/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8440 - precision: 0.6339\n",
      "Epoch 5: val_loss improved from 1.01789 to 0.97741, saving model to model_31.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8413 - precision: 0.6330 - val_loss: 0.9774 - val_precision: 0.6308\n",
      "Epoch 6/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8210 - precision: 0.6455\n",
      "Epoch 6: val_loss did not improve from 0.97741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8197 - precision: 0.6447 - val_loss: 1.0070 - val_precision: 0.6263\n",
      "Epoch 7/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8017 - precision: 0.6490\n",
      "Epoch 7: val_loss did not improve from 0.97741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8017 - precision: 0.6493 - val_loss: 0.9927 - val_precision: 0.6206\n",
      "Epoch 8/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7732 - precision: 0.6573\n",
      "Epoch 8: val_loss did not improve from 0.97741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7758 - precision: 0.6569 - val_loss: 0.9848 - val_precision: 0.6301\n",
      "Epoch 9/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7643 - precision: 0.6624\n",
      "Epoch 9: val_loss did not improve from 0.97741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7643 - precision: 0.6624 - val_loss: 0.9778 - val_precision: 0.6311\n",
      "Epoch 10/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7376 - precision: 0.6698\n",
      "Epoch 10: val_loss did not improve from 0.97741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7364 - precision: 0.6699 - val_loss: 0.9968 - val_precision: 0.6320\n",
      "Epoch 11/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7211 - precision: 0.6751\n",
      "Epoch 11: val_loss did not improve from 0.97741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7201 - precision: 0.6741 - val_loss: 0.9994 - val_precision: 0.6244\n",
      "Epoch 12/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7043 - precision: 0.6793\n",
      "Epoch 12: val_loss improved from 0.97741 to 0.96156, saving model to model_31.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7064 - precision: 0.6780 - val_loss: 0.9616 - val_precision: 0.6394\n",
      "Epoch 13/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6935 - precision: 0.6863\n",
      "Epoch 13: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6943 - precision: 0.6851 - val_loss: 0.9837 - val_precision: 0.6307\n",
      "Epoch 14/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.6794 - precision: 0.6873\n",
      "Epoch 14: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6823 - precision: 0.6851 - val_loss: 0.9915 - val_precision: 0.6276\n",
      "Epoch 15/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6645 - precision: 0.6972\n",
      "Epoch 15: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6669 - precision: 0.6946 - val_loss: 1.0105 - val_precision: 0.6202\n",
      "Epoch 16/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6498 - precision: 0.7016\n",
      "Epoch 16: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6493 - precision: 0.7009 - val_loss: 1.0256 - val_precision: 0.6203\n",
      "Epoch 17/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6523 - precision: 0.6947\n",
      "Epoch 17: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6514 - precision: 0.6951 - val_loss: 1.0091 - val_precision: 0.6220\n",
      "Epoch 18/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6305 - precision: 0.7035\n",
      "Epoch 18: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6340 - precision: 0.7017 - val_loss: 1.0308 - val_precision: 0.6212\n",
      "Epoch 19/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.6147 - precision: 0.7123\n",
      "Epoch 19: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6159 - precision: 0.7111 - val_loss: 1.0350 - val_precision: 0.6205\n",
      "Epoch 20/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6152 - precision: 0.7086\n",
      "Epoch 20: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6133 - precision: 0.7120 - val_loss: 1.0811 - val_precision: 0.6064\n",
      "Epoch 21/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6058 - precision: 0.7132\n",
      "Epoch 21: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6068 - precision: 0.7121 - val_loss: 1.0844 - val_precision: 0.6091\n",
      "Epoch 22/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.5868 - precision: 0.7183\n",
      "Epoch 22: val_loss did not improve from 0.96156\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5864 - precision: 0.7176 - val_loss: 1.0760 - val_precision: 0.6159\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7402 - precision: 0.7129\n",
      "Combinación 30 = (True, False, True, 32, 0.1) \n",
      " precision train: [0.7401940226554871, 0.7128571271896362]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 32: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.3585 - precision: 0.6019\n",
      "Epoch 1: val_loss improved from inf to 1.17960, saving model to model_32.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.3545 - precision: 0.6005 - val_loss: 1.1796 - val_precision: 0.6471\n",
      "Epoch 2/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.0634 - precision: 0.6222\n",
      "Epoch 2: val_loss improved from 1.17960 to 1.10316, saving model to model_32.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0619 - precision: 0.6244 - val_loss: 1.1032 - val_precision: 0.6523\n",
      "Epoch 3/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9818 - precision: 0.6391\n",
      "Epoch 3: val_loss improved from 1.10316 to 1.07191, saving model to model_32.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9824 - precision: 0.6379 - val_loss: 1.0719 - val_precision: 0.6320\n",
      "Epoch 4/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9283 - precision: 0.6235\n",
      "Epoch 4: val_loss improved from 1.07191 to 1.02124, saving model to model_32.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9290 - precision: 0.6227 - val_loss: 1.0212 - val_precision: 0.6080\n",
      "Epoch 5/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8950 - precision: 0.6192\n",
      "Epoch 5: val_loss improved from 1.02124 to 0.99795, saving model to model_32.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8987 - precision: 0.6173 - val_loss: 0.9979 - val_precision: 0.6291\n",
      "Epoch 6/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8761 - precision: 0.6251\n",
      "Epoch 6: val_loss did not improve from 0.99795\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8732 - precision: 0.6278 - val_loss: 0.9988 - val_precision: 0.6256\n",
      "Epoch 7/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8547 - precision: 0.6290\n",
      "Epoch 7: val_loss did not improve from 0.99795\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8504 - precision: 0.6299 - val_loss: 1.0172 - val_precision: 0.6150\n",
      "Epoch 8/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8323 - precision: 0.6376\n",
      "Epoch 8: val_loss did not improve from 0.99795\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8326 - precision: 0.6372 - val_loss: 1.0184 - val_precision: 0.6129\n",
      "Epoch 9/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8279 - precision: 0.6312\n",
      "Epoch 9: val_loss did not improve from 0.99795\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8272 - precision: 0.6310 - val_loss: 1.0016 - val_precision: 0.6274\n",
      "Epoch 10/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8120 - precision: 0.6391\n",
      "Epoch 10: val_loss did not improve from 0.99795\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8118 - precision: 0.6388 - val_loss: 1.0122 - val_precision: 0.6203\n",
      "Epoch 11/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7949 - precision: 0.6457\n",
      "Epoch 11: val_loss did not improve from 0.99795\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7973 - precision: 0.6442 - val_loss: 1.0331 - val_precision: 0.6131\n",
      "Epoch 12/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7932 - precision: 0.6440\n",
      "Epoch 12: val_loss improved from 0.99795 to 0.99741, saving model to model_32.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7925 - precision: 0.6440 - val_loss: 0.9974 - val_precision: 0.6292\n",
      "Epoch 13/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7747 - precision: 0.6489\n",
      "Epoch 13: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7770 - precision: 0.6502 - val_loss: 1.0217 - val_precision: 0.6182\n",
      "Epoch 14/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7711 - precision: 0.6495\n",
      "Epoch 14: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7711 - precision: 0.6495 - val_loss: 0.9981 - val_precision: 0.6250\n",
      "Epoch 15/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7538 - precision: 0.6616\n",
      "Epoch 15: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7551 - precision: 0.6599 - val_loss: 1.0119 - val_precision: 0.6208\n",
      "Epoch 16/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7454 - precision: 0.6645\n",
      "Epoch 16: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7436 - precision: 0.6637 - val_loss: 1.0303 - val_precision: 0.6124\n",
      "Epoch 17/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7449 - precision: 0.6662\n",
      "Epoch 17: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7420 - precision: 0.6675 - val_loss: 1.0447 - val_precision: 0.6074\n",
      "Epoch 18/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7318 - precision: 0.6696\n",
      "Epoch 18: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7315 - precision: 0.6700 - val_loss: 1.0648 - val_precision: 0.5959\n",
      "Epoch 19/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7077 - precision: 0.6741\n",
      "Epoch 19: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7088 - precision: 0.6742 - val_loss: 1.0407 - val_precision: 0.6127\n",
      "Epoch 20/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7093 - precision: 0.6787\n",
      "Epoch 20: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7117 - precision: 0.6764 - val_loss: 1.0398 - val_precision: 0.6061\n",
      "Epoch 21/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6948 - precision: 0.6806\n",
      "Epoch 21: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6962 - precision: 0.6810 - val_loss: 1.0344 - val_precision: 0.6054\n",
      "Epoch 22/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6951 - precision: 0.6832\n",
      "Epoch 22: val_loss did not improve from 0.99741\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6959 - precision: 0.6829 - val_loss: 1.0479 - val_precision: 0.6083\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8221 - precision: 0.6807\n",
      "Combinación 31 = (True, False, True, 32, 0.25) \n",
      " precision train: [0.8221284747123718, 0.6806521415710449]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 33: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.5141 - precision: 0.6673\n",
      "Epoch 1: val_loss improved from inf to 1.32169, saving model to model_33.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5123 - precision: 0.6690 - val_loss: 1.3217 - val_precision: 0.7008\n",
      "Epoch 2/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.2439 - precision: 0.6436\n",
      "Epoch 2: val_loss improved from 1.32169 to 1.10946, saving model to model_33.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2427 - precision: 0.6411 - val_loss: 1.1095 - val_precision: 0.6390\n",
      "Epoch 3/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.0939 - precision: 0.5932\n",
      "Epoch 3: val_loss improved from 1.10946 to 1.05532, saving model to model_33.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0931 - precision: 0.5917 - val_loss: 1.0553 - val_precision: 0.6219\n",
      "Epoch 4/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0376 - precision: 0.6007\n",
      "Epoch 4: val_loss improved from 1.05532 to 1.04869, saving model to model_33.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0366 - precision: 0.6015 - val_loss: 1.0487 - val_precision: 0.6136\n",
      "Epoch 5/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9975 - precision: 0.6064\n",
      "Epoch 5: val_loss did not improve from 1.04869\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9987 - precision: 0.6057 - val_loss: 1.0504 - val_precision: 0.6047\n",
      "Epoch 6/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9779 - precision: 0.6163\n",
      "Epoch 6: val_loss improved from 1.04869 to 1.03143, saving model to model_33.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9774 - precision: 0.6169 - val_loss: 1.0314 - val_precision: 0.6244\n",
      "Epoch 7/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9675 - precision: 0.6138\n",
      "Epoch 7: val_loss did not improve from 1.03143\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9709 - precision: 0.6140 - val_loss: 1.0479 - val_precision: 0.6165\n",
      "Epoch 8/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9435 - precision: 0.6227\n",
      "Epoch 8: val_loss improved from 1.03143 to 1.01658, saving model to model_33.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9504 - precision: 0.6203 - val_loss: 1.0166 - val_precision: 0.6324\n",
      "Epoch 9/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9482 - precision: 0.6245\n",
      "Epoch 9: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9502 - precision: 0.6233 - val_loss: 1.0179 - val_precision: 0.6331\n",
      "Epoch 10/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9274 - precision: 0.6266\n",
      "Epoch 10: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9291 - precision: 0.6265 - val_loss: 1.0383 - val_precision: 0.6116\n",
      "Epoch 11/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9388 - precision: 0.6252\n",
      "Epoch 11: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9327 - precision: 0.6272 - val_loss: 1.0279 - val_precision: 0.6246\n",
      "Epoch 12/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9116 - precision: 0.6418\n",
      "Epoch 12: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9127 - precision: 0.6390 - val_loss: 1.0578 - val_precision: 0.6067\n",
      "Epoch 13/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.9063 - precision: 0.6310\n",
      "Epoch 13: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9064 - precision: 0.6327 - val_loss: 1.0341 - val_precision: 0.6183\n",
      "Epoch 14/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9110 - precision: 0.6334\n",
      "Epoch 14: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9121 - precision: 0.6343 - val_loss: 1.0216 - val_precision: 0.6260\n",
      "Epoch 15/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9040 - precision: 0.6405\n",
      "Epoch 15: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9034 - precision: 0.6411 - val_loss: 1.0401 - val_precision: 0.6120\n",
      "Epoch 16/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8841 - precision: 0.6450\n",
      "Epoch 16: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8843 - precision: 0.6464 - val_loss: 1.0448 - val_precision: 0.6195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8828 - precision: 0.6417\n",
      "Epoch 17: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8821 - precision: 0.6403 - val_loss: 1.0376 - val_precision: 0.6190\n",
      "Epoch 18/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8834 - precision: 0.6417\n",
      "Epoch 18: val_loss did not improve from 1.01658\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8837 - precision: 0.6418 - val_loss: 1.0576 - val_precision: 0.6080\n",
      "Epoch 18: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9514 - precision: 0.6371\n",
      "Combinación 32 = (True, False, True, 32, 0.5) \n",
      " precision train: [0.9514352679252625, 0.6371292471885681]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 34: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.2457 - precision: 0.6327\n",
      "Epoch 1: val_loss improved from inf to 1.04758, saving model to model_34.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.2436 - precision: 0.6327 - val_loss: 1.0476 - val_precision: 0.6386\n",
      "Epoch 2/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9139 - precision: 0.6159\n",
      "Epoch 2: val_loss improved from 1.04758 to 0.99529, saving model to model_34.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9140 - precision: 0.6160 - val_loss: 0.9953 - val_precision: 0.6395\n",
      "Epoch 3/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8537 - precision: 0.6316\n",
      "Epoch 3: val_loss improved from 0.99529 to 0.98280, saving model to model_34.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8549 - precision: 0.6306 - val_loss: 0.9828 - val_precision: 0.6328\n",
      "Epoch 4/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8240 - precision: 0.6329\n",
      "Epoch 4: val_loss improved from 0.98280 to 0.96625, saving model to model_34.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8223 - precision: 0.6338 - val_loss: 0.9663 - val_precision: 0.6329\n",
      "Epoch 5/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7845 - precision: 0.6496\n",
      "Epoch 5: val_loss improved from 0.96625 to 0.94987, saving model to model_34.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7908 - precision: 0.6471 - val_loss: 0.9499 - val_precision: 0.6429\n",
      "Epoch 6/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7686 - precision: 0.6491\n",
      "Epoch 6: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7680 - precision: 0.6491 - val_loss: 0.9799 - val_precision: 0.6300\n",
      "Epoch 7/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7518 - precision: 0.6564\n",
      "Epoch 7: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7496 - precision: 0.6563 - val_loss: 0.9601 - val_precision: 0.6327\n",
      "Epoch 8/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7204 - precision: 0.6650\n",
      "Epoch 8: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7221 - precision: 0.6644 - val_loss: 0.9606 - val_precision: 0.6258\n",
      "Epoch 9/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7094 - precision: 0.6655\n",
      "Epoch 9: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7085 - precision: 0.6655 - val_loss: 0.9612 - val_precision: 0.6323\n",
      "Epoch 10/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6904 - precision: 0.6759\n",
      "Epoch 10: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6938 - precision: 0.6733 - val_loss: 0.9811 - val_precision: 0.6234\n",
      "Epoch 11/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6715 - precision: 0.6818\n",
      "Epoch 11: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6731 - precision: 0.6802 - val_loss: 0.9977 - val_precision: 0.6319\n",
      "Epoch 12/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6548 - precision: 0.6877\n",
      "Epoch 12: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6548 - precision: 0.6877 - val_loss: 0.9982 - val_precision: 0.6230\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6421 - precision: 0.6893\n",
      "Epoch 13: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6422 - precision: 0.6899 - val_loss: 1.0119 - val_precision: 0.6182\n",
      "Epoch 14/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.6308 - precision: 0.6920\n",
      "Epoch 14: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6314 - precision: 0.6908 - val_loss: 1.0373 - val_precision: 0.6155\n",
      "Epoch 15/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6114 - precision: 0.6985\n",
      "Epoch 15: val_loss did not improve from 0.94987\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6115 - precision: 0.6983 - val_loss: 1.0669 - val_precision: 0.6078\n",
      "Epoch 15: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7500 - precision: 0.6978\n",
      "Combinación 33 = (True, False, True, 64, 0.1) \n",
      " precision train: [0.7500038146972656, 0.6977689862251282]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 35: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.3432 - precision: 0.6672\n",
      "Epoch 1: val_loss improved from inf to 1.09629, saving model to model_35.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.3244 - precision: 0.6661 - val_loss: 1.0963 - val_precision: 0.6356\n",
      "Epoch 2/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9749 - precision: 0.6080\n",
      "Epoch 2: val_loss improved from 1.09629 to 1.02038, saving model to model_35.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9719 - precision: 0.6083 - val_loss: 1.0204 - val_precision: 0.6210\n",
      "Epoch 3/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9029 - precision: 0.6167\n",
      "Epoch 3: val_loss improved from 1.02038 to 1.01270, saving model to model_35.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9023 - precision: 0.6166 - val_loss: 1.0127 - val_precision: 0.6232\n",
      "Epoch 4/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8592 - precision: 0.6213\n",
      "Epoch 4: val_loss improved from 1.01270 to 0.99164, saving model to model_35.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8580 - precision: 0.6213 - val_loss: 0.9916 - val_precision: 0.6173\n",
      "Epoch 5/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8363 - precision: 0.6269\n",
      "Epoch 5: val_loss improved from 0.99164 to 0.98086, saving model to model_35.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8363 - precision: 0.6267 - val_loss: 0.9809 - val_precision: 0.6301\n",
      "Epoch 6/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8201 - precision: 0.6353\n",
      "Epoch 6: val_loss improved from 0.98086 to 0.96561, saving model to model_35.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8201 - precision: 0.6353 - val_loss: 0.9656 - val_precision: 0.6322\n",
      "Epoch 7/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7989 - precision: 0.6416\n",
      "Epoch 7: val_loss did not improve from 0.96561\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8004 - precision: 0.6418 - val_loss: 0.9806 - val_precision: 0.6303\n",
      "Epoch 8/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7776 - precision: 0.6449\n",
      "Epoch 8: val_loss did not improve from 0.96561\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7782 - precision: 0.6435 - val_loss: 0.9853 - val_precision: 0.6206\n",
      "Epoch 9/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7588 - precision: 0.6556\n",
      "Epoch 9: val_loss improved from 0.96561 to 0.96282, saving model to model_35.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7604 - precision: 0.6551 - val_loss: 0.9628 - val_precision: 0.6286\n",
      "Epoch 10/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7470 - precision: 0.6612\n",
      "Epoch 10: val_loss did not improve from 0.96282\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7467 - precision: 0.6620 - val_loss: 0.9950 - val_precision: 0.6205\n",
      "Epoch 11/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7357 - precision: 0.6635\n",
      "Epoch 11: val_loss did not improve from 0.96282\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7356 - precision: 0.6633 - val_loss: 1.0256 - val_precision: 0.6127\n",
      "Epoch 12/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7171 - precision: 0.6736\n",
      "Epoch 12: val_loss did not improve from 0.96282\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7170 - precision: 0.6736 - val_loss: 0.9715 - val_precision: 0.6275\n",
      "Epoch 13/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7021 - precision: 0.6688\n",
      "Epoch 13: val_loss did not improve from 0.96282\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7014 - precision: 0.6687 - val_loss: 0.9711 - val_precision: 0.6320\n",
      "Epoch 14/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6826 - precision: 0.6853\n",
      "Epoch 14: val_loss did not improve from 0.96282\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6837 - precision: 0.6847 - val_loss: 1.0193 - val_precision: 0.6182\n",
      "Epoch 15/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.6757 - precision: 0.6851\n",
      "Epoch 15: val_loss improved from 0.96282 to 0.96202, saving model to model_35.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6750 - precision: 0.6851 - val_loss: 0.9620 - val_precision: 0.6362\n",
      "Epoch 16/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.6639 - precision: 0.6840\n",
      "Epoch 16: val_loss improved from 0.96202 to 0.95650, saving model to model_35.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6645 - precision: 0.6843 - val_loss: 0.9565 - val_precision: 0.6325\n",
      "Epoch 17/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6494 - precision: 0.6972\n",
      "Epoch 17: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6485 - precision: 0.6975 - val_loss: 0.9937 - val_precision: 0.6299\n",
      "Epoch 18/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6391 - precision: 0.7005\n",
      "Epoch 18: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6391 - precision: 0.7005 - val_loss: 1.0148 - val_precision: 0.6169\n",
      "Epoch 19/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6292 - precision: 0.6994\n",
      "Epoch 19: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6282 - precision: 0.6992 - val_loss: 1.0238 - val_precision: 0.6150\n",
      "Epoch 20/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6251 - precision: 0.6968\n",
      "Epoch 20: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6245 - precision: 0.6973 - val_loss: 1.0276 - val_precision: 0.6251\n",
      "Epoch 21/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6025 - precision: 0.7055\n",
      "Epoch 21: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6029 - precision: 0.7048 - val_loss: 1.0509 - val_precision: 0.6107\n",
      "Epoch 22/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6025 - precision: 0.7063\n",
      "Epoch 22: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6012 - precision: 0.7069 - val_loss: 1.0591 - val_precision: 0.6055\n",
      "Epoch 23/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.5844 - precision: 0.7158\n",
      "Epoch 23: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5857 - precision: 0.7146 - val_loss: 1.0755 - val_precision: 0.6042\n",
      "Epoch 24/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.5871 - precision: 0.7126\n",
      "Epoch 24: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5865 - precision: 0.7132 - val_loss: 1.0654 - val_precision: 0.6049\n",
      "Epoch 25/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.5624 - precision: 0.7212\n",
      "Epoch 25: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5632 - precision: 0.7214 - val_loss: 1.0699 - val_precision: 0.6047\n",
      "Epoch 26/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.5664 - precision: 0.7231\n",
      "Epoch 26: val_loss did not improve from 0.95650\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5666 - precision: 0.7240 - val_loss: 1.0854 - val_precision: 0.6022\n",
      "Epoch 26: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7206 - precision: 0.7124\n",
      "Combinación 34 = (True, False, True, 64, 0.25) \n",
      " precision train: [0.7205806970596313, 0.7124204635620117]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 36: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.4380 - precision: 0.5838\n",
      "Epoch 1: val_loss improved from inf to 1.26606, saving model to model_36.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.4299 - precision: 0.5910 - val_loss: 1.2661 - val_precision: 0.7216\n",
      "Epoch 2/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1974 - precision: 0.6619\n",
      "Epoch 2: val_loss improved from 1.26606 to 1.11646, saving model to model_36.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1921 - precision: 0.6632 - val_loss: 1.1165 - val_precision: 0.6792\n",
      "Epoch 3/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0358 - precision: 0.6272\n",
      "Epoch 3: val_loss improved from 1.11646 to 1.04881, saving model to model_36.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.0352 - precision: 0.6275 - val_loss: 1.0488 - val_precision: 0.6193\n",
      "Epoch 4/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9676 - precision: 0.6169\n",
      "Epoch 4: val_loss improved from 1.04881 to 1.02548, saving model to model_36.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9663 - precision: 0.6174 - val_loss: 1.0255 - val_precision: 0.6164\n",
      "Epoch 5/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9329 - precision: 0.6193\n",
      "Epoch 5: val_loss did not improve from 1.02548\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9307 - precision: 0.6206 - val_loss: 1.0288 - val_precision: 0.6056\n",
      "Epoch 6/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9194 - precision: 0.6174\n",
      "Epoch 6: val_loss improved from 1.02548 to 1.01642, saving model to model_36.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9207 - precision: 0.6173 - val_loss: 1.0164 - val_precision: 0.6160\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8984 - precision: 0.6224\n",
      "Epoch 7: val_loss did not improve from 1.01642\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8981 - precision: 0.6221 - val_loss: 1.0176 - val_precision: 0.6125\n",
      "Epoch 8/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8883 - precision: 0.6248\n",
      "Epoch 8: val_loss did not improve from 1.01642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8884 - precision: 0.6225 - val_loss: 1.0338 - val_precision: 0.6000\n",
      "Epoch 9/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8681 - precision: 0.6312\n",
      "Epoch 9: val_loss did not improve from 1.01642\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8683 - precision: 0.6308 - val_loss: 1.0167 - val_precision: 0.6093\n",
      "Epoch 10/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8527 - precision: 0.6334\n",
      "Epoch 10: val_loss improved from 1.01642 to 1.00277, saving model to model_36.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8547 - precision: 0.6336 - val_loss: 1.0028 - val_precision: 0.6179\n",
      "Epoch 11/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8510 - precision: 0.6284\n",
      "Epoch 11: val_loss did not improve from 1.00277\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8508 - precision: 0.6287 - val_loss: 1.0110 - val_precision: 0.6128\n",
      "Epoch 12/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8312 - precision: 0.6353\n",
      "Epoch 12: val_loss did not improve from 1.00277\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8341 - precision: 0.6345 - val_loss: 1.0077 - val_precision: 0.6111\n",
      "Epoch 13/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8201 - precision: 0.6390\n",
      "Epoch 13: val_loss did not improve from 1.00277\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8238 - precision: 0.6390 - val_loss: 1.0330 - val_precision: 0.6068\n",
      "Epoch 14/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8140 - precision: 0.6408\n",
      "Epoch 14: val_loss did not improve from 1.00277\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8149 - precision: 0.6393 - val_loss: 1.0123 - val_precision: 0.6178\n",
      "Epoch 15/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8108 - precision: 0.6445\n",
      "Epoch 15: val_loss did not improve from 1.00277\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8104 - precision: 0.6442 - val_loss: 1.0229 - val_precision: 0.6141\n",
      "Epoch 16/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8012 - precision: 0.6461\n",
      "Epoch 16: val_loss did not improve from 1.00277\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8001 - precision: 0.6459 - val_loss: 1.0297 - val_precision: 0.6090\n",
      "Epoch 17/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7947 - precision: 0.6480\n",
      "Epoch 17: val_loss did not improve from 1.00277\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7946 - precision: 0.6482 - val_loss: 1.0111 - val_precision: 0.6174\n",
      "Epoch 18/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7883 - precision: 0.6508\n",
      "Epoch 18: val_loss did not improve from 1.00277\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7872 - precision: 0.6505 - val_loss: 1.0409 - val_precision: 0.6107\n",
      "Epoch 19/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7796 - precision: 0.6468\n",
      "Epoch 19: val_loss improved from 1.00277 to 1.00064, saving model to model_36.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7792 - precision: 0.6476 - val_loss: 1.0006 - val_precision: 0.6236\n",
      "Epoch 20/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7674 - precision: 0.6585\n",
      "Epoch 20: val_loss did not improve from 1.00064\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7703 - precision: 0.6582 - val_loss: 1.0209 - val_precision: 0.6198\n",
      "Epoch 21/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7738 - precision: 0.6525\n",
      "Epoch 21: val_loss did not improve from 1.00064\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7734 - precision: 0.6530 - val_loss: 1.0180 - val_precision: 0.6067\n",
      "Epoch 22/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7618 - precision: 0.6566\n",
      "Epoch 22: val_loss did not improve from 1.00064\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7620 - precision: 0.6564 - val_loss: 1.0157 - val_precision: 0.6200\n",
      "Epoch 23/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7494 - precision: 0.6648\n",
      "Epoch 23: val_loss did not improve from 1.00064\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7495 - precision: 0.6653 - val_loss: 1.0229 - val_precision: 0.6142\n",
      "Epoch 24/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7382 - precision: 0.6698\n",
      "Epoch 24: val_loss did not improve from 1.00064\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7382 - precision: 0.6696 - val_loss: 1.0197 - val_precision: 0.6106\n",
      "Epoch 25/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7341 - precision: 0.6740\n",
      "Epoch 25: val_loss improved from 1.00064 to 0.98714, saving model to model_36.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7339 - precision: 0.6746 - val_loss: 0.9871 - val_precision: 0.6298\n",
      "Epoch 26/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7315 - precision: 0.6701\n",
      "Epoch 26: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7321 - precision: 0.6701 - val_loss: 1.0399 - val_precision: 0.6164\n",
      "Epoch 27/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7244 - precision: 0.6762\n",
      "Epoch 27: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7237 - precision: 0.6759 - val_loss: 1.0326 - val_precision: 0.6080\n",
      "Epoch 28/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7017 - precision: 0.6790\n",
      "Epoch 28: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7032 - precision: 0.6792 - val_loss: 1.0267 - val_precision: 0.6190\n",
      "Epoch 29/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7092 - precision: 0.6750\n",
      "Epoch 29: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7083 - precision: 0.6751 - val_loss: 1.0424 - val_precision: 0.6106\n",
      "Epoch 30/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7096 - precision: 0.6811\n",
      "Epoch 30: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7086 - precision: 0.6799 - val_loss: 1.0646 - val_precision: 0.6031\n",
      "Epoch 31/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7016 - precision: 0.6777\n",
      "Epoch 31: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7018 - precision: 0.6785 - val_loss: 1.0431 - val_precision: 0.6179\n",
      "Epoch 32/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6819 - precision: 0.6902\n",
      "Epoch 32: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6825 - precision: 0.6890 - val_loss: 1.0463 - val_precision: 0.6114\n",
      "Epoch 33/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6869 - precision: 0.6900\n",
      "Epoch 33: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6866 - precision: 0.6899 - val_loss: 1.0469 - val_precision: 0.6141\n",
      "Epoch 34/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6799 - precision: 0.6911\n",
      "Epoch 34: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6800 - precision: 0.6914 - val_loss: 1.0888 - val_precision: 0.5941\n",
      "Epoch 35/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6761 - precision: 0.6860\n",
      "Epoch 35: val_loss did not improve from 0.98714\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6755 - precision: 0.6854 - val_loss: 1.0944 - val_precision: 0.5992\n",
      "Epoch 35: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8227 - precision: 0.6804\n",
      "Combinación 35 = (True, False, True, 64, 0.5) \n",
      " precision train: [0.8226659893989563, 0.6803744435310364]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 37: \n",
      "\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.5115 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.35114, saving model to model_37.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.5050 - precision: 0.0000e+00 - val_loss: 1.3511 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.1920 - precision: 0.6595\n",
      "Epoch 2: val_loss improved from 1.35114 to 1.14404, saving model to model_37.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1824 - precision: 0.6552 - val_loss: 1.1440 - val_precision: 0.6652\n",
      "Epoch 3/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0162 - precision: 0.6275\n",
      "Epoch 3: val_loss improved from 1.14404 to 1.06723, saving model to model_37.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0164 - precision: 0.6270 - val_loss: 1.0672 - val_precision: 0.6319\n",
      "Epoch 4/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.9559 - precision: 0.6095\n",
      "Epoch 4: val_loss improved from 1.06723 to 1.03448, saving model to model_37.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9537 - precision: 0.6121 - val_loss: 1.0345 - val_precision: 0.6248\n",
      "Epoch 5/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.9276 - precision: 0.6183\n",
      "Epoch 5: val_loss improved from 1.03448 to 1.03271, saving model to model_37.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9278 - precision: 0.6152 - val_loss: 1.0327 - val_precision: 0.6095\n",
      "Epoch 6/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9046 - precision: 0.6183\n",
      "Epoch 6: val_loss improved from 1.03271 to 1.03055, saving model to model_37.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9048 - precision: 0.6208 - val_loss: 1.0305 - val_precision: 0.6135\n",
      "Epoch 7/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9011 - precision: 0.6176\n",
      "Epoch 7: val_loss improved from 1.03055 to 1.01851, saving model to model_37.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8935 - precision: 0.6194 - val_loss: 1.0185 - val_precision: 0.6174\n",
      "Epoch 8/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8779 - precision: 0.6275\n",
      "Epoch 8: val_loss improved from 1.01851 to 1.00999, saving model to model_37.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8781 - precision: 0.6266 - val_loss: 1.0100 - val_precision: 0.6186\n",
      "Epoch 9/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8654 - precision: 0.6334\n",
      "Epoch 9: val_loss did not improve from 1.00999\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8645 - precision: 0.6320 - val_loss: 1.0112 - val_precision: 0.6177\n",
      "Epoch 10/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8609 - precision: 0.6328\n",
      "Epoch 10: val_loss improved from 1.00999 to 1.00272, saving model to model_37.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8607 - precision: 0.6329 - val_loss: 1.0027 - val_precision: 0.6239\n",
      "Epoch 11/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8430 - precision: 0.6472\n",
      "Epoch 11: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8461 - precision: 0.6463 - val_loss: 1.0068 - val_precision: 0.6239\n",
      "Epoch 12/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.8327 - precision: 0.6547\n",
      "Epoch 12: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8292 - precision: 0.6542 - val_loss: 1.0294 - val_precision: 0.6181\n",
      "Epoch 13/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8197 - precision: 0.6508\n",
      "Epoch 13: val_loss improved from 1.00272 to 1.00023, saving model to model_37.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8197 - precision: 0.6508 - val_loss: 1.0002 - val_precision: 0.6276\n",
      "Epoch 14/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8126 - precision: 0.6561\n",
      "Epoch 14: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8115 - precision: 0.6572 - val_loss: 1.0033 - val_precision: 0.6260\n",
      "Epoch 15/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.8091 - precision: 0.6592\n",
      "Epoch 15: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8091 - precision: 0.6579 - val_loss: 1.0040 - val_precision: 0.6294\n",
      "Epoch 16/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.8041 - precision: 0.6610\n",
      "Epoch 16: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8018 - precision: 0.6601 - val_loss: 1.0039 - val_precision: 0.6261\n",
      "Epoch 17/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7872 - precision: 0.6701\n",
      "Epoch 17: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7872 - precision: 0.6701 - val_loss: 1.0165 - val_precision: 0.6301\n",
      "Epoch 18/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7869 - precision: 0.6678\n",
      "Epoch 18: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7862 - precision: 0.6691 - val_loss: 1.0090 - val_precision: 0.6258\n",
      "Epoch 19/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7741 - precision: 0.6711\n",
      "Epoch 19: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7730 - precision: 0.6723 - val_loss: 1.0197 - val_precision: 0.6241\n",
      "Epoch 20/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7678 - precision: 0.6734\n",
      "Epoch 20: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7681 - precision: 0.6769 - val_loss: 1.0123 - val_precision: 0.6190\n",
      "Epoch 21/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7658 - precision: 0.6741\n",
      "Epoch 21: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7689 - precision: 0.6723 - val_loss: 1.0259 - val_precision: 0.6207\n",
      "Epoch 22/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7528 - precision: 0.6843\n",
      "Epoch 22: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7532 - precision: 0.6840 - val_loss: 1.0256 - val_precision: 0.6230\n",
      "Epoch 23/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7481 - precision: 0.6828\n",
      "Epoch 23: val_loss did not improve from 1.00023\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7494 - precision: 0.6812 - val_loss: 1.0169 - val_precision: 0.6180\n",
      "Epoch 23: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8511 - precision: 0.6822\n",
      "Combinación 36 = (True, False, False, 8, 0.1) \n",
      " precision train: [0.8511258959770203, 0.6822317838668823]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 38: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.5293 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.37980, saving model to model_38.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.5283 - precision: 1.0000 - val_loss: 1.3798 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.2916 - precision: 0.5246\n",
      "Epoch 2: val_loss improved from 1.37980 to 1.26179, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2843 - precision: 0.5312 - val_loss: 1.2618 - val_precision: 0.6215\n",
      "Epoch 3/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1848 - precision: 0.6017\n",
      "Epoch 3: val_loss improved from 1.26179 to 1.17200, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1842 - precision: 0.6014 - val_loss: 1.1720 - val_precision: 0.6701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1137 - precision: 0.6269\n",
      "Epoch 4: val_loss improved from 1.17200 to 1.12258, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1113 - precision: 0.6267 - val_loss: 1.1226 - val_precision: 0.6697\n",
      "Epoch 5/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.0650 - precision: 0.6184\n",
      "Epoch 5: val_loss improved from 1.12258 to 1.07833, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0639 - precision: 0.6187 - val_loss: 1.0783 - val_precision: 0.6597\n",
      "Epoch 6/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.0427 - precision: 0.6142\n",
      "Epoch 6: val_loss improved from 1.07833 to 1.06629, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0411 - precision: 0.6147 - val_loss: 1.0663 - val_precision: 0.6300\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0248 - precision: 0.6057\n",
      "Epoch 7: val_loss improved from 1.06629 to 1.04987, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0250 - precision: 0.6055 - val_loss: 1.0499 - val_precision: 0.6276\n",
      "Epoch 8/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0064 - precision: 0.6111\n",
      "Epoch 8: val_loss improved from 1.04987 to 1.04942, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0064 - precision: 0.6111 - val_loss: 1.0494 - val_precision: 0.6186\n",
      "Epoch 9/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9986 - precision: 0.6131\n",
      "Epoch 9: val_loss improved from 1.04942 to 1.03730, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9956 - precision: 0.6132 - val_loss: 1.0373 - val_precision: 0.6277\n",
      "Epoch 10/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.9822 - precision: 0.6158\n",
      "Epoch 10: val_loss improved from 1.03730 to 1.03098, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9767 - precision: 0.6174 - val_loss: 1.0310 - val_precision: 0.6291\n",
      "Epoch 11/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.9646 - precision: 0.6247\n",
      "Epoch 11: val_loss improved from 1.03098 to 1.03080, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9658 - precision: 0.6255 - val_loss: 1.0308 - val_precision: 0.6290\n",
      "Epoch 12/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.9561 - precision: 0.6248\n",
      "Epoch 12: val_loss did not improve from 1.03080\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9522 - precision: 0.6295 - val_loss: 1.0324 - val_precision: 0.6265\n",
      "Epoch 13/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.9509 - precision: 0.6303\n",
      "Epoch 13: val_loss improved from 1.03080 to 1.02169, saving model to model_38.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9517 - precision: 0.6287 - val_loss: 1.0217 - val_precision: 0.6365\n",
      "Epoch 14/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9418 - precision: 0.6405\n",
      "Epoch 14: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9349 - precision: 0.6445 - val_loss: 1.0338 - val_precision: 0.6294\n",
      "Epoch 15/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9331 - precision: 0.6388\n",
      "Epoch 15: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9331 - precision: 0.6389 - val_loss: 1.0311 - val_precision: 0.6257\n",
      "Epoch 16/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.9359 - precision: 0.6373\n",
      "Epoch 16: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9323 - precision: 0.6400 - val_loss: 1.0383 - val_precision: 0.6260\n",
      "Epoch 17/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.9170 - precision: 0.6465\n",
      "Epoch 17: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9191 - precision: 0.6449 - val_loss: 1.0382 - val_precision: 0.6290\n",
      "Epoch 18/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.9108 - precision: 0.6505\n",
      "Epoch 18: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9138 - precision: 0.6495 - val_loss: 1.0333 - val_precision: 0.6253\n",
      "Epoch 19/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.9074 - precision: 0.6482\n",
      "Epoch 19: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9069 - precision: 0.6494 - val_loss: 1.0426 - val_precision: 0.6238\n",
      "Epoch 20/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8927 - precision: 0.6485\n",
      "Epoch 20: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8919 - precision: 0.6488 - val_loss: 1.0573 - val_precision: 0.6218\n",
      "Epoch 21/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8928 - precision: 0.6495\n",
      "Epoch 21: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8942 - precision: 0.6506 - val_loss: 1.0461 - val_precision: 0.6238\n",
      "Epoch 22/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8917 - precision: 0.6466\n",
      "Epoch 22: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8884 - precision: 0.6505 - val_loss: 1.0398 - val_precision: 0.6280\n",
      "Epoch 23/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8796 - precision: 0.6612\n",
      "Epoch 23: val_loss did not improve from 1.02169\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8848 - precision: 0.6572 - val_loss: 1.0401 - val_precision: 0.6232\n",
      "Epoch 23: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9206 - precision: 0.6642\n",
      "Combinación 37 = (True, False, False, 8, 0.25) \n",
      " precision train: [0.9205923676490784, 0.6642277240753174]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 39: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.5624 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.46397, saving model to model_39.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.5619 - precision: 0.0000e+00 - val_loss: 1.4640 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.4019 - precision: 0.2605\n",
      "Epoch 2: val_loss improved from 1.46397 to 1.35316, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3977 - precision: 0.2950 - val_loss: 1.3532 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.3311 - precision: 0.4495\n",
      "Epoch 3: val_loss improved from 1.35316 to 1.31011, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.3309 - precision: 0.4324 - val_loss: 1.3101 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2874 - precision: 0.5000\n",
      "Epoch 4: val_loss improved from 1.31011 to 1.28267, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2894 - precision: 0.4956 - val_loss: 1.2827 - val_precision: 0.7719\n",
      "Epoch 5/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2783 - precision: 0.4828\n",
      "Epoch 5: val_loss improved from 1.28267 to 1.24160, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2748 - precision: 0.4906 - val_loss: 1.2416 - val_precision: 0.6871\n",
      "Epoch 6/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2714 - precision: 0.5230\n",
      "Epoch 6: val_loss improved from 1.24160 to 1.22229, saving model to model_39.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2655 - precision: 0.5238 - val_loss: 1.2223 - val_precision: 0.6533\n",
      "Epoch 7/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.2596 - precision: 0.5191\n",
      "Epoch 7: val_loss improved from 1.22229 to 1.21199, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2609 - precision: 0.5237 - val_loss: 1.2120 - val_precision: 0.6787\n",
      "Epoch 8/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2495 - precision: 0.5297\n",
      "Epoch 8: val_loss improved from 1.21199 to 1.20445, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2480 - precision: 0.5287 - val_loss: 1.2044 - val_precision: 0.6448\n",
      "Epoch 9/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.2354 - precision: 0.5600\n",
      "Epoch 9: val_loss improved from 1.20445 to 1.19985, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2364 - precision: 0.5578 - val_loss: 1.1999 - val_precision: 0.6237\n",
      "Epoch 10/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.2314 - precision: 0.5488\n",
      "Epoch 10: val_loss improved from 1.19985 to 1.19438, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2327 - precision: 0.5483 - val_loss: 1.1944 - val_precision: 0.6203\n",
      "Epoch 11/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2317 - precision: 0.5271\n",
      "Epoch 11: val_loss did not improve from 1.19438\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2287 - precision: 0.5268 - val_loss: 1.1953 - val_precision: 0.6283\n",
      "Epoch 12/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2128 - precision: 0.5515\n",
      "Epoch 12: val_loss improved from 1.19438 to 1.18343, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2168 - precision: 0.5528 - val_loss: 1.1834 - val_precision: 0.6237\n",
      "Epoch 13/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.2183 - precision: 0.5255\n",
      "Epoch 13: val_loss improved from 1.18343 to 1.18102, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2150 - precision: 0.5296 - val_loss: 1.1810 - val_precision: 0.6133\n",
      "Epoch 14/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2052 - precision: 0.5478\n",
      "Epoch 14: val_loss did not improve from 1.18102\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2042 - precision: 0.5477 - val_loss: 1.1819 - val_precision: 0.6127\n",
      "Epoch 15/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2015 - precision: 0.5419\n",
      "Epoch 15: val_loss did not improve from 1.18102\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2046 - precision: 0.5422 - val_loss: 1.1833 - val_precision: 0.6114\n",
      "Epoch 16/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1989 - precision: 0.5595\n",
      "Epoch 16: val_loss improved from 1.18102 to 1.17709, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1954 - precision: 0.5589 - val_loss: 1.1771 - val_precision: 0.6095\n",
      "Epoch 17/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.1959 - precision: 0.5478\n",
      "Epoch 17: val_loss did not improve from 1.17709\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1941 - precision: 0.5498 - val_loss: 1.1823 - val_precision: 0.6132\n",
      "Epoch 18/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.1834 - precision: 0.5443\n",
      "Epoch 18: val_loss improved from 1.17709 to 1.17620, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1877 - precision: 0.5458 - val_loss: 1.1762 - val_precision: 0.6282\n",
      "Epoch 19/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1934 - precision: 0.5550\n",
      "Epoch 19: val_loss did not improve from 1.17620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1944 - precision: 0.5560 - val_loss: 1.1842 - val_precision: 0.6152\n",
      "Epoch 20/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1886 - precision: 0.5473\n",
      "Epoch 20: val_loss improved from 1.17620 to 1.17261, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1884 - precision: 0.5530 - val_loss: 1.1726 - val_precision: 0.6275\n",
      "Epoch 21/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.1908 - precision: 0.5351\n",
      "Epoch 21: val_loss improved from 1.17261 to 1.17085, saving model to model_39.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1904 - precision: 0.5353 - val_loss: 1.1708 - val_precision: 0.6200\n",
      "Epoch 22/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1706 - precision: 0.5511\n",
      "Epoch 22: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1692 - precision: 0.5484 - val_loss: 1.1846 - val_precision: 0.6137\n",
      "Epoch 23/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.1663 - precision: 0.5496\n",
      "Epoch 23: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1702 - precision: 0.5459 - val_loss: 1.1833 - val_precision: 0.6012\n",
      "Epoch 24/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1711 - precision: 0.5326\n",
      "Epoch 24: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1711 - precision: 0.5326 - val_loss: 1.1790 - val_precision: 0.6100\n",
      "Epoch 25/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.1635 - precision: 0.5385\n",
      "Epoch 25: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1692 - precision: 0.5361 - val_loss: 1.1737 - val_precision: 0.6199\n",
      "Epoch 26/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.1765 - precision: 0.5325\n",
      "Epoch 26: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1762 - precision: 0.5317 - val_loss: 1.1769 - val_precision: 0.6022\n",
      "Epoch 27/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1625 - precision: 0.5707\n",
      "Epoch 27: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1599 - precision: 0.5715 - val_loss: 1.1747 - val_precision: 0.6184\n",
      "Epoch 28/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1621 - precision: 0.5403\n",
      "Epoch 28: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1614 - precision: 0.5406 - val_loss: 1.1735 - val_precision: 0.6035\n",
      "Epoch 29/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.1419 - precision: 0.5619\n",
      "Epoch 29: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1448 - precision: 0.5631 - val_loss: 1.1782 - val_precision: 0.6190\n",
      "Epoch 30/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 1.1595 - precision: 0.5533\n",
      "Epoch 30: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1527 - precision: 0.5567 - val_loss: 1.1816 - val_precision: 0.5948\n",
      "Epoch 31/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.1660 - precision: 0.5364\n",
      "Epoch 31: val_loss did not improve from 1.17085\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1673 - precision: 0.5354 - val_loss: 1.1709 - val_precision: 0.5974\n",
      "Epoch 31: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.1025 - precision: 0.6280\n",
      "Combinación 38 = (True, False, False, 8, 0.5) \n",
      " precision train: [1.102501630783081, 0.6279523372650146]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 40: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.4135 - precision: 0.6175\n",
      "Epoch 1: val_loss improved from inf to 1.16633, saving model to model_40.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.3967 - precision: 0.6192 - val_loss: 1.1663 - val_precision: 0.6657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0220 - precision: 0.6245\n",
      "Epoch 2: val_loss improved from 1.16633 to 1.05250, saving model to model_40.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0164 - precision: 0.6227 - val_loss: 1.0525 - val_precision: 0.6287\n",
      "Epoch 3/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9304 - precision: 0.6214\n",
      "Epoch 3: val_loss improved from 1.05250 to 1.02288, saving model to model_40.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9312 - precision: 0.6212 - val_loss: 1.0229 - val_precision: 0.6269\n",
      "Epoch 4/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8923 - precision: 0.6316\n",
      "Epoch 4: val_loss did not improve from 1.02288\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8910 - precision: 0.6324 - val_loss: 1.0324 - val_precision: 0.6259\n",
      "Epoch 5/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8726 - precision: 0.6387\n",
      "Epoch 5: val_loss improved from 1.02288 to 0.99738, saving model to model_40.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8726 - precision: 0.6387 - val_loss: 0.9974 - val_precision: 0.6323\n",
      "Epoch 6/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8423 - precision: 0.6449\n",
      "Epoch 6: val_loss improved from 0.99738 to 0.99650, saving model to model_40.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8406 - precision: 0.6450 - val_loss: 0.9965 - val_precision: 0.6260\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8231 - precision: 0.6521\n",
      "Epoch 7: val_loss improved from 0.99650 to 0.97304, saving model to model_40.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8229 - precision: 0.6516 - val_loss: 0.9730 - val_precision: 0.6355\n",
      "Epoch 8/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8105 - precision: 0.6503\n",
      "Epoch 8: val_loss did not improve from 0.97304\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8094 - precision: 0.6518 - val_loss: 0.9763 - val_precision: 0.6393\n",
      "Epoch 9/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7915 - precision: 0.6617\n",
      "Epoch 9: val_loss did not improve from 0.97304\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7909 - precision: 0.6620 - val_loss: 1.0153 - val_precision: 0.6250\n",
      "Epoch 10/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7760 - precision: 0.6628\n",
      "Epoch 10: val_loss improved from 0.97304 to 0.96711, saving model to model_40.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7760 - precision: 0.6625 - val_loss: 0.9671 - val_precision: 0.6397\n",
      "Epoch 11/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7635 - precision: 0.6686\n",
      "Epoch 11: val_loss did not improve from 0.96711\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7639 - precision: 0.6682 - val_loss: 0.9757 - val_precision: 0.6403\n",
      "Epoch 12/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7501 - precision: 0.6748\n",
      "Epoch 12: val_loss improved from 0.96711 to 0.96609, saving model to model_40.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7497 - precision: 0.6747 - val_loss: 0.9661 - val_precision: 0.6349\n",
      "Epoch 13/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7336 - precision: 0.6790\n",
      "Epoch 13: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7342 - precision: 0.6784 - val_loss: 0.9942 - val_precision: 0.6273\n",
      "Epoch 14/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7262 - precision: 0.6836\n",
      "Epoch 14: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7254 - precision: 0.6832 - val_loss: 0.9741 - val_precision: 0.6374\n",
      "Epoch 15/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.7108 - precision: 0.6855\n",
      "Epoch 15: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7145 - precision: 0.6835 - val_loss: 0.9846 - val_precision: 0.6297\n",
      "Epoch 16/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7006 - precision: 0.6891\n",
      "Epoch 16: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7006 - precision: 0.6891 - val_loss: 0.9939 - val_precision: 0.6250\n",
      "Epoch 17/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6851 - precision: 0.6907\n",
      "Epoch 17: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6850 - precision: 0.6927 - val_loss: 0.9878 - val_precision: 0.6290\n",
      "Epoch 18/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6781 - precision: 0.6952\n",
      "Epoch 18: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6781 - precision: 0.6947 - val_loss: 0.9973 - val_precision: 0.6253\n",
      "Epoch 19/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6620 - precision: 0.6993\n",
      "Epoch 19: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6620 - precision: 0.6995 - val_loss: 1.0043 - val_precision: 0.6233\n",
      "Epoch 20/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6615 - precision: 0.7027\n",
      "Epoch 20: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6615 - precision: 0.7027 - val_loss: 1.0040 - val_precision: 0.6174\n",
      "Epoch 21/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6500 - precision: 0.7019\n",
      "Epoch 21: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6500 - precision: 0.7019 - val_loss: 0.9873 - val_precision: 0.6252\n",
      "Epoch 22/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6401 - precision: 0.7114\n",
      "Epoch 22: val_loss did not improve from 0.96609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6411 - precision: 0.7105 - val_loss: 1.0448 - val_precision: 0.6124\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8079 - precision: 0.6924\n",
      "Combinación 39 = (True, False, False, 16, 0.1) \n",
      " precision train: [0.8078823089599609, 0.6924027800559998]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 41: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.4111 - precision: 0.6315\n",
      "Epoch 1: val_loss improved from inf to 1.10050, saving model to model_41.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.3947 - precision: 0.6308 - val_loss: 1.1005 - val_precision: 0.6674\n",
      "Epoch 2/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0081 - precision: 0.6183\n",
      "Epoch 2: val_loss improved from 1.10050 to 1.03835, saving model to model_41.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0079 - precision: 0.6175 - val_loss: 1.0384 - val_precision: 0.6276\n",
      "Epoch 3/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9572 - precision: 0.6188\n",
      "Epoch 3: val_loss improved from 1.03835 to 1.01881, saving model to model_41.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9569 - precision: 0.6177 - val_loss: 1.0188 - val_precision: 0.6226\n",
      "Epoch 4/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9337 - precision: 0.6212\n",
      "Epoch 4: val_loss improved from 1.01881 to 0.99768, saving model to model_41.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9337 - precision: 0.6212 - val_loss: 0.9977 - val_precision: 0.6230\n",
      "Epoch 5/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9028 - precision: 0.6297\n",
      "Epoch 5: val_loss improved from 0.99768 to 0.98777, saving model to model_41.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9028 - precision: 0.6297 - val_loss: 0.9878 - val_precision: 0.6252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.9022 - precision: 0.6275\n",
      "Epoch 6: val_loss did not improve from 0.98777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9004 - precision: 0.6267 - val_loss: 0.9935 - val_precision: 0.6239\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8763 - precision: 0.6334\n",
      "Epoch 7: val_loss did not improve from 0.98777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8755 - precision: 0.6337 - val_loss: 0.9982 - val_precision: 0.6237\n",
      "Epoch 8/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8664 - precision: 0.6323\n",
      "Epoch 8: val_loss did not improve from 0.98777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8664 - precision: 0.6323 - val_loss: 1.0054 - val_precision: 0.6176\n",
      "Epoch 9/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8604 - precision: 0.6350\n",
      "Epoch 9: val_loss improved from 0.98777 to 0.98417, saving model to model_41.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8594 - precision: 0.6351 - val_loss: 0.9842 - val_precision: 0.6288\n",
      "Epoch 10/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8476 - precision: 0.6445\n",
      "Epoch 10: val_loss improved from 0.98417 to 0.98105, saving model to model_41.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8485 - precision: 0.6434 - val_loss: 0.9810 - val_precision: 0.6317\n",
      "Epoch 11/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8413 - precision: 0.6445\n",
      "Epoch 11: val_loss did not improve from 0.98105\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8413 - precision: 0.6447 - val_loss: 0.9912 - val_precision: 0.6267\n",
      "Epoch 12/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8302 - precision: 0.6525\n",
      "Epoch 12: val_loss did not improve from 0.98105\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8302 - precision: 0.6520 - val_loss: 1.0006 - val_precision: 0.6212\n",
      "Epoch 13/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8208 - precision: 0.6490\n",
      "Epoch 13: val_loss did not improve from 0.98105\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8208 - precision: 0.6490 - val_loss: 1.0008 - val_precision: 0.6194\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8171 - precision: 0.6496\n",
      "Epoch 14: val_loss did not improve from 0.98105\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8172 - precision: 0.6493 - val_loss: 0.9860 - val_precision: 0.6314\n",
      "Epoch 15/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8021 - precision: 0.6574\n",
      "Epoch 15: val_loss did not improve from 0.98105\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8032 - precision: 0.6572 - val_loss: 0.9877 - val_precision: 0.6287\n",
      "Epoch 16/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7931 - precision: 0.6582\n",
      "Epoch 16: val_loss improved from 0.98105 to 0.98044, saving model to model_41.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7936 - precision: 0.6573 - val_loss: 0.9804 - val_precision: 0.6356\n",
      "Epoch 17/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7898 - precision: 0.6584\n",
      "Epoch 17: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7889 - precision: 0.6586 - val_loss: 0.9851 - val_precision: 0.6330\n",
      "Epoch 18/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7763 - precision: 0.6650\n",
      "Epoch 18: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7759 - precision: 0.6663 - val_loss: 1.0000 - val_precision: 0.6193\n",
      "Epoch 19/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7638 - precision: 0.6705\n",
      "Epoch 19: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7655 - precision: 0.6708 - val_loss: 1.0213 - val_precision: 0.6187\n",
      "Epoch 20/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7528 - precision: 0.6725\n",
      "Epoch 20: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7525 - precision: 0.6727 - val_loss: 0.9850 - val_precision: 0.6287\n",
      "Epoch 21/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7550 - precision: 0.6750\n",
      "Epoch 21: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7553 - precision: 0.6757 - val_loss: 0.9865 - val_precision: 0.6285\n",
      "Epoch 22/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7557 - precision: 0.6792\n",
      "Epoch 22: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7551 - precision: 0.6792 - val_loss: 1.0011 - val_precision: 0.6263\n",
      "Epoch 23/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7455 - precision: 0.6795\n",
      "Epoch 23: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7450 - precision: 0.6796 - val_loss: 0.9891 - val_precision: 0.6296\n",
      "Epoch 24/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7426 - precision: 0.6774\n",
      "Epoch 24: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7421 - precision: 0.6771 - val_loss: 1.0188 - val_precision: 0.6233\n",
      "Epoch 25/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7285 - precision: 0.6887\n",
      "Epoch 25: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7299 - precision: 0.6883 - val_loss: 1.0003 - val_precision: 0.6287\n",
      "Epoch 26/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7260 - precision: 0.6884\n",
      "Epoch 26: val_loss did not improve from 0.98044\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7263 - precision: 0.6885 - val_loss: 1.0223 - val_precision: 0.6149\n",
      "Epoch 26: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8269 - precision: 0.6854\n",
      "Combinación 40 = (True, False, False, 16, 0.25) \n",
      " precision train: [0.8268582224845886, 0.6853655576705933]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 42: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.4980 - precision: 0.5180 \n",
      "Epoch 1: val_loss improved from inf to 1.31007, saving model to model_42.h5\n",
      "240/240 [==============================] - 6s 6ms/step - loss: 1.4892 - precision: 0.5279 - val_loss: 1.3101 - val_precision: 0.6574\n",
      "Epoch 2/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.3012 - precision: 0.5863\n",
      "Epoch 2: val_loss improved from 1.31007 to 1.24307, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2994 - precision: 0.5904 - val_loss: 1.2431 - val_precision: 0.7190\n",
      "Epoch 3/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2340 - precision: 0.5970\n",
      "Epoch 3: val_loss improved from 1.24307 to 1.19523, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2327 - precision: 0.5956 - val_loss: 1.1952 - val_precision: 0.6937\n",
      "Epoch 4/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1933 - precision: 0.5949\n",
      "Epoch 4: val_loss improved from 1.19523 to 1.16662, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1918 - precision: 0.5946 - val_loss: 1.1666 - val_precision: 0.6423\n",
      "Epoch 5/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1677 - precision: 0.6066\n",
      "Epoch 5: val_loss improved from 1.16662 to 1.15069, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1671 - precision: 0.6058 - val_loss: 1.1507 - val_precision: 0.6439\n",
      "Epoch 6/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1494 - precision: 0.6162\n",
      "Epoch 6: val_loss improved from 1.15069 to 1.13670, saving model to model_42.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1509 - precision: 0.6162 - val_loss: 1.1367 - val_precision: 0.6547\n",
      "Epoch 7/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1311 - precision: 0.6098\n",
      "Epoch 7: val_loss did not improve from 1.13670\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1316 - precision: 0.6074 - val_loss: 1.1430 - val_precision: 0.6192\n",
      "Epoch 8/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1212 - precision: 0.6131\n",
      "Epoch 8: val_loss improved from 1.13670 to 1.13532, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1210 - precision: 0.6161 - val_loss: 1.1353 - val_precision: 0.6449\n",
      "Epoch 9/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1154 - precision: 0.6248\n",
      "Epoch 9: val_loss improved from 1.13532 to 1.12583, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1145 - precision: 0.6249 - val_loss: 1.1258 - val_precision: 0.6492\n",
      "Epoch 10/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1044 - precision: 0.6165\n",
      "Epoch 10: val_loss improved from 1.12583 to 1.11267, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1025 - precision: 0.6178 - val_loss: 1.1127 - val_precision: 0.6455\n",
      "Epoch 11/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0881 - precision: 0.6358\n",
      "Epoch 11: val_loss improved from 1.11267 to 1.10155, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0885 - precision: 0.6361 - val_loss: 1.1016 - val_precision: 0.6554\n",
      "Epoch 12/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0580 - precision: 0.6206\n",
      "Epoch 12: val_loss improved from 1.10155 to 1.08688, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0568 - precision: 0.6212 - val_loss: 1.0869 - val_precision: 0.6510\n",
      "Epoch 13/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0555 - precision: 0.6148\n",
      "Epoch 13: val_loss improved from 1.08688 to 1.08090, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0558 - precision: 0.6141 - val_loss: 1.0809 - val_precision: 0.6331\n",
      "Epoch 14/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0352 - precision: 0.6164\n",
      "Epoch 14: val_loss improved from 1.08090 to 1.05942, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0352 - precision: 0.6164 - val_loss: 1.0594 - val_precision: 0.6331\n",
      "Epoch 15/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0183 - precision: 0.6213\n",
      "Epoch 15: val_loss improved from 1.05942 to 1.05322, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0191 - precision: 0.6204 - val_loss: 1.0532 - val_precision: 0.6177\n",
      "Epoch 16/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.0207 - precision: 0.6117\n",
      "Epoch 16: val_loss improved from 1.05322 to 1.04400, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0207 - precision: 0.6118 - val_loss: 1.0440 - val_precision: 0.6187\n",
      "Epoch 17/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9984 - precision: 0.6225\n",
      "Epoch 17: val_loss did not improve from 1.04400\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9992 - precision: 0.6220 - val_loss: 1.0443 - val_precision: 0.6133\n",
      "Epoch 18/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9909 - precision: 0.6172\n",
      "Epoch 18: val_loss did not improve from 1.04400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9906 - precision: 0.6169 - val_loss: 1.0443 - val_precision: 0.6139\n",
      "Epoch 19/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9921 - precision: 0.6190\n",
      "Epoch 19: val_loss improved from 1.04400 to 1.03978, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9892 - precision: 0.6198 - val_loss: 1.0398 - val_precision: 0.6093\n",
      "Epoch 20/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9830 - precision: 0.6216\n",
      "Epoch 20: val_loss did not improve from 1.03978\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9830 - precision: 0.6216 - val_loss: 1.0400 - val_precision: 0.6101\n",
      "Epoch 21/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9760 - precision: 0.6218\n",
      "Epoch 21: val_loss improved from 1.03978 to 1.02959, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9755 - precision: 0.6222 - val_loss: 1.0296 - val_precision: 0.6119\n",
      "Epoch 22/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9699 - precision: 0.6250\n",
      "Epoch 22: val_loss did not improve from 1.02959\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9702 - precision: 0.6242 - val_loss: 1.0336 - val_precision: 0.6122\n",
      "Epoch 23/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9537 - precision: 0.6276\n",
      "Epoch 23: val_loss improved from 1.02959 to 1.02922, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9541 - precision: 0.6279 - val_loss: 1.0292 - val_precision: 0.6168\n",
      "Epoch 24/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9696 - precision: 0.6224\n",
      "Epoch 24: val_loss did not improve from 1.02922\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9697 - precision: 0.6234 - val_loss: 1.0297 - val_precision: 0.6146\n",
      "Epoch 25/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9472 - precision: 0.6280\n",
      "Epoch 25: val_loss did not improve from 1.02922\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9518 - precision: 0.6256 - val_loss: 1.0381 - val_precision: 0.6111\n",
      "Epoch 26/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9648 - precision: 0.6260\n",
      "Epoch 26: val_loss improved from 1.02922 to 1.02420, saving model to model_42.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9648 - precision: 0.6263 - val_loss: 1.0242 - val_precision: 0.6215\n",
      "Epoch 27/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9480 - precision: 0.6331\n",
      "Epoch 27: val_loss did not improve from 1.02420\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9476 - precision: 0.6325 - val_loss: 1.0272 - val_precision: 0.6149\n",
      "Epoch 28/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9355 - precision: 0.6363\n",
      "Epoch 28: val_loss did not improve from 1.02420\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9346 - precision: 0.6372 - val_loss: 1.0417 - val_precision: 0.6077\n",
      "Epoch 29/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9237 - precision: 0.6377\n",
      "Epoch 29: val_loss did not improve from 1.02420\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9254 - precision: 0.6380 - val_loss: 1.0443 - val_precision: 0.6069\n",
      "Epoch 30/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9257 - precision: 0.6387\n",
      "Epoch 30: val_loss did not improve from 1.02420\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9256 - precision: 0.6391 - val_loss: 1.0359 - val_precision: 0.6107\n",
      "Epoch 31/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9278 - precision: 0.6337\n",
      "Epoch 31: val_loss did not improve from 1.02420\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9277 - precision: 0.6341 - val_loss: 1.0304 - val_precision: 0.6095\n",
      "Epoch 32/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9183 - precision: 0.6405\n",
      "Epoch 32: val_loss did not improve from 1.02420\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9150 - precision: 0.6426 - val_loss: 1.0484 - val_precision: 0.6057\n",
      "Epoch 33/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9227 - precision: 0.6284\n",
      "Epoch 33: val_loss did not improve from 1.02420\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9262 - precision: 0.6271 - val_loss: 1.0304 - val_precision: 0.6123\n",
      "Epoch 34/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9165 - precision: 0.6477\n",
      "Epoch 34: val_loss did not improve from 1.02420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9171 - precision: 0.6473 - val_loss: 1.0408 - val_precision: 0.6098\n",
      "Epoch 35/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9237 - precision: 0.6380\n",
      "Epoch 35: val_loss did not improve from 1.02420\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9219 - precision: 0.6384 - val_loss: 1.0384 - val_precision: 0.6111\n",
      "Epoch 36/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9056 - precision: 0.6461\n",
      "Epoch 36: val_loss did not improve from 1.02420\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9068 - precision: 0.6466 - val_loss: 1.0495 - val_precision: 0.6050\n",
      "Epoch 36: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9256 - precision: 0.6438\n",
      "Combinación 41 = (True, False, False, 16, 0.5) \n",
      " precision train: [0.9256336688995361, 0.6438255906105042]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 43: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.2421 - precision: 0.6379\n",
      "Epoch 1: val_loss improved from inf to 1.03080, saving model to model_43.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.2406 - precision: 0.6377 - val_loss: 1.0308 - val_precision: 0.6340\n",
      "Epoch 2/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8984 - precision: 0.6248\n",
      "Epoch 2: val_loss improved from 1.03080 to 0.98728, saving model to model_43.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8907 - precision: 0.6250 - val_loss: 0.9873 - val_precision: 0.6295\n",
      "Epoch 3/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8455 - precision: 0.6330\n",
      "Epoch 3: val_loss improved from 0.98728 to 0.97909, saving model to model_43.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8486 - precision: 0.6318 - val_loss: 0.9791 - val_precision: 0.6273\n",
      "Epoch 4/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8094 - precision: 0.6437\n",
      "Epoch 4: val_loss improved from 0.97909 to 0.94315, saving model to model_43.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8087 - precision: 0.6428 - val_loss: 0.9432 - val_precision: 0.6433\n",
      "Epoch 5/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7886 - precision: 0.6535\n",
      "Epoch 5: val_loss did not improve from 0.94315\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7928 - precision: 0.6536 - val_loss: 0.9531 - val_precision: 0.6419\n",
      "Epoch 6/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7620 - precision: 0.6619\n",
      "Epoch 6: val_loss improved from 0.94315 to 0.92720, saving model to model_43.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7632 - precision: 0.6602 - val_loss: 0.9272 - val_precision: 0.6423\n",
      "Epoch 7/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7447 - precision: 0.6658\n",
      "Epoch 7: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7451 - precision: 0.6656 - val_loss: 0.9541 - val_precision: 0.6367\n",
      "Epoch 8/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7378 - precision: 0.6652\n",
      "Epoch 8: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7355 - precision: 0.6666 - val_loss: 0.9451 - val_precision: 0.6420\n",
      "Epoch 9/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7140 - precision: 0.6742\n",
      "Epoch 9: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7153 - precision: 0.6724 - val_loss: 0.9307 - val_precision: 0.6424\n",
      "Epoch 10/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7050 - precision: 0.6693\n",
      "Epoch 10: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7029 - precision: 0.6714 - val_loss: 0.9433 - val_precision: 0.6415\n",
      "Epoch 11/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6841 - precision: 0.6809\n",
      "Epoch 11: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6837 - precision: 0.6798 - val_loss: 0.9400 - val_precision: 0.6450\n",
      "Epoch 12/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6714 - precision: 0.6869\n",
      "Epoch 12: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6722 - precision: 0.6871 - val_loss: 0.9612 - val_precision: 0.6422\n",
      "Epoch 13/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6599 - precision: 0.6897\n",
      "Epoch 13: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6601 - precision: 0.6899 - val_loss: 0.9692 - val_precision: 0.6337\n",
      "Epoch 14/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6536 - precision: 0.6960\n",
      "Epoch 14: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6515 - precision: 0.6971 - val_loss: 1.0073 - val_precision: 0.6295\n",
      "Epoch 15/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6410 - precision: 0.7003\n",
      "Epoch 15: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6400 - precision: 0.6988 - val_loss: 0.9824 - val_precision: 0.6308\n",
      "Epoch 16/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.6267 - precision: 0.7052\n",
      "Epoch 16: val_loss did not improve from 0.92720\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6289 - precision: 0.7046 - val_loss: 0.9703 - val_precision: 0.6276\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7529 - precision: 0.7019\n",
      "Combinación 42 = (True, False, False, 32, 0.1) \n",
      " precision train: [0.7528893351554871, 0.7018525004386902]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 44: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.2570 - precision: 0.6217\n",
      "Epoch 1: val_loss improved from inf to 1.05248, saving model to model_44.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.2558 - precision: 0.6203 - val_loss: 1.0525 - val_precision: 0.6334\n",
      "Epoch 2/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9291 - precision: 0.6257\n",
      "Epoch 2: val_loss improved from 1.05248 to 1.00934, saving model to model_44.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9290 - precision: 0.6245 - val_loss: 1.0093 - val_precision: 0.6329\n",
      "Epoch 3/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8931 - precision: 0.6272\n",
      "Epoch 3: val_loss improved from 1.00934 to 1.00163, saving model to model_44.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8893 - precision: 0.6271 - val_loss: 1.0016 - val_precision: 0.6298\n",
      "Epoch 4/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8660 - precision: 0.6264\n",
      "Epoch 4: val_loss improved from 1.00163 to 0.98197, saving model to model_44.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8658 - precision: 0.6280 - val_loss: 0.9820 - val_precision: 0.6284\n",
      "Epoch 5/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8415 - precision: 0.6351\n",
      "Epoch 5: val_loss improved from 0.98197 to 0.96744, saving model to model_44.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8438 - precision: 0.6362 - val_loss: 0.9674 - val_precision: 0.6328\n",
      "Epoch 6/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8246 - precision: 0.6419\n",
      "Epoch 6: val_loss did not improve from 0.96744\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8267 - precision: 0.6432 - val_loss: 0.9675 - val_precision: 0.6328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8073 - precision: 0.6501\n",
      "Epoch 7: val_loss improved from 0.96744 to 0.95483, saving model to model_44.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8088 - precision: 0.6495 - val_loss: 0.9548 - val_precision: 0.6448\n",
      "Epoch 8/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7975 - precision: 0.6461\n",
      "Epoch 8: val_loss improved from 0.95483 to 0.94293, saving model to model_44.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7952 - precision: 0.6499 - val_loss: 0.9429 - val_precision: 0.6469\n",
      "Epoch 9/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7782 - precision: 0.6589\n",
      "Epoch 9: val_loss did not improve from 0.94293\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7766 - precision: 0.6597 - val_loss: 0.9679 - val_precision: 0.6357\n",
      "Epoch 10/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7654 - precision: 0.6648\n",
      "Epoch 10: val_loss did not improve from 0.94293\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7614 - precision: 0.6657 - val_loss: 0.9525 - val_precision: 0.6422\n",
      "Epoch 11/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7450 - precision: 0.6709\n",
      "Epoch 11: val_loss did not improve from 0.94293\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7475 - precision: 0.6707 - val_loss: 0.9584 - val_precision: 0.6402\n",
      "Epoch 12/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7407 - precision: 0.6716\n",
      "Epoch 12: val_loss improved from 0.94293 to 0.94216, saving model to model_44.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7407 - precision: 0.6737 - val_loss: 0.9422 - val_precision: 0.6459\n",
      "Epoch 13/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7298 - precision: 0.6782\n",
      "Epoch 13: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7322 - precision: 0.6771 - val_loss: 0.9782 - val_precision: 0.6297\n",
      "Epoch 14/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7142 - precision: 0.6808\n",
      "Epoch 14: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7145 - precision: 0.6794 - val_loss: 0.9589 - val_precision: 0.6432\n",
      "Epoch 15/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7035 - precision: 0.6876\n",
      "Epoch 15: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7042 - precision: 0.6864 - val_loss: 0.9540 - val_precision: 0.6413\n",
      "Epoch 16/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6913 - precision: 0.6891\n",
      "Epoch 16: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6905 - precision: 0.6903 - val_loss: 0.9981 - val_precision: 0.6331\n",
      "Epoch 17/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.6947 - precision: 0.6871\n",
      "Epoch 17: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6946 - precision: 0.6871 - val_loss: 0.9921 - val_precision: 0.6335\n",
      "Epoch 18/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6703 - precision: 0.7002\n",
      "Epoch 18: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6695 - precision: 0.7007 - val_loss: 0.9925 - val_precision: 0.6343\n",
      "Epoch 19/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6612 - precision: 0.6925\n",
      "Epoch 19: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6603 - precision: 0.6958 - val_loss: 1.0171 - val_precision: 0.6231\n",
      "Epoch 20/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6584 - precision: 0.6952\n",
      "Epoch 20: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6584 - precision: 0.6952 - val_loss: 0.9897 - val_precision: 0.6338\n",
      "Epoch 21/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6478 - precision: 0.7086\n",
      "Epoch 21: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6509 - precision: 0.7065 - val_loss: 0.9868 - val_precision: 0.6296\n",
      "Epoch 22/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6449 - precision: 0.6988\n",
      "Epoch 22: val_loss did not improve from 0.94216\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6481 - precision: 0.6989 - val_loss: 1.0004 - val_precision: 0.6269\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7511 - precision: 0.7034\n",
      "Combinación 43 = (True, False, False, 32, 0.25) \n",
      " precision train: [0.7510619163513184, 0.703412652015686]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 45: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.4450 - precision: 0.6590\n",
      "Epoch 1: val_loss improved from inf to 1.18481, saving model to model_45.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.4420 - precision: 0.6601 - val_loss: 1.1848 - val_precision: 0.6933\n",
      "Epoch 2/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0996 - precision: 0.6251\n",
      "Epoch 2: val_loss improved from 1.18481 to 1.06224, saving model to model_45.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0977 - precision: 0.6219 - val_loss: 1.0622 - val_precision: 0.6377\n",
      "Epoch 3/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.0223 - precision: 0.6111\n",
      "Epoch 3: val_loss improved from 1.06224 to 1.03977, saving model to model_45.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0227 - precision: 0.6110 - val_loss: 1.0398 - val_precision: 0.6289\n",
      "Epoch 4/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9819 - precision: 0.6261\n",
      "Epoch 4: val_loss did not improve from 1.03977\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9824 - precision: 0.6257 - val_loss: 1.0448 - val_precision: 0.6201\n",
      "Epoch 5/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9515 - precision: 0.6264\n",
      "Epoch 5: val_loss improved from 1.03977 to 1.01407, saving model to model_45.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9521 - precision: 0.6274 - val_loss: 1.0141 - val_precision: 0.6362\n",
      "Epoch 6/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9383 - precision: 0.6330\n",
      "Epoch 6: val_loss did not improve from 1.01407\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9350 - precision: 0.6338 - val_loss: 1.0340 - val_precision: 0.6215\n",
      "Epoch 7/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9319 - precision: 0.6225\n",
      "Epoch 7: val_loss did not improve from 1.01407\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9317 - precision: 0.6214 - val_loss: 1.0260 - val_precision: 0.6236\n",
      "Epoch 8/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9204 - precision: 0.6298\n",
      "Epoch 8: val_loss improved from 1.01407 to 0.99666, saving model to model_45.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9219 - precision: 0.6296 - val_loss: 0.9967 - val_precision: 0.6349\n",
      "Epoch 9/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9063 - precision: 0.6302\n",
      "Epoch 9: val_loss did not improve from 0.99666\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9025 - precision: 0.6341 - val_loss: 0.9968 - val_precision: 0.6375\n",
      "Epoch 10/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8982 - precision: 0.6360\n",
      "Epoch 10: val_loss did not improve from 0.99666\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8992 - precision: 0.6359 - val_loss: 1.0099 - val_precision: 0.6203\n",
      "Epoch 11/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8862 - precision: 0.6390\n",
      "Epoch 11: val_loss did not improve from 0.99666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8868 - precision: 0.6389 - val_loss: 0.9980 - val_precision: 0.6270\n",
      "Epoch 12/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8785 - precision: 0.6421\n",
      "Epoch 12: val_loss did not improve from 0.99666\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8782 - precision: 0.6412 - val_loss: 1.0086 - val_precision: 0.6241\n",
      "Epoch 13/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8766 - precision: 0.6337\n",
      "Epoch 13: val_loss did not improve from 0.99666\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8786 - precision: 0.6356 - val_loss: 1.0027 - val_precision: 0.6274\n",
      "Epoch 14/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8532 - precision: 0.6436\n",
      "Epoch 14: val_loss did not improve from 0.99666\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8567 - precision: 0.6408 - val_loss: 1.0077 - val_precision: 0.6165\n",
      "Epoch 15/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8556 - precision: 0.6443\n",
      "Epoch 15: val_loss did not improve from 0.99666\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8585 - precision: 0.6426 - val_loss: 0.9974 - val_precision: 0.6237\n",
      "Epoch 16/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.8534 - precision: 0.6404\n",
      "Epoch 16: val_loss did not improve from 0.99666\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8558 - precision: 0.6425 - val_loss: 1.0152 - val_precision: 0.6226\n",
      "Epoch 17/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8297 - precision: 0.6499\n",
      "Epoch 17: val_loss did not improve from 0.99666\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8286 - precision: 0.6492 - val_loss: 1.0182 - val_precision: 0.6151\n",
      "Epoch 18/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8481 - precision: 0.6398\n",
      "Epoch 18: val_loss did not improve from 0.99666\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8445 - precision: 0.6414 - val_loss: 1.0180 - val_precision: 0.6165\n",
      "Epoch 18: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9073 - precision: 0.6492\n",
      "Combinación 44 = (True, False, False, 32, 0.5) \n",
      " precision train: [0.9072613716125488, 0.6491733193397522]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 46: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1704 - precision: 0.6164\n",
      "Epoch 1: val_loss improved from inf to 1.02386, saving model to model_46.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.1658 - precision: 0.6162 - val_loss: 1.0239 - val_precision: 0.6379\n",
      "Epoch 2/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8868 - precision: 0.6282\n",
      "Epoch 2: val_loss improved from 1.02386 to 0.96467, saving model to model_46.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8847 - precision: 0.6274 - val_loss: 0.9647 - val_precision: 0.6554\n",
      "Epoch 3/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8278 - precision: 0.6407\n",
      "Epoch 3: val_loss improved from 0.96467 to 0.95014, saving model to model_46.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8266 - precision: 0.6418 - val_loss: 0.9501 - val_precision: 0.6463\n",
      "Epoch 4/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7837 - precision: 0.6563\n",
      "Epoch 4: val_loss improved from 0.95014 to 0.94477, saving model to model_46.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7816 - precision: 0.6554 - val_loss: 0.9448 - val_precision: 0.6393\n",
      "Epoch 5/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7543 - precision: 0.6644\n",
      "Epoch 5: val_loss improved from 0.94477 to 0.93183, saving model to model_46.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7545 - precision: 0.6632 - val_loss: 0.9318 - val_precision: 0.6499\n",
      "Epoch 6/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7336 - precision: 0.6631\n",
      "Epoch 6: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7325 - precision: 0.6634 - val_loss: 0.9371 - val_precision: 0.6439\n",
      "Epoch 7/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7078 - precision: 0.6688\n",
      "Epoch 7: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7151 - precision: 0.6662 - val_loss: 0.9556 - val_precision: 0.6394\n",
      "Epoch 8/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.6967 - precision: 0.6734\n",
      "Epoch 8: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6971 - precision: 0.6725 - val_loss: 0.9537 - val_precision: 0.6336\n",
      "Epoch 9/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6779 - precision: 0.6767\n",
      "Epoch 9: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6799 - precision: 0.6755 - val_loss: 0.9933 - val_precision: 0.6216\n",
      "Epoch 10/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6646 - precision: 0.6825\n",
      "Epoch 10: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6646 - precision: 0.6825 - val_loss: 1.0045 - val_precision: 0.6254\n",
      "Epoch 11/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6515 - precision: 0.6831\n",
      "Epoch 11: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6520 - precision: 0.6823 - val_loss: 0.9513 - val_precision: 0.6363\n",
      "Epoch 12/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6287 - precision: 0.6954\n",
      "Epoch 12: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6287 - precision: 0.6954 - val_loss: 0.9897 - val_precision: 0.6273\n",
      "Epoch 13/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.6145 - precision: 0.6963\n",
      "Epoch 13: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6178 - precision: 0.6968 - val_loss: 0.9828 - val_precision: 0.6294\n",
      "Epoch 14/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.5995 - precision: 0.7026\n",
      "Epoch 14: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6004 - precision: 0.7020 - val_loss: 1.0493 - val_precision: 0.6164\n",
      "Epoch 15/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.5902 - precision: 0.7075\n",
      "Epoch 15: val_loss did not improve from 0.93183\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5899 - precision: 0.7072 - val_loss: 1.0378 - val_precision: 0.6120\n",
      "Epoch 15: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7448 - precision: 0.6972\n",
      "Combinación 45 = (True, False, False, 64, 0.1) \n",
      " precision train: [0.7447698712348938, 0.6972456574440002]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 47: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.1791 - precision: 0.6278\n",
      "Epoch 1: val_loss improved from inf to 1.01468, saving model to model_47.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.1700 - precision: 0.6276 - val_loss: 1.0147 - val_precision: 0.6415\n",
      "Epoch 2/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8944 - precision: 0.6268\n",
      "Epoch 2: val_loss improved from 1.01468 to 0.95678, saving model to model_47.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8942 - precision: 0.6270 - val_loss: 0.9568 - val_precision: 0.6594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8392 - precision: 0.6384\n",
      "Epoch 3: val_loss improved from 0.95678 to 0.94911, saving model to model_47.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8410 - precision: 0.6377 - val_loss: 0.9491 - val_precision: 0.6449\n",
      "Epoch 4/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8061 - precision: 0.6532\n",
      "Epoch 4: val_loss improved from 0.94911 to 0.94386, saving model to model_47.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8087 - precision: 0.6513 - val_loss: 0.9439 - val_precision: 0.6365\n",
      "Epoch 5/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7813 - precision: 0.6532\n",
      "Epoch 5: val_loss improved from 0.94386 to 0.91843, saving model to model_47.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7803 - precision: 0.6546 - val_loss: 0.9184 - val_precision: 0.6491\n",
      "Epoch 6/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7618 - precision: 0.6625\n",
      "Epoch 6: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7614 - precision: 0.6626 - val_loss: 0.9225 - val_precision: 0.6449\n",
      "Epoch 7/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7398 - precision: 0.6631\n",
      "Epoch 7: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7398 - precision: 0.6631 - val_loss: 0.9760 - val_precision: 0.6240\n",
      "Epoch 8/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7330 - precision: 0.6662\n",
      "Epoch 8: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7352 - precision: 0.6647 - val_loss: 0.9524 - val_precision: 0.6305\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7121 - precision: 0.6690\n",
      "Epoch 9: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7143 - precision: 0.6683 - val_loss: 0.9363 - val_precision: 0.6449\n",
      "Epoch 10/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6951 - precision: 0.6795\n",
      "Epoch 10: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6951 - precision: 0.6795 - val_loss: 0.9569 - val_precision: 0.6425\n",
      "Epoch 11/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6883 - precision: 0.6799\n",
      "Epoch 11: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6859 - precision: 0.6813 - val_loss: 0.9953 - val_precision: 0.6281\n",
      "Epoch 12/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6745 - precision: 0.6833\n",
      "Epoch 12: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6733 - precision: 0.6842 - val_loss: 0.9669 - val_precision: 0.6375\n",
      "Epoch 13/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6602 - precision: 0.6853\n",
      "Epoch 13: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6605 - precision: 0.6860 - val_loss: 0.9714 - val_precision: 0.6346\n",
      "Epoch 14/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.6490 - precision: 0.6891\n",
      "Epoch 14: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6505 - precision: 0.6899 - val_loss: 0.9646 - val_precision: 0.6323\n",
      "Epoch 15/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.6437 - precision: 0.6907\n",
      "Epoch 15: val_loss did not improve from 0.91843\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6451 - precision: 0.6892 - val_loss: 0.9845 - val_precision: 0.6294\n",
      "Epoch 15: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7518 - precision: 0.6910\n",
      "Combinación 46 = (True, False, False, 64, 0.25) \n",
      " precision train: [0.751797080039978, 0.6909900903701782]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 48: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.3025 - precision: 0.6037\n",
      "Epoch 1: val_loss improved from inf to 1.04382, saving model to model_48.h5\n",
      "240/240 [==============================] - 4s 7ms/step - loss: 1.2895 - precision: 0.6034 - val_loss: 1.0438 - val_precision: 0.6286\n",
      "Epoch 2/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9581 - precision: 0.6264\n",
      "Epoch 2: val_loss improved from 1.04382 to 1.00229, saving model to model_48.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9583 - precision: 0.6243 - val_loss: 1.0023 - val_precision: 0.6267\n",
      "Epoch 3/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9184 - precision: 0.6266\n",
      "Epoch 3: val_loss improved from 1.00229 to 0.99164, saving model to model_48.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9151 - precision: 0.6274 - val_loss: 0.9916 - val_precision: 0.6270\n",
      "Epoch 4/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8860 - precision: 0.6275\n",
      "Epoch 4: val_loss improved from 0.99164 to 0.95958, saving model to model_48.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8859 - precision: 0.6273 - val_loss: 0.9596 - val_precision: 0.6392\n",
      "Epoch 5/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8534 - precision: 0.6357\n",
      "Epoch 5: val_loss did not improve from 0.95958\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8523 - precision: 0.6369 - val_loss: 0.9663 - val_precision: 0.6314\n",
      "Epoch 6/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8396 - precision: 0.6443\n",
      "Epoch 6: val_loss improved from 0.95958 to 0.94361, saving model to model_48.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8389 - precision: 0.6444 - val_loss: 0.9436 - val_precision: 0.6443\n",
      "Epoch 7/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8227 - precision: 0.6441\n",
      "Epoch 7: val_loss improved from 0.94361 to 0.93513, saving model to model_48.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8227 - precision: 0.6441 - val_loss: 0.9351 - val_precision: 0.6457\n",
      "Epoch 8/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8040 - precision: 0.6585\n",
      "Epoch 8: val_loss did not improve from 0.93513\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8041 - precision: 0.6584 - val_loss: 1.0007 - val_precision: 0.6305\n",
      "Epoch 9/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7959 - precision: 0.6577\n",
      "Epoch 9: val_loss did not improve from 0.93513\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7988 - precision: 0.6556 - val_loss: 0.9589 - val_precision: 0.6396\n",
      "Epoch 10/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7817 - precision: 0.6608\n",
      "Epoch 10: val_loss did not improve from 0.93513\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7811 - precision: 0.6618 - val_loss: 0.9478 - val_precision: 0.6444\n",
      "Epoch 11/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7764 - precision: 0.6572\n",
      "Epoch 11: val_loss did not improve from 0.93513\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7789 - precision: 0.6579 - val_loss: 0.9403 - val_precision: 0.6462\n",
      "Epoch 12/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7700 - precision: 0.6651\n",
      "Epoch 12: val_loss did not improve from 0.93513\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7669 - precision: 0.6650 - val_loss: 0.9499 - val_precision: 0.6511\n",
      "Epoch 13/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7576 - precision: 0.6655\n",
      "Epoch 13: val_loss did not improve from 0.93513\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7556 - precision: 0.6664 - val_loss: 0.9628 - val_precision: 0.6408\n",
      "Epoch 14/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7462 - precision: 0.6678\n",
      "Epoch 14: val_loss did not improve from 0.93513\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7468 - precision: 0.6685 - val_loss: 0.9442 - val_precision: 0.6445\n",
      "Epoch 15/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7401 - precision: 0.6685\n",
      "Epoch 15: val_loss did not improve from 0.93513\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7378 - precision: 0.6718 - val_loss: 0.9480 - val_precision: 0.6404\n",
      "Epoch 16/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7262 - precision: 0.6776\n",
      "Epoch 16: val_loss did not improve from 0.93513\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7262 - precision: 0.6776 - val_loss: 0.9792 - val_precision: 0.6309\n",
      "Epoch 17/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7237 - precision: 0.6742\n",
      "Epoch 17: val_loss improved from 0.93513 to 0.93485, saving model to model_48.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7251 - precision: 0.6764 - val_loss: 0.9349 - val_precision: 0.6435\n",
      "Epoch 18/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7112 - precision: 0.6810\n",
      "Epoch 18: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7123 - precision: 0.6817 - val_loss: 0.9811 - val_precision: 0.6321\n",
      "Epoch 19/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7083 - precision: 0.6816\n",
      "Epoch 19: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7098 - precision: 0.6789 - val_loss: 0.9666 - val_precision: 0.6375\n",
      "Epoch 20/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.6976 - precision: 0.6857\n",
      "Epoch 20: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6962 - precision: 0.6862 - val_loss: 0.9816 - val_precision: 0.6287\n",
      "Epoch 21/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.6911 - precision: 0.6834\n",
      "Epoch 21: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6912 - precision: 0.6849 - val_loss: 0.9930 - val_precision: 0.6294\n",
      "Epoch 22/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.6887 - precision: 0.6825\n",
      "Epoch 22: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6890 - precision: 0.6827 - val_loss: 0.9756 - val_precision: 0.6313\n",
      "Epoch 23/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.6776 - precision: 0.6897\n",
      "Epoch 23: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6812 - precision: 0.6882 - val_loss: 0.9791 - val_precision: 0.6303\n",
      "Epoch 24/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6676 - precision: 0.6914\n",
      "Epoch 24: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6676 - precision: 0.6914 - val_loss: 1.0053 - val_precision: 0.6290\n",
      "Epoch 25/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6743 - precision: 0.6892\n",
      "Epoch 25: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6704 - precision: 0.6905 - val_loss: 0.9928 - val_precision: 0.6316\n",
      "Epoch 26/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6601 - precision: 0.6918\n",
      "Epoch 26: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6601 - precision: 0.6918 - val_loss: 1.0181 - val_precision: 0.6185\n",
      "Epoch 27/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6589 - precision: 0.7019\n",
      "Epoch 27: val_loss did not improve from 0.93485\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6589 - precision: 0.7019 - val_loss: 0.9958 - val_precision: 0.6232\n",
      "Epoch 27: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7635 - precision: 0.6958\n",
      "Combinación 47 = (True, False, False, 64, 0.5) \n",
      " precision train: [0.7635489106178284, 0.6958426833152771]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 49: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.5340 - precision: 0.6968 \n",
      "Epoch 1: val_loss improved from inf to 1.37444, saving model to model_49.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5334 - precision: 0.6934 - val_loss: 1.3744 - val_precision: 0.6868\n",
      "Epoch 2/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.3385 - precision: 0.6947\n",
      "Epoch 2: val_loss improved from 1.37444 to 1.26057, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3333 - precision: 0.7001 - val_loss: 1.2606 - val_precision: 0.6777\n",
      "Epoch 3/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.2278 - precision: 0.6880\n",
      "Epoch 3: val_loss improved from 1.26057 to 1.21701, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2261 - precision: 0.6860 - val_loss: 1.2170 - val_precision: 0.6474\n",
      "Epoch 4/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1643 - precision: 0.6124\n",
      "Epoch 4: val_loss improved from 1.21701 to 1.20293, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1664 - precision: 0.6118 - val_loss: 1.2029 - val_precision: 0.5980\n",
      "Epoch 5/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1339 - precision: 0.6083\n",
      "Epoch 5: val_loss improved from 1.20293 to 1.17233, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1325 - precision: 0.6118 - val_loss: 1.1723 - val_precision: 0.5998\n",
      "Epoch 6/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1051 - precision: 0.6200\n",
      "Epoch 6: val_loss improved from 1.17233 to 1.14134, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1069 - precision: 0.6191 - val_loss: 1.1413 - val_precision: 0.5962\n",
      "Epoch 7/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0614 - precision: 0.6377\n",
      "Epoch 7: val_loss improved from 1.14134 to 1.11292, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0637 - precision: 0.6383 - val_loss: 1.1129 - val_precision: 0.6390\n",
      "Epoch 8/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9977 - precision: 0.6359\n",
      "Epoch 8: val_loss improved from 1.11292 to 1.07535, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9985 - precision: 0.6346 - val_loss: 1.0754 - val_precision: 0.6281\n",
      "Epoch 9/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9472 - precision: 0.6340\n",
      "Epoch 9: val_loss improved from 1.07535 to 1.04541, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9467 - precision: 0.6316 - val_loss: 1.0454 - val_precision: 0.6372\n",
      "Epoch 10/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9171 - precision: 0.6320\n",
      "Epoch 10: val_loss improved from 1.04541 to 1.02193, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9177 - precision: 0.6315 - val_loss: 1.0219 - val_precision: 0.6297\n",
      "Epoch 11/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9024 - precision: 0.6333\n",
      "Epoch 11: val_loss did not improve from 1.02193\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9003 - precision: 0.6347 - val_loss: 1.0232 - val_precision: 0.6327\n",
      "Epoch 12/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8867 - precision: 0.6414\n",
      "Epoch 12: val_loss did not improve from 1.02193\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8886 - precision: 0.6400 - val_loss: 1.0316 - val_precision: 0.6273\n",
      "Epoch 13/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8717 - precision: 0.6444\n",
      "Epoch 13: val_loss did not improve from 1.02193\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8718 - precision: 0.6427 - val_loss: 1.0298 - val_precision: 0.6236\n",
      "Epoch 14/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8652 - precision: 0.6447\n",
      "Epoch 14: val_loss did not improve from 1.02193\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8602 - precision: 0.6482 - val_loss: 1.0265 - val_precision: 0.6245\n",
      "Epoch 15/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8576 - precision: 0.6475\n",
      "Epoch 15: val_loss did not improve from 1.02193\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8572 - precision: 0.6489 - val_loss: 1.0342 - val_precision: 0.6184\n",
      "Epoch 16/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8427 - precision: 0.6517\n",
      "Epoch 16: val_loss improved from 1.02193 to 1.02165, saving model to model_49.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8402 - precision: 0.6540 - val_loss: 1.0217 - val_precision: 0.6284\n",
      "Epoch 17/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8293 - precision: 0.6584\n",
      "Epoch 17: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8305 - precision: 0.6566 - val_loss: 1.0360 - val_precision: 0.6224\n",
      "Epoch 18/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8241 - precision: 0.6544\n",
      "Epoch 18: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8231 - precision: 0.6553 - val_loss: 1.0340 - val_precision: 0.6247\n",
      "Epoch 19/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8120 - precision: 0.6659\n",
      "Epoch 19: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8097 - precision: 0.6666 - val_loss: 1.0290 - val_precision: 0.6301\n",
      "Epoch 20/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7995 - precision: 0.6737\n",
      "Epoch 20: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7994 - precision: 0.6724 - val_loss: 1.0297 - val_precision: 0.6244\n",
      "Epoch 21/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7990 - precision: 0.6718\n",
      "Epoch 21: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7984 - precision: 0.6687 - val_loss: 1.0324 - val_precision: 0.6217\n",
      "Epoch 22/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7924 - precision: 0.6645\n",
      "Epoch 22: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7924 - precision: 0.6650 - val_loss: 1.0514 - val_precision: 0.6107\n",
      "Epoch 23/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7835 - precision: 0.6745\n",
      "Epoch 23: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7837 - precision: 0.6729 - val_loss: 1.0358 - val_precision: 0.6235\n",
      "Epoch 24/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7785 - precision: 0.6774\n",
      "Epoch 24: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7819 - precision: 0.6755 - val_loss: 1.0629 - val_precision: 0.6138\n",
      "Epoch 25/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7758 - precision: 0.6731\n",
      "Epoch 25: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7779 - precision: 0.6739 - val_loss: 1.0604 - val_precision: 0.6161\n",
      "Epoch 26/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7667 - precision: 0.6791\n",
      "Epoch 26: val_loss did not improve from 1.02165\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7723 - precision: 0.6759 - val_loss: 1.0637 - val_precision: 0.6125\n",
      "Epoch 26: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8824 - precision: 0.6775\n",
      "Combinación 48 = (False, True, True, 8, 0.1) \n",
      " precision train: [0.8824370503425598, 0.6775137186050415]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 50: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.5745 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.43681, saving model to model_50.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5727 - precision: 0.0000e+00 - val_loss: 1.4368 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.4037 - precision: 0.4502\n",
      "Epoch 2: val_loss improved from 1.43681 to 1.39182, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.4002 - precision: 0.4502 - val_loss: 1.3918 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.3529 - precision: 0.5189\n",
      "Epoch 3: val_loss improved from 1.39182 to 1.37911, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3506 - precision: 0.5235 - val_loss: 1.3791 - val_precision: 0.7862\n",
      "Epoch 4/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.3320 - precision: 0.5384\n",
      "Epoch 4: val_loss improved from 1.37911 to 1.35806, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3309 - precision: 0.5399 - val_loss: 1.3581 - val_precision: 0.7323\n",
      "Epoch 5/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.3136 - precision: 0.5680\n",
      "Epoch 5: val_loss improved from 1.35806 to 1.33315, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3089 - precision: 0.5774 - val_loss: 1.3332 - val_precision: 0.6586\n",
      "Epoch 6/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2720 - precision: 0.6129\n",
      "Epoch 6: val_loss improved from 1.33315 to 1.28874, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2689 - precision: 0.6110 - val_loss: 1.2887 - val_precision: 0.6672\n",
      "Epoch 7/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.2372 - precision: 0.6039\n",
      "Epoch 7: val_loss improved from 1.28874 to 1.26020, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2358 - precision: 0.6056 - val_loss: 1.2602 - val_precision: 0.6155\n",
      "Epoch 8/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.1804 - precision: 0.6093\n",
      "Epoch 8: val_loss improved from 1.26020 to 1.22302, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1787 - precision: 0.6081 - val_loss: 1.2230 - val_precision: 0.6089\n",
      "Epoch 9/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1424 - precision: 0.5960\n",
      "Epoch 9: val_loss improved from 1.22302 to 1.17324, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1408 - precision: 0.5980 - val_loss: 1.1732 - val_precision: 0.6044\n",
      "Epoch 10/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0984 - precision: 0.6021\n",
      "Epoch 10: val_loss improved from 1.17324 to 1.13593, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0976 - precision: 0.6034 - val_loss: 1.1359 - val_precision: 0.6259\n",
      "Epoch 11/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.0892 - precision: 0.6005\n",
      "Epoch 11: val_loss improved from 1.13593 to 1.11745, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0865 - precision: 0.5986 - val_loss: 1.1175 - val_precision: 0.6203\n",
      "Epoch 12/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0511 - precision: 0.5979\n",
      "Epoch 12: val_loss improved from 1.11745 to 1.11650, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0526 - precision: 0.5967 - val_loss: 1.1165 - val_precision: 0.6157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0348 - precision: 0.6082\n",
      "Epoch 13: val_loss improved from 1.11650 to 1.09449, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0367 - precision: 0.6053 - val_loss: 1.0945 - val_precision: 0.6192\n",
      "Epoch 14/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0335 - precision: 0.5993\n",
      "Epoch 14: val_loss improved from 1.09449 to 1.08874, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0346 - precision: 0.6016 - val_loss: 1.0887 - val_precision: 0.6137\n",
      "Epoch 15/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0047 - precision: 0.6143\n",
      "Epoch 15: val_loss improved from 1.08874 to 1.08833, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0029 - precision: 0.6126 - val_loss: 1.0883 - val_precision: 0.6115\n",
      "Epoch 16/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9953 - precision: 0.6127\n",
      "Epoch 16: val_loss improved from 1.08833 to 1.07579, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9954 - precision: 0.6130 - val_loss: 1.0758 - val_precision: 0.6119\n",
      "Epoch 17/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9815 - precision: 0.6182\n",
      "Epoch 17: val_loss did not improve from 1.07579\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9809 - precision: 0.6162 - val_loss: 1.0762 - val_precision: 0.6109\n",
      "Epoch 18/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9705 - precision: 0.6133\n",
      "Epoch 18: val_loss did not improve from 1.07579\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9703 - precision: 0.6151 - val_loss: 1.0900 - val_precision: 0.6039\n",
      "Epoch 19/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9571 - precision: 0.6245\n",
      "Epoch 19: val_loss improved from 1.07579 to 1.07368, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9540 - precision: 0.6241 - val_loss: 1.0737 - val_precision: 0.5985\n",
      "Epoch 20/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9665 - precision: 0.6176\n",
      "Epoch 20: val_loss improved from 1.07368 to 1.05400, saving model to model_50.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9627 - precision: 0.6190 - val_loss: 1.0540 - val_precision: 0.6087\n",
      "Epoch 21/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9539 - precision: 0.6181\n",
      "Epoch 21: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9515 - precision: 0.6205 - val_loss: 1.0915 - val_precision: 0.5955\n",
      "Epoch 22/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9518 - precision: 0.6138\n",
      "Epoch 22: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9459 - precision: 0.6179 - val_loss: 1.0836 - val_precision: 0.5982\n",
      "Epoch 23/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9408 - precision: 0.6158\n",
      "Epoch 23: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9373 - precision: 0.6183 - val_loss: 1.0657 - val_precision: 0.6021\n",
      "Epoch 24/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9250 - precision: 0.6224\n",
      "Epoch 24: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9293 - precision: 0.6203 - val_loss: 1.0878 - val_precision: 0.5962\n",
      "Epoch 25/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9242 - precision: 0.6286\n",
      "Epoch 25: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9269 - precision: 0.6253 - val_loss: 1.0720 - val_precision: 0.6005\n",
      "Epoch 26/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9295 - precision: 0.6235\n",
      "Epoch 26: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9276 - precision: 0.6221 - val_loss: 1.0720 - val_precision: 0.6009\n",
      "Epoch 27/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9055 - precision: 0.6304\n",
      "Epoch 27: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9111 - precision: 0.6289 - val_loss: 1.0722 - val_precision: 0.5945\n",
      "Epoch 28/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9181 - precision: 0.6298\n",
      "Epoch 28: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9184 - precision: 0.6288 - val_loss: 1.0711 - val_precision: 0.5988\n",
      "Epoch 29/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.9085 - precision: 0.6284\n",
      "Epoch 29: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9102 - precision: 0.6290 - val_loss: 1.0693 - val_precision: 0.5956\n",
      "Epoch 30/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8967 - precision: 0.6301\n",
      "Epoch 30: val_loss did not improve from 1.05400\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8988 - precision: 0.6282 - val_loss: 1.0726 - val_precision: 0.5956\n",
      "Epoch 30: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9464 - precision: 0.6331\n",
      "Combinación 49 = (False, True, True, 8, 0.25) \n",
      " precision train: [0.9463574290275574, 0.6331459879875183]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 51: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.5813 - precision: 0.5556   \n",
      "Epoch 1: val_loss improved from inf to 1.43298, saving model to model_51.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5806 - precision: 0.5455 - val_loss: 1.4330 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.4185 - precision: 0.5226\n",
      "Epoch 2: val_loss improved from 1.43298 to 1.30511, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.4157 - precision: 0.5189 - val_loss: 1.3051 - val_precision: 0.6969\n",
      "Epoch 3/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.3431 - precision: 0.5099\n",
      "Epoch 3: val_loss improved from 1.30511 to 1.28760, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3436 - precision: 0.5070 - val_loss: 1.2876 - val_precision: 0.5000\n",
      "Epoch 4/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.3168 - precision: 0.5413\n",
      "Epoch 4: val_loss improved from 1.28760 to 1.27429, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3182 - precision: 0.5370 - val_loss: 1.2743 - val_precision: 0.7539\n",
      "Epoch 5/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2908 - precision: 0.5718\n",
      "Epoch 5: val_loss improved from 1.27429 to 1.25524, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2906 - precision: 0.5731 - val_loss: 1.2552 - val_precision: 0.6973\n",
      "Epoch 6/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.2806 - precision: 0.5977\n",
      "Epoch 6: val_loss improved from 1.25524 to 1.23721, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2833 - precision: 0.5985 - val_loss: 1.2372 - val_precision: 0.7044\n",
      "Epoch 7/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.2683 - precision: 0.6050\n",
      "Epoch 7: val_loss did not improve from 1.23721\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2668 - precision: 0.6088 - val_loss: 1.2530 - val_precision: 0.6508\n",
      "Epoch 8/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2594 - precision: 0.6004\n",
      "Epoch 8: val_loss improved from 1.23721 to 1.23484, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2572 - precision: 0.6036 - val_loss: 1.2348 - val_precision: 0.6840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2532 - precision: 0.6262\n",
      "Epoch 9: val_loss did not improve from 1.23484\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2537 - precision: 0.6189 - val_loss: 1.2407 - val_precision: 0.6855\n",
      "Epoch 10/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.2424 - precision: 0.6205\n",
      "Epoch 10: val_loss improved from 1.23484 to 1.22796, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2416 - precision: 0.6172 - val_loss: 1.2280 - val_precision: 0.6883\n",
      "Epoch 11/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2354 - precision: 0.6357\n",
      "Epoch 11: val_loss did not improve from 1.22796\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2363 - precision: 0.6333 - val_loss: 1.2328 - val_precision: 0.6916\n",
      "Epoch 12/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2328 - precision: 0.6288\n",
      "Epoch 12: val_loss did not improve from 1.22796\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2305 - precision: 0.6274 - val_loss: 1.2325 - val_precision: 0.6914\n",
      "Epoch 13/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.2269 - precision: 0.6231\n",
      "Epoch 13: val_loss improved from 1.22796 to 1.22422, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2270 - precision: 0.6224 - val_loss: 1.2242 - val_precision: 0.7009\n",
      "Epoch 14/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.2258 - precision: 0.6316\n",
      "Epoch 14: val_loss improved from 1.22422 to 1.22347, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2223 - precision: 0.6292 - val_loss: 1.2235 - val_precision: 0.6769\n",
      "Epoch 15/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.2157 - precision: 0.6468\n",
      "Epoch 15: val_loss improved from 1.22347 to 1.21953, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2169 - precision: 0.6459 - val_loss: 1.2195 - val_precision: 0.7113\n",
      "Epoch 16/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2176 - precision: 0.6307\n",
      "Epoch 16: val_loss did not improve from 1.21953\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2176 - precision: 0.6267 - val_loss: 1.2209 - val_precision: 0.6963\n",
      "Epoch 17/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2085 - precision: 0.6250\n",
      "Epoch 17: val_loss did not improve from 1.21953\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2139 - precision: 0.6196 - val_loss: 1.2220 - val_precision: 0.7020\n",
      "Epoch 18/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2160 - precision: 0.6368\n",
      "Epoch 18: val_loss did not improve from 1.21953\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2106 - precision: 0.6350 - val_loss: 1.2214 - val_precision: 0.6741\n",
      "Epoch 19/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2138 - precision: 0.6197\n",
      "Epoch 19: val_loss improved from 1.21953 to 1.21310, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2110 - precision: 0.6224 - val_loss: 1.2131 - val_precision: 0.6989\n",
      "Epoch 20/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2131 - precision: 0.6173\n",
      "Epoch 20: val_loss did not improve from 1.21310\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2120 - precision: 0.6163 - val_loss: 1.2166 - val_precision: 0.7033\n",
      "Epoch 21/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.2093 - precision: 0.6223\n",
      "Epoch 21: val_loss improved from 1.21310 to 1.20569, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2071 - precision: 0.6231 - val_loss: 1.2057 - val_precision: 0.6972\n",
      "Epoch 22/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.1942 - precision: 0.6340\n",
      "Epoch 22: val_loss did not improve from 1.20569\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1986 - precision: 0.6332 - val_loss: 1.2077 - val_precision: 0.6835\n",
      "Epoch 23/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.1986 - precision: 0.6271\n",
      "Epoch 23: val_loss did not improve from 1.20569\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1981 - precision: 0.6251 - val_loss: 1.2063 - val_precision: 0.7067\n",
      "Epoch 24/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1890 - precision: 0.6219\n",
      "Epoch 24: val_loss did not improve from 1.20569\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1862 - precision: 0.6207 - val_loss: 1.2077 - val_precision: 0.7098\n",
      "Epoch 25/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.1904 - precision: 0.6185\n",
      "Epoch 25: val_loss improved from 1.20569 to 1.20357, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1925 - precision: 0.6123 - val_loss: 1.2036 - val_precision: 0.6897\n",
      "Epoch 26/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1944 - precision: 0.5960\n",
      "Epoch 26: val_loss did not improve from 1.20357\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1957 - precision: 0.5941 - val_loss: 1.2040 - val_precision: 0.6874\n",
      "Epoch 27/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1815 - precision: 0.6035\n",
      "Epoch 27: val_loss did not improve from 1.20357\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1850 - precision: 0.6029 - val_loss: 1.2046 - val_precision: 0.6930\n",
      "Epoch 28/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.1874 - precision: 0.5834\n",
      "Epoch 28: val_loss did not improve from 1.20357\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1848 - precision: 0.5835 - val_loss: 1.2106 - val_precision: 0.6998\n",
      "Epoch 29/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1747 - precision: 0.5975\n",
      "Epoch 29: val_loss did not improve from 1.20357\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1760 - precision: 0.5962 - val_loss: 1.2114 - val_precision: 0.6511\n",
      "Epoch 30/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1846 - precision: 0.5633\n",
      "Epoch 30: val_loss did not improve from 1.20357\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1818 - precision: 0.5671 - val_loss: 1.2081 - val_precision: 0.6966\n",
      "Epoch 31/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1812 - precision: 0.5850\n",
      "Epoch 31: val_loss did not improve from 1.20357\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1837 - precision: 0.5806 - val_loss: 1.2092 - val_precision: 0.6799\n",
      "Epoch 32/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1857 - precision: 0.5797\n",
      "Epoch 32: val_loss did not improve from 1.20357\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1833 - precision: 0.5804 - val_loss: 1.2109 - val_precision: 0.6803\n",
      "Epoch 33/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.1703 - precision: 0.5804\n",
      "Epoch 33: val_loss did not improve from 1.20357\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1684 - precision: 0.5811 - val_loss: 1.2170 - val_precision: 0.6876\n",
      "Epoch 34/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1737 - precision: 0.5764\n",
      "Epoch 34: val_loss did not improve from 1.20357\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1718 - precision: 0.5777 - val_loss: 1.2087 - val_precision: 0.6576\n",
      "Epoch 35/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1803 - precision: 0.5628\n",
      "Epoch 35: val_loss improved from 1.20357 to 1.19953, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1794 - precision: 0.5613 - val_loss: 1.1995 - val_precision: 0.6825\n",
      "Epoch 36/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1609 - precision: 0.5776\n",
      "Epoch 36: val_loss did not improve from 1.19953\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1647 - precision: 0.5735 - val_loss: 1.1998 - val_precision: 0.6831\n",
      "Epoch 37/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1675 - precision: 0.5704\n",
      "Epoch 37: val_loss did not improve from 1.19953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1652 - precision: 0.5660 - val_loss: 1.2045 - val_precision: 0.6561\n",
      "Epoch 38/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1615 - precision: 0.5738\n",
      "Epoch 38: val_loss did not improve from 1.19953\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1595 - precision: 0.5734 - val_loss: 1.2001 - val_precision: 0.6735\n",
      "Epoch 39/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1774 - precision: 0.5536\n",
      "Epoch 39: val_loss improved from 1.19953 to 1.19464, saving model to model_51.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1792 - precision: 0.5536 - val_loss: 1.1946 - val_precision: 0.6767\n",
      "Epoch 40/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1704 - precision: 0.5440\n",
      "Epoch 40: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1659 - precision: 0.5424 - val_loss: 1.2074 - val_precision: 0.6803\n",
      "Epoch 41/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1791 - precision: 0.5508\n",
      "Epoch 41: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1786 - precision: 0.5552 - val_loss: 1.2022 - val_precision: 0.6701\n",
      "Epoch 42/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1604 - precision: 0.5505\n",
      "Epoch 42: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1573 - precision: 0.5537 - val_loss: 1.2021 - val_precision: 0.6620\n",
      "Epoch 43/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.1628 - precision: 0.5672\n",
      "Epoch 43: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1642 - precision: 0.5649 - val_loss: 1.2043 - val_precision: 0.7038\n",
      "Epoch 44/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1621 - precision: 0.5458\n",
      "Epoch 44: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1652 - precision: 0.5477 - val_loss: 1.2060 - val_precision: 0.6766\n",
      "Epoch 45/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1607 - precision: 0.5542\n",
      "Epoch 45: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1603 - precision: 0.5565 - val_loss: 1.2069 - val_precision: 0.6701\n",
      "Epoch 46/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1568 - precision: 0.5620\n",
      "Epoch 46: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1582 - precision: 0.5612 - val_loss: 1.2055 - val_precision: 0.6760\n",
      "Epoch 47/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1549 - precision: 0.5564\n",
      "Epoch 47: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1552 - precision: 0.5561 - val_loss: 1.2077 - val_precision: 0.6766\n",
      "Epoch 48/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1560 - precision: 0.5403\n",
      "Epoch 48: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1586 - precision: 0.5370 - val_loss: 1.2078 - val_precision: 0.6694\n",
      "Epoch 49/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1615 - precision: 0.5599\n",
      "Epoch 49: val_loss did not improve from 1.19464\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1609 - precision: 0.5601 - val_loss: 1.2021 - val_precision: 0.6660\n",
      "Epoch 49: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.1262 - precision: 0.6869\n",
      "Combinación 50 = (False, True, True, 8, 0.5) \n",
      " precision train: [1.1261743307113647, 0.6869460344314575]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 52: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.4770 - precision: 0.7101\n",
      "Epoch 1: val_loss improved from inf to 1.34606, saving model to model_52.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.4704 - precision: 0.7110 - val_loss: 1.3461 - val_precision: 0.6923\n",
      "Epoch 2/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.3454 - precision: 0.6919\n",
      "Epoch 2: val_loss improved from 1.34606 to 1.30129, saving model to model_52.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3405 - precision: 0.6949 - val_loss: 1.3013 - val_precision: 0.6792\n",
      "Epoch 3/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.2472 - precision: 0.7025\n",
      "Epoch 3: val_loss improved from 1.30129 to 1.18705, saving model to model_52.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2464 - precision: 0.7012 - val_loss: 1.1871 - val_precision: 0.7153\n",
      "Epoch 4/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1377 - precision: 0.6945\n",
      "Epoch 4: val_loss improved from 1.18705 to 1.15003, saving model to model_52.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1352 - precision: 0.6940 - val_loss: 1.1500 - val_precision: 0.6759\n",
      "Epoch 5/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.0864 - precision: 0.6891\n",
      "Epoch 5: val_loss improved from 1.15003 to 1.12631, saving model to model_52.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0838 - precision: 0.6890 - val_loss: 1.1263 - val_precision: 0.6865\n",
      "Epoch 6/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.0019 - precision: 0.6522\n",
      "Epoch 6: val_loss improved from 1.12631 to 1.08333, saving model to model_52.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0012 - precision: 0.6501 - val_loss: 1.0833 - val_precision: 0.6426\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9400 - precision: 0.6375\n",
      "Epoch 7: val_loss improved from 1.08333 to 1.04220, saving model to model_52.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9400 - precision: 0.6373 - val_loss: 1.0422 - val_precision: 0.6349\n",
      "Epoch 8/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9017 - precision: 0.6392\n",
      "Epoch 8: val_loss improved from 1.04220 to 1.02487, saving model to model_52.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9024 - precision: 0.6391 - val_loss: 1.0249 - val_precision: 0.6332\n",
      "Epoch 9/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8683 - precision: 0.6397\n",
      "Epoch 9: val_loss did not improve from 1.02487\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8708 - precision: 0.6395 - val_loss: 1.0306 - val_precision: 0.6207\n",
      "Epoch 10/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8453 - precision: 0.6420\n",
      "Epoch 10: val_loss improved from 1.02487 to 1.01638, saving model to model_52.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8425 - precision: 0.6419 - val_loss: 1.0164 - val_precision: 0.6257\n",
      "Epoch 11/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8198 - precision: 0.6526\n",
      "Epoch 11: val_loss did not improve from 1.01638\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8244 - precision: 0.6481 - val_loss: 1.0170 - val_precision: 0.6189\n",
      "Epoch 12/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8037 - precision: 0.6552\n",
      "Epoch 12: val_loss improved from 1.01638 to 1.01451, saving model to model_52.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8074 - precision: 0.6537 - val_loss: 1.0145 - val_precision: 0.6172\n",
      "Epoch 13/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7953 - precision: 0.6525\n",
      "Epoch 13: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7969 - precision: 0.6508 - val_loss: 1.0292 - val_precision: 0.6144\n",
      "Epoch 14/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7799 - precision: 0.6564\n",
      "Epoch 14: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7791 - precision: 0.6577 - val_loss: 1.0163 - val_precision: 0.6205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7700 - precision: 0.6579\n",
      "Epoch 15: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7693 - precision: 0.6596 - val_loss: 1.0390 - val_precision: 0.6134\n",
      "Epoch 16/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7597 - precision: 0.6626\n",
      "Epoch 16: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7595 - precision: 0.6624 - val_loss: 1.0515 - val_precision: 0.6056\n",
      "Epoch 17/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7473 - precision: 0.6709\n",
      "Epoch 17: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7489 - precision: 0.6702 - val_loss: 1.0587 - val_precision: 0.6029\n",
      "Epoch 18/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7357 - precision: 0.6740\n",
      "Epoch 18: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7351 - precision: 0.6742 - val_loss: 1.0398 - val_precision: 0.6079\n",
      "Epoch 19/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7277 - precision: 0.6791\n",
      "Epoch 19: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7277 - precision: 0.6791 - val_loss: 1.0520 - val_precision: 0.5989\n",
      "Epoch 20/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7215 - precision: 0.6775\n",
      "Epoch 20: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7255 - precision: 0.6776 - val_loss: 1.0308 - val_precision: 0.6105\n",
      "Epoch 21/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7057 - precision: 0.6872\n",
      "Epoch 21: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7069 - precision: 0.6864 - val_loss: 1.0702 - val_precision: 0.6034\n",
      "Epoch 22/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7023 - precision: 0.6869\n",
      "Epoch 22: val_loss did not improve from 1.01451\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7035 - precision: 0.6868 - val_loss: 1.0663 - val_precision: 0.6078\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8453 - precision: 0.6830\n",
      "Combinación 51 = (False, True, True, 16, 0.1) \n",
      " precision train: [0.8453031182289124, 0.682956337928772]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 53: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.4705 - precision: 0.5763\n",
      "Epoch 1: val_loss improved from inf to 1.32336, saving model to model_53.h5\n",
      "240/240 [==============================] - 7s 7ms/step - loss: 1.4705 - precision: 0.5763 - val_loss: 1.3234 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2400 - precision: 0.6302\n",
      "Epoch 2: val_loss improved from 1.32336 to 1.20969, saving model to model_53.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2380 - precision: 0.6307 - val_loss: 1.2097 - val_precision: 0.6544\n",
      "Epoch 3/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1441 - precision: 0.6109\n",
      "Epoch 3: val_loss improved from 1.20969 to 1.19456, saving model to model_53.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1448 - precision: 0.6101 - val_loss: 1.1946 - val_precision: 0.5951\n",
      "Epoch 4/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0964 - precision: 0.6278\n",
      "Epoch 4: val_loss improved from 1.19456 to 1.12811, saving model to model_53.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0952 - precision: 0.6289 - val_loss: 1.1281 - val_precision: 0.7049\n",
      "Epoch 5/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0524 - precision: 0.6321\n",
      "Epoch 5: val_loss improved from 1.12811 to 1.08463, saving model to model_53.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0536 - precision: 0.6308 - val_loss: 1.0846 - val_precision: 0.6768\n",
      "Epoch 6/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0026 - precision: 0.6368\n",
      "Epoch 6: val_loss improved from 1.08463 to 1.04424, saving model to model_53.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0018 - precision: 0.6374 - val_loss: 1.0442 - val_precision: 0.6505\n",
      "Epoch 7/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9652 - precision: 0.6202\n",
      "Epoch 7: val_loss improved from 1.04424 to 1.04361, saving model to model_53.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9654 - precision: 0.6200 - val_loss: 1.0436 - val_precision: 0.6250\n",
      "Epoch 8/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9444 - precision: 0.6204\n",
      "Epoch 8: val_loss improved from 1.04361 to 1.03121, saving model to model_53.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9436 - precision: 0.6206 - val_loss: 1.0312 - val_precision: 0.6116\n",
      "Epoch 9/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9267 - precision: 0.6191\n",
      "Epoch 9: val_loss improved from 1.03121 to 1.02099, saving model to model_53.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9252 - precision: 0.6176 - val_loss: 1.0210 - val_precision: 0.6175\n",
      "Epoch 10/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9161 - precision: 0.6154\n",
      "Epoch 10: val_loss did not improve from 1.02099\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9151 - precision: 0.6158 - val_loss: 1.0284 - val_precision: 0.6065\n",
      "Epoch 11/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9026 - precision: 0.6220\n",
      "Epoch 11: val_loss improved from 1.02099 to 1.01782, saving model to model_53.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9026 - precision: 0.6220 - val_loss: 1.0178 - val_precision: 0.6124\n",
      "Epoch 12/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9016 - precision: 0.6258\n",
      "Epoch 12: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9014 - precision: 0.6257 - val_loss: 1.0217 - val_precision: 0.6132\n",
      "Epoch 13/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8807 - precision: 0.6352\n",
      "Epoch 13: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8812 - precision: 0.6329 - val_loss: 1.0330 - val_precision: 0.6101\n",
      "Epoch 14/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8701 - precision: 0.6381\n",
      "Epoch 14: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8701 - precision: 0.6370 - val_loss: 1.0397 - val_precision: 0.6055\n",
      "Epoch 15/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8562 - precision: 0.6424\n",
      "Epoch 15: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8598 - precision: 0.6414 - val_loss: 1.0486 - val_precision: 0.6060\n",
      "Epoch 16/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8593 - precision: 0.6430\n",
      "Epoch 16: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8595 - precision: 0.6427 - val_loss: 1.0215 - val_precision: 0.6244\n",
      "Epoch 17/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8478 - precision: 0.6470\n",
      "Epoch 17: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8485 - precision: 0.6480 - val_loss: 1.0338 - val_precision: 0.6139\n",
      "Epoch 18/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8322 - precision: 0.6512\n",
      "Epoch 18: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8325 - precision: 0.6507 - val_loss: 1.0367 - val_precision: 0.6128\n",
      "Epoch 19/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8342 - precision: 0.6567\n",
      "Epoch 19: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8333 - precision: 0.6566 - val_loss: 1.0299 - val_precision: 0.6270\n",
      "Epoch 20/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8271 - precision: 0.6546\n",
      "Epoch 20: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8268 - precision: 0.6543 - val_loss: 1.0430 - val_precision: 0.6153\n",
      "Epoch 21/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8093 - precision: 0.6579\n",
      "Epoch 21: val_loss did not improve from 1.01782\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8092 - precision: 0.6587 - val_loss: 1.0586 - val_precision: 0.6131\n",
      "Epoch 21: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9141 - precision: 0.6581\n",
      "Combinación 52 = (False, True, True, 16, 0.25) \n",
      " precision train: [0.9140673875808716, 0.65805584192276]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 54: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.5561 - precision: 0.6920\n",
      "Epoch 1: val_loss improved from inf to 1.34796, saving model to model_54.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5437 - precision: 0.6997 - val_loss: 1.3480 - val_precision: 0.6764\n",
      "Epoch 2/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.3720 - precision: 0.6965\n",
      "Epoch 2: val_loss improved from 1.34796 to 1.27867, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3705 - precision: 0.6977 - val_loss: 1.2787 - val_precision: 0.6816\n",
      "Epoch 3/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.3105 - precision: 0.6704\n",
      "Epoch 3: val_loss improved from 1.27867 to 1.23432, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3105 - precision: 0.6704 - val_loss: 1.2343 - val_precision: 0.7062\n",
      "Epoch 4/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.2475 - precision: 0.6563\n",
      "Epoch 4: val_loss improved from 1.23432 to 1.22413, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2475 - precision: 0.6563 - val_loss: 1.2241 - val_precision: 0.7287\n",
      "Epoch 5/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.2168 - precision: 0.6120\n",
      "Epoch 5: val_loss improved from 1.22413 to 1.19223, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2164 - precision: 0.6128 - val_loss: 1.1922 - val_precision: 0.6746\n",
      "Epoch 6/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1868 - precision: 0.5960\n",
      "Epoch 6: val_loss improved from 1.19223 to 1.17605, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1869 - precision: 0.5956 - val_loss: 1.1761 - val_precision: 0.6408\n",
      "Epoch 7/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1727 - precision: 0.5946\n",
      "Epoch 7: val_loss improved from 1.17605 to 1.16769, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1727 - precision: 0.5946 - val_loss: 1.1677 - val_precision: 0.6393\n",
      "Epoch 8/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.1503 - precision: 0.5993\n",
      "Epoch 8: val_loss improved from 1.16769 to 1.16746, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1484 - precision: 0.5989 - val_loss: 1.1675 - val_precision: 0.6170\n",
      "Epoch 9/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1368 - precision: 0.6131\n",
      "Epoch 9: val_loss improved from 1.16746 to 1.16154, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1391 - precision: 0.6126 - val_loss: 1.1615 - val_precision: 0.6255\n",
      "Epoch 10/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1345 - precision: 0.6094\n",
      "Epoch 10: val_loss did not improve from 1.16154\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1370 - precision: 0.6120 - val_loss: 1.1750 - val_precision: 0.6039\n",
      "Epoch 11/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1259 - precision: 0.6060\n",
      "Epoch 11: val_loss did not improve from 1.16154\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1249 - precision: 0.6064 - val_loss: 1.1665 - val_precision: 0.6317\n",
      "Epoch 12/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1208 - precision: 0.6036\n",
      "Epoch 12: val_loss improved from 1.16154 to 1.15310, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1174 - precision: 0.6072 - val_loss: 1.1531 - val_precision: 0.6330\n",
      "Epoch 13/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1061 - precision: 0.6156\n",
      "Epoch 13: val_loss did not improve from 1.15310\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1070 - precision: 0.6149 - val_loss: 1.1601 - val_precision: 0.6379\n",
      "Epoch 14/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.0998 - precision: 0.6293\n",
      "Epoch 14: val_loss did not improve from 1.15310\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1008 - precision: 0.6280 - val_loss: 1.1563 - val_precision: 0.6247\n",
      "Epoch 15/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1044 - precision: 0.6159\n",
      "Epoch 15: val_loss improved from 1.15310 to 1.14925, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1052 - precision: 0.6159 - val_loss: 1.1493 - val_precision: 0.6363\n",
      "Epoch 16/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.1017 - precision: 0.6215\n",
      "Epoch 16: val_loss improved from 1.14925 to 1.14262, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1018 - precision: 0.6217 - val_loss: 1.1426 - val_precision: 0.6361\n",
      "Epoch 17/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0837 - precision: 0.6261\n",
      "Epoch 17: val_loss improved from 1.14262 to 1.13864, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0837 - precision: 0.6261 - val_loss: 1.1386 - val_precision: 0.6417\n",
      "Epoch 18/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0748 - precision: 0.6330\n",
      "Epoch 18: val_loss improved from 1.13864 to 1.13240, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0748 - precision: 0.6330 - val_loss: 1.1324 - val_precision: 0.6567\n",
      "Epoch 19/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0697 - precision: 0.6358\n",
      "Epoch 19: val_loss improved from 1.13240 to 1.12300, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0682 - precision: 0.6373 - val_loss: 1.1230 - val_precision: 0.6548\n",
      "Epoch 20/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.0583 - precision: 0.6386\n",
      "Epoch 20: val_loss improved from 1.12300 to 1.10772, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0576 - precision: 0.6394 - val_loss: 1.1077 - val_precision: 0.6525\n",
      "Epoch 21/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0546 - precision: 0.6445\n",
      "Epoch 21: val_loss did not improve from 1.10772\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0531 - precision: 0.6448 - val_loss: 1.1088 - val_precision: 0.6469\n",
      "Epoch 22/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0456 - precision: 0.6486\n",
      "Epoch 22: val_loss improved from 1.10772 to 1.10123, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0439 - precision: 0.6477 - val_loss: 1.1012 - val_precision: 0.6485\n",
      "Epoch 23/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.0365 - precision: 0.6480\n",
      "Epoch 23: val_loss did not improve from 1.10123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0356 - precision: 0.6469 - val_loss: 1.1021 - val_precision: 0.6443\n",
      "Epoch 24/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0273 - precision: 0.6383\n",
      "Epoch 24: val_loss improved from 1.10123 to 1.09347, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0276 - precision: 0.6375 - val_loss: 1.0935 - val_precision: 0.6422\n",
      "Epoch 25/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.0155 - precision: 0.6375\n",
      "Epoch 25: val_loss improved from 1.09347 to 1.08868, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0159 - precision: 0.6379 - val_loss: 1.0887 - val_precision: 0.6295\n",
      "Epoch 26/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0032 - precision: 0.6339\n",
      "Epoch 26: val_loss improved from 1.08868 to 1.08790, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0077 - precision: 0.6336 - val_loss: 1.0879 - val_precision: 0.6311\n",
      "Epoch 27/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9955 - precision: 0.6370\n",
      "Epoch 27: val_loss improved from 1.08790 to 1.07096, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9948 - precision: 0.6370 - val_loss: 1.0710 - val_precision: 0.6219\n",
      "Epoch 28/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9986 - precision: 0.6376\n",
      "Epoch 28: val_loss improved from 1.07096 to 1.06963, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9958 - precision: 0.6394 - val_loss: 1.0696 - val_precision: 0.6156\n",
      "Epoch 29/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9921 - precision: 0.6323\n",
      "Epoch 29: val_loss did not improve from 1.06963\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9944 - precision: 0.6307 - val_loss: 1.0718 - val_precision: 0.6160\n",
      "Epoch 30/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9837 - precision: 0.6349\n",
      "Epoch 30: val_loss improved from 1.06963 to 1.06832, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9853 - precision: 0.6352 - val_loss: 1.0683 - val_precision: 0.6219\n",
      "Epoch 31/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9841 - precision: 0.6288\n",
      "Epoch 31: val_loss improved from 1.06832 to 1.06478, saving model to model_54.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9843 - precision: 0.6270 - val_loss: 1.0648 - val_precision: 0.6179\n",
      "Epoch 32/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9821 - precision: 0.6265\n",
      "Epoch 32: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9839 - precision: 0.6234 - val_loss: 1.0652 - val_precision: 0.6139\n",
      "Epoch 33/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9714 - precision: 0.6326\n",
      "Epoch 33: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9716 - precision: 0.6326 - val_loss: 1.0655 - val_precision: 0.6115\n",
      "Epoch 34/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9795 - precision: 0.6347\n",
      "Epoch 34: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9786 - precision: 0.6334 - val_loss: 1.0653 - val_precision: 0.6105\n",
      "Epoch 35/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9761 - precision: 0.6315\n",
      "Epoch 35: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9742 - precision: 0.6297 - val_loss: 1.0734 - val_precision: 0.6067\n",
      "Epoch 36/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9557 - precision: 0.6352\n",
      "Epoch 36: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9560 - precision: 0.6351 - val_loss: 1.0728 - val_precision: 0.6018\n",
      "Epoch 37/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9539 - precision: 0.6415\n",
      "Epoch 37: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9543 - precision: 0.6413 - val_loss: 1.0842 - val_precision: 0.6029\n",
      "Epoch 38/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9498 - precision: 0.6341\n",
      "Epoch 38: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9511 - precision: 0.6327 - val_loss: 1.0794 - val_precision: 0.5977\n",
      "Epoch 39/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9518 - precision: 0.6385\n",
      "Epoch 39: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9481 - precision: 0.6402 - val_loss: 1.0794 - val_precision: 0.5953\n",
      "Epoch 40/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9428 - precision: 0.6301\n",
      "Epoch 40: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9408 - precision: 0.6334 - val_loss: 1.0784 - val_precision: 0.6002\n",
      "Epoch 41/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9472 - precision: 0.6362\n",
      "Epoch 41: val_loss did not improve from 1.06478\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9513 - precision: 0.6361 - val_loss: 1.0925 - val_precision: 0.5984\n",
      "Epoch 41: early stopping\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.9630 - precision: 0.6393\n",
      "Combinación 53 = (False, True, True, 16, 0.5) \n",
      " precision train: [0.9629873633384705, 0.6393083333969116]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 55: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.3141 - precision: 0.6245\n",
      "Epoch 1: val_loss improved from inf to 1.11243, saving model to model_55.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.3097 - precision: 0.6219 - val_loss: 1.1124 - val_precision: 0.5880\n",
      "Epoch 2/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9573 - precision: 0.5954\n",
      "Epoch 2: val_loss improved from 1.11243 to 1.02987, saving model to model_55.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9548 - precision: 0.5968 - val_loss: 1.0299 - val_precision: 0.6178\n",
      "Epoch 3/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8984 - precision: 0.6120\n",
      "Epoch 3: val_loss did not improve from 1.02987\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9041 - precision: 0.6115 - val_loss: 1.0478 - val_precision: 0.6045\n",
      "Epoch 4/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8798 - precision: 0.6150\n",
      "Epoch 4: val_loss improved from 1.02987 to 1.00939, saving model to model_55.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8798 - precision: 0.6150 - val_loss: 1.0094 - val_precision: 0.6142\n",
      "Epoch 5/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8510 - precision: 0.6305\n",
      "Epoch 5: val_loss did not improve from 1.00939\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8504 - precision: 0.6308 - val_loss: 1.0155 - val_precision: 0.6112\n",
      "Epoch 6/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8243 - precision: 0.6402\n",
      "Epoch 6: val_loss improved from 1.00939 to 0.98096, saving model to model_55.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8221 - precision: 0.6413 - val_loss: 0.9810 - val_precision: 0.6284\n",
      "Epoch 7/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8020 - precision: 0.6523\n",
      "Epoch 7: val_loss did not improve from 0.98096\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8034 - precision: 0.6515 - val_loss: 0.9849 - val_precision: 0.6322\n",
      "Epoch 8/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7849 - precision: 0.6560\n",
      "Epoch 8: val_loss did not improve from 0.98096\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7851 - precision: 0.6564 - val_loss: 0.9882 - val_precision: 0.6374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7648 - precision: 0.6676\n",
      "Epoch 9: val_loss did not improve from 0.98096\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7665 - precision: 0.6670 - val_loss: 0.9989 - val_precision: 0.6339\n",
      "Epoch 10/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7556 - precision: 0.6606\n",
      "Epoch 10: val_loss improved from 0.98096 to 0.95554, saving model to model_55.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7546 - precision: 0.6612 - val_loss: 0.9555 - val_precision: 0.6429\n",
      "Epoch 11/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7283 - precision: 0.6714\n",
      "Epoch 11: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7309 - precision: 0.6720 - val_loss: 0.9908 - val_precision: 0.6354\n",
      "Epoch 12/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7132 - precision: 0.6796\n",
      "Epoch 12: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7130 - precision: 0.6796 - val_loss: 0.9908 - val_precision: 0.6260\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7053 - precision: 0.6863\n",
      "Epoch 13: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7042 - precision: 0.6863 - val_loss: 0.9929 - val_precision: 0.6192\n",
      "Epoch 14/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.6866 - precision: 0.6862\n",
      "Epoch 14: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6886 - precision: 0.6858 - val_loss: 0.9948 - val_precision: 0.6297\n",
      "Epoch 15/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6648 - precision: 0.6958\n",
      "Epoch 15: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6666 - precision: 0.6944 - val_loss: 1.0186 - val_precision: 0.6178\n",
      "Epoch 16/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6647 - precision: 0.6937\n",
      "Epoch 16: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6647 - precision: 0.6937 - val_loss: 0.9947 - val_precision: 0.6169\n",
      "Epoch 17/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6431 - precision: 0.7043\n",
      "Epoch 17: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6431 - precision: 0.7043 - val_loss: 1.0321 - val_precision: 0.6120\n",
      "Epoch 18/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6303 - precision: 0.7030\n",
      "Epoch 18: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6307 - precision: 0.7032 - val_loss: 1.0233 - val_precision: 0.6184\n",
      "Epoch 19/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6243 - precision: 0.7107\n",
      "Epoch 19: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6243 - precision: 0.7107 - val_loss: 1.0239 - val_precision: 0.6168\n",
      "Epoch 20/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6190 - precision: 0.7049\n",
      "Epoch 20: val_loss did not improve from 0.95554\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6187 - precision: 0.7055 - val_loss: 1.0405 - val_precision: 0.6192\n",
      "Epoch 20: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7689 - precision: 0.7004\n",
      "Combinación 54 = (False, True, True, 32, 0.1) \n",
      " precision train: [0.7689384818077087, 0.7003585696220398]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 56: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.3624 - precision: 0.6122\n",
      "Epoch 1: val_loss improved from inf to 1.19505, saving model to model_56.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.3617 - precision: 0.6049 - val_loss: 1.1951 - val_precision: 0.6457\n",
      "Epoch 2/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0334 - precision: 0.5954\n",
      "Epoch 2: val_loss improved from 1.19505 to 1.06691, saving model to model_56.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0309 - precision: 0.5965 - val_loss: 1.0669 - val_precision: 0.6061\n",
      "Epoch 3/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9453 - precision: 0.6105\n",
      "Epoch 3: val_loss improved from 1.06691 to 1.02774, saving model to model_56.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9468 - precision: 0.6094 - val_loss: 1.0277 - val_precision: 0.6180\n",
      "Epoch 4/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9247 - precision: 0.6160\n",
      "Epoch 4: val_loss improved from 1.02774 to 1.01920, saving model to model_56.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9247 - precision: 0.6160 - val_loss: 1.0192 - val_precision: 0.6201\n",
      "Epoch 5/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8985 - precision: 0.6192\n",
      "Epoch 5: val_loss improved from 1.01920 to 1.00202, saving model to model_56.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8989 - precision: 0.6195 - val_loss: 1.0020 - val_precision: 0.6391\n",
      "Epoch 6/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8711 - precision: 0.6338\n",
      "Epoch 6: val_loss did not improve from 1.00202\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8700 - precision: 0.6352 - val_loss: 1.0193 - val_precision: 0.6173\n",
      "Epoch 7/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8528 - precision: 0.6379\n",
      "Epoch 7: val_loss did not improve from 1.00202\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8528 - precision: 0.6379 - val_loss: 1.0147 - val_precision: 0.6208\n",
      "Epoch 8/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.8389 - precision: 0.6490\n",
      "Epoch 8: val_loss improved from 1.00202 to 0.99175, saving model to model_56.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8412 - precision: 0.6466 - val_loss: 0.9917 - val_precision: 0.6322\n",
      "Epoch 9/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8194 - precision: 0.6466\n",
      "Epoch 9: val_loss did not improve from 0.99175\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8202 - precision: 0.6472 - val_loss: 1.0045 - val_precision: 0.6288\n",
      "Epoch 10/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7963 - precision: 0.6575\n",
      "Epoch 10: val_loss did not improve from 0.99175\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8010 - precision: 0.6570 - val_loss: 1.0510 - val_precision: 0.6093\n",
      "Epoch 11/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7920 - precision: 0.6589\n",
      "Epoch 11: val_loss did not improve from 0.99175\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7973 - precision: 0.6565 - val_loss: 1.0031 - val_precision: 0.6294\n",
      "Epoch 12/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7836 - precision: 0.6601\n",
      "Epoch 12: val_loss did not improve from 0.99175\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7826 - precision: 0.6618 - val_loss: 1.0042 - val_precision: 0.6245\n",
      "Epoch 13/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7755 - precision: 0.6646\n",
      "Epoch 13: val_loss did not improve from 0.99175\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7741 - precision: 0.6647 - val_loss: 1.0140 - val_precision: 0.6345\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7670 - precision: 0.6711\n",
      "Epoch 14: val_loss improved from 0.99175 to 0.99042, saving model to model_56.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7669 - precision: 0.6708 - val_loss: 0.9904 - val_precision: 0.6353\n",
      "Epoch 15/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7551 - precision: 0.6675\n",
      "Epoch 15: val_loss improved from 0.99042 to 0.97902, saving model to model_56.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7566 - precision: 0.6665 - val_loss: 0.9790 - val_precision: 0.6394\n",
      "Epoch 16/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7411 - precision: 0.6726\n",
      "Epoch 16: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7440 - precision: 0.6725 - val_loss: 0.9958 - val_precision: 0.6302\n",
      "Epoch 17/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7364 - precision: 0.6756\n",
      "Epoch 17: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7367 - precision: 0.6756 - val_loss: 1.0076 - val_precision: 0.6247\n",
      "Epoch 18/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7290 - precision: 0.6790\n",
      "Epoch 18: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7273 - precision: 0.6792 - val_loss: 1.0209 - val_precision: 0.6147\n",
      "Epoch 19/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7145 - precision: 0.6850\n",
      "Epoch 19: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7136 - precision: 0.6849 - val_loss: 1.0505 - val_precision: 0.6099\n",
      "Epoch 20/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7148 - precision: 0.6843\n",
      "Epoch 20: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7146 - precision: 0.6833 - val_loss: 1.0067 - val_precision: 0.6226\n",
      "Epoch 21/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7061 - precision: 0.6909\n",
      "Epoch 21: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7070 - precision: 0.6901 - val_loss: 1.0219 - val_precision: 0.6171\n",
      "Epoch 22/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.6870 - precision: 0.6984\n",
      "Epoch 22: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6891 - precision: 0.6975 - val_loss: 1.0129 - val_precision: 0.6205\n",
      "Epoch 23/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6890 - precision: 0.6927\n",
      "Epoch 23: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6845 - precision: 0.6940 - val_loss: 1.0469 - val_precision: 0.6193\n",
      "Epoch 24/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6831 - precision: 0.6916\n",
      "Epoch 24: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6843 - precision: 0.6909 - val_loss: 1.0359 - val_precision: 0.6123\n",
      "Epoch 25/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6575 - precision: 0.7063\n",
      "Epoch 25: val_loss did not improve from 0.97902\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6636 - precision: 0.7057 - val_loss: 1.0230 - val_precision: 0.6178\n",
      "Epoch 25: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7662 - precision: 0.7133\n",
      "Combinación 55 = (False, True, True, 32, 0.25) \n",
      " precision train: [0.7662424445152283, 0.7132571339607239]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 57: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.5155 - precision: 0.6147 \n",
      "Epoch 1: val_loss improved from inf to 1.24438, saving model to model_57.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.5120 - precision: 0.6118 - val_loss: 1.2444 - val_precision: 0.6583\n",
      "Epoch 2/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.1473 - precision: 0.6148\n",
      "Epoch 2: val_loss improved from 1.24438 to 1.09728, saving model to model_57.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1443 - precision: 0.6103 - val_loss: 1.0973 - val_precision: 0.6208\n",
      "Epoch 3/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.0494 - precision: 0.5937\n",
      "Epoch 3: val_loss improved from 1.09728 to 1.07187, saving model to model_57.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0480 - precision: 0.5950 - val_loss: 1.0719 - val_precision: 0.6137\n",
      "Epoch 4/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0060 - precision: 0.6032\n",
      "Epoch 4: val_loss improved from 1.07187 to 1.04555, saving model to model_57.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0046 - precision: 0.6053 - val_loss: 1.0456 - val_precision: 0.6308\n",
      "Epoch 5/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9848 - precision: 0.6141\n",
      "Epoch 5: val_loss improved from 1.04555 to 1.02876, saving model to model_57.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9849 - precision: 0.6168 - val_loss: 1.0288 - val_precision: 0.6321\n",
      "Epoch 6/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9718 - precision: 0.6164\n",
      "Epoch 6: val_loss did not improve from 1.02876\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9703 - precision: 0.6180 - val_loss: 1.0459 - val_precision: 0.6184\n",
      "Epoch 7/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9589 - precision: 0.6239\n",
      "Epoch 7: val_loss did not improve from 1.02876\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9587 - precision: 0.6232 - val_loss: 1.0432 - val_precision: 0.6124\n",
      "Epoch 8/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9548 - precision: 0.6232\n",
      "Epoch 8: val_loss did not improve from 1.02876\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9530 - precision: 0.6236 - val_loss: 1.0373 - val_precision: 0.6211\n",
      "Epoch 9/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9457 - precision: 0.6314\n",
      "Epoch 9: val_loss did not improve from 1.02876\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9450 - precision: 0.6319 - val_loss: 1.0288 - val_precision: 0.6280\n",
      "Epoch 10/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9317 - precision: 0.6383\n",
      "Epoch 10: val_loss improved from 1.02876 to 1.02398, saving model to model_57.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9277 - precision: 0.6380 - val_loss: 1.0240 - val_precision: 0.6304\n",
      "Epoch 11/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9232 - precision: 0.6348\n",
      "Epoch 11: val_loss did not improve from 1.02398\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9194 - precision: 0.6389 - val_loss: 1.0456 - val_precision: 0.6171\n",
      "Epoch 12/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9124 - precision: 0.6406\n",
      "Epoch 12: val_loss improved from 1.02398 to 1.01780, saving model to model_57.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9144 - precision: 0.6412 - val_loss: 1.0178 - val_precision: 0.6431\n",
      "Epoch 13/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9053 - precision: 0.6426\n",
      "Epoch 13: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9030 - precision: 0.6417 - val_loss: 1.0454 - val_precision: 0.6150\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8926 - precision: 0.6476\n",
      "Epoch 14: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8919 - precision: 0.6477 - val_loss: 1.0449 - val_precision: 0.6217\n",
      "Epoch 15/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9015 - precision: 0.6458\n",
      "Epoch 15: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9007 - precision: 0.6460 - val_loss: 1.0247 - val_precision: 0.6262\n",
      "Epoch 16/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8823 - precision: 0.6508\n",
      "Epoch 16: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8811 - precision: 0.6498 - val_loss: 1.0285 - val_precision: 0.6259\n",
      "Epoch 17/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8793 - precision: 0.6545\n",
      "Epoch 17: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8853 - precision: 0.6533 - val_loss: 1.0444 - val_precision: 0.6224\n",
      "Epoch 18/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8689 - precision: 0.6561\n",
      "Epoch 18: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8697 - precision: 0.6553 - val_loss: 1.0442 - val_precision: 0.6187\n",
      "Epoch 19/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8573 - precision: 0.6510\n",
      "Epoch 19: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8642 - precision: 0.6473 - val_loss: 1.0408 - val_precision: 0.6139\n",
      "Epoch 20/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8627 - precision: 0.6550\n",
      "Epoch 20: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8630 - precision: 0.6531 - val_loss: 1.0593 - val_precision: 0.6092\n",
      "Epoch 21/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8557 - precision: 0.6573\n",
      "Epoch 21: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8560 - precision: 0.6576 - val_loss: 1.0574 - val_precision: 0.6118\n",
      "Epoch 22/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8530 - precision: 0.6539\n",
      "Epoch 22: val_loss did not improve from 1.01780\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8545 - precision: 0.6530 - val_loss: 1.0378 - val_precision: 0.6199\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9140 - precision: 0.6590\n",
      "Combinación 56 = (False, True, True, 32, 0.5) \n",
      " precision train: [0.9140012860298157, 0.659029483795166]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 58: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2207 - precision: 0.6204\n",
      "Epoch 1: val_loss improved from inf to 1.04194, saving model to model_58.h5\n",
      "240/240 [==============================] - 6s 9ms/step - loss: 1.2012 - precision: 0.6158 - val_loss: 1.0419 - val_precision: 0.6275\n",
      "Epoch 2/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9066 - precision: 0.6159\n",
      "Epoch 2: val_loss improved from 1.04194 to 1.00562, saving model to model_58.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9057 - precision: 0.6164 - val_loss: 1.0056 - val_precision: 0.6227\n",
      "Epoch 3/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8591 - precision: 0.6259\n",
      "Epoch 3: val_loss did not improve from 1.00562\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8582 - precision: 0.6258 - val_loss: 1.0123 - val_precision: 0.6255\n",
      "Epoch 4/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8277 - precision: 0.6336\n",
      "Epoch 4: val_loss did not improve from 1.00562\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8302 - precision: 0.6331 - val_loss: 1.0059 - val_precision: 0.6174\n",
      "Epoch 5/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7955 - precision: 0.6405\n",
      "Epoch 5: val_loss improved from 1.00562 to 0.99956, saving model to model_58.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7974 - precision: 0.6391 - val_loss: 0.9996 - val_precision: 0.6200\n",
      "Epoch 6/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7777 - precision: 0.6483\n",
      "Epoch 6: val_loss improved from 0.99956 to 0.96047, saving model to model_58.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7803 - precision: 0.6460 - val_loss: 0.9605 - val_precision: 0.6421\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7578 - precision: 0.6526\n",
      "Epoch 7: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7589 - precision: 0.6528 - val_loss: 0.9802 - val_precision: 0.6290\n",
      "Epoch 8/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7434 - precision: 0.6627\n",
      "Epoch 8: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7420 - precision: 0.6644 - val_loss: 0.9942 - val_precision: 0.6266\n",
      "Epoch 9/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7232 - precision: 0.6665\n",
      "Epoch 9: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7231 - precision: 0.6665 - val_loss: 0.9725 - val_precision: 0.6358\n",
      "Epoch 10/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7096 - precision: 0.6705\n",
      "Epoch 10: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7069 - precision: 0.6734 - val_loss: 0.9650 - val_precision: 0.6286\n",
      "Epoch 11/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.6863 - precision: 0.6814\n",
      "Epoch 11: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6874 - precision: 0.6810 - val_loss: 1.0024 - val_precision: 0.6187\n",
      "Epoch 12/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6748 - precision: 0.6800\n",
      "Epoch 12: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6747 - precision: 0.6786 - val_loss: 0.9994 - val_precision: 0.6196\n",
      "Epoch 13/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6630 - precision: 0.6874\n",
      "Epoch 13: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6604 - precision: 0.6879 - val_loss: 0.9807 - val_precision: 0.6319\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6470 - precision: 0.6915\n",
      "Epoch 14: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6469 - precision: 0.6915 - val_loss: 1.0162 - val_precision: 0.6241\n",
      "Epoch 15/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6286 - precision: 0.6995\n",
      "Epoch 15: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6286 - precision: 0.6995 - val_loss: 1.0240 - val_precision: 0.6175\n",
      "Epoch 16/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6146 - precision: 0.7042\n",
      "Epoch 16: val_loss did not improve from 0.96047\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6149 - precision: 0.7041 - val_loss: 0.9704 - val_precision: 0.6303\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7168 - precision: 0.7198\n",
      "Combinación 57 = (False, True, True, 64, 0.1) \n",
      " precision train: [0.716831624507904, 0.7197533845901489]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 59: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2778 - precision: 0.6373\n",
      "Epoch 1: val_loss improved from inf to 1.10218, saving model to model_59.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.2671 - precision: 0.6370 - val_loss: 1.1022 - val_precision: 0.6568\n",
      "Epoch 2/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9720 - precision: 0.6213\n",
      "Epoch 2: val_loss improved from 1.10218 to 1.02085, saving model to model_59.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9718 - precision: 0.6213 - val_loss: 1.0209 - val_precision: 0.6392\n",
      "Epoch 3/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8958 - precision: 0.6297\n",
      "Epoch 3: val_loss improved from 1.02085 to 1.00403, saving model to model_59.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8959 - precision: 0.6295 - val_loss: 1.0040 - val_precision: 0.6240\n",
      "Epoch 4/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8771 - precision: 0.6311\n",
      "Epoch 4: val_loss improved from 1.00403 to 0.99267, saving model to model_59.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8723 - precision: 0.6321 - val_loss: 0.9927 - val_precision: 0.6286\n",
      "Epoch 5/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8392 - precision: 0.6297\n",
      "Epoch 5: val_loss improved from 0.99267 to 0.96878, saving model to model_59.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8410 - precision: 0.6287 - val_loss: 0.9688 - val_precision: 0.6381\n",
      "Epoch 6/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8106 - precision: 0.6437\n",
      "Epoch 6: val_loss did not improve from 0.96878\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8105 - precision: 0.6437 - val_loss: 0.9987 - val_precision: 0.6168\n",
      "Epoch 7/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7891 - precision: 0.6411\n",
      "Epoch 7: val_loss did not improve from 0.96878\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7935 - precision: 0.6411 - val_loss: 1.0119 - val_precision: 0.6108\n",
      "Epoch 8/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7774 - precision: 0.6507\n",
      "Epoch 8: val_loss did not improve from 0.96878\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7755 - precision: 0.6512 - val_loss: 0.9735 - val_precision: 0.6323\n",
      "Epoch 9/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7578 - precision: 0.6575\n",
      "Epoch 9: val_loss improved from 0.96878 to 0.94815, saving model to model_59.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7577 - precision: 0.6574 - val_loss: 0.9482 - val_precision: 0.6492\n",
      "Epoch 10/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7474 - precision: 0.6616\n",
      "Epoch 10: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7462 - precision: 0.6620 - val_loss: 1.0065 - val_precision: 0.6299\n",
      "Epoch 11/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7302 - precision: 0.6646\n",
      "Epoch 11: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7301 - precision: 0.6642 - val_loss: 1.0038 - val_precision: 0.6232\n",
      "Epoch 12/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7202 - precision: 0.6686\n",
      "Epoch 12: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7208 - precision: 0.6671 - val_loss: 0.9792 - val_precision: 0.6260\n",
      "Epoch 13/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6969 - precision: 0.6689\n",
      "Epoch 13: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6961 - precision: 0.6703 - val_loss: 0.9818 - val_precision: 0.6257\n",
      "Epoch 14/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6876 - precision: 0.6805\n",
      "Epoch 14: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6884 - precision: 0.6806 - val_loss: 0.9759 - val_precision: 0.6243\n",
      "Epoch 15/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6797 - precision: 0.6882\n",
      "Epoch 15: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6779 - precision: 0.6902 - val_loss: 1.0168 - val_precision: 0.6181\n",
      "Epoch 16/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6658 - precision: 0.6877\n",
      "Epoch 16: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6657 - precision: 0.6875 - val_loss: 1.0276 - val_precision: 0.6175\n",
      "Epoch 17/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6538 - precision: 0.6896\n",
      "Epoch 17: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6536 - precision: 0.6899 - val_loss: 1.0306 - val_precision: 0.6202\n",
      "Epoch 18/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6381 - precision: 0.6964\n",
      "Epoch 18: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6406 - precision: 0.6946 - val_loss: 0.9920 - val_precision: 0.6210\n",
      "Epoch 19/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6277 - precision: 0.7003\n",
      "Epoch 19: val_loss did not improve from 0.94815\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.6266 - precision: 0.6994 - val_loss: 1.0322 - val_precision: 0.6238\n",
      "Epoch 19: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7446 - precision: 0.7037\n",
      "Combinación 58 = (False, True, True, 64, 0.25) \n",
      " precision train: [0.7446287870407104, 0.7037037014961243]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 60: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.4168 - precision: 0.5700\n",
      "Epoch 1: val_loss improved from inf to 1.23865, saving model to model_60.h5\n",
      "240/240 [==============================] - 6s 8ms/step - loss: 1.4099 - precision: 0.5696 - val_loss: 1.2387 - val_precision: 0.6794\n",
      "Epoch 2/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.1795 - precision: 0.6306\n",
      "Epoch 2: val_loss improved from 1.23865 to 1.14706, saving model to model_60.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.1765 - precision: 0.6331 - val_loss: 1.1471 - val_precision: 0.6399\n",
      "Epoch 3/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0660 - precision: 0.6338\n",
      "Epoch 3: val_loss improved from 1.14706 to 1.05502, saving model to model_60.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0619 - precision: 0.6354 - val_loss: 1.0550 - val_precision: 0.6382\n",
      "Epoch 4/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9923 - precision: 0.6166\n",
      "Epoch 4: val_loss improved from 1.05502 to 1.02489, saving model to model_60.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9883 - precision: 0.6187 - val_loss: 1.0249 - val_precision: 0.6240\n",
      "Epoch 5/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9404 - precision: 0.6195\n",
      "Epoch 5: val_loss improved from 1.02489 to 1.02053, saving model to model_60.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9389 - precision: 0.6217 - val_loss: 1.0205 - val_precision: 0.6258\n",
      "Epoch 6/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9231 - precision: 0.6232\n",
      "Epoch 6: val_loss improved from 1.02053 to 1.01499, saving model to model_60.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9253 - precision: 0.6224 - val_loss: 1.0150 - val_precision: 0.6218\n",
      "Epoch 7/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9011 - precision: 0.6250\n",
      "Epoch 7: val_loss improved from 1.01499 to 1.00272, saving model to model_60.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8979 - precision: 0.6260 - val_loss: 1.0027 - val_precision: 0.6221\n",
      "Epoch 8/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8912 - precision: 0.6257\n",
      "Epoch 8: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8933 - precision: 0.6271 - val_loss: 1.0076 - val_precision: 0.6181\n",
      "Epoch 9/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8729 - precision: 0.6294\n",
      "Epoch 9: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8716 - precision: 0.6288 - val_loss: 1.0086 - val_precision: 0.6202\n",
      "Epoch 10/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8571 - precision: 0.6312\n",
      "Epoch 10: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8565 - precision: 0.6319 - val_loss: 1.0376 - val_precision: 0.6009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8435 - precision: 0.6337\n",
      "Epoch 11: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8480 - precision: 0.6316 - val_loss: 1.0069 - val_precision: 0.6179\n",
      "Epoch 12/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8415 - precision: 0.6357\n",
      "Epoch 12: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8412 - precision: 0.6368 - val_loss: 1.0244 - val_precision: 0.6084\n",
      "Epoch 13/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8228 - precision: 0.6364\n",
      "Epoch 13: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8226 - precision: 0.6364 - val_loss: 1.0042 - val_precision: 0.6123\n",
      "Epoch 14/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8164 - precision: 0.6370\n",
      "Epoch 14: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8179 - precision: 0.6381 - val_loss: 1.0343 - val_precision: 0.6043\n",
      "Epoch 15/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8115 - precision: 0.6392\n",
      "Epoch 15: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8111 - precision: 0.6393 - val_loss: 1.0190 - val_precision: 0.6134\n",
      "Epoch 16/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7965 - precision: 0.6409\n",
      "Epoch 16: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7952 - precision: 0.6427 - val_loss: 1.0058 - val_precision: 0.6153\n",
      "Epoch 17/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7895 - precision: 0.6455\n",
      "Epoch 17: val_loss did not improve from 1.00272\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7899 - precision: 0.6454 - val_loss: 1.0299 - val_precision: 0.6067\n",
      "Epoch 17: early stopping\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.9035 - precision: 0.6405\n",
      "Combinación 59 = (False, True, True, 64, 0.5) \n",
      " precision train: [0.9034544825553894, 0.6405484676361084]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 61: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.5130 - precision: 0.6856 \n",
      "Epoch 1: val_loss improved from inf to 1.35566, saving model to model_61.h5\n",
      "240/240 [==============================] - 5s 6ms/step - loss: 1.4956 - precision: 0.6711 - val_loss: 1.3557 - val_precision: 0.7035\n",
      "Epoch 2/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.2635 - precision: 0.6445\n",
      "Epoch 2: val_loss improved from 1.35566 to 1.20814, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2559 - precision: 0.6470 - val_loss: 1.2081 - val_precision: 0.7042\n",
      "Epoch 3/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1430 - precision: 0.6157\n",
      "Epoch 3: val_loss improved from 1.20814 to 1.15803, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1414 - precision: 0.6165 - val_loss: 1.1580 - val_precision: 0.6005\n",
      "Epoch 4/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0707 - precision: 0.6259\n",
      "Epoch 4: val_loss improved from 1.15803 to 1.10640, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0697 - precision: 0.6237 - val_loss: 1.1064 - val_precision: 0.6328\n",
      "Epoch 5/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.0025 - precision: 0.6321\n",
      "Epoch 5: val_loss improved from 1.10640 to 1.06385, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0013 - precision: 0.6325 - val_loss: 1.0638 - val_precision: 0.6224\n",
      "Epoch 6/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9632 - precision: 0.6210\n",
      "Epoch 6: val_loss improved from 1.06385 to 1.04471, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9603 - precision: 0.6210 - val_loss: 1.0447 - val_precision: 0.6216\n",
      "Epoch 7/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9259 - precision: 0.6262\n",
      "Epoch 7: val_loss improved from 1.04471 to 1.04342, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9265 - precision: 0.6264 - val_loss: 1.0434 - val_precision: 0.6189\n",
      "Epoch 8/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9070 - precision: 0.6288\n",
      "Epoch 8: val_loss did not improve from 1.04342\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9065 - precision: 0.6285 - val_loss: 1.0438 - val_precision: 0.6062\n",
      "Epoch 9/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8964 - precision: 0.6326\n",
      "Epoch 9: val_loss improved from 1.04342 to 1.03082, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8920 - precision: 0.6348 - val_loss: 1.0308 - val_precision: 0.6175\n",
      "Epoch 10/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8759 - precision: 0.6443\n",
      "Epoch 10: val_loss did not improve from 1.03082\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8747 - precision: 0.6447 - val_loss: 1.0315 - val_precision: 0.6103\n",
      "Epoch 11/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8714 - precision: 0.6391\n",
      "Epoch 11: val_loss improved from 1.03082 to 1.02511, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8718 - precision: 0.6378 - val_loss: 1.0251 - val_precision: 0.6193\n",
      "Epoch 12/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8563 - precision: 0.6467\n",
      "Epoch 12: val_loss improved from 1.02511 to 1.02467, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8598 - precision: 0.6452 - val_loss: 1.0247 - val_precision: 0.6220\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8461 - precision: 0.6512\n",
      "Epoch 13: val_loss improved from 1.02467 to 1.01962, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8467 - precision: 0.6510 - val_loss: 1.0196 - val_precision: 0.6209\n",
      "Epoch 14/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.8394 - precision: 0.6545\n",
      "Epoch 14: val_loss did not improve from 1.01962\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8431 - precision: 0.6556 - val_loss: 1.0331 - val_precision: 0.6230\n",
      "Epoch 15/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8218 - precision: 0.6544\n",
      "Epoch 15: val_loss did not improve from 1.01962\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8234 - precision: 0.6537 - val_loss: 1.0270 - val_precision: 0.6246\n",
      "Epoch 16/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8208 - precision: 0.6616\n",
      "Epoch 16: val_loss did not improve from 1.01962\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8204 - precision: 0.6620 - val_loss: 1.0279 - val_precision: 0.6239\n",
      "Epoch 17/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8114 - precision: 0.6715\n",
      "Epoch 17: val_loss improved from 1.01962 to 1.01683, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8110 - precision: 0.6690 - val_loss: 1.0168 - val_precision: 0.6250\n",
      "Epoch 18/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8019 - precision: 0.6709\n",
      "Epoch 18: val_loss improved from 1.01683 to 1.01089, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8024 - precision: 0.6711 - val_loss: 1.0109 - val_precision: 0.6279\n",
      "Epoch 19/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8014 - precision: 0.6714\n",
      "Epoch 19: val_loss did not improve from 1.01089\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7999 - precision: 0.6727 - val_loss: 1.0353 - val_precision: 0.6176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7920 - precision: 0.6747\n",
      "Epoch 20: val_loss improved from 1.01089 to 1.00749, saving model to model_61.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7941 - precision: 0.6721 - val_loss: 1.0075 - val_precision: 0.6251\n",
      "Epoch 21/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7816 - precision: 0.6796\n",
      "Epoch 21: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7824 - precision: 0.6796 - val_loss: 1.0243 - val_precision: 0.6158\n",
      "Epoch 22/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7684 - precision: 0.6826\n",
      "Epoch 22: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7675 - precision: 0.6831 - val_loss: 1.0315 - val_precision: 0.6177\n",
      "Epoch 23/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7682 - precision: 0.6817\n",
      "Epoch 23: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7653 - precision: 0.6819 - val_loss: 1.0419 - val_precision: 0.6239\n",
      "Epoch 24/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7643 - precision: 0.6865\n",
      "Epoch 24: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7628 - precision: 0.6868 - val_loss: 1.0280 - val_precision: 0.6180\n",
      "Epoch 25/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7596 - precision: 0.6864\n",
      "Epoch 25: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7573 - precision: 0.6863 - val_loss: 1.0401 - val_precision: 0.6160\n",
      "Epoch 26/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7394 - precision: 0.6941\n",
      "Epoch 26: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7438 - precision: 0.6934 - val_loss: 1.0374 - val_precision: 0.6164\n",
      "Epoch 27/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7424 - precision: 0.6938\n",
      "Epoch 27: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7429 - precision: 0.6943 - val_loss: 1.0597 - val_precision: 0.6140\n",
      "Epoch 28/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7339 - precision: 0.6944\n",
      "Epoch 28: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7337 - precision: 0.6941 - val_loss: 1.0322 - val_precision: 0.6222\n",
      "Epoch 29/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7341 - precision: 0.6961\n",
      "Epoch 29: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7328 - precision: 0.6962 - val_loss: 1.0435 - val_precision: 0.6193\n",
      "Epoch 30/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.7182 - precision: 0.7093\n",
      "Epoch 30: val_loss did not improve from 1.00749\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7232 - precision: 0.7059 - val_loss: 1.0475 - val_precision: 0.6062\n",
      "Epoch 30: early stopping\n",
      "300/300 [==============================] - 0s 984us/step - loss: 0.8346 - precision: 0.6921\n",
      "Combinación 60 = (False, True, False, 8, 0.1) \n",
      " precision train: [0.8345910310745239, 0.6920587420463562]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 62: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.5377 - precision: 0.5574  \n",
      "Epoch 1: val_loss improved from inf to 1.41177, saving model to model_62.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.5326 - precision: 0.5586 - val_loss: 1.4118 - val_precision: 0.5581\n",
      "Epoch 2/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.2557 - precision: 0.5722\n",
      "Epoch 2: val_loss improved from 1.41177 to 1.18566, saving model to model_62.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2547 - precision: 0.5732 - val_loss: 1.1857 - val_precision: 0.6141\n",
      "Epoch 3/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.1264 - precision: 0.5943\n",
      "Epoch 3: val_loss improved from 1.18566 to 1.10996, saving model to model_62.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1241 - precision: 0.5943 - val_loss: 1.1100 - val_precision: 0.6166\n",
      "Epoch 4/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.0647 - precision: 0.5929\n",
      "Epoch 4: val_loss improved from 1.10996 to 1.07869, saving model to model_62.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0658 - precision: 0.5935 - val_loss: 1.0787 - val_precision: 0.6159\n",
      "Epoch 5/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0410 - precision: 0.6047\n",
      "Epoch 5: val_loss improved from 1.07869 to 1.05338, saving model to model_62.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0390 - precision: 0.6046 - val_loss: 1.0534 - val_precision: 0.6229\n",
      "Epoch 6/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.0101 - precision: 0.6082\n",
      "Epoch 6: val_loss improved from 1.05338 to 1.04016, saving model to model_62.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0107 - precision: 0.6081 - val_loss: 1.0402 - val_precision: 0.6185\n",
      "Epoch 7/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9953 - precision: 0.6145\n",
      "Epoch 7: val_loss improved from 1.04016 to 1.03180, saving model to model_62.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9971 - precision: 0.6130 - val_loss: 1.0318 - val_precision: 0.6264\n",
      "Epoch 8/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9864 - precision: 0.6115\n",
      "Epoch 8: val_loss improved from 1.03180 to 1.02544, saving model to model_62.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9801 - precision: 0.6149 - val_loss: 1.0254 - val_precision: 0.6281\n",
      "Epoch 9/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9672 - precision: 0.6233\n",
      "Epoch 9: val_loss did not improve from 1.02544\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9665 - precision: 0.6246 - val_loss: 1.0320 - val_precision: 0.6228\n",
      "Epoch 10/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9758 - precision: 0.6230\n",
      "Epoch 10: val_loss did not improve from 1.02544\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9728 - precision: 0.6266 - val_loss: 1.0273 - val_precision: 0.6224\n",
      "Epoch 11/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9530 - precision: 0.6297\n",
      "Epoch 11: val_loss improved from 1.02544 to 1.01218, saving model to model_62.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9525 - precision: 0.6316 - val_loss: 1.0122 - val_precision: 0.6358\n",
      "Epoch 12/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.9411 - precision: 0.6327\n",
      "Epoch 12: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9448 - precision: 0.6290 - val_loss: 1.0202 - val_precision: 0.6302\n",
      "Epoch 13/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9386 - precision: 0.6359\n",
      "Epoch 13: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9390 - precision: 0.6351 - val_loss: 1.0298 - val_precision: 0.6194\n",
      "Epoch 14/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.9269 - precision: 0.6400\n",
      "Epoch 14: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9257 - precision: 0.6417 - val_loss: 1.0353 - val_precision: 0.6185\n",
      "Epoch 15/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9196 - precision: 0.6390\n",
      "Epoch 15: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9218 - precision: 0.6375 - val_loss: 1.0185 - val_precision: 0.6290\n",
      "Epoch 16/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9154 - precision: 0.6422\n",
      "Epoch 16: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9129 - precision: 0.6443 - val_loss: 1.0337 - val_precision: 0.6248\n",
      "Epoch 17/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9108 - precision: 0.6421\n",
      "Epoch 17: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9111 - precision: 0.6419 - val_loss: 1.0356 - val_precision: 0.6183\n",
      "Epoch 18/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9041 - precision: 0.6465\n",
      "Epoch 18: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9006 - precision: 0.6482 - val_loss: 1.0323 - val_precision: 0.6341\n",
      "Epoch 19/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8962 - precision: 0.6497\n",
      "Epoch 19: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8937 - precision: 0.6510 - val_loss: 1.0476 - val_precision: 0.6164\n",
      "Epoch 20/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8963 - precision: 0.6471\n",
      "Epoch 20: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8971 - precision: 0.6476 - val_loss: 1.0495 - val_precision: 0.6146\n",
      "Epoch 21/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8829 - precision: 0.6512\n",
      "Epoch 21: val_loss did not improve from 1.01218\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8868 - precision: 0.6505 - val_loss: 1.0573 - val_precision: 0.6106\n",
      "Epoch 21: early stopping\n",
      "300/300 [==============================] - 0s 924us/step - loss: 0.9445 - precision: 0.6494\n",
      "Combinación 61 = (False, True, False, 8, 0.25) \n",
      " precision train: [0.9445147514343262, 0.6494373083114624]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 63: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.5829 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.48547, saving model to model_63.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.5827 - precision: 0.0000e+00 - val_loss: 1.4855 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.4164 - precision: 0.5680\n",
      "Epoch 2: val_loss improved from 1.48547 to 1.31702, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.4160 - precision: 0.5597 - val_loss: 1.3170 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 1.3355 - precision: 0.5431\n",
      "Epoch 3: val_loss improved from 1.31702 to 1.29035, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.3347 - precision: 0.5410 - val_loss: 1.2903 - val_precision: 0.8378\n",
      "Epoch 4/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.2981 - precision: 0.5666\n",
      "Epoch 4: val_loss improved from 1.29035 to 1.23256, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.3004 - precision: 0.5634 - val_loss: 1.2326 - val_precision: 0.7210\n",
      "Epoch 5/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.2646 - precision: 0.5729\n",
      "Epoch 5: val_loss improved from 1.23256 to 1.21139, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2622 - precision: 0.5724 - val_loss: 1.2114 - val_precision: 0.6828\n",
      "Epoch 6/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.2532 - precision: 0.5587\n",
      "Epoch 6: val_loss improved from 1.21139 to 1.18715, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2563 - precision: 0.5549 - val_loss: 1.1871 - val_precision: 0.6749\n",
      "Epoch 7/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2349 - precision: 0.5791\n",
      "Epoch 7: val_loss improved from 1.18715 to 1.18030, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2341 - precision: 0.5792 - val_loss: 1.1803 - val_precision: 0.6338\n",
      "Epoch 8/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.2369 - precision: 0.5599\n",
      "Epoch 8: val_loss improved from 1.18030 to 1.17703, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2311 - precision: 0.5649 - val_loss: 1.1770 - val_precision: 0.6201\n",
      "Epoch 9/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.2218 - precision: 0.5652\n",
      "Epoch 9: val_loss did not improve from 1.17703\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2212 - precision: 0.5672 - val_loss: 1.1775 - val_precision: 0.6260\n",
      "Epoch 10/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 1.2257 - precision: 0.5686\n",
      "Epoch 10: val_loss improved from 1.17703 to 1.16151, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2228 - precision: 0.5719 - val_loss: 1.1615 - val_precision: 0.6178\n",
      "Epoch 11/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.2200 - precision: 0.5745\n",
      "Epoch 11: val_loss improved from 1.16151 to 1.15844, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2200 - precision: 0.5745 - val_loss: 1.1584 - val_precision: 0.6210\n",
      "Epoch 12/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.2099 - precision: 0.5829\n",
      "Epoch 12: val_loss did not improve from 1.15844\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2101 - precision: 0.5878 - val_loss: 1.1725 - val_precision: 0.6291\n",
      "Epoch 13/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.1972 - precision: 0.5853\n",
      "Epoch 13: val_loss did not improve from 1.15844\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1956 - precision: 0.5863 - val_loss: 1.1639 - val_precision: 0.6154\n",
      "Epoch 14/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.1916 - precision: 0.5789\n",
      "Epoch 14: val_loss did not improve from 1.15844\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1864 - precision: 0.5825 - val_loss: 1.1701 - val_precision: 0.6024\n",
      "Epoch 15/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1927 - precision: 0.5884\n",
      "Epoch 15: val_loss did not improve from 1.15844\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1934 - precision: 0.5867 - val_loss: 1.1605 - val_precision: 0.6114\n",
      "Epoch 16/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.1991 - precision: 0.5923\n",
      "Epoch 16: val_loss did not improve from 1.15844\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1960 - precision: 0.5935 - val_loss: 1.1657 - val_precision: 0.6287\n",
      "Epoch 17/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1787 - precision: 0.6020\n",
      "Epoch 17: val_loss did not improve from 1.15844\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1796 - precision: 0.6050 - val_loss: 1.1685 - val_precision: 0.6022\n",
      "Epoch 18/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 1.1753 - precision: 0.5888\n",
      "Epoch 18: val_loss improved from 1.15844 to 1.15606, saving model to model_63.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1747 - precision: 0.5872 - val_loss: 1.1561 - val_precision: 0.6053\n",
      "Epoch 19/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.1740 - precision: 0.6104\n",
      "Epoch 19: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1765 - precision: 0.6101 - val_loss: 1.1593 - val_precision: 0.6032\n",
      "Epoch 20/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1759 - precision: 0.5898\n",
      "Epoch 20: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1726 - precision: 0.5933 - val_loss: 1.1628 - val_precision: 0.6117\n",
      "Epoch 21/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1770 - precision: 0.5965\n",
      "Epoch 21: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1781 - precision: 0.5966 - val_loss: 1.1693 - val_precision: 0.5988\n",
      "Epoch 22/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.1766 - precision: 0.5820\n",
      "Epoch 22: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1733 - precision: 0.5830 - val_loss: 1.1625 - val_precision: 0.6164\n",
      "Epoch 23/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1660 - precision: 0.6004\n",
      "Epoch 23: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 1.1700 - precision: 0.5985 - val_loss: 1.1703 - val_precision: 0.6055\n",
      "Epoch 24/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.1556 - precision: 0.6003\n",
      "Epoch 24: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1530 - precision: 0.6028 - val_loss: 1.1619 - val_precision: 0.5941\n",
      "Epoch 25/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.1649 - precision: 0.5671\n",
      "Epoch 25: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1665 - precision: 0.5671 - val_loss: 1.1644 - val_precision: 0.6005\n",
      "Epoch 26/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.1571 - precision: 0.5901\n",
      "Epoch 26: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1579 - precision: 0.5946 - val_loss: 1.1820 - val_precision: 0.6054\n",
      "Epoch 27/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1591 - precision: 0.5885\n",
      "Epoch 27: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1591 - precision: 0.5885 - val_loss: 1.1716 - val_precision: 0.6044\n",
      "Epoch 28/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1628 - precision: 0.5961\n",
      "Epoch 28: val_loss did not improve from 1.15606\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1621 - precision: 0.5941 - val_loss: 1.1698 - val_precision: 0.6054\n",
      "Epoch 28: early stopping\n",
      "300/300 [==============================] - 0s 929us/step - loss: 1.1069 - precision: 0.6341\n",
      "Combinación 62 = (False, True, False, 8, 0.5) \n",
      " precision train: [1.1069254875183105, 0.6341047286987305]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 64: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 1.4007 - precision: 0.6438 \n",
      "Epoch 1: val_loss improved from inf to 1.20199, saving model to model_64.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.3728 - precision: 0.6591 - val_loss: 1.2020 - val_precision: 0.6373\n",
      "Epoch 2/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 1.0334 - precision: 0.6255\n",
      "Epoch 2: val_loss improved from 1.20199 to 1.08602, saving model to model_64.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0241 - precision: 0.6292 - val_loss: 1.0860 - val_precision: 0.6341\n",
      "Epoch 3/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9277 - precision: 0.6302\n",
      "Epoch 3: val_loss improved from 1.08602 to 1.01794, saving model to model_64.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9277 - precision: 0.6300 - val_loss: 1.0179 - val_precision: 0.6309\n",
      "Epoch 4/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8872 - precision: 0.6366\n",
      "Epoch 4: val_loss improved from 1.01794 to 1.00920, saving model to model_64.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8868 - precision: 0.6352 - val_loss: 1.0092 - val_precision: 0.6226\n",
      "Epoch 5/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.8543 - precision: 0.6334\n",
      "Epoch 5: val_loss improved from 1.00920 to 0.99069, saving model to model_64.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8505 - precision: 0.6371 - val_loss: 0.9907 - val_precision: 0.6256\n",
      "Epoch 6/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.8388 - precision: 0.6400\n",
      "Epoch 6: val_loss improved from 0.99069 to 0.98167, saving model to model_64.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8344 - precision: 0.6427 - val_loss: 0.9817 - val_precision: 0.6315\n",
      "Epoch 7/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8154 - precision: 0.6469\n",
      "Epoch 7: val_loss improved from 0.98167 to 0.97701, saving model to model_64.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8127 - precision: 0.6486 - val_loss: 0.9770 - val_precision: 0.6337\n",
      "Epoch 8/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7872 - precision: 0.6592\n",
      "Epoch 8: val_loss did not improve from 0.97701\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7937 - precision: 0.6570 - val_loss: 0.9799 - val_precision: 0.6254\n",
      "Epoch 9/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.7743 - precision: 0.6584\n",
      "Epoch 9: val_loss did not improve from 0.97701\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7791 - precision: 0.6594 - val_loss: 0.9797 - val_precision: 0.6262\n",
      "Epoch 10/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7642 - precision: 0.6666\n",
      "Epoch 10: val_loss improved from 0.97701 to 0.95000, saving model to model_64.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7671 - precision: 0.6653 - val_loss: 0.9500 - val_precision: 0.6415\n",
      "Epoch 11/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7522 - precision: 0.6684\n",
      "Epoch 11: val_loss did not improve from 0.95000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7537 - precision: 0.6681 - val_loss: 0.9819 - val_precision: 0.6314\n",
      "Epoch 12/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7326 - precision: 0.6801\n",
      "Epoch 12: val_loss did not improve from 0.95000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7352 - precision: 0.6792 - val_loss: 0.9657 - val_precision: 0.6353\n",
      "Epoch 13/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7220 - precision: 0.6837\n",
      "Epoch 13: val_loss did not improve from 0.95000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7231 - precision: 0.6833 - val_loss: 0.9642 - val_precision: 0.6306\n",
      "Epoch 14/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7140 - precision: 0.6800\n",
      "Epoch 14: val_loss did not improve from 0.95000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7147 - precision: 0.6803 - val_loss: 0.9701 - val_precision: 0.6393\n",
      "Epoch 15/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7094 - precision: 0.6827\n",
      "Epoch 15: val_loss did not improve from 0.95000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7094 - precision: 0.6822 - val_loss: 0.9646 - val_precision: 0.6391\n",
      "Epoch 16/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.6966 - precision: 0.6850\n",
      "Epoch 16: val_loss did not improve from 0.95000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6982 - precision: 0.6849 - val_loss: 0.9731 - val_precision: 0.6361\n",
      "Epoch 17/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6789 - precision: 0.6960\n",
      "Epoch 17: val_loss did not improve from 0.95000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6800 - precision: 0.6963 - val_loss: 0.9876 - val_precision: 0.6342\n",
      "Epoch 18/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.6677 - precision: 0.7011\n",
      "Epoch 18: val_loss did not improve from 0.95000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6676 - precision: 0.7004 - val_loss: 1.0075 - val_precision: 0.6316\n",
      "Epoch 19/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.6638 - precision: 0.7012\n",
      "Epoch 19: val_loss did not improve from 0.95000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6658 - precision: 0.7004 - val_loss: 0.9753 - val_precision: 0.6381\n",
      "Epoch 20/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.6564 - precision: 0.7069\n",
      "Epoch 20: val_loss did not improve from 0.95000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6593 - precision: 0.7048 - val_loss: 1.0065 - val_precision: 0.6322\n",
      "Epoch 20: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7696 - precision: 0.7044\n",
      "Combinación 63 = (False, True, False, 16, 0.1) \n",
      " precision train: [0.7695759534835815, 0.7043903470039368]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 65: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.4533 - precision: 0.7112\n",
      "Epoch 1: val_loss improved from inf to 1.24594, saving model to model_65.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.4424 - precision: 0.7082 - val_loss: 1.2459 - val_precision: 0.6940\n",
      "Epoch 2/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1445 - precision: 0.6622\n",
      "Epoch 2: val_loss improved from 1.24594 to 1.07023, saving model to model_65.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1406 - precision: 0.6621 - val_loss: 1.0702 - val_precision: 0.6561\n",
      "Epoch 3/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.9992 - precision: 0.6308\n",
      "Epoch 3: val_loss improved from 1.07023 to 1.04074, saving model to model_65.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9910 - precision: 0.6335 - val_loss: 1.0407 - val_precision: 0.6279\n",
      "Epoch 4/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9491 - precision: 0.6280\n",
      "Epoch 4: val_loss improved from 1.04074 to 1.03328, saving model to model_65.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9491 - precision: 0.6285 - val_loss: 1.0333 - val_precision: 0.6183\n",
      "Epoch 5/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9413 - precision: 0.6233\n",
      "Epoch 5: val_loss improved from 1.03328 to 1.01078, saving model to model_65.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9363 - precision: 0.6265 - val_loss: 1.0108 - val_precision: 0.6314\n",
      "Epoch 6/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9055 - precision: 0.6314\n",
      "Epoch 6: val_loss did not improve from 1.01078\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9087 - precision: 0.6299 - val_loss: 1.0175 - val_precision: 0.6185\n",
      "Epoch 7/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9052 - precision: 0.6284\n",
      "Epoch 7: val_loss improved from 1.01078 to 1.00760, saving model to model_65.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9048 - precision: 0.6283 - val_loss: 1.0076 - val_precision: 0.6231\n",
      "Epoch 8/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8901 - precision: 0.6335\n",
      "Epoch 8: val_loss did not improve from 1.00760\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8953 - precision: 0.6329 - val_loss: 1.0219 - val_precision: 0.6174\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8707 - precision: 0.6381\n",
      "Epoch 9: val_loss improved from 1.00760 to 0.99875, saving model to model_65.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8695 - precision: 0.6390 - val_loss: 0.9987 - val_precision: 0.6226\n",
      "Epoch 10/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8568 - precision: 0.6393\n",
      "Epoch 10: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8562 - precision: 0.6404 - val_loss: 1.0125 - val_precision: 0.6172\n",
      "Epoch 11/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8586 - precision: 0.6433\n",
      "Epoch 11: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8589 - precision: 0.6414 - val_loss: 1.0243 - val_precision: 0.6143\n",
      "Epoch 12/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8355 - precision: 0.6502\n",
      "Epoch 12: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8355 - precision: 0.6502 - val_loss: 1.0191 - val_precision: 0.6218\n",
      "Epoch 13/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8270 - precision: 0.6551\n",
      "Epoch 13: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8245 - precision: 0.6559 - val_loss: 1.0085 - val_precision: 0.6226\n",
      "Epoch 14/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8147 - precision: 0.6577\n",
      "Epoch 14: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8137 - precision: 0.6581 - val_loss: 1.0236 - val_precision: 0.6238\n",
      "Epoch 15/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8161 - precision: 0.6627\n",
      "Epoch 15: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8187 - precision: 0.6619 - val_loss: 1.0034 - val_precision: 0.6254\n",
      "Epoch 16/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7995 - precision: 0.6662\n",
      "Epoch 16: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7995 - precision: 0.6662 - val_loss: 1.0012 - val_precision: 0.6275\n",
      "Epoch 17/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7780 - precision: 0.6725\n",
      "Epoch 17: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7825 - precision: 0.6706 - val_loss: 1.0077 - val_precision: 0.6290\n",
      "Epoch 18/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.7843 - precision: 0.6704\n",
      "Epoch 18: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7871 - precision: 0.6727 - val_loss: 0.9999 - val_precision: 0.6269\n",
      "Epoch 19/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7790 - precision: 0.6741\n",
      "Epoch 19: val_loss did not improve from 0.99875\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7815 - precision: 0.6739 - val_loss: 1.0168 - val_precision: 0.6205\n",
      "Epoch 19: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8653 - precision: 0.6733\n",
      "Combinación 64 = (False, True, False, 16, 0.25) \n",
      " precision train: [0.8653464913368225, 0.6733349561691284]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 66: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.5215 - precision: 0.6062 \n",
      "Epoch 1: val_loss improved from inf to 1.31243, saving model to model_66.h5\n",
      "240/240 [==============================] - 7s 18ms/step - loss: 1.5127 - precision: 0.6361 - val_loss: 1.3124 - val_precision: 0.7577\n",
      "Epoch 2/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.3080 - precision: 0.6480\n",
      "Epoch 2: val_loss improved from 1.31243 to 1.17867, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.3101 - precision: 0.6457 - val_loss: 1.1787 - val_precision: 0.7039\n",
      "Epoch 3/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1880 - precision: 0.6563\n",
      "Epoch 3: val_loss improved from 1.17867 to 1.08126, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1884 - precision: 0.6561 - val_loss: 1.0813 - val_precision: 0.6661\n",
      "Epoch 4/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.1105 - precision: 0.6314\n",
      "Epoch 4: val_loss improved from 1.08126 to 1.05523, saving model to model_66.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1080 - precision: 0.6320 - val_loss: 1.0552 - val_precision: 0.6457\n",
      "Epoch 5/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0795 - precision: 0.6190\n",
      "Epoch 5: val_loss improved from 1.05523 to 1.03956, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0798 - precision: 0.6189 - val_loss: 1.0396 - val_precision: 0.6301\n",
      "Epoch 6/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.0605 - precision: 0.6099\n",
      "Epoch 6: val_loss improved from 1.03956 to 1.03897, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0643 - precision: 0.6090 - val_loss: 1.0390 - val_precision: 0.6360\n",
      "Epoch 7/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0403 - precision: 0.6141\n",
      "Epoch 7: val_loss improved from 1.03897 to 1.02526, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0406 - precision: 0.6152 - val_loss: 1.0253 - val_precision: 0.6270\n",
      "Epoch 8/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.0454 - precision: 0.6100\n",
      "Epoch 8: val_loss did not improve from 1.02526\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0436 - precision: 0.6116 - val_loss: 1.0298 - val_precision: 0.6226\n",
      "Epoch 9/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.0072 - precision: 0.6205\n",
      "Epoch 9: val_loss did not improve from 1.02526\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0140 - precision: 0.6155 - val_loss: 1.0344 - val_precision: 0.6186\n",
      "Epoch 10/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.0065 - precision: 0.6148\n",
      "Epoch 10: val_loss improved from 1.02526 to 1.02366, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0048 - precision: 0.6158 - val_loss: 1.0237 - val_precision: 0.6225\n",
      "Epoch 11/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.9973 - precision: 0.6190\n",
      "Epoch 11: val_loss did not improve from 1.02366\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9980 - precision: 0.6184 - val_loss: 1.0266 - val_precision: 0.6207\n",
      "Epoch 12/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.9824 - precision: 0.6222\n",
      "Epoch 12: val_loss improved from 1.02366 to 1.02135, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9800 - precision: 0.6220 - val_loss: 1.0214 - val_precision: 0.6211\n",
      "Epoch 13/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9865 - precision: 0.6191\n",
      "Epoch 13: val_loss improved from 1.02135 to 1.01782, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9889 - precision: 0.6201 - val_loss: 1.0178 - val_precision: 0.6217\n",
      "Epoch 14/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9790 - precision: 0.6274\n",
      "Epoch 14: val_loss improved from 1.01782 to 1.01135, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9801 - precision: 0.6255 - val_loss: 1.0114 - val_precision: 0.6266\n",
      "Epoch 15/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9725 - precision: 0.6305\n",
      "Epoch 15: val_loss did not improve from 1.01135\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9717 - precision: 0.6275 - val_loss: 1.0161 - val_precision: 0.6219\n",
      "Epoch 16/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9694 - precision: 0.6274\n",
      "Epoch 16: val_loss did not improve from 1.01135\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9657 - precision: 0.6292 - val_loss: 1.0272 - val_precision: 0.6267\n",
      "Epoch 17/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9603 - precision: 0.6342\n",
      "Epoch 17: val_loss did not improve from 1.01135\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9603 - precision: 0.6335 - val_loss: 1.0217 - val_precision: 0.6222\n",
      "Epoch 18/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9530 - precision: 0.6385\n",
      "Epoch 18: val_loss improved from 1.01135 to 1.01038, saving model to model_66.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9541 - precision: 0.6378 - val_loss: 1.0104 - val_precision: 0.6259\n",
      "Epoch 19/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9503 - precision: 0.6393\n",
      "Epoch 19: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9510 - precision: 0.6371 - val_loss: 1.0370 - val_precision: 0.6162\n",
      "Epoch 20/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9456 - precision: 0.6373\n",
      "Epoch 20: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9462 - precision: 0.6363 - val_loss: 1.0232 - val_precision: 0.6179\n",
      "Epoch 21/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9425 - precision: 0.6315\n",
      "Epoch 21: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9445 - precision: 0.6299 - val_loss: 1.0272 - val_precision: 0.6185\n",
      "Epoch 22/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9383 - precision: 0.6469\n",
      "Epoch 22: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9419 - precision: 0.6441 - val_loss: 1.0241 - val_precision: 0.6237\n",
      "Epoch 23/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9289 - precision: 0.6459\n",
      "Epoch 23: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9253 - precision: 0.6469 - val_loss: 1.0426 - val_precision: 0.6103\n",
      "Epoch 24/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9225 - precision: 0.6404\n",
      "Epoch 24: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9214 - precision: 0.6431 - val_loss: 1.0334 - val_precision: 0.6157\n",
      "Epoch 25/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9316 - precision: 0.6435\n",
      "Epoch 25: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9320 - precision: 0.6441 - val_loss: 1.0386 - val_precision: 0.6146\n",
      "Epoch 26/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9237 - precision: 0.6396\n",
      "Epoch 26: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9239 - precision: 0.6394 - val_loss: 1.0234 - val_precision: 0.6179\n",
      "Epoch 27/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9210 - precision: 0.6401\n",
      "Epoch 27: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9198 - precision: 0.6407 - val_loss: 1.0370 - val_precision: 0.6077\n",
      "Epoch 28/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9060 - precision: 0.6447\n",
      "Epoch 28: val_loss did not improve from 1.01038\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9061 - precision: 0.6439 - val_loss: 1.0189 - val_precision: 0.6177\n",
      "Epoch 28: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9108 - precision: 0.6543\n",
      "Combinación 65 = (False, True, False, 16, 0.5) \n",
      " precision train: [0.9108184576034546, 0.6543365716934204]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 67: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.2080 - precision: 0.6332\n",
      "Epoch 1: val_loss improved from inf to 1.02956, saving model to model_67.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.2015 - precision: 0.6355 - val_loss: 1.0296 - val_precision: 0.6313\n",
      "Epoch 2/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8882 - precision: 0.6256\n",
      "Epoch 2: val_loss improved from 1.02956 to 0.97564, saving model to model_67.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8877 - precision: 0.6254 - val_loss: 0.9756 - val_precision: 0.6421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.8482 - precision: 0.6379\n",
      "Epoch 3: val_loss did not improve from 0.97564\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8504 - precision: 0.6367 - val_loss: 0.9782 - val_precision: 0.6382\n",
      "Epoch 4/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8179 - precision: 0.6482\n",
      "Epoch 4: val_loss improved from 0.97564 to 0.94262, saving model to model_67.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8179 - precision: 0.6482 - val_loss: 0.9426 - val_precision: 0.6467\n",
      "Epoch 5/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7869 - precision: 0.6529\n",
      "Epoch 5: val_loss improved from 0.94262 to 0.93744, saving model to model_67.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7869 - precision: 0.6535 - val_loss: 0.9374 - val_precision: 0.6433\n",
      "Epoch 6/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7709 - precision: 0.6625\n",
      "Epoch 6: val_loss improved from 0.93744 to 0.92775, saving model to model_67.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7735 - precision: 0.6586 - val_loss: 0.9278 - val_precision: 0.6509\n",
      "Epoch 7/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7525 - precision: 0.6690\n",
      "Epoch 7: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7515 - precision: 0.6683 - val_loss: 0.9386 - val_precision: 0.6466\n",
      "Epoch 8/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7345 - precision: 0.6694\n",
      "Epoch 8: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7365 - precision: 0.6711 - val_loss: 0.9358 - val_precision: 0.6482\n",
      "Epoch 9/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7179 - precision: 0.6730\n",
      "Epoch 9: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7179 - precision: 0.6730 - val_loss: 0.9461 - val_precision: 0.6447\n",
      "Epoch 10/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.6985 - precision: 0.6788\n",
      "Epoch 10: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7007 - precision: 0.6791 - val_loss: 0.9298 - val_precision: 0.6473\n",
      "Epoch 11/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.6847 - precision: 0.6876\n",
      "Epoch 11: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6831 - precision: 0.6867 - val_loss: 0.9726 - val_precision: 0.6353\n",
      "Epoch 12/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.6798 - precision: 0.6871\n",
      "Epoch 12: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6760 - precision: 0.6879 - val_loss: 0.9699 - val_precision: 0.6367\n",
      "Epoch 13/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6606 - precision: 0.6927\n",
      "Epoch 13: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6593 - precision: 0.6937 - val_loss: 0.9627 - val_precision: 0.6425\n",
      "Epoch 14/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6516 - precision: 0.6892\n",
      "Epoch 14: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6523 - precision: 0.6908 - val_loss: 1.0072 - val_precision: 0.6292\n",
      "Epoch 15/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6389 - precision: 0.6997\n",
      "Epoch 15: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6400 - precision: 0.6983 - val_loss: 0.9847 - val_precision: 0.6366\n",
      "Epoch 16/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6201 - precision: 0.7033\n",
      "Epoch 16: val_loss did not improve from 0.92775\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6209 - precision: 0.7034 - val_loss: 1.0032 - val_precision: 0.6286\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7524 - precision: 0.7054\n",
      "Combinación 66 = (False, True, False, 32, 0.1) \n",
      " precision train: [0.7524429559707642, 0.7053692936897278]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 68: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.2820 - precision: 0.6297\n",
      "Epoch 1: val_loss improved from inf to 1.05103, saving model to model_68.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.2636 - precision: 0.6220 - val_loss: 1.0510 - val_precision: 0.6361\n",
      "Epoch 2/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9418 - precision: 0.6154\n",
      "Epoch 2: val_loss improved from 1.05103 to 0.98753, saving model to model_68.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9378 - precision: 0.6169 - val_loss: 0.9875 - val_precision: 0.6373\n",
      "Epoch 3/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8801 - precision: 0.6315\n",
      "Epoch 3: val_loss improved from 0.98753 to 0.98686, saving model to model_68.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8821 - precision: 0.6297 - val_loss: 0.9869 - val_precision: 0.6302\n",
      "Epoch 4/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8664 - precision: 0.6309\n",
      "Epoch 4: val_loss did not improve from 0.98686\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8666 - precision: 0.6310 - val_loss: 0.9922 - val_precision: 0.6216\n",
      "Epoch 5/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8377 - precision: 0.6389\n",
      "Epoch 5: val_loss improved from 0.98686 to 0.96896, saving model to model_68.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8372 - precision: 0.6390 - val_loss: 0.9690 - val_precision: 0.6367\n",
      "Epoch 6/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8179 - precision: 0.6449\n",
      "Epoch 6: val_loss improved from 0.96896 to 0.94763, saving model to model_68.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8212 - precision: 0.6436 - val_loss: 0.9476 - val_precision: 0.6334\n",
      "Epoch 7/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8080 - precision: 0.6545\n",
      "Epoch 7: val_loss did not improve from 0.94763\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8074 - precision: 0.6534 - val_loss: 0.9860 - val_precision: 0.6255\n",
      "Epoch 8/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7909 - precision: 0.6517\n",
      "Epoch 8: val_loss did not improve from 0.94763\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7907 - precision: 0.6511 - val_loss: 0.9638 - val_precision: 0.6366\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7752 - precision: 0.6590\n",
      "Epoch 9: val_loss did not improve from 0.94763\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7755 - precision: 0.6586 - val_loss: 0.9731 - val_precision: 0.6377\n",
      "Epoch 10/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7543 - precision: 0.6630\n",
      "Epoch 10: val_loss did not improve from 0.94763\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7552 - precision: 0.6627 - val_loss: 0.9704 - val_precision: 0.6366\n",
      "Epoch 11/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7405 - precision: 0.6674\n",
      "Epoch 11: val_loss did not improve from 0.94763\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7408 - precision: 0.6676 - val_loss: 0.9565 - val_precision: 0.6367\n",
      "Epoch 12/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7330 - precision: 0.6721\n",
      "Epoch 12: val_loss did not improve from 0.94763\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7328 - precision: 0.6719 - val_loss: 0.9817 - val_precision: 0.6308\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7262 - precision: 0.6737\n",
      "Epoch 13: val_loss did not improve from 0.94763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7256 - precision: 0.6740 - val_loss: 0.9810 - val_precision: 0.6328\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7152 - precision: 0.6779\n",
      "Epoch 14: val_loss did not improve from 0.94763\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7164 - precision: 0.6782 - val_loss: 0.9916 - val_precision: 0.6370\n",
      "Epoch 15/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7070 - precision: 0.6825\n",
      "Epoch 15: val_loss did not improve from 0.94763\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7060 - precision: 0.6829 - val_loss: 1.0038 - val_precision: 0.6328\n",
      "Epoch 16/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.6857 - precision: 0.6850\n",
      "Epoch 16: val_loss did not improve from 0.94763\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6882 - precision: 0.6842 - val_loss: 0.9726 - val_precision: 0.6288\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7773 - precision: 0.6914\n",
      "Combinación 67 = (False, True, False, 32, 0.25) \n",
      " precision train: [0.7772894501686096, 0.6913889050483704]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 69: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.4588 - precision: 0.6605\n",
      "Epoch 1: val_loss improved from inf to 1.24834, saving model to model_69.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.4449 - precision: 0.6471 - val_loss: 1.2483 - val_precision: 0.7184\n",
      "Epoch 2/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1516 - precision: 0.6589\n",
      "Epoch 2: val_loss improved from 1.24834 to 1.08224, saving model to model_69.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1464 - precision: 0.6584 - val_loss: 1.0822 - val_precision: 0.6425\n",
      "Epoch 3/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.0224 - precision: 0.6147\n",
      "Epoch 3: val_loss improved from 1.08224 to 1.04922, saving model to model_69.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0229 - precision: 0.6165 - val_loss: 1.0492 - val_precision: 0.6188\n",
      "Epoch 4/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9819 - precision: 0.6160\n",
      "Epoch 4: val_loss improved from 1.04922 to 1.02587, saving model to model_69.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9813 - precision: 0.6158 - val_loss: 1.0259 - val_precision: 0.6230\n",
      "Epoch 5/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9609 - precision: 0.6153\n",
      "Epoch 5: val_loss improved from 1.02587 to 1.02161, saving model to model_69.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9619 - precision: 0.6168 - val_loss: 1.0216 - val_precision: 0.6187\n",
      "Epoch 6/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9461 - precision: 0.6214\n",
      "Epoch 6: val_loss improved from 1.02161 to 1.01743, saving model to model_69.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9461 - precision: 0.6234 - val_loss: 1.0174 - val_precision: 0.6217\n",
      "Epoch 7/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9249 - precision: 0.6243\n",
      "Epoch 7: val_loss did not improve from 1.01743\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9272 - precision: 0.6240 - val_loss: 1.0233 - val_precision: 0.6184\n",
      "Epoch 8/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9235 - precision: 0.6274\n",
      "Epoch 8: val_loss improved from 1.01743 to 0.99685, saving model to model_69.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9222 - precision: 0.6274 - val_loss: 0.9968 - val_precision: 0.6371\n",
      "Epoch 9/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.9172 - precision: 0.6334\n",
      "Epoch 9: val_loss did not improve from 0.99685\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9138 - precision: 0.6314 - val_loss: 1.0017 - val_precision: 0.6269\n",
      "Epoch 10/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.9133 - precision: 0.6267\n",
      "Epoch 10: val_loss did not improve from 0.99685\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9078 - precision: 0.6287 - val_loss: 1.0099 - val_precision: 0.6234\n",
      "Epoch 11/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8896 - precision: 0.6336\n",
      "Epoch 11: val_loss did not improve from 0.99685\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8868 - precision: 0.6333 - val_loss: 0.9997 - val_precision: 0.6247\n",
      "Epoch 12/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8847 - precision: 0.6365\n",
      "Epoch 12: val_loss did not improve from 0.99685\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8820 - precision: 0.6374 - val_loss: 0.9995 - val_precision: 0.6282\n",
      "Epoch 13/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8793 - precision: 0.6355\n",
      "Epoch 13: val_loss improved from 0.99685 to 0.99009, saving model to model_69.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8798 - precision: 0.6343 - val_loss: 0.9901 - val_precision: 0.6313\n",
      "Epoch 14/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8659 - precision: 0.6381\n",
      "Epoch 14: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8676 - precision: 0.6368 - val_loss: 0.9984 - val_precision: 0.6291\n",
      "Epoch 15/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8614 - precision: 0.6421\n",
      "Epoch 15: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8675 - precision: 0.6397 - val_loss: 1.0115 - val_precision: 0.6270\n",
      "Epoch 16/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8485 - precision: 0.6427\n",
      "Epoch 16: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8504 - precision: 0.6435 - val_loss: 1.0007 - val_precision: 0.6266\n",
      "Epoch 17/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8336 - precision: 0.6450\n",
      "Epoch 17: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8339 - precision: 0.6479 - val_loss: 1.0205 - val_precision: 0.6205\n",
      "Epoch 18/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8369 - precision: 0.6449\n",
      "Epoch 18: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8367 - precision: 0.6439 - val_loss: 0.9972 - val_precision: 0.6248\n",
      "Epoch 19/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8361 - precision: 0.6457\n",
      "Epoch 19: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8392 - precision: 0.6435 - val_loss: 1.0115 - val_precision: 0.6168\n",
      "Epoch 20/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8257 - precision: 0.6550\n",
      "Epoch 20: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8254 - precision: 0.6550 - val_loss: 1.0235 - val_precision: 0.6152\n",
      "Epoch 21/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8204 - precision: 0.6492\n",
      "Epoch 21: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8219 - precision: 0.6526 - val_loss: 1.0013 - val_precision: 0.6218\n",
      "Epoch 22/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8143 - precision: 0.6540\n",
      "Epoch 22: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8143 - precision: 0.6540 - val_loss: 0.9971 - val_precision: 0.6230\n",
      "Epoch 23/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8131 - precision: 0.6508\n",
      "Epoch 23: val_loss did not improve from 0.99009\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8131 - precision: 0.6514 - val_loss: 1.0115 - val_precision: 0.6203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8783 - precision: 0.6577\n",
      "Combinación 68 = (False, True, False, 32, 0.5) \n",
      " precision train: [0.8783200979232788, 0.6577466726303101]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 70: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1419 - precision: 0.6386\n",
      "Epoch 1: val_loss improved from inf to 0.98510, saving model to model_70.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.1392 - precision: 0.6326 - val_loss: 0.9851 - val_precision: 0.6549\n",
      "Epoch 2/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8627 - precision: 0.6319\n",
      "Epoch 2: val_loss improved from 0.98510 to 0.97917, saving model to model_70.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8620 - precision: 0.6322 - val_loss: 0.9792 - val_precision: 0.6370\n",
      "Epoch 3/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8095 - precision: 0.6466\n",
      "Epoch 3: val_loss improved from 0.97917 to 0.97618, saving model to model_70.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8084 - precision: 0.6464 - val_loss: 0.9762 - val_precision: 0.6273\n",
      "Epoch 4/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7771 - precision: 0.6547\n",
      "Epoch 4: val_loss improved from 0.97618 to 0.92577, saving model to model_70.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7746 - precision: 0.6554 - val_loss: 0.9258 - val_precision: 0.6452\n",
      "Epoch 5/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7497 - precision: 0.6592\n",
      "Epoch 5: val_loss improved from 0.92577 to 0.91997, saving model to model_70.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7486 - precision: 0.6592 - val_loss: 0.9200 - val_precision: 0.6542\n",
      "Epoch 6/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7291 - precision: 0.6633\n",
      "Epoch 6: val_loss improved from 0.91997 to 0.90740, saving model to model_70.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7303 - precision: 0.6635 - val_loss: 0.9074 - val_precision: 0.6488\n",
      "Epoch 7/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7060 - precision: 0.6731\n",
      "Epoch 7: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7072 - precision: 0.6727 - val_loss: 0.9475 - val_precision: 0.6403\n",
      "Epoch 8/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.6915 - precision: 0.6701\n",
      "Epoch 8: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6909 - precision: 0.6707 - val_loss: 0.9593 - val_precision: 0.6352\n",
      "Epoch 9/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6664 - precision: 0.6832\n",
      "Epoch 9: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6699 - precision: 0.6818 - val_loss: 0.9471 - val_precision: 0.6395\n",
      "Epoch 10/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6617 - precision: 0.6831\n",
      "Epoch 10: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6612 - precision: 0.6836 - val_loss: 0.9880 - val_precision: 0.6229\n",
      "Epoch 11/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6467 - precision: 0.6876\n",
      "Epoch 11: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6464 - precision: 0.6866 - val_loss: 0.9487 - val_precision: 0.6367\n",
      "Epoch 12/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6332 - precision: 0.6913\n",
      "Epoch 12: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6342 - precision: 0.6913 - val_loss: 0.9728 - val_precision: 0.6366\n",
      "Epoch 13/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6221 - precision: 0.6946\n",
      "Epoch 13: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6194 - precision: 0.6946 - val_loss: 1.0288 - val_precision: 0.6283\n",
      "Epoch 14/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6049 - precision: 0.7005\n",
      "Epoch 14: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6067 - precision: 0.7007 - val_loss: 1.0740 - val_precision: 0.6156\n",
      "Epoch 15/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.5881 - precision: 0.7105\n",
      "Epoch 15: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5898 - precision: 0.7092 - val_loss: 1.0270 - val_precision: 0.6202\n",
      "Epoch 16/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.5672 - precision: 0.7159\n",
      "Epoch 16: val_loss did not improve from 0.90740\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5711 - precision: 0.7122 - val_loss: 1.0292 - val_precision: 0.6213\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7120 - precision: 0.7134\n",
      "Combinación 69 = (False, True, False, 64, 0.1) \n",
      " precision train: [0.712011456489563, 0.7133584022521973]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 71: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1997 - precision: 0.6418\n",
      "Epoch 1: val_loss improved from inf to 1.06242, saving model to model_71.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.1981 - precision: 0.6417 - val_loss: 1.0624 - val_precision: 0.6187\n",
      "Epoch 2/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9097 - precision: 0.6227\n",
      "Epoch 2: val_loss improved from 1.06242 to 0.97198, saving model to model_71.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9093 - precision: 0.6224 - val_loss: 0.9720 - val_precision: 0.6505\n",
      "Epoch 3/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8570 - precision: 0.6367\n",
      "Epoch 3: val_loss did not improve from 0.97198\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8545 - precision: 0.6362 - val_loss: 0.9724 - val_precision: 0.6430\n",
      "Epoch 4/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8116 - precision: 0.6487\n",
      "Epoch 4: val_loss improved from 0.97198 to 0.95241, saving model to model_71.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8138 - precision: 0.6477 - val_loss: 0.9524 - val_precision: 0.6459\n",
      "Epoch 5/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7853 - precision: 0.6585\n",
      "Epoch 5: val_loss did not improve from 0.95241\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7852 - precision: 0.6576 - val_loss: 0.9528 - val_precision: 0.6405\n",
      "Epoch 6/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7653 - precision: 0.6602\n",
      "Epoch 6: val_loss improved from 0.95241 to 0.93066, saving model to model_71.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7657 - precision: 0.6604 - val_loss: 0.9307 - val_precision: 0.6464\n",
      "Epoch 7/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7458 - precision: 0.6664\n",
      "Epoch 7: val_loss improved from 0.93066 to 0.91598, saving model to model_71.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7472 - precision: 0.6638 - val_loss: 0.9160 - val_precision: 0.6436\n",
      "Epoch 8/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7339 - precision: 0.6690\n",
      "Epoch 8: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7330 - precision: 0.6700 - val_loss: 0.9772 - val_precision: 0.6370\n",
      "Epoch 9/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7174 - precision: 0.6735\n",
      "Epoch 9: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7190 - precision: 0.6707 - val_loss: 0.9573 - val_precision: 0.6405\n",
      "Epoch 10/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7054 - precision: 0.6748\n",
      "Epoch 10: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7049 - precision: 0.6748 - val_loss: 0.9645 - val_precision: 0.6363\n",
      "Epoch 11/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.6842 - precision: 0.6731\n",
      "Epoch 11: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6907 - precision: 0.6704 - val_loss: 0.9407 - val_precision: 0.6419\n",
      "Epoch 12/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6806 - precision: 0.6826\n",
      "Epoch 12: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6800 - precision: 0.6841 - val_loss: 0.9600 - val_precision: 0.6372\n",
      "Epoch 13/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6725 - precision: 0.6833\n",
      "Epoch 13: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6699 - precision: 0.6852 - val_loss: 0.9945 - val_precision: 0.6325\n",
      "Epoch 14/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6566 - precision: 0.6865\n",
      "Epoch 14: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6585 - precision: 0.6856 - val_loss: 1.0239 - val_precision: 0.6144\n",
      "Epoch 15/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.6425 - precision: 0.6901\n",
      "Epoch 15: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6423 - precision: 0.6889 - val_loss: 1.0289 - val_precision: 0.6257\n",
      "Epoch 16/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6380 - precision: 0.6917\n",
      "Epoch 16: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6403 - precision: 0.6912 - val_loss: 0.9663 - val_precision: 0.6376\n",
      "Epoch 17/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6217 - precision: 0.6991\n",
      "Epoch 17: val_loss did not improve from 0.91598\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6213 - precision: 0.6996 - val_loss: 1.0079 - val_precision: 0.6300\n",
      "Epoch 17: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7257 - precision: 0.7060\n",
      "Combinación 70 = (False, True, False, 64, 0.25) \n",
      " precision train: [0.7256511449813843, 0.7060073614120483]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 72: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.3282 - precision: 0.6398\n",
      "Epoch 1: val_loss improved from inf to 1.05680, saving model to model_72.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.3084 - precision: 0.6418 - val_loss: 1.0568 - val_precision: 0.6647\n",
      "Epoch 2/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9706 - precision: 0.6258\n",
      "Epoch 2: val_loss improved from 1.05680 to 1.01439, saving model to model_72.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9706 - precision: 0.6258 - val_loss: 1.0144 - val_precision: 0.6356\n",
      "Epoch 3/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9291 - precision: 0.6267\n",
      "Epoch 3: val_loss improved from 1.01439 to 0.99399, saving model to model_72.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9283 - precision: 0.6263 - val_loss: 0.9940 - val_precision: 0.6313\n",
      "Epoch 4/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8925 - precision: 0.6316\n",
      "Epoch 4: val_loss did not improve from 0.99399\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8914 - precision: 0.6324 - val_loss: 0.9962 - val_precision: 0.6244\n",
      "Epoch 5/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8751 - precision: 0.6299\n",
      "Epoch 5: val_loss improved from 0.99399 to 0.98799, saving model to model_72.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8756 - precision: 0.6292 - val_loss: 0.9880 - val_precision: 0.6239\n",
      "Epoch 6/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8543 - precision: 0.6354\n",
      "Epoch 6: val_loss improved from 0.98799 to 0.98149, saving model to model_72.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8542 - precision: 0.6356 - val_loss: 0.9815 - val_precision: 0.6225\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8333 - precision: 0.6378\n",
      "Epoch 7: val_loss improved from 0.98149 to 0.96349, saving model to model_72.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8327 - precision: 0.6385 - val_loss: 0.9635 - val_precision: 0.6296\n",
      "Epoch 8/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8286 - precision: 0.6378\n",
      "Epoch 8: val_loss did not improve from 0.96349\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8265 - precision: 0.6396 - val_loss: 0.9647 - val_precision: 0.6340\n",
      "Epoch 9/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8181 - precision: 0.6477\n",
      "Epoch 9: val_loss did not improve from 0.96349\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8155 - precision: 0.6493 - val_loss: 0.9646 - val_precision: 0.6363\n",
      "Epoch 10/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7897 - precision: 0.6546\n",
      "Epoch 10: val_loss did not improve from 0.96349\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7914 - precision: 0.6540 - val_loss: 0.9690 - val_precision: 0.6314\n",
      "Epoch 11/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7966 - precision: 0.6522\n",
      "Epoch 11: val_loss improved from 0.96349 to 0.96109, saving model to model_72.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7935 - precision: 0.6535 - val_loss: 0.9611 - val_precision: 0.6375\n",
      "Epoch 12/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7730 - precision: 0.6605\n",
      "Epoch 12: val_loss improved from 0.96109 to 0.95492, saving model to model_72.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.7728 - precision: 0.6606 - val_loss: 0.9549 - val_precision: 0.6346\n",
      "Epoch 13/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7637 - precision: 0.6619\n",
      "Epoch 13: val_loss improved from 0.95492 to 0.95269, saving model to model_72.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7637 - precision: 0.6619 - val_loss: 0.9527 - val_precision: 0.6379\n",
      "Epoch 14/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7617 - precision: 0.6688\n",
      "Epoch 14: val_loss did not improve from 0.95269\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7613 - precision: 0.6681 - val_loss: 0.9604 - val_precision: 0.6381\n",
      "Epoch 15/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7486 - precision: 0.6651\n",
      "Epoch 15: val_loss did not improve from 0.95269\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7533 - precision: 0.6623 - val_loss: 0.9577 - val_precision: 0.6417\n",
      "Epoch 16/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7335 - precision: 0.6730\n",
      "Epoch 16: val_loss did not improve from 0.95269\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7367 - precision: 0.6729 - val_loss: 0.9700 - val_precision: 0.6240\n",
      "Epoch 17/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7267 - precision: 0.6803\n",
      "Epoch 17: val_loss did not improve from 0.95269\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7277 - precision: 0.6788 - val_loss: 0.9815 - val_precision: 0.6341\n",
      "Epoch 18/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7240 - precision: 0.6756\n",
      "Epoch 18: val_loss did not improve from 0.95269\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7264 - precision: 0.6756 - val_loss: 0.9937 - val_precision: 0.6282\n",
      "Epoch 19/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7142 - precision: 0.6735\n",
      "Epoch 19: val_loss did not improve from 0.95269\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7145 - precision: 0.6738 - val_loss: 0.9858 - val_precision: 0.6299\n",
      "Epoch 20/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7132 - precision: 0.6798\n",
      "Epoch 20: val_loss did not improve from 0.95269\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7109 - precision: 0.6803 - val_loss: 0.9923 - val_precision: 0.6337\n",
      "Epoch 21/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7082 - precision: 0.6810\n",
      "Epoch 21: val_loss improved from 0.95269 to 0.94613, saving model to model_72.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7082 - precision: 0.6813 - val_loss: 0.9461 - val_precision: 0.6391\n",
      "Epoch 22/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6976 - precision: 0.6860\n",
      "Epoch 22: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6972 - precision: 0.6855 - val_loss: 0.9831 - val_precision: 0.6301\n",
      "Epoch 23/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6803 - precision: 0.6899\n",
      "Epoch 23: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6793 - precision: 0.6921 - val_loss: 0.9953 - val_precision: 0.6244\n",
      "Epoch 24/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6766 - precision: 0.6901\n",
      "Epoch 24: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6774 - precision: 0.6898 - val_loss: 0.9796 - val_precision: 0.6278\n",
      "Epoch 25/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6694 - precision: 0.6962\n",
      "Epoch 25: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6701 - precision: 0.6953 - val_loss: 0.9927 - val_precision: 0.6262\n",
      "Epoch 26/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6683 - precision: 0.6926\n",
      "Epoch 26: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6677 - precision: 0.6929 - val_loss: 1.0143 - val_precision: 0.6220\n",
      "Epoch 27/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6455 - precision: 0.6953\n",
      "Epoch 27: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6486 - precision: 0.6940 - val_loss: 0.9969 - val_precision: 0.6230\n",
      "Epoch 28/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6541 - precision: 0.6983\n",
      "Epoch 28: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6549 - precision: 0.6968 - val_loss: 1.0103 - val_precision: 0.6192\n",
      "Epoch 29/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.6401 - precision: 0.6999\n",
      "Epoch 29: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6400 - precision: 0.7004 - val_loss: 1.0361 - val_precision: 0.6253\n",
      "Epoch 30/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.6490 - precision: 0.6978\n",
      "Epoch 30: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6482 - precision: 0.6995 - val_loss: 1.0036 - val_precision: 0.6104\n",
      "Epoch 31/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6355 - precision: 0.6986\n",
      "Epoch 31: val_loss did not improve from 0.94613\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6357 - precision: 0.6999 - val_loss: 1.0337 - val_precision: 0.6163\n",
      "Epoch 31: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7402 - precision: 0.7040\n",
      "Combinación 71 = (False, True, False, 64, 0.5) \n",
      " precision train: [0.7402380108833313, 0.7040114998817444]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 73: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.4942 - precision: 0.7273    \n",
      "Epoch 1: val_loss improved from inf to 1.26497, saving model to model_73.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.4756 - precision: 0.7451 - val_loss: 1.2650 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.1378 - precision: 0.6575\n",
      "Epoch 2: val_loss improved from 1.26497 to 1.09900, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1318 - precision: 0.6521 - val_loss: 1.0990 - val_precision: 0.6578\n",
      "Epoch 3/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9968 - precision: 0.6227\n",
      "Epoch 3: val_loss improved from 1.09900 to 1.06838, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9936 - precision: 0.6254 - val_loss: 1.0684 - val_precision: 0.6156\n",
      "Epoch 4/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.9355 - precision: 0.6197\n",
      "Epoch 4: val_loss improved from 1.06838 to 1.06149, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9426 - precision: 0.6150 - val_loss: 1.0615 - val_precision: 0.6061\n",
      "Epoch 5/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.9182 - precision: 0.6137\n",
      "Epoch 5: val_loss improved from 1.06149 to 1.04432, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9160 - precision: 0.6154 - val_loss: 1.0443 - val_precision: 0.6010\n",
      "Epoch 6/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9104 - precision: 0.6151\n",
      "Epoch 6: val_loss improved from 1.04432 to 1.02787, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9091 - precision: 0.6157 - val_loss: 1.0279 - val_precision: 0.6101\n",
      "Epoch 7/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8810 - precision: 0.6269\n",
      "Epoch 7: val_loss did not improve from 1.02787\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8818 - precision: 0.6259 - val_loss: 1.0362 - val_precision: 0.6006\n",
      "Epoch 8/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.8682 - precision: 0.6317\n",
      "Epoch 8: val_loss did not improve from 1.02787\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8756 - precision: 0.6286 - val_loss: 1.0425 - val_precision: 0.5993\n",
      "Epoch 9/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.8699 - precision: 0.6268\n",
      "Epoch 9: val_loss did not improve from 1.02787\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8691 - precision: 0.6271 - val_loss: 1.0346 - val_precision: 0.6026\n",
      "Epoch 10/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8515 - precision: 0.6325\n",
      "Epoch 10: val_loss improved from 1.02787 to 1.01502, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8547 - precision: 0.6313 - val_loss: 1.0150 - val_precision: 0.6128\n",
      "Epoch 11/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8495 - precision: 0.6347\n",
      "Epoch 11: val_loss improved from 1.01502 to 1.01491, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8506 - precision: 0.6324 - val_loss: 1.0149 - val_precision: 0.6156\n",
      "Epoch 12/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8443 - precision: 0.6408\n",
      "Epoch 12: val_loss improved from 1.01491 to 1.01338, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8397 - precision: 0.6394 - val_loss: 1.0134 - val_precision: 0.6158\n",
      "Epoch 13/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/240 [============================>.] - ETA: 0s - loss: 0.8277 - precision: 0.6386\n",
      "Epoch 13: val_loss improved from 1.01338 to 1.01146, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8265 - precision: 0.6393 - val_loss: 1.0115 - val_precision: 0.6124\n",
      "Epoch 14/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8243 - precision: 0.6468\n",
      "Epoch 14: val_loss did not improve from 1.01146\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8262 - precision: 0.6452 - val_loss: 1.0251 - val_precision: 0.6033\n",
      "Epoch 15/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8108 - precision: 0.6515\n",
      "Epoch 15: val_loss improved from 1.01146 to 1.00428, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8108 - precision: 0.6508 - val_loss: 1.0043 - val_precision: 0.6143\n",
      "Epoch 16/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8031 - precision: 0.6543\n",
      "Epoch 16: val_loss did not improve from 1.00428\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8068 - precision: 0.6530 - val_loss: 1.0061 - val_precision: 0.6173\n",
      "Epoch 17/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7993 - precision: 0.6487\n",
      "Epoch 17: val_loss improved from 1.00428 to 1.00102, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7986 - precision: 0.6497 - val_loss: 1.0010 - val_precision: 0.6171\n",
      "Epoch 18/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7971 - precision: 0.6528\n",
      "Epoch 18: val_loss did not improve from 1.00102\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7965 - precision: 0.6525 - val_loss: 1.0044 - val_precision: 0.6171\n",
      "Epoch 19/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7821 - precision: 0.6630\n",
      "Epoch 19: val_loss improved from 1.00102 to 0.99770, saving model to model_73.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7870 - precision: 0.6610 - val_loss: 0.9977 - val_precision: 0.6189\n",
      "Epoch 20/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.7773 - precision: 0.6622\n",
      "Epoch 20: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7766 - precision: 0.6636 - val_loss: 1.0191 - val_precision: 0.6115\n",
      "Epoch 21/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7676 - precision: 0.6582\n",
      "Epoch 21: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7669 - precision: 0.6582 - val_loss: 1.0225 - val_precision: 0.6124\n",
      "Epoch 22/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7586 - precision: 0.6690\n",
      "Epoch 22: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7594 - precision: 0.6687 - val_loss: 1.0488 - val_precision: 0.6039\n",
      "Epoch 23/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.7488 - precision: 0.6710\n",
      "Epoch 23: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7472 - precision: 0.6715 - val_loss: 1.0410 - val_precision: 0.6048\n",
      "Epoch 24/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7500 - precision: 0.6732\n",
      "Epoch 24: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7483 - precision: 0.6725 - val_loss: 1.0415 - val_precision: 0.6066\n",
      "Epoch 25/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7268 - precision: 0.6832\n",
      "Epoch 25: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7309 - precision: 0.6825 - val_loss: 1.0084 - val_precision: 0.6194\n",
      "Epoch 26/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7421 - precision: 0.6763\n",
      "Epoch 26: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7416 - precision: 0.6769 - val_loss: 1.0349 - val_precision: 0.6118\n",
      "Epoch 27/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7202 - precision: 0.6846\n",
      "Epoch 27: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7229 - precision: 0.6840 - val_loss: 1.0315 - val_precision: 0.6135\n",
      "Epoch 28/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7214 - precision: 0.6850\n",
      "Epoch 28: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7243 - precision: 0.6848 - val_loss: 1.0287 - val_precision: 0.6101\n",
      "Epoch 29/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7226 - precision: 0.6859\n",
      "Epoch 29: val_loss did not improve from 0.99770\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7209 - precision: 0.6838 - val_loss: 1.0415 - val_precision: 0.6126\n",
      "Epoch 29: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8345 - precision: 0.6821\n",
      "Combinación 72 = (False, False, True, 8, 0.1) \n",
      " precision train: [0.834487795829773, 0.682053804397583]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 74: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.5321 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.36375, saving model to model_74.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.5207 - precision: 0.5000 - val_loss: 1.3637 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.3104 - precision: 0.6587\n",
      "Epoch 2: val_loss improved from 1.36375 to 1.30657, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.3094 - precision: 0.6628 - val_loss: 1.3066 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 1.2604 - precision: 0.6146\n",
      "Epoch 3: val_loss improved from 1.30657 to 1.27220, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2625 - precision: 0.6150 - val_loss: 1.2722 - val_precision: 0.8214\n",
      "Epoch 4/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.2253 - precision: 0.6324\n",
      "Epoch 4: val_loss improved from 1.27220 to 1.22216, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2275 - precision: 0.6327 - val_loss: 1.2222 - val_precision: 0.7739\n",
      "Epoch 5/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.1719 - precision: 0.6391\n",
      "Epoch 5: val_loss improved from 1.22216 to 1.15667, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1724 - precision: 0.6406 - val_loss: 1.1567 - val_precision: 0.7036\n",
      "Epoch 6/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 1.1021 - precision: 0.6408\n",
      "Epoch 6: val_loss improved from 1.15667 to 1.11204, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1027 - precision: 0.6370 - val_loss: 1.1120 - val_precision: 0.6777\n",
      "Epoch 7/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.0660 - precision: 0.6307\n",
      "Epoch 7: val_loss improved from 1.11204 to 1.07733, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0645 - precision: 0.6302 - val_loss: 1.0773 - val_precision: 0.6550\n",
      "Epoch 8/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.0328 - precision: 0.6215\n",
      "Epoch 8: val_loss improved from 1.07733 to 1.04253, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0331 - precision: 0.6227 - val_loss: 1.0425 - val_precision: 0.6436\n",
      "Epoch 9/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.0177 - precision: 0.6196\n",
      "Epoch 9: val_loss improved from 1.04253 to 1.03437, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0093 - precision: 0.6231 - val_loss: 1.0344 - val_precision: 0.6373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.9777 - precision: 0.6299\n",
      "Epoch 10: val_loss improved from 1.03437 to 1.02609, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9786 - precision: 0.6298 - val_loss: 1.0261 - val_precision: 0.6287\n",
      "Epoch 11/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9715 - precision: 0.6247\n",
      "Epoch 11: val_loss did not improve from 1.02609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9731 - precision: 0.6243 - val_loss: 1.0298 - val_precision: 0.6206\n",
      "Epoch 12/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.9686 - precision: 0.6207\n",
      "Epoch 12: val_loss did not improve from 1.02609\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9654 - precision: 0.6236 - val_loss: 1.0313 - val_precision: 0.6279\n",
      "Epoch 13/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.9470 - precision: 0.6231\n",
      "Epoch 13: val_loss improved from 1.02609 to 1.02386, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9402 - precision: 0.6261 - val_loss: 1.0239 - val_precision: 0.6224\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9388 - precision: 0.6351\n",
      "Epoch 14: val_loss improved from 1.02386 to 1.02047, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9390 - precision: 0.6346 - val_loss: 1.0205 - val_precision: 0.6273\n",
      "Epoch 15/70\n",
      "214/240 [=========================>....] - ETA: 0s - loss: 0.9393 - precision: 0.6301\n",
      "Epoch 15: val_loss improved from 1.02047 to 1.01825, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9390 - precision: 0.6289 - val_loss: 1.0182 - val_precision: 0.6246\n",
      "Epoch 16/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9269 - precision: 0.6395\n",
      "Epoch 16: val_loss improved from 1.01825 to 1.01615, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9269 - precision: 0.6395 - val_loss: 1.0162 - val_precision: 0.6253\n",
      "Epoch 17/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9354 - precision: 0.6301\n",
      "Epoch 17: val_loss improved from 1.01615 to 1.00707, saving model to model_74.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9352 - precision: 0.6305 - val_loss: 1.0071 - val_precision: 0.6297\n",
      "Epoch 18/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9151 - precision: 0.6377\n",
      "Epoch 18: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9142 - precision: 0.6376 - val_loss: 1.0222 - val_precision: 0.6233\n",
      "Epoch 19/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9145 - precision: 0.6410\n",
      "Epoch 19: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9100 - precision: 0.6419 - val_loss: 1.0223 - val_precision: 0.6195\n",
      "Epoch 20/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9111 - precision: 0.6399\n",
      "Epoch 20: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9088 - precision: 0.6414 - val_loss: 1.0316 - val_precision: 0.6168\n",
      "Epoch 21/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9038 - precision: 0.6390\n",
      "Epoch 21: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9041 - precision: 0.6380 - val_loss: 1.0242 - val_precision: 0.6200\n",
      "Epoch 22/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8844 - precision: 0.6451\n",
      "Epoch 22: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8853 - precision: 0.6441 - val_loss: 1.0206 - val_precision: 0.6211\n",
      "Epoch 23/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8865 - precision: 0.6480\n",
      "Epoch 23: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8851 - precision: 0.6473 - val_loss: 1.0391 - val_precision: 0.6145\n",
      "Epoch 24/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8869 - precision: 0.6468\n",
      "Epoch 24: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8885 - precision: 0.6454 - val_loss: 1.0108 - val_precision: 0.6216\n",
      "Epoch 25/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8716 - precision: 0.6551\n",
      "Epoch 25: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8716 - precision: 0.6549 - val_loss: 1.0216 - val_precision: 0.6191\n",
      "Epoch 26/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8805 - precision: 0.6511\n",
      "Epoch 26: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8797 - precision: 0.6524 - val_loss: 1.0280 - val_precision: 0.6129\n",
      "Epoch 27/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8766 - precision: 0.6490\n",
      "Epoch 27: val_loss did not improve from 1.00707\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8773 - precision: 0.6479 - val_loss: 1.0216 - val_precision: 0.6177\n",
      "Epoch 27: early stopping\n",
      "300/300 [==============================] - 0s 994us/step - loss: 0.8988 - precision: 0.6586\n",
      "Combinación 73 = (False, False, True, 8, 0.25) \n",
      " precision train: [0.8988063335418701, 0.6586490273475647]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 75: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.5842 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.50538, saving model to model_75.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.5834 - precision: 1.0000 - val_loss: 1.5054 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.4188 - precision: 0.6395\n",
      "Epoch 2: val_loss improved from 1.50538 to 1.27188, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.4160 - precision: 0.6440 - val_loss: 1.2719 - val_precision: 0.7133\n",
      "Epoch 3/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.3133 - precision: 0.5917\n",
      "Epoch 3: val_loss improved from 1.27188 to 1.20248, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.3109 - precision: 0.5939 - val_loss: 1.2025 - val_precision: 0.6782\n",
      "Epoch 4/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.2712 - precision: 0.5745\n",
      "Epoch 4: val_loss improved from 1.20248 to 1.18973, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2688 - precision: 0.5727 - val_loss: 1.1897 - val_precision: 0.6627\n",
      "Epoch 5/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.2430 - precision: 0.5791\n",
      "Epoch 5: val_loss improved from 1.18973 to 1.16324, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2425 - precision: 0.5791 - val_loss: 1.1632 - val_precision: 0.6434\n",
      "Epoch 6/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.2405 - precision: 0.5663\n",
      "Epoch 6: val_loss improved from 1.16324 to 1.15576, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2396 - precision: 0.5680 - val_loss: 1.1558 - val_precision: 0.6457\n",
      "Epoch 7/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.2154 - precision: 0.5835\n",
      "Epoch 7: val_loss improved from 1.15576 to 1.14777, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2168 - precision: 0.5832 - val_loss: 1.1478 - val_precision: 0.6474\n",
      "Epoch 8/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2158 - precision: 0.5907\n",
      "Epoch 8: val_loss improved from 1.14777 to 1.13983, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2179 - precision: 0.5869 - val_loss: 1.1398 - val_precision: 0.6572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1957 - precision: 0.5941\n",
      "Epoch 9: val_loss improved from 1.13983 to 1.12890, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1964 - precision: 0.5953 - val_loss: 1.1289 - val_precision: 0.6551\n",
      "Epoch 10/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.2026 - precision: 0.5892\n",
      "Epoch 10: val_loss did not improve from 1.12890\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.2026 - precision: 0.5902 - val_loss: 1.1326 - val_precision: 0.6433\n",
      "Epoch 11/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.1805 - precision: 0.6016\n",
      "Epoch 11: val_loss improved from 1.12890 to 1.10626, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1825 - precision: 0.6029 - val_loss: 1.1063 - val_precision: 0.6838\n",
      "Epoch 12/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1760 - precision: 0.6125\n",
      "Epoch 12: val_loss improved from 1.10626 to 1.09679, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1750 - precision: 0.6128 - val_loss: 1.0968 - val_precision: 0.6764\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1601 - precision: 0.6089\n",
      "Epoch 13: val_loss improved from 1.09679 to 1.07910, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1600 - precision: 0.6079 - val_loss: 1.0791 - val_precision: 0.6802\n",
      "Epoch 14/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1662 - precision: 0.5954\n",
      "Epoch 14: val_loss improved from 1.07910 to 1.07419, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1630 - precision: 0.5959 - val_loss: 1.0742 - val_precision: 0.6831\n",
      "Epoch 15/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1500 - precision: 0.6054\n",
      "Epoch 15: val_loss improved from 1.07419 to 1.06548, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1480 - precision: 0.6059 - val_loss: 1.0655 - val_precision: 0.6830\n",
      "Epoch 16/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1461 - precision: 0.6145\n",
      "Epoch 16: val_loss improved from 1.06548 to 1.06517, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1465 - precision: 0.6136 - val_loss: 1.0652 - val_precision: 0.6814\n",
      "Epoch 17/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1440 - precision: 0.6108\n",
      "Epoch 17: val_loss improved from 1.06517 to 1.05552, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1427 - precision: 0.6102 - val_loss: 1.0555 - val_precision: 0.6761\n",
      "Epoch 18/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.1354 - precision: 0.6104\n",
      "Epoch 18: val_loss did not improve from 1.05552\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1360 - precision: 0.6114 - val_loss: 1.0575 - val_precision: 0.6651\n",
      "Epoch 19/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1336 - precision: 0.6222\n",
      "Epoch 19: val_loss improved from 1.05552 to 1.05260, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1351 - precision: 0.6216 - val_loss: 1.0526 - val_precision: 0.6726\n",
      "Epoch 20/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 1.1070 - precision: 0.6387\n",
      "Epoch 20: val_loss did not improve from 1.05260\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1116 - precision: 0.6365 - val_loss: 1.0549 - val_precision: 0.6642\n",
      "Epoch 21/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1322 - precision: 0.6217\n",
      "Epoch 21: val_loss improved from 1.05260 to 1.03971, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1278 - precision: 0.6243 - val_loss: 1.0397 - val_precision: 0.6733\n",
      "Epoch 22/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1148 - precision: 0.6237\n",
      "Epoch 22: val_loss did not improve from 1.03971\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1144 - precision: 0.6232 - val_loss: 1.0453 - val_precision: 0.6691\n",
      "Epoch 23/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1204 - precision: 0.6132\n",
      "Epoch 23: val_loss did not improve from 1.03971\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1213 - precision: 0.6145 - val_loss: 1.0443 - val_precision: 0.6701\n",
      "Epoch 24/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.1079 - precision: 0.6263\n",
      "Epoch 24: val_loss did not improve from 1.03971\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1084 - precision: 0.6271 - val_loss: 1.0424 - val_precision: 0.6615\n",
      "Epoch 25/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.1272 - precision: 0.6219\n",
      "Epoch 25: val_loss did not improve from 1.03971\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1272 - precision: 0.6200 - val_loss: 1.0481 - val_precision: 0.6561\n",
      "Epoch 26/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.1154 - precision: 0.6218\n",
      "Epoch 26: val_loss improved from 1.03971 to 1.03632, saving model to model_75.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1169 - precision: 0.6192 - val_loss: 1.0363 - val_precision: 0.6726\n",
      "Epoch 27/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.1009 - precision: 0.6218\n",
      "Epoch 27: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1012 - precision: 0.6200 - val_loss: 1.0534 - val_precision: 0.6508\n",
      "Epoch 28/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.0928 - precision: 0.6232\n",
      "Epoch 28: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0925 - precision: 0.6222 - val_loss: 1.0402 - val_precision: 0.6612\n",
      "Epoch 29/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0877 - precision: 0.6335\n",
      "Epoch 29: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0876 - precision: 0.6339 - val_loss: 1.0435 - val_precision: 0.6579\n",
      "Epoch 30/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0948 - precision: 0.6251\n",
      "Epoch 30: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0948 - precision: 0.6251 - val_loss: 1.0425 - val_precision: 0.6541\n",
      "Epoch 31/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.1071 - precision: 0.6102\n",
      "Epoch 31: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1013 - precision: 0.6135 - val_loss: 1.0456 - val_precision: 0.6560\n",
      "Epoch 32/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.0922 - precision: 0.6350\n",
      "Epoch 32: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0911 - precision: 0.6313 - val_loss: 1.0449 - val_precision: 0.6485\n",
      "Epoch 33/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.0892 - precision: 0.6327\n",
      "Epoch 33: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0890 - precision: 0.6329 - val_loss: 1.0464 - val_precision: 0.6485\n",
      "Epoch 34/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0770 - precision: 0.6386\n",
      "Epoch 34: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0782 - precision: 0.6389 - val_loss: 1.0407 - val_precision: 0.6487\n",
      "Epoch 35/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0832 - precision: 0.6279\n",
      "Epoch 35: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0838 - precision: 0.6287 - val_loss: 1.0510 - val_precision: 0.6391\n",
      "Epoch 36/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.0833 - precision: 0.6392\n",
      "Epoch 36: val_loss did not improve from 1.03632\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0827 - precision: 0.6403 - val_loss: 1.0491 - val_precision: 0.6473\n",
      "Epoch 36: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9807 - precision: 0.6693\n",
      "Combinación 74 = (False, False, True, 8, 0.5) \n",
      " precision train: [0.980731189250946, 0.6693055629730225]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 76: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.4048 - precision: 0.6548\n",
      "Epoch 1: val_loss improved from inf to 1.21204, saving model to model_76.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.3985 - precision: 0.6537 - val_loss: 1.2120 - val_precision: 0.7046\n",
      "Epoch 2/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.0721 - precision: 0.6502\n",
      "Epoch 2: val_loss improved from 1.21204 to 1.07162, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0619 - precision: 0.6503 - val_loss: 1.0716 - val_precision: 0.6294\n",
      "Epoch 3/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.9309 - precision: 0.6247\n",
      "Epoch 3: val_loss improved from 1.07162 to 1.04044, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9280 - precision: 0.6273 - val_loss: 1.0404 - val_precision: 0.6244\n",
      "Epoch 4/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8858 - precision: 0.6274\n",
      "Epoch 4: val_loss improved from 1.04044 to 1.00200, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8871 - precision: 0.6276 - val_loss: 1.0020 - val_precision: 0.6293\n",
      "Epoch 5/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8632 - precision: 0.6363\n",
      "Epoch 5: val_loss improved from 1.00200 to 0.99705, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8638 - precision: 0.6370 - val_loss: 0.9971 - val_precision: 0.6289\n",
      "Epoch 6/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8443 - precision: 0.6434\n",
      "Epoch 6: val_loss improved from 0.99705 to 0.98813, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8420 - precision: 0.6437 - val_loss: 0.9881 - val_precision: 0.6297\n",
      "Epoch 7/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8209 - precision: 0.6532\n",
      "Epoch 7: val_loss improved from 0.98813 to 0.98424, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8241 - precision: 0.6515 - val_loss: 0.9842 - val_precision: 0.6316\n",
      "Epoch 8/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8041 - precision: 0.6566\n",
      "Epoch 8: val_loss improved from 0.98424 to 0.97972, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8039 - precision: 0.6572 - val_loss: 0.9797 - val_precision: 0.6308\n",
      "Epoch 9/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7936 - precision: 0.6553\n",
      "Epoch 9: val_loss improved from 0.97972 to 0.97967, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7941 - precision: 0.6558 - val_loss: 0.9797 - val_precision: 0.6288\n",
      "Epoch 10/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7813 - precision: 0.6673\n",
      "Epoch 10: val_loss improved from 0.97967 to 0.96668, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7817 - precision: 0.6673 - val_loss: 0.9667 - val_precision: 0.6315\n",
      "Epoch 11/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7724 - precision: 0.6705\n",
      "Epoch 11: val_loss did not improve from 0.96668\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7712 - precision: 0.6702 - val_loss: 0.9813 - val_precision: 0.6335\n",
      "Epoch 12/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7533 - precision: 0.6778\n",
      "Epoch 12: val_loss improved from 0.96668 to 0.96135, saving model to model_76.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7523 - precision: 0.6783 - val_loss: 0.9614 - val_precision: 0.6319\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7489 - precision: 0.6745\n",
      "Epoch 13: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7461 - precision: 0.6758 - val_loss: 0.9798 - val_precision: 0.6342\n",
      "Epoch 14/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7269 - precision: 0.6809\n",
      "Epoch 14: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7267 - precision: 0.6806 - val_loss: 0.9664 - val_precision: 0.6304\n",
      "Epoch 15/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7196 - precision: 0.6855\n",
      "Epoch 15: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7177 - precision: 0.6870 - val_loss: 0.9614 - val_precision: 0.6367\n",
      "Epoch 16/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7002 - precision: 0.6952\n",
      "Epoch 16: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6999 - precision: 0.6948 - val_loss: 0.9920 - val_precision: 0.6313\n",
      "Epoch 17/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6916 - precision: 0.6900\n",
      "Epoch 17: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6908 - precision: 0.6904 - val_loss: 0.9700 - val_precision: 0.6328\n",
      "Epoch 18/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6763 - precision: 0.6991\n",
      "Epoch 18: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6765 - precision: 0.6987 - val_loss: 0.9801 - val_precision: 0.6254\n",
      "Epoch 19/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.6716 - precision: 0.6996\n",
      "Epoch 19: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6756 - precision: 0.6989 - val_loss: 1.0058 - val_precision: 0.6253\n",
      "Epoch 20/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.6539 - precision: 0.7098\n",
      "Epoch 20: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6565 - precision: 0.7112 - val_loss: 0.9884 - val_precision: 0.6209\n",
      "Epoch 21/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.6489 - precision: 0.7062\n",
      "Epoch 21: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6493 - precision: 0.7058 - val_loss: 1.0163 - val_precision: 0.6217\n",
      "Epoch 22/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.6459 - precision: 0.7123\n",
      "Epoch 22: val_loss did not improve from 0.96135\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6487 - precision: 0.7096 - val_loss: 1.0188 - val_precision: 0.6207\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7781 - precision: 0.6985\n",
      "Combinación 75 = (False, False, True, 16, 0.1) \n",
      " precision train: [0.7780886292457581, 0.6985378265380859]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 77: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.4483 - precision: 0.6869 \n",
      "Epoch 1: val_loss improved from inf to 1.27437, saving model to model_77.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.4442 - precision: 0.6694 - val_loss: 1.2744 - val_precision: 0.7051\n",
      "Epoch 2/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1565 - precision: 0.6424\n",
      "Epoch 2: val_loss improved from 1.27437 to 1.18919, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1558 - precision: 0.6438 - val_loss: 1.1892 - val_precision: 0.6627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 1.0729 - precision: 0.6394\n",
      "Epoch 3: val_loss improved from 1.18919 to 1.09945, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0746 - precision: 0.6404 - val_loss: 1.0994 - val_precision: 0.6723\n",
      "Epoch 4/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9979 - precision: 0.6277\n",
      "Epoch 4: val_loss improved from 1.09945 to 1.04730, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9972 - precision: 0.6276 - val_loss: 1.0473 - val_precision: 0.6347\n",
      "Epoch 5/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9467 - precision: 0.6259\n",
      "Epoch 5: val_loss improved from 1.04730 to 1.03467, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9484 - precision: 0.6251 - val_loss: 1.0347 - val_precision: 0.6263\n",
      "Epoch 6/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9190 - precision: 0.6247\n",
      "Epoch 6: val_loss improved from 1.03467 to 1.03205, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9189 - precision: 0.6254 - val_loss: 1.0321 - val_precision: 0.6183\n",
      "Epoch 7/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8958 - precision: 0.6293\n",
      "Epoch 7: val_loss improved from 1.03205 to 1.02172, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8969 - precision: 0.6287 - val_loss: 1.0217 - val_precision: 0.6167\n",
      "Epoch 8/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8928 - precision: 0.6344\n",
      "Epoch 8: val_loss improved from 1.02172 to 1.01166, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8914 - precision: 0.6346 - val_loss: 1.0117 - val_precision: 0.6179\n",
      "Epoch 9/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8758 - precision: 0.6296\n",
      "Epoch 9: val_loss improved from 1.01166 to 1.00469, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8712 - precision: 0.6317 - val_loss: 1.0047 - val_precision: 0.6202\n",
      "Epoch 10/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8587 - precision: 0.6345\n",
      "Epoch 10: val_loss improved from 1.00469 to 0.99815, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8567 - precision: 0.6363 - val_loss: 0.9981 - val_precision: 0.6232\n",
      "Epoch 11/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8477 - precision: 0.6370\n",
      "Epoch 11: val_loss improved from 0.99815 to 0.98996, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8489 - precision: 0.6371 - val_loss: 0.9900 - val_precision: 0.6275\n",
      "Epoch 12/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8342 - precision: 0.6455\n",
      "Epoch 12: val_loss improved from 0.98996 to 0.98919, saving model to model_77.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8333 - precision: 0.6456 - val_loss: 0.9892 - val_precision: 0.6246\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8258 - precision: 0.6446\n",
      "Epoch 13: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8264 - precision: 0.6443 - val_loss: 0.9979 - val_precision: 0.6234\n",
      "Epoch 14/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8180 - precision: 0.6485\n",
      "Epoch 14: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8158 - precision: 0.6498 - val_loss: 1.0002 - val_precision: 0.6233\n",
      "Epoch 15/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8027 - precision: 0.6538\n",
      "Epoch 15: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8062 - precision: 0.6523 - val_loss: 0.9956 - val_precision: 0.6186\n",
      "Epoch 16/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7991 - precision: 0.6535\n",
      "Epoch 16: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7991 - precision: 0.6532 - val_loss: 0.9963 - val_precision: 0.6295\n",
      "Epoch 17/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7843 - precision: 0.6609\n",
      "Epoch 17: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7940 - precision: 0.6575 - val_loss: 1.0138 - val_precision: 0.6212\n",
      "Epoch 18/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7907 - precision: 0.6629\n",
      "Epoch 18: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7885 - precision: 0.6646 - val_loss: 0.9965 - val_precision: 0.6291\n",
      "Epoch 19/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7820 - precision: 0.6632\n",
      "Epoch 19: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7773 - precision: 0.6657 - val_loss: 1.0182 - val_precision: 0.6225\n",
      "Epoch 20/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7698 - precision: 0.6680\n",
      "Epoch 20: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7698 - precision: 0.6680 - val_loss: 1.0174 - val_precision: 0.6194\n",
      "Epoch 21/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7743 - precision: 0.6671\n",
      "Epoch 21: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7716 - precision: 0.6681 - val_loss: 0.9955 - val_precision: 0.6226\n",
      "Epoch 22/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7623 - precision: 0.6726\n",
      "Epoch 22: val_loss did not improve from 0.98919\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7623 - precision: 0.6740 - val_loss: 1.0176 - val_precision: 0.6238\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8539 - precision: 0.6770\n",
      "Combinación 76 = (False, False, True, 16, 0.25) \n",
      " precision train: [0.8538705706596375, 0.6770405173301697]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 78: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.5402 - precision: 0.6964 \n",
      "Epoch 1: val_loss improved from inf to 1.29919, saving model to model_78.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.5334 - precision: 0.6667 - val_loss: 1.2992 - val_precision: 0.7232\n",
      "Epoch 2/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.2812 - precision: 0.6360\n",
      "Epoch 2: val_loss improved from 1.29919 to 1.13503, saving model to model_78.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2775 - precision: 0.6355 - val_loss: 1.1350 - val_precision: 0.6776\n",
      "Epoch 3/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1664 - precision: 0.5974\n",
      "Epoch 3: val_loss improved from 1.13503 to 1.05758, saving model to model_78.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1624 - precision: 0.5965 - val_loss: 1.0576 - val_precision: 0.6517\n",
      "Epoch 4/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.1029 - precision: 0.6094\n",
      "Epoch 4: val_loss improved from 1.05758 to 1.04360, saving model to model_78.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1040 - precision: 0.6062 - val_loss: 1.0436 - val_precision: 0.6425\n",
      "Epoch 5/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0700 - precision: 0.6172\n",
      "Epoch 5: val_loss improved from 1.04360 to 1.02999, saving model to model_78.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0688 - precision: 0.6158 - val_loss: 1.0300 - val_precision: 0.6341\n",
      "Epoch 6/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0582 - precision: 0.6073\n",
      "Epoch 6: val_loss did not improve from 1.02999\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0564 - precision: 0.6092 - val_loss: 1.0371 - val_precision: 0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0403 - precision: 0.6183\n",
      "Epoch 7: val_loss improved from 1.02999 to 1.01060, saving model to model_78.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0433 - precision: 0.6180 - val_loss: 1.0106 - val_precision: 0.6415\n",
      "Epoch 8/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.0212 - precision: 0.6162\n",
      "Epoch 8: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0243 - precision: 0.6161 - val_loss: 1.0224 - val_precision: 0.6329\n",
      "Epoch 9/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 1.0124 - precision: 0.6199\n",
      "Epoch 9: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0107 - precision: 0.6242 - val_loss: 1.0276 - val_precision: 0.6288\n",
      "Epoch 10/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 1.0196 - precision: 0.6170\n",
      "Epoch 10: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0261 - precision: 0.6145 - val_loss: 1.0174 - val_precision: 0.6369\n",
      "Epoch 11/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9948 - precision: 0.6263\n",
      "Epoch 11: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9961 - precision: 0.6283 - val_loss: 1.0161 - val_precision: 0.6365\n",
      "Epoch 12/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9974 - precision: 0.6295\n",
      "Epoch 12: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0013 - precision: 0.6274 - val_loss: 1.0171 - val_precision: 0.6346\n",
      "Epoch 13/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.9894 - precision: 0.6244\n",
      "Epoch 13: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9880 - precision: 0.6262 - val_loss: 1.0254 - val_precision: 0.6280\n",
      "Epoch 14/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9823 - precision: 0.6320\n",
      "Epoch 14: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9874 - precision: 0.6326 - val_loss: 1.0273 - val_precision: 0.6325\n",
      "Epoch 15/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9609 - precision: 0.6365\n",
      "Epoch 15: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9625 - precision: 0.6351 - val_loss: 1.0260 - val_precision: 0.6286\n",
      "Epoch 16/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9682 - precision: 0.6300\n",
      "Epoch 16: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9667 - precision: 0.6320 - val_loss: 1.0246 - val_precision: 0.6306\n",
      "Epoch 17/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.9575 - precision: 0.6344\n",
      "Epoch 17: val_loss did not improve from 1.01060\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9595 - precision: 0.6339 - val_loss: 1.0314 - val_precision: 0.6339\n",
      "Epoch 17: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9673 - precision: 0.6456\n",
      "Combinación 77 = (False, False, True, 16, 0.5) \n",
      " precision train: [0.9672766923904419, 0.6456353664398193]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 79: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.2523 - precision: 0.6450\n",
      "Epoch 1: val_loss improved from inf to 1.03056, saving model to model_79.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.2269 - precision: 0.6377 - val_loss: 1.0306 - val_precision: 0.6378\n",
      "Epoch 2/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8884 - precision: 0.6300\n",
      "Epoch 2: val_loss improved from 1.03056 to 0.98588, saving model to model_79.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8868 - precision: 0.6304 - val_loss: 0.9859 - val_precision: 0.6372\n",
      "Epoch 3/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.8426 - precision: 0.6387\n",
      "Epoch 3: val_loss improved from 0.98588 to 0.95538, saving model to model_79.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8428 - precision: 0.6367 - val_loss: 0.9554 - val_precision: 0.6388\n",
      "Epoch 4/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8032 - precision: 0.6529\n",
      "Epoch 4: val_loss improved from 0.95538 to 0.93290, saving model to model_79.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8042 - precision: 0.6522 - val_loss: 0.9329 - val_precision: 0.6524\n",
      "Epoch 5/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7794 - precision: 0.6565\n",
      "Epoch 5: val_loss did not improve from 0.93290\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7801 - precision: 0.6564 - val_loss: 0.9478 - val_precision: 0.6422\n",
      "Epoch 6/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7546 - precision: 0.6618\n",
      "Epoch 6: val_loss improved from 0.93290 to 0.91576, saving model to model_79.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7552 - precision: 0.6616 - val_loss: 0.9158 - val_precision: 0.6535\n",
      "Epoch 7/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7389 - precision: 0.6674\n",
      "Epoch 7: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7370 - precision: 0.6679 - val_loss: 0.9373 - val_precision: 0.6497\n",
      "Epoch 8/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7133 - precision: 0.6723\n",
      "Epoch 8: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7146 - precision: 0.6720 - val_loss: 0.9599 - val_precision: 0.6325\n",
      "Epoch 9/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7008 - precision: 0.6743\n",
      "Epoch 9: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7001 - precision: 0.6750 - val_loss: 0.9457 - val_precision: 0.6471\n",
      "Epoch 10/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6867 - precision: 0.6808\n",
      "Epoch 10: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6867 - precision: 0.6808 - val_loss: 0.9372 - val_precision: 0.6416\n",
      "Epoch 11/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.6764 - precision: 0.6896\n",
      "Epoch 11: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6766 - precision: 0.6873 - val_loss: 0.9316 - val_precision: 0.6431\n",
      "Epoch 12/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6638 - precision: 0.6897\n",
      "Epoch 12: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6650 - precision: 0.6902 - val_loss: 0.9636 - val_precision: 0.6371\n",
      "Epoch 13/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6505 - precision: 0.6908\n",
      "Epoch 13: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6499 - precision: 0.6892 - val_loss: 0.9527 - val_precision: 0.6419\n",
      "Epoch 14/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6376 - precision: 0.6973\n",
      "Epoch 14: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6356 - precision: 0.6981 - val_loss: 1.0010 - val_precision: 0.6275\n",
      "Epoch 15/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6258 - precision: 0.7025\n",
      "Epoch 15: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6254 - precision: 0.7031 - val_loss: 0.9862 - val_precision: 0.6298\n",
      "Epoch 16/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.6084 - precision: 0.7064\n",
      "Epoch 16: val_loss did not improve from 0.91576\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6087 - precision: 0.7066 - val_loss: 1.0181 - val_precision: 0.6254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7646 - precision: 0.6985\n",
      "Combinación 78 = (False, False, True, 32, 0.1) \n",
      " precision train: [0.764595627784729, 0.6984715461730957]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 80: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.3383 - precision: 0.6653\n",
      "Epoch 1: val_loss improved from inf to 1.09880, saving model to model_80.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.3274 - precision: 0.6629 - val_loss: 1.0988 - val_precision: 0.6699\n",
      "Epoch 2/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.9707 - precision: 0.6303\n",
      "Epoch 2: val_loss improved from 1.09880 to 1.02473, saving model to model_80.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9693 - precision: 0.6303 - val_loss: 1.0247 - val_precision: 0.6289\n",
      "Epoch 3/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.9115 - precision: 0.6251\n",
      "Epoch 3: val_loss improved from 1.02473 to 1.00433, saving model to model_80.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9113 - precision: 0.6254 - val_loss: 1.0043 - val_precision: 0.6299\n",
      "Epoch 4/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8890 - precision: 0.6268\n",
      "Epoch 4: val_loss improved from 1.00433 to 1.00280, saving model to model_80.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8886 - precision: 0.6267 - val_loss: 1.0028 - val_precision: 0.6182\n",
      "Epoch 5/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8661 - precision: 0.6319\n",
      "Epoch 5: val_loss improved from 1.00280 to 0.98770, saving model to model_80.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8658 - precision: 0.6321 - val_loss: 0.9877 - val_precision: 0.6256\n",
      "Epoch 6/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8454 - precision: 0.6359\n",
      "Epoch 6: val_loss did not improve from 0.98770\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8454 - precision: 0.6362 - val_loss: 0.9992 - val_precision: 0.6230\n",
      "Epoch 7/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.8230 - precision: 0.6447\n",
      "Epoch 7: val_loss improved from 0.98770 to 0.95947, saving model to model_80.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8244 - precision: 0.6441 - val_loss: 0.9595 - val_precision: 0.6349\n",
      "Epoch 8/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8104 - precision: 0.6558\n",
      "Epoch 8: val_loss did not improve from 0.95947\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8091 - precision: 0.6562 - val_loss: 0.9675 - val_precision: 0.6371\n",
      "Epoch 9/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7890 - precision: 0.6505\n",
      "Epoch 9: val_loss improved from 0.95947 to 0.95640, saving model to model_80.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7877 - precision: 0.6516 - val_loss: 0.9564 - val_precision: 0.6304\n",
      "Epoch 10/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7678 - precision: 0.6677\n",
      "Epoch 10: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7715 - precision: 0.6649 - val_loss: 0.9827 - val_precision: 0.6286\n",
      "Epoch 11/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7612 - precision: 0.6664\n",
      "Epoch 11: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7612 - precision: 0.6661 - val_loss: 0.9659 - val_precision: 0.6392\n",
      "Epoch 12/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.7493 - precision: 0.6745\n",
      "Epoch 12: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7481 - precision: 0.6731 - val_loss: 0.9724 - val_precision: 0.6260\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7427 - precision: 0.6749\n",
      "Epoch 13: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7427 - precision: 0.6752 - val_loss: 0.9731 - val_precision: 0.6229\n",
      "Epoch 14/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7207 - precision: 0.6802\n",
      "Epoch 14: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7220 - precision: 0.6797 - val_loss: 0.9852 - val_precision: 0.6248\n",
      "Epoch 15/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7191 - precision: 0.6768\n",
      "Epoch 15: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7188 - precision: 0.6771 - val_loss: 1.0133 - val_precision: 0.6150\n",
      "Epoch 16/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7035 - precision: 0.6861\n",
      "Epoch 16: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7019 - precision: 0.6855 - val_loss: 0.9770 - val_precision: 0.6280\n",
      "Epoch 17/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6909 - precision: 0.6878\n",
      "Epoch 17: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6902 - precision: 0.6878 - val_loss: 0.9795 - val_precision: 0.6321\n",
      "Epoch 18/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.6790 - precision: 0.6902\n",
      "Epoch 18: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6799 - precision: 0.6884 - val_loss: 1.0004 - val_precision: 0.6235\n",
      "Epoch 19/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.6842 - precision: 0.6902\n",
      "Epoch 19: val_loss did not improve from 0.95640\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6797 - precision: 0.6918 - val_loss: 1.0230 - val_precision: 0.6122\n",
      "Epoch 19: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8053 - precision: 0.6831\n",
      "Combinación 79 = (False, False, True, 32, 0.25) \n",
      " precision train: [0.8052664399147034, 0.6831372380256653]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 81: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.4397 - precision: 0.6786\n",
      "Epoch 1: val_loss improved from inf to 1.15350, saving model to model_81.h5\n",
      "240/240 [==============================] - 5s 7ms/step - loss: 1.4365 - precision: 0.6777 - val_loss: 1.1535 - val_precision: 0.6821\n",
      "Epoch 2/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.1337 - precision: 0.6536\n",
      "Epoch 2: val_loss improved from 1.15350 to 1.06763, saving model to model_81.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1302 - precision: 0.6530 - val_loss: 1.0676 - val_precision: 0.6460\n",
      "Epoch 3/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.0350 - precision: 0.6275\n",
      "Epoch 3: val_loss improved from 1.06763 to 1.04423, saving model to model_81.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0313 - precision: 0.6290 - val_loss: 1.0442 - val_precision: 0.6312\n",
      "Epoch 4/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9824 - precision: 0.6264\n",
      "Epoch 4: val_loss improved from 1.04423 to 1.02339, saving model to model_81.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9821 - precision: 0.6264 - val_loss: 1.0234 - val_precision: 0.6264\n",
      "Epoch 5/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.9510 - precision: 0.6302\n",
      "Epoch 5: val_loss improved from 1.02339 to 1.00859, saving model to model_81.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9507 - precision: 0.6301 - val_loss: 1.0086 - val_precision: 0.6273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9415 - precision: 0.6278\n",
      "Epoch 6: val_loss did not improve from 1.00859\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9398 - precision: 0.6286 - val_loss: 1.0150 - val_precision: 0.6191\n",
      "Epoch 7/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9171 - precision: 0.6308\n",
      "Epoch 7: val_loss improved from 1.00859 to 0.99530, saving model to model_81.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9186 - precision: 0.6290 - val_loss: 0.9953 - val_precision: 0.6297\n",
      "Epoch 8/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8988 - precision: 0.6360\n",
      "Epoch 8: val_loss improved from 0.99530 to 0.99010, saving model to model_81.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8992 - precision: 0.6378 - val_loss: 0.9901 - val_precision: 0.6287\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9058 - precision: 0.6325\n",
      "Epoch 9: val_loss did not improve from 0.99010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9021 - precision: 0.6333 - val_loss: 0.9980 - val_precision: 0.6276\n",
      "Epoch 10/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8871 - precision: 0.6375\n",
      "Epoch 10: val_loss did not improve from 0.99010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8894 - precision: 0.6374 - val_loss: 0.9937 - val_precision: 0.6314\n",
      "Epoch 11/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8811 - precision: 0.6371\n",
      "Epoch 11: val_loss did not improve from 0.99010\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8800 - precision: 0.6381 - val_loss: 1.0336 - val_precision: 0.6127\n",
      "Epoch 12/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8783 - precision: 0.6372\n",
      "Epoch 12: val_loss improved from 0.99010 to 0.98414, saving model to model_81.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8789 - precision: 0.6371 - val_loss: 0.9841 - val_precision: 0.6326\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8691 - precision: 0.6404\n",
      "Epoch 13: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8701 - precision: 0.6409 - val_loss: 0.9964 - val_precision: 0.6282\n",
      "Epoch 14/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8553 - precision: 0.6425\n",
      "Epoch 14: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8553 - precision: 0.6425 - val_loss: 1.0088 - val_precision: 0.6183\n",
      "Epoch 15/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8494 - precision: 0.6452\n",
      "Epoch 15: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8483 - precision: 0.6494 - val_loss: 0.9877 - val_precision: 0.6305\n",
      "Epoch 16/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8455 - precision: 0.6385\n",
      "Epoch 16: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8460 - precision: 0.6390 - val_loss: 1.0101 - val_precision: 0.6186\n",
      "Epoch 17/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8381 - precision: 0.6409\n",
      "Epoch 17: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8362 - precision: 0.6434 - val_loss: 1.0032 - val_precision: 0.6225\n",
      "Epoch 18/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8265 - precision: 0.6495\n",
      "Epoch 18: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8262 - precision: 0.6507 - val_loss: 0.9955 - val_precision: 0.6280\n",
      "Epoch 19/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8232 - precision: 0.6472\n",
      "Epoch 19: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8232 - precision: 0.6483 - val_loss: 1.0082 - val_precision: 0.6216\n",
      "Epoch 20/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.8151 - precision: 0.6524\n",
      "Epoch 20: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8138 - precision: 0.6548 - val_loss: 1.0228 - val_precision: 0.6154\n",
      "Epoch 21/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8117 - precision: 0.6519\n",
      "Epoch 21: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8125 - precision: 0.6512 - val_loss: 1.0074 - val_precision: 0.6197\n",
      "Epoch 22/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7955 - precision: 0.6606\n",
      "Epoch 22: val_loss did not improve from 0.98414\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7953 - precision: 0.6599 - val_loss: 1.0159 - val_precision: 0.6149\n",
      "Epoch 22: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8796 - precision: 0.6522\n",
      "Combinación 80 = (False, False, True, 32, 0.5) \n",
      " precision train: [0.8795568943023682, 0.652195394039154]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 82: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1444 - precision: 0.6318\n",
      "Epoch 1: val_loss improved from inf to 1.00656, saving model to model_82.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.1389 - precision: 0.6290 - val_loss: 1.0066 - val_precision: 0.6447\n",
      "Epoch 2/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8747 - precision: 0.6248\n",
      "Epoch 2: val_loss improved from 1.00656 to 0.96863, saving model to model_82.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8738 - precision: 0.6264 - val_loss: 0.9686 - val_precision: 0.6428\n",
      "Epoch 3/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8293 - precision: 0.6410\n",
      "Epoch 3: val_loss improved from 0.96863 to 0.93698, saving model to model_82.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8278 - precision: 0.6410 - val_loss: 0.9370 - val_precision: 0.6463\n",
      "Epoch 4/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7836 - precision: 0.6517\n",
      "Epoch 4: val_loss did not improve from 0.93698\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7834 - precision: 0.6501 - val_loss: 0.9382 - val_precision: 0.6456\n",
      "Epoch 5/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7546 - precision: 0.6645\n",
      "Epoch 5: val_loss did not improve from 0.93698\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7589 - precision: 0.6633 - val_loss: 0.9393 - val_precision: 0.6426\n",
      "Epoch 6/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7325 - precision: 0.6611\n",
      "Epoch 6: val_loss improved from 0.93698 to 0.93025, saving model to model_82.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7375 - precision: 0.6596 - val_loss: 0.9303 - val_precision: 0.6373\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7063 - precision: 0.6720\n",
      "Epoch 7: val_loss did not improve from 0.93025\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7070 - precision: 0.6723 - val_loss: 0.9370 - val_precision: 0.6389\n",
      "Epoch 8/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6979 - precision: 0.6728\n",
      "Epoch 8: val_loss improved from 0.93025 to 0.92914, saving model to model_82.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6958 - precision: 0.6729 - val_loss: 0.9291 - val_precision: 0.6450\n",
      "Epoch 9/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6705 - precision: 0.6857\n",
      "Epoch 9: val_loss did not improve from 0.92914\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6705 - precision: 0.6857 - val_loss: 0.9992 - val_precision: 0.6296\n",
      "Epoch 10/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.6535 - precision: 0.6896\n",
      "Epoch 10: val_loss did not improve from 0.92914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6560 - precision: 0.6884 - val_loss: 0.9293 - val_precision: 0.6477\n",
      "Epoch 11/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.6460 - precision: 0.6924\n",
      "Epoch 11: val_loss did not improve from 0.92914\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6433 - precision: 0.6940 - val_loss: 0.9844 - val_precision: 0.6309\n",
      "Epoch 12/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.6250 - precision: 0.6992\n",
      "Epoch 12: val_loss did not improve from 0.92914\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6256 - precision: 0.7004 - val_loss: 0.9823 - val_precision: 0.6306\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.6127 - precision: 0.6991\n",
      "Epoch 13: val_loss did not improve from 0.92914\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6133 - precision: 0.6991 - val_loss: 0.9844 - val_precision: 0.6272\n",
      "Epoch 14/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.5986 - precision: 0.7066\n",
      "Epoch 14: val_loss did not improve from 0.92914\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5984 - precision: 0.7053 - val_loss: 0.9742 - val_precision: 0.6274\n",
      "Epoch 15/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.5849 - precision: 0.7063\n",
      "Epoch 15: val_loss did not improve from 0.92914\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5826 - precision: 0.7074 - val_loss: 1.0510 - val_precision: 0.6224\n",
      "Epoch 16/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.5701 - precision: 0.7128\n",
      "Epoch 16: val_loss did not improve from 0.92914\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5701 - precision: 0.7128 - val_loss: 1.0488 - val_precision: 0.6212\n",
      "Epoch 17/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.5601 - precision: 0.7192\n",
      "Epoch 17: val_loss did not improve from 0.92914\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.5596 - precision: 0.7176 - val_loss: 1.0599 - val_precision: 0.6213\n",
      "Epoch 18/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.5493 - precision: 0.7190\n",
      "Epoch 18: val_loss did not improve from 0.92914\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.5476 - precision: 0.7200 - val_loss: 1.0986 - val_precision: 0.6132\n",
      "Epoch 18: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.6989 - precision: 0.7173\n",
      "Combinación 81 = (False, False, True, 64, 0.1) \n",
      " precision train: [0.6989232301712036, 0.7173121571540833]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 83: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.1950 - precision: 0.6145\n",
      "Epoch 1: val_loss improved from inf to 1.01973, saving model to model_83.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.1915 - precision: 0.6102 - val_loss: 1.0197 - val_precision: 0.6602\n",
      "Epoch 2/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9054 - precision: 0.6266\n",
      "Epoch 2: val_loss improved from 1.01973 to 0.99582, saving model to model_83.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9054 - precision: 0.6266 - val_loss: 0.9958 - val_precision: 0.6294\n",
      "Epoch 3/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8519 - precision: 0.6375\n",
      "Epoch 3: val_loss improved from 0.99582 to 0.98950, saving model to model_83.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8491 - precision: 0.6387 - val_loss: 0.9895 - val_precision: 0.6282\n",
      "Epoch 4/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8214 - precision: 0.6449\n",
      "Epoch 4: val_loss improved from 0.98950 to 0.95780, saving model to model_83.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8196 - precision: 0.6457 - val_loss: 0.9578 - val_precision: 0.6345\n",
      "Epoch 5/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7803 - precision: 0.6546\n",
      "Epoch 5: val_loss improved from 0.95780 to 0.94381, saving model to model_83.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7819 - precision: 0.6538 - val_loss: 0.9438 - val_precision: 0.6504\n",
      "Epoch 6/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7672 - precision: 0.6584\n",
      "Epoch 6: val_loss improved from 0.94381 to 0.93855, saving model to model_83.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7682 - precision: 0.6576 - val_loss: 0.9386 - val_precision: 0.6475\n",
      "Epoch 7/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7493 - precision: 0.6619\n",
      "Epoch 7: val_loss improved from 0.93855 to 0.92837, saving model to model_83.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7484 - precision: 0.6626 - val_loss: 0.9284 - val_precision: 0.6534\n",
      "Epoch 8/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7283 - precision: 0.6648\n",
      "Epoch 8: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7287 - precision: 0.6647 - val_loss: 0.9294 - val_precision: 0.6507\n",
      "Epoch 9/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7131 - precision: 0.6707\n",
      "Epoch 9: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7116 - precision: 0.6714 - val_loss: 0.9552 - val_precision: 0.6381\n",
      "Epoch 10/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7007 - precision: 0.6755\n",
      "Epoch 10: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6990 - precision: 0.6764 - val_loss: 0.9420 - val_precision: 0.6491\n",
      "Epoch 11/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6802 - precision: 0.6862\n",
      "Epoch 11: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6808 - precision: 0.6859 - val_loss: 0.9701 - val_precision: 0.6363\n",
      "Epoch 12/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6779 - precision: 0.6785\n",
      "Epoch 12: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6772 - precision: 0.6791 - val_loss: 0.9565 - val_precision: 0.6416\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6591 - precision: 0.6913\n",
      "Epoch 13: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6598 - precision: 0.6906 - val_loss: 0.9820 - val_precision: 0.6383\n",
      "Epoch 14/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6475 - precision: 0.6941\n",
      "Epoch 14: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6474 - precision: 0.6935 - val_loss: 0.9888 - val_precision: 0.6266\n",
      "Epoch 15/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.6390 - precision: 0.6982\n",
      "Epoch 15: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6391 - precision: 0.6971 - val_loss: 0.9561 - val_precision: 0.6382\n",
      "Epoch 16/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6358 - precision: 0.6926\n",
      "Epoch 16: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6362 - precision: 0.6917 - val_loss: 0.9839 - val_precision: 0.6286\n",
      "Epoch 17/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6122 - precision: 0.6999\n",
      "Epoch 17: val_loss did not improve from 0.92837\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6142 - precision: 0.6994 - val_loss: 1.0547 - val_precision: 0.6228\n",
      "Epoch 17: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7564 - precision: 0.6961\n",
      "Combinación 82 = (False, False, True, 64, 0.25) \n",
      " precision train: [0.7564293742179871, 0.6961245536804199]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 84: \n",
      "\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 1.2916 - precision: 0.6307\n",
      "Epoch 1: val_loss improved from inf to 1.02673, saving model to model_84.h5\n",
      "240/240 [==============================] - 5s 8ms/step - loss: 1.2787 - precision: 0.6295 - val_loss: 1.0267 - val_precision: 0.6467\n",
      "Epoch 2/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9601 - precision: 0.6228\n",
      "Epoch 2: val_loss improved from 1.02673 to 0.99567, saving model to model_84.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9595 - precision: 0.6220 - val_loss: 0.9957 - val_precision: 0.6401\n",
      "Epoch 3/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.9077 - precision: 0.6285\n",
      "Epoch 3: val_loss improved from 0.99567 to 0.99103, saving model to model_84.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9110 - precision: 0.6258 - val_loss: 0.9910 - val_precision: 0.6300\n",
      "Epoch 4/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8874 - precision: 0.6315\n",
      "Epoch 4: val_loss improved from 0.99103 to 0.95816, saving model to model_84.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8851 - precision: 0.6319 - val_loss: 0.9582 - val_precision: 0.6411\n",
      "Epoch 5/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8662 - precision: 0.6311\n",
      "Epoch 5: val_loss improved from 0.95816 to 0.94393, saving model to model_84.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.8663 - precision: 0.6311 - val_loss: 0.9439 - val_precision: 0.6439\n",
      "Epoch 6/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8533 - precision: 0.6428\n",
      "Epoch 6: val_loss did not improve from 0.94393\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8527 - precision: 0.6430 - val_loss: 0.9521 - val_precision: 0.6367\n",
      "Epoch 7/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8190 - precision: 0.6451\n",
      "Epoch 7: val_loss did not improve from 0.94393\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8160 - precision: 0.6456 - val_loss: 0.9655 - val_precision: 0.6367\n",
      "Epoch 8/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8126 - precision: 0.6553\n",
      "Epoch 8: val_loss did not improve from 0.94393\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8124 - precision: 0.6548 - val_loss: 0.9797 - val_precision: 0.6377\n",
      "Epoch 9/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8031 - precision: 0.6539\n",
      "Epoch 9: val_loss did not improve from 0.94393\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8027 - precision: 0.6545 - val_loss: 0.9568 - val_precision: 0.6358\n",
      "Epoch 10/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7872 - precision: 0.6563\n",
      "Epoch 10: val_loss improved from 0.94393 to 0.94273, saving model to model_84.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7851 - precision: 0.6580 - val_loss: 0.9427 - val_precision: 0.6431\n",
      "Epoch 11/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7888 - precision: 0.6542\n",
      "Epoch 11: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7849 - precision: 0.6570 - val_loss: 0.9466 - val_precision: 0.6484\n",
      "Epoch 12/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7589 - precision: 0.6665\n",
      "Epoch 12: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7608 - precision: 0.6665 - val_loss: 0.9562 - val_precision: 0.6394\n",
      "Epoch 13/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7525 - precision: 0.6708\n",
      "Epoch 13: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7516 - precision: 0.6712 - val_loss: 0.9525 - val_precision: 0.6374\n",
      "Epoch 14/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7492 - precision: 0.6722\n",
      "Epoch 14: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7522 - precision: 0.6691 - val_loss: 0.9537 - val_precision: 0.6405\n",
      "Epoch 15/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7401 - precision: 0.6722\n",
      "Epoch 15: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7416 - precision: 0.6710 - val_loss: 0.9452 - val_precision: 0.6439\n",
      "Epoch 16/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7314 - precision: 0.6739\n",
      "Epoch 16: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7329 - precision: 0.6736 - val_loss: 0.9664 - val_precision: 0.6401\n",
      "Epoch 17/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7239 - precision: 0.6757\n",
      "Epoch 17: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7258 - precision: 0.6763 - val_loss: 0.9675 - val_precision: 0.6429\n",
      "Epoch 18/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7235 - precision: 0.6750\n",
      "Epoch 18: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7236 - precision: 0.6743 - val_loss: 0.9532 - val_precision: 0.6406\n",
      "Epoch 19/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7149 - precision: 0.6747\n",
      "Epoch 19: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7143 - precision: 0.6754 - val_loss: 0.9749 - val_precision: 0.6359\n",
      "Epoch 20/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.6992 - precision: 0.6830\n",
      "Epoch 20: val_loss did not improve from 0.94273\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7016 - precision: 0.6815 - val_loss: 0.9824 - val_precision: 0.6260\n",
      "Epoch 20: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7966 - precision: 0.6787\n",
      "Combinación 83 = (False, False, True, 64, 0.5) \n",
      " precision train: [0.7966348528862, 0.678726315498352]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 85: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.4423 - precision: 0.6893   \n",
      "Epoch 1: val_loss improved from inf to 1.22596, saving model to model_85.h5\n",
      "240/240 [==============================] - 10s 6ms/step - loss: 1.4298 - precision: 0.6541 - val_loss: 1.2260 - val_precision: 0.6977\n",
      "Epoch 2/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.0614 - precision: 0.6339\n",
      "Epoch 2: val_loss improved from 1.22596 to 1.06800, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0571 - precision: 0.6336 - val_loss: 1.0680 - val_precision: 0.6541\n",
      "Epoch 3/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.9552 - precision: 0.6261\n",
      "Epoch 3: val_loss improved from 1.06800 to 1.01398, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.9557 - precision: 0.6258 - val_loss: 1.0140 - val_precision: 0.6531\n",
      "Epoch 4/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.9114 - precision: 0.6370\n",
      "Epoch 4: val_loss improved from 1.01398 to 0.98489, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9126 - precision: 0.6369 - val_loss: 0.9849 - val_precision: 0.6456\n",
      "Epoch 5/70\n",
      "212/240 [=========================>....] - ETA: 0s - loss: 0.8885 - precision: 0.6389\n",
      "Epoch 5: val_loss improved from 0.98489 to 0.96825, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8874 - precision: 0.6375 - val_loss: 0.9682 - val_precision: 0.6513\n",
      "Epoch 6/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8807 - precision: 0.6384\n",
      "Epoch 6: val_loss did not improve from 0.96825\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8779 - precision: 0.6400 - val_loss: 0.9753 - val_precision: 0.6393\n",
      "Epoch 7/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8557 - precision: 0.6461\n",
      "Epoch 7: val_loss improved from 0.96825 to 0.96661, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8554 - precision: 0.6442 - val_loss: 0.9666 - val_precision: 0.6515\n",
      "Epoch 8/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8426 - precision: 0.6519\n",
      "Epoch 8: val_loss improved from 0.96661 to 0.96069, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8422 - precision: 0.6519 - val_loss: 0.9607 - val_precision: 0.6462\n",
      "Epoch 9/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8274 - precision: 0.6587\n",
      "Epoch 9: val_loss improved from 0.96069 to 0.95616, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8261 - precision: 0.6587 - val_loss: 0.9562 - val_precision: 0.6453\n",
      "Epoch 10/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8215 - precision: 0.6588\n",
      "Epoch 10: val_loss did not improve from 0.95616\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8209 - precision: 0.6604 - val_loss: 0.9563 - val_precision: 0.6519\n",
      "Epoch 11/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8104 - precision: 0.6647\n",
      "Epoch 11: val_loss improved from 0.95616 to 0.94472, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8112 - precision: 0.6652 - val_loss: 0.9447 - val_precision: 0.6458\n",
      "Epoch 12/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7917 - precision: 0.6739\n",
      "Epoch 12: val_loss did not improve from 0.94472\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7956 - precision: 0.6714 - val_loss: 0.9552 - val_precision: 0.6439\n",
      "Epoch 13/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7959 - precision: 0.6626\n",
      "Epoch 13: val_loss did not improve from 0.94472\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7963 - precision: 0.6632 - val_loss: 0.9545 - val_precision: 0.6453\n",
      "Epoch 14/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7834 - precision: 0.6714\n",
      "Epoch 14: val_loss did not improve from 0.94472\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7875 - precision: 0.6700 - val_loss: 0.9615 - val_precision: 0.6470\n",
      "Epoch 15/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7756 - precision: 0.6732\n",
      "Epoch 15: val_loss did not improve from 0.94472\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7770 - precision: 0.6727 - val_loss: 0.9647 - val_precision: 0.6458\n",
      "Epoch 16/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7643 - precision: 0.6819\n",
      "Epoch 16: val_loss did not improve from 0.94472\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7634 - precision: 0.6832 - val_loss: 0.9491 - val_precision: 0.6498\n",
      "Epoch 17/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7637 - precision: 0.6825\n",
      "Epoch 17: val_loss improved from 0.94472 to 0.94034, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7554 - precision: 0.6865 - val_loss: 0.9403 - val_precision: 0.6455\n",
      "Epoch 18/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7538 - precision: 0.6810\n",
      "Epoch 18: val_loss did not improve from 0.94034\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7538 - precision: 0.6801 - val_loss: 0.9503 - val_precision: 0.6433\n",
      "Epoch 19/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.7484 - precision: 0.6825\n",
      "Epoch 19: val_loss did not improve from 0.94034\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7484 - precision: 0.6825 - val_loss: 0.9410 - val_precision: 0.6396\n",
      "Epoch 20/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7330 - precision: 0.6920\n",
      "Epoch 20: val_loss improved from 0.94034 to 0.93329, saving model to model_85.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7361 - precision: 0.6918 - val_loss: 0.9333 - val_precision: 0.6447\n",
      "Epoch 21/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7199 - precision: 0.6952\n",
      "Epoch 21: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7226 - precision: 0.6939 - val_loss: 0.9606 - val_precision: 0.6371\n",
      "Epoch 22/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.7157 - precision: 0.6984\n",
      "Epoch 22: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7159 - precision: 0.6951 - val_loss: 0.9562 - val_precision: 0.6389\n",
      "Epoch 23/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7149 - precision: 0.6949\n",
      "Epoch 23: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7158 - precision: 0.6954 - val_loss: 0.9610 - val_precision: 0.6344\n",
      "Epoch 24/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.7059 - precision: 0.6979\n",
      "Epoch 24: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7085 - precision: 0.6984 - val_loss: 0.9754 - val_precision: 0.6320\n",
      "Epoch 25/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.6989 - precision: 0.6982\n",
      "Epoch 25: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7009 - precision: 0.6976 - val_loss: 0.9684 - val_precision: 0.6370\n",
      "Epoch 26/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6933 - precision: 0.7015\n",
      "Epoch 26: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6915 - precision: 0.7020 - val_loss: 0.9533 - val_precision: 0.6345\n",
      "Epoch 27/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6842 - precision: 0.7083\n",
      "Epoch 27: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6844 - precision: 0.7062 - val_loss: 0.9581 - val_precision: 0.6335\n",
      "Epoch 28/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6897 - precision: 0.7015\n",
      "Epoch 28: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6892 - precision: 0.7016 - val_loss: 0.9679 - val_precision: 0.6281\n",
      "Epoch 29/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6806 - precision: 0.7056\n",
      "Epoch 29: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6801 - precision: 0.7068 - val_loss: 0.9606 - val_precision: 0.6319\n",
      "Epoch 30/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.6676 - precision: 0.7121\n",
      "Epoch 30: val_loss did not improve from 0.93329\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6674 - precision: 0.7129 - val_loss: 0.9887 - val_precision: 0.6245\n",
      "Epoch 30: early stopping\n",
      "300/300 [==============================] - 0s 1000us/step - loss: 0.7722 - precision: 0.7057\n",
      "Combinación 84 = (False, False, False, 8, 0.1) \n",
      " precision train: [0.7722482085227966, 0.7056552171707153]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 86: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.4514 - precision: 0.7922 \n",
      "Epoch 1: val_loss improved from inf to 1.22411, saving model to model_86.h5\n",
      "240/240 [==============================] - 4s 5ms/step - loss: 1.4379 - precision: 0.7817 - val_loss: 1.2241 - val_precision: 0.7607\n",
      "Epoch 2/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1257 - precision: 0.6686\n",
      "Epoch 2: val_loss improved from 1.22411 to 1.09273, saving model to model_86.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1243 - precision: 0.6656 - val_loss: 1.0927 - val_precision: 0.6787\n",
      "Epoch 3/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 1.0233 - precision: 0.6317\n",
      "Epoch 3: val_loss improved from 1.09273 to 1.05182, saving model to model_86.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0234 - precision: 0.6333 - val_loss: 1.0518 - val_precision: 0.6505\n",
      "Epoch 4/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9880 - precision: 0.6338\n",
      "Epoch 4: val_loss improved from 1.05182 to 1.02976, saving model to model_86.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9887 - precision: 0.6328 - val_loss: 1.0298 - val_precision: 0.6467\n",
      "Epoch 5/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9703 - precision: 0.6369\n",
      "Epoch 5: val_loss improved from 1.02976 to 1.02491, saving model to model_86.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9690 - precision: 0.6379 - val_loss: 1.0249 - val_precision: 0.6395\n",
      "Epoch 6/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9581 - precision: 0.6297\n",
      "Epoch 6: val_loss improved from 1.02491 to 1.01620, saving model to model_86.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9586 - precision: 0.6292 - val_loss: 1.0162 - val_precision: 0.6389\n",
      "Epoch 7/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9361 - precision: 0.6282\n",
      "Epoch 7: val_loss improved from 1.01620 to 0.99439, saving model to model_86.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9365 - precision: 0.6283 - val_loss: 0.9944 - val_precision: 0.6479\n",
      "Epoch 8/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9221 - precision: 0.6352\n",
      "Epoch 8: val_loss improved from 0.99439 to 0.99059, saving model to model_86.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9234 - precision: 0.6349 - val_loss: 0.9906 - val_precision: 0.6483\n",
      "Epoch 9/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9227 - precision: 0.6418\n",
      "Epoch 9: val_loss improved from 0.99059 to 0.98768, saving model to model_86.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9222 - precision: 0.6412 - val_loss: 0.9877 - val_precision: 0.6453\n",
      "Epoch 10/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9112 - precision: 0.6422\n",
      "Epoch 10: val_loss did not improve from 0.98768\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9118 - precision: 0.6416 - val_loss: 0.9999 - val_precision: 0.6390\n",
      "Epoch 11/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8943 - precision: 0.6377\n",
      "Epoch 11: val_loss did not improve from 0.98768\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8975 - precision: 0.6365 - val_loss: 0.9927 - val_precision: 0.6385\n",
      "Epoch 12/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.8952 - precision: 0.6424\n",
      "Epoch 12: val_loss did not improve from 0.98768\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8957 - precision: 0.6423 - val_loss: 1.0003 - val_precision: 0.6348\n",
      "Epoch 13/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8819 - precision: 0.6505\n",
      "Epoch 13: val_loss did not improve from 0.98768\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8805 - precision: 0.6503 - val_loss: 0.9979 - val_precision: 0.6347\n",
      "Epoch 14/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8885 - precision: 0.6455\n",
      "Epoch 14: val_loss improved from 0.98768 to 0.98012, saving model to model_86.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8861 - precision: 0.6446 - val_loss: 0.9801 - val_precision: 0.6426\n",
      "Epoch 15/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8699 - precision: 0.6538\n",
      "Epoch 15: val_loss did not improve from 0.98012\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8744 - precision: 0.6539 - val_loss: 0.9871 - val_precision: 0.6362\n",
      "Epoch 16/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8584 - precision: 0.6533\n",
      "Epoch 16: val_loss did not improve from 0.98012\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8627 - precision: 0.6518 - val_loss: 0.9965 - val_precision: 0.6345\n",
      "Epoch 17/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.8617 - precision: 0.6523\n",
      "Epoch 17: val_loss did not improve from 0.98012\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8627 - precision: 0.6551 - val_loss: 1.0020 - val_precision: 0.6282\n",
      "Epoch 18/70\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 0.8584 - precision: 0.6552\n",
      "Epoch 18: val_loss did not improve from 0.98012\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8539 - precision: 0.6589 - val_loss: 0.9909 - val_precision: 0.6329\n",
      "Epoch 19/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8482 - precision: 0.6555\n",
      "Epoch 19: val_loss improved from 0.98012 to 0.96987, saving model to model_86.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8484 - precision: 0.6547 - val_loss: 0.9699 - val_precision: 0.6467\n",
      "Epoch 20/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8371 - precision: 0.6648\n",
      "Epoch 20: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8399 - precision: 0.6648 - val_loss: 0.9718 - val_precision: 0.6436\n",
      "Epoch 21/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8463 - precision: 0.6617\n",
      "Epoch 21: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8472 - precision: 0.6622 - val_loss: 0.9775 - val_precision: 0.6461\n",
      "Epoch 22/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.8318 - precision: 0.6677\n",
      "Epoch 22: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8354 - precision: 0.6622 - val_loss: 0.9766 - val_precision: 0.6443\n",
      "Epoch 23/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8210 - precision: 0.6689\n",
      "Epoch 23: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8222 - precision: 0.6683 - val_loss: 0.9884 - val_precision: 0.6382\n",
      "Epoch 24/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.8304 - precision: 0.6643\n",
      "Epoch 24: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8305 - precision: 0.6657 - val_loss: 0.9913 - val_precision: 0.6350\n",
      "Epoch 25/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8124 - precision: 0.6756\n",
      "Epoch 25: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8126 - precision: 0.6750 - val_loss: 0.9854 - val_precision: 0.6369\n",
      "Epoch 26/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8058 - precision: 0.6734\n",
      "Epoch 26: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8058 - precision: 0.6734 - val_loss: 1.0080 - val_precision: 0.6237\n",
      "Epoch 27/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.8137 - precision: 0.6694\n",
      "Epoch 27: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8142 - precision: 0.6690 - val_loss: 0.9776 - val_precision: 0.6365\n",
      "Epoch 28/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8110 - precision: 0.6682\n",
      "Epoch 28: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8110 - precision: 0.6682 - val_loss: 0.9780 - val_precision: 0.6405\n",
      "Epoch 29/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8090 - precision: 0.6763\n",
      "Epoch 29: val_loss did not improve from 0.96987\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8080 - precision: 0.6761 - val_loss: 0.9912 - val_precision: 0.6387\n",
      "Epoch 29: early stopping\n",
      "300/300 [==============================] - 0s 980us/step - loss: 0.8458 - precision: 0.6890\n",
      "Combinación 85 = (False, False, False, 8, 0.25) \n",
      " precision train: [0.8457650542259216, 0.6889753937721252]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 87: \n",
      "\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.5471 - precision: 0.6364  \n",
      "Epoch 1: val_loss improved from inf to 1.40301, saving model to model_87.h5\n",
      "240/240 [==============================] - 4s 7ms/step - loss: 1.5406 - precision: 0.5185 - val_loss: 1.4030 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.3385 - precision: 0.6027\n",
      "Epoch 2: val_loss improved from 1.40301 to 1.21827, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.3338 - precision: 0.6060 - val_loss: 1.2183 - val_precision: 0.6692\n",
      "Epoch 3/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.2366 - precision: 0.6144\n",
      "Epoch 3: val_loss improved from 1.21827 to 1.13978, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.2356 - precision: 0.6094 - val_loss: 1.1398 - val_precision: 0.6909\n",
      "Epoch 4/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.1907 - precision: 0.5927\n",
      "Epoch 4: val_loss improved from 1.13978 to 1.08507, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1897 - precision: 0.5928 - val_loss: 1.0851 - val_precision: 0.6729\n",
      "Epoch 5/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1475 - precision: 0.6080\n",
      "Epoch 5: val_loss improved from 1.08507 to 1.06498, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1475 - precision: 0.6080 - val_loss: 1.0650 - val_precision: 0.6693\n",
      "Epoch 6/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1400 - precision: 0.6031\n",
      "Epoch 6: val_loss improved from 1.06498 to 1.05322, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1410 - precision: 0.6014 - val_loss: 1.0532 - val_precision: 0.6620\n",
      "Epoch 7/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.1263 - precision: 0.6028\n",
      "Epoch 7: val_loss improved from 1.05322 to 1.03576, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1273 - precision: 0.6012 - val_loss: 1.0358 - val_precision: 0.6600\n",
      "Epoch 8/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.1181 - precision: 0.6068\n",
      "Epoch 8: val_loss improved from 1.03576 to 1.02713, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.1214 - precision: 0.6049 - val_loss: 1.0271 - val_precision: 0.6538\n",
      "Epoch 9/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.0945 - precision: 0.6157\n",
      "Epoch 9: val_loss improved from 1.02713 to 1.01770, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0976 - precision: 0.6150 - val_loss: 1.0177 - val_precision: 0.6439\n",
      "Epoch 10/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1058 - precision: 0.6037\n",
      "Epoch 10: val_loss did not improve from 1.01770\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.1058 - precision: 0.6037 - val_loss: 1.0249 - val_precision: 0.6543\n",
      "Epoch 11/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0883 - precision: 0.6169\n",
      "Epoch 11: val_loss improved from 1.01770 to 1.01514, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0896 - precision: 0.6163 - val_loss: 1.0151 - val_precision: 0.6432\n",
      "Epoch 12/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0875 - precision: 0.6222\n",
      "Epoch 12: val_loss improved from 1.01514 to 1.00994, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0855 - precision: 0.6237 - val_loss: 1.0099 - val_precision: 0.6440\n",
      "Epoch 13/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0851 - precision: 0.6147\n",
      "Epoch 13: val_loss improved from 1.00994 to 1.00666, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0872 - precision: 0.6159 - val_loss: 1.0067 - val_precision: 0.6490\n",
      "Epoch 14/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.0736 - precision: 0.6294\n",
      "Epoch 14: val_loss did not improve from 1.00666\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0726 - precision: 0.6286 - val_loss: 1.0078 - val_precision: 0.6419\n",
      "Epoch 15/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 1.0695 - precision: 0.6217\n",
      "Epoch 15: val_loss improved from 1.00666 to 1.00623, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0687 - precision: 0.6217 - val_loss: 1.0062 - val_precision: 0.6537\n",
      "Epoch 16/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 1.0746 - precision: 0.6242\n",
      "Epoch 16: val_loss improved from 1.00623 to 1.00345, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0777 - precision: 0.6223 - val_loss: 1.0034 - val_precision: 0.6454\n",
      "Epoch 17/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0633 - precision: 0.6320\n",
      "Epoch 17: val_loss improved from 1.00345 to 0.99827, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0639 - precision: 0.6309 - val_loss: 0.9983 - val_precision: 0.6442\n",
      "Epoch 18/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.0567 - precision: 0.6254\n",
      "Epoch 18: val_loss improved from 0.99827 to 0.99059, saving model to model_87.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0586 - precision: 0.6253 - val_loss: 0.9906 - val_precision: 0.6587\n",
      "Epoch 19/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.0501 - precision: 0.6280\n",
      "Epoch 19: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0509 - precision: 0.6272 - val_loss: 1.0077 - val_precision: 0.6478\n",
      "Epoch 20/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0550 - precision: 0.6312\n",
      "Epoch 20: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0553 - precision: 0.6314 - val_loss: 1.0091 - val_precision: 0.6486\n",
      "Epoch 21/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.0453 - precision: 0.6439\n",
      "Epoch 21: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0471 - precision: 0.6407 - val_loss: 1.0026 - val_precision: 0.6485\n",
      "Epoch 22/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 1.0440 - precision: 0.6362\n",
      "Epoch 22: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0436 - precision: 0.6368 - val_loss: 1.0009 - val_precision: 0.6484\n",
      "Epoch 23/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 1.0404 - precision: 0.6324\n",
      "Epoch 23: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0406 - precision: 0.6331 - val_loss: 1.0033 - val_precision: 0.6531\n",
      "Epoch 24/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 1.0334 - precision: 0.6392\n",
      "Epoch 24: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0330 - precision: 0.6384 - val_loss: 1.0039 - val_precision: 0.6479\n",
      "Epoch 25/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 1.0351 - precision: 0.6332\n",
      "Epoch 25: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0363 - precision: 0.6337 - val_loss: 0.9972 - val_precision: 0.6446\n",
      "Epoch 26/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 1.0303 - precision: 0.6314\n",
      "Epoch 26: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.0314 - precision: 0.6327 - val_loss: 0.9919 - val_precision: 0.6455\n",
      "Epoch 27/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.0314 - precision: 0.6354\n",
      "Epoch 27: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0279 - precision: 0.6359 - val_loss: 0.9994 - val_precision: 0.6439\n",
      "Epoch 28/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.0306 - precision: 0.6447\n",
      "Epoch 28: val_loss did not improve from 0.99059\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.0309 - precision: 0.6464 - val_loss: 0.9947 - val_precision: 0.6471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9303 - precision: 0.6705\n",
      "Combinación 86 = (False, False, False, 8, 0.5) \n",
      " precision train: [0.9303359985351562, 0.6705323457717896]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 88: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 1.3022 - precision: 0.6637\n",
      "Epoch 1: val_loss improved from inf to 1.07587, saving model to model_88.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.2830 - precision: 0.6622 - val_loss: 1.0759 - val_precision: 0.6543\n",
      "Epoch 2/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9322 - precision: 0.6347\n",
      "Epoch 2: val_loss improved from 1.07587 to 1.02345, saving model to model_88.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9329 - precision: 0.6324 - val_loss: 1.0234 - val_precision: 0.6340\n",
      "Epoch 3/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8705 - precision: 0.6398\n",
      "Epoch 3: val_loss improved from 1.02345 to 0.95940, saving model to model_88.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8696 - precision: 0.6404 - val_loss: 0.9594 - val_precision: 0.6567\n",
      "Epoch 4/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8364 - precision: 0.6519\n",
      "Epoch 4: val_loss did not improve from 0.95940\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8352 - precision: 0.6519 - val_loss: 0.9610 - val_precision: 0.6507\n",
      "Epoch 5/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8122 - precision: 0.6577\n",
      "Epoch 5: val_loss improved from 0.95940 to 0.93910, saving model to model_88.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8126 - precision: 0.6573 - val_loss: 0.9391 - val_precision: 0.6492\n",
      "Epoch 6/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7813 - precision: 0.6673\n",
      "Epoch 6: val_loss did not improve from 0.93910\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7817 - precision: 0.6673 - val_loss: 0.9513 - val_precision: 0.6433\n",
      "Epoch 7/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.7692 - precision: 0.6672\n",
      "Epoch 7: val_loss did not improve from 0.93910\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7721 - precision: 0.6655 - val_loss: 0.9418 - val_precision: 0.6456\n",
      "Epoch 8/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7544 - precision: 0.6692\n",
      "Epoch 8: val_loss did not improve from 0.93910\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7543 - precision: 0.6690 - val_loss: 0.9569 - val_precision: 0.6430\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7408 - precision: 0.6770\n",
      "Epoch 9: val_loss improved from 0.93910 to 0.93225, saving model to model_88.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7398 - precision: 0.6779 - val_loss: 0.9322 - val_precision: 0.6487\n",
      "Epoch 10/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 0.7249 - precision: 0.6819\n",
      "Epoch 10: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7281 - precision: 0.6807 - val_loss: 0.9425 - val_precision: 0.6494\n",
      "Epoch 11/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7144 - precision: 0.6849\n",
      "Epoch 11: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7146 - precision: 0.6846 - val_loss: 0.9418 - val_precision: 0.6429\n",
      "Epoch 12/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7122 - precision: 0.6822\n",
      "Epoch 12: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7116 - precision: 0.6806 - val_loss: 0.9325 - val_precision: 0.6462\n",
      "Epoch 13/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.6898 - precision: 0.6881\n",
      "Epoch 13: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6927 - precision: 0.6885 - val_loss: 0.9555 - val_precision: 0.6435\n",
      "Epoch 14/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6824 - precision: 0.6904\n",
      "Epoch 14: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6843 - precision: 0.6886 - val_loss: 0.9558 - val_precision: 0.6356\n",
      "Epoch 15/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6803 - precision: 0.6933\n",
      "Epoch 15: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6785 - precision: 0.6929 - val_loss: 0.9487 - val_precision: 0.6426\n",
      "Epoch 16/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.6710 - precision: 0.6893\n",
      "Epoch 16: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6699 - precision: 0.6910 - val_loss: 1.0056 - val_precision: 0.6244\n",
      "Epoch 17/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.6596 - precision: 0.6988\n",
      "Epoch 17: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6596 - precision: 0.6977 - val_loss: 0.9742 - val_precision: 0.6297\n",
      "Epoch 18/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.6542 - precision: 0.6960\n",
      "Epoch 18: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6577 - precision: 0.6978 - val_loss: 0.9829 - val_precision: 0.6371\n",
      "Epoch 19/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.6462 - precision: 0.7003\n",
      "Epoch 19: val_loss did not improve from 0.93225\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6461 - precision: 0.7000 - val_loss: 0.9556 - val_precision: 0.6399\n",
      "Epoch 19: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7402 - precision: 0.7074\n",
      "Combinación 87 = (False, False, False, 16, 0.1) \n",
      " precision train: [0.7401946187019348, 0.7074040174484253]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 89: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 1.3378 - precision: 0.6883\n",
      "Epoch 1: val_loss improved from inf to 1.07416, saving model to model_89.h5\n",
      "240/240 [==============================] - 4s 7ms/step - loss: 1.3239 - precision: 0.6824 - val_loss: 1.0742 - val_precision: 0.6714\n",
      "Epoch 2/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.9814 - precision: 0.6452\n",
      "Epoch 2: val_loss improved from 1.07416 to 1.01553, saving model to model_89.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9806 - precision: 0.6449 - val_loss: 1.0155 - val_precision: 0.6587\n",
      "Epoch 3/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9240 - precision: 0.6434\n",
      "Epoch 3: val_loss improved from 1.01553 to 1.00176, saving model to model_89.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9218 - precision: 0.6455 - val_loss: 1.0018 - val_precision: 0.6560\n",
      "Epoch 4/70\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 0.8993 - precision: 0.6501\n",
      "Epoch 4: val_loss improved from 1.00176 to 0.97027, saving model to model_89.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8969 - precision: 0.6503 - val_loss: 0.9703 - val_precision: 0.6626\n",
      "Epoch 5/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.8669 - precision: 0.6585\n",
      "Epoch 5: val_loss improved from 0.97027 to 0.96452, saving model to model_89.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8682 - precision: 0.6604 - val_loss: 0.9645 - val_precision: 0.6569\n",
      "Epoch 6/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.8641 - precision: 0.6632\n",
      "Epoch 6: val_loss improved from 0.96452 to 0.94362, saving model to model_89.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8595 - precision: 0.6649 - val_loss: 0.9436 - val_precision: 0.6605\n",
      "Epoch 7/70\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 0.8360 - precision: 0.6708\n",
      "Epoch 7: val_loss did not improve from 0.94362\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8398 - precision: 0.6678 - val_loss: 0.9527 - val_precision: 0.6578\n",
      "Epoch 8/70\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 0.8306 - precision: 0.6622\n",
      "Epoch 8: val_loss did not improve from 0.94362\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8286 - precision: 0.6621 - val_loss: 0.9470 - val_precision: 0.6608\n",
      "Epoch 9/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.8051 - precision: 0.6716\n",
      "Epoch 9: val_loss did not improve from 0.94362\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8081 - precision: 0.6725 - val_loss: 0.9450 - val_precision: 0.6609\n",
      "Epoch 10/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.7995 - precision: 0.6709\n",
      "Epoch 10: val_loss improved from 0.94362 to 0.94345, saving model to model_89.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7991 - precision: 0.6708 - val_loss: 0.9435 - val_precision: 0.6598\n",
      "Epoch 11/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.8002 - precision: 0.6737\n",
      "Epoch 11: val_loss did not improve from 0.94345\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7966 - precision: 0.6757 - val_loss: 0.9441 - val_precision: 0.6570\n",
      "Epoch 12/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7856 - precision: 0.6803\n",
      "Epoch 12: val_loss did not improve from 0.94345\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7851 - precision: 0.6805 - val_loss: 0.9570 - val_precision: 0.6519\n",
      "Epoch 13/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7791 - precision: 0.6777\n",
      "Epoch 13: val_loss improved from 0.94345 to 0.93092, saving model to model_89.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7784 - precision: 0.6778 - val_loss: 0.9309 - val_precision: 0.6602\n",
      "Epoch 14/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7590 - precision: 0.6906\n",
      "Epoch 14: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7633 - precision: 0.6875 - val_loss: 0.9406 - val_precision: 0.6530\n",
      "Epoch 15/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.7538 - precision: 0.6846\n",
      "Epoch 15: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7570 - precision: 0.6825 - val_loss: 0.9448 - val_precision: 0.6510\n",
      "Epoch 16/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.7525 - precision: 0.6862\n",
      "Epoch 16: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7502 - precision: 0.6872 - val_loss: 0.9527 - val_precision: 0.6497\n",
      "Epoch 17/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.7418 - precision: 0.6870\n",
      "Epoch 17: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7400 - precision: 0.6874 - val_loss: 0.9481 - val_precision: 0.6477\n",
      "Epoch 18/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.7251 - precision: 0.6923\n",
      "Epoch 18: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7279 - precision: 0.6910 - val_loss: 0.9372 - val_precision: 0.6521\n",
      "Epoch 19/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7256 - precision: 0.6959\n",
      "Epoch 19: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7263 - precision: 0.6984 - val_loss: 0.9900 - val_precision: 0.6355\n",
      "Epoch 20/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.7177 - precision: 0.6906\n",
      "Epoch 20: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7205 - precision: 0.6924 - val_loss: 0.9736 - val_precision: 0.6395\n",
      "Epoch 21/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7207 - precision: 0.6959\n",
      "Epoch 21: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7191 - precision: 0.6959 - val_loss: 0.9393 - val_precision: 0.6496\n",
      "Epoch 22/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7171 - precision: 0.6975\n",
      "Epoch 22: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7173 - precision: 0.6963 - val_loss: 0.9567 - val_precision: 0.6389\n",
      "Epoch 23/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7000 - precision: 0.6960\n",
      "Epoch 23: val_loss did not improve from 0.93092\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7059 - precision: 0.6941 - val_loss: 0.9816 - val_precision: 0.6342\n",
      "Epoch 23: early stopping\n",
      "300/300 [==============================] - 0s 974us/step - loss: 0.7849 - precision: 0.6947\n",
      "Combinación 88 = (False, False, False, 16, 0.25) \n",
      " precision train: [0.7849428653717041, 0.6946994066238403]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 90: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 1.4594 - precision: 0.7147 \n",
      "Epoch 1: val_loss improved from inf to 1.18176, saving model to model_90.h5\n",
      "240/240 [==============================] - 4s 5ms/step - loss: 1.4541 - precision: 0.7008 - val_loss: 1.1818 - val_precision: 0.7512\n",
      "Epoch 2/70\n",
      "212/240 [=========================>....] - ETA: 0s - loss: 1.1292 - precision: 0.6633\n",
      "Epoch 2: val_loss improved from 1.18176 to 1.05379, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 1.1256 - precision: 0.6553 - val_loss: 1.0538 - val_precision: 0.6691\n",
      "Epoch 3/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.0510 - precision: 0.6190\n",
      "Epoch 3: val_loss improved from 1.05379 to 1.03013, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 1.0496 - precision: 0.6197 - val_loss: 1.0301 - val_precision: 0.6560\n",
      "Epoch 4/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 1.0177 - precision: 0.6282\n",
      "Epoch 4: val_loss improved from 1.03013 to 1.02201, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 1.0104 - precision: 0.6311 - val_loss: 1.0220 - val_precision: 0.6449\n",
      "Epoch 5/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 1.0033 - precision: 0.6263\n",
      "Epoch 5: val_loss improved from 1.02201 to 0.99912, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 1.0005 - precision: 0.6281 - val_loss: 0.9991 - val_precision: 0.6539\n",
      "Epoch 6/70\n",
      "212/240 [=========================>....] - ETA: 0s - loss: 0.9781 - precision: 0.6364\n",
      "Epoch 6: val_loss improved from 0.99912 to 0.99772, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9832 - precision: 0.6307 - val_loss: 0.9977 - val_precision: 0.6468\n",
      "Epoch 7/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.9747 - precision: 0.6347\n",
      "Epoch 7: val_loss improved from 0.99772 to 0.99695, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9704 - precision: 0.6371 - val_loss: 0.9970 - val_precision: 0.6412\n",
      "Epoch 8/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.9747 - precision: 0.6363\n",
      "Epoch 8: val_loss did not improve from 0.99695\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9743 - precision: 0.6359 - val_loss: 0.9991 - val_precision: 0.6380\n",
      "Epoch 9/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/240 [==========================>...] - ETA: 0s - loss: 0.9460 - precision: 0.6371\n",
      "Epoch 9: val_loss improved from 0.99695 to 0.98661, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9470 - precision: 0.6370 - val_loss: 0.9866 - val_precision: 0.6444\n",
      "Epoch 10/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.9433 - precision: 0.6404\n",
      "Epoch 10: val_loss improved from 0.98661 to 0.98555, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9457 - precision: 0.6379 - val_loss: 0.9855 - val_precision: 0.6411\n",
      "Epoch 11/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.9404 - precision: 0.6405\n",
      "Epoch 11: val_loss improved from 0.98555 to 0.98386, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9376 - precision: 0.6423 - val_loss: 0.9839 - val_precision: 0.6413\n",
      "Epoch 12/70\n",
      "213/240 [=========================>....] - ETA: 0s - loss: 0.9404 - precision: 0.6422\n",
      "Epoch 12: val_loss did not improve from 0.98386\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9357 - precision: 0.6454 - val_loss: 0.9880 - val_precision: 0.6362\n",
      "Epoch 13/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9225 - precision: 0.6443\n",
      "Epoch 13: val_loss did not improve from 0.98386\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9226 - precision: 0.6453 - val_loss: 0.9894 - val_precision: 0.6367\n",
      "Epoch 14/70\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 0.9165 - precision: 0.6478\n",
      "Epoch 14: val_loss did not improve from 0.98386\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9218 - precision: 0.6472 - val_loss: 0.9978 - val_precision: 0.6327\n",
      "Epoch 15/70\n",
      "212/240 [=========================>....] - ETA: 0s - loss: 0.9120 - precision: 0.6464\n",
      "Epoch 15: val_loss improved from 0.98386 to 0.97983, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9161 - precision: 0.6458 - val_loss: 0.9798 - val_precision: 0.6363\n",
      "Epoch 16/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.9163 - precision: 0.6448\n",
      "Epoch 16: val_loss improved from 0.97983 to 0.97304, saving model to model_90.h5\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.9173 - precision: 0.6446 - val_loss: 0.9730 - val_precision: 0.6395\n",
      "Epoch 17/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.9023 - precision: 0.6514\n",
      "Epoch 17: val_loss did not improve from 0.97304\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9040 - precision: 0.6523 - val_loss: 0.9821 - val_precision: 0.6332\n",
      "Epoch 18/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8983 - precision: 0.6477\n",
      "Epoch 18: val_loss did not improve from 0.97304\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8983 - precision: 0.6477 - val_loss: 0.9816 - val_precision: 0.6396\n",
      "Epoch 19/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8852 - precision: 0.6517\n",
      "Epoch 19: val_loss did not improve from 0.97304\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8852 - precision: 0.6517 - val_loss: 0.9786 - val_precision: 0.6430\n",
      "Epoch 20/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.8988 - precision: 0.6529\n",
      "Epoch 20: val_loss did not improve from 0.97304\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8962 - precision: 0.6573 - val_loss: 0.9967 - val_precision: 0.6290\n",
      "Epoch 21/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.8925 - precision: 0.6544\n",
      "Epoch 21: val_loss improved from 0.97304 to 0.97291, saving model to model_90.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8951 - precision: 0.6513 - val_loss: 0.9729 - val_precision: 0.6359\n",
      "Epoch 22/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8744 - precision: 0.6532\n",
      "Epoch 22: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8711 - precision: 0.6541 - val_loss: 0.9757 - val_precision: 0.6335\n",
      "Epoch 23/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.8917 - precision: 0.6540\n",
      "Epoch 23: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8903 - precision: 0.6540 - val_loss: 0.9847 - val_precision: 0.6367\n",
      "Epoch 24/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8726 - precision: 0.6597\n",
      "Epoch 24: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8707 - precision: 0.6595 - val_loss: 0.9981 - val_precision: 0.6281\n",
      "Epoch 25/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8702 - precision: 0.6615\n",
      "Epoch 25: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8711 - precision: 0.6604 - val_loss: 0.9901 - val_precision: 0.6248\n",
      "Epoch 26/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8538 - precision: 0.6670\n",
      "Epoch 26: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8546 - precision: 0.6675 - val_loss: 0.9944 - val_precision: 0.6317\n",
      "Epoch 27/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8498 - precision: 0.6688\n",
      "Epoch 27: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8509 - precision: 0.6685 - val_loss: 0.9838 - val_precision: 0.6373\n",
      "Epoch 28/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.8689 - precision: 0.6614\n",
      "Epoch 28: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8667 - precision: 0.6621 - val_loss: 0.9943 - val_precision: 0.6310\n",
      "Epoch 29/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8444 - precision: 0.6617\n",
      "Epoch 29: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8449 - precision: 0.6622 - val_loss: 0.9940 - val_precision: 0.6272\n",
      "Epoch 30/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8453 - precision: 0.6632\n",
      "Epoch 30: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8439 - precision: 0.6629 - val_loss: 0.9975 - val_precision: 0.6312\n",
      "Epoch 31/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8400 - precision: 0.6692\n",
      "Epoch 31: val_loss did not improve from 0.97291\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8356 - precision: 0.6721 - val_loss: 1.0091 - val_precision: 0.6222\n",
      "Epoch 31: early stopping\n",
      "300/300 [==============================] - 0s 982us/step - loss: 0.8734 - precision: 0.6641\n",
      "Combinación 89 = (False, False, False, 16, 0.5) \n",
      " precision train: [0.8733754754066467, 0.664053738117218]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 91: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 1.1788 - precision: 0.6413\n",
      "Epoch 1: val_loss improved from inf to 1.03090, saving model to model_91.h5\n",
      "240/240 [==============================] - 4s 5ms/step - loss: 1.1718 - precision: 0.6430 - val_loss: 1.0309 - val_precision: 0.6455\n",
      "Epoch 2/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.8746 - precision: 0.6409\n",
      "Epoch 2: val_loss improved from 1.03090 to 0.97413, saving model to model_91.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8732 - precision: 0.6412 - val_loss: 0.9741 - val_precision: 0.6516\n",
      "Epoch 3/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.8224 - precision: 0.6546\n",
      "Epoch 3: val_loss improved from 0.97413 to 0.94702, saving model to model_91.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8209 - precision: 0.6545 - val_loss: 0.9470 - val_precision: 0.6587\n",
      "Epoch 4/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.7875 - precision: 0.6634\n",
      "Epoch 4: val_loss improved from 0.94702 to 0.92386, saving model to model_91.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7871 - precision: 0.6630 - val_loss: 0.9239 - val_precision: 0.6595\n",
      "Epoch 5/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.7632 - precision: 0.6700\n",
      "Epoch 5: val_loss improved from 0.92386 to 0.90694, saving model to model_91.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7600 - precision: 0.6718 - val_loss: 0.9069 - val_precision: 0.6611\n",
      "Epoch 6/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7385 - precision: 0.6752\n",
      "Epoch 6: val_loss improved from 0.90694 to 0.89686, saving model to model_91.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7398 - precision: 0.6718 - val_loss: 0.8969 - val_precision: 0.6613\n",
      "Epoch 7/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.7189 - precision: 0.6774\n",
      "Epoch 7: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7192 - precision: 0.6766 - val_loss: 0.9227 - val_precision: 0.6491\n",
      "Epoch 8/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.7037 - precision: 0.6825\n",
      "Epoch 8: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7052 - precision: 0.6790 - val_loss: 0.9435 - val_precision: 0.6432\n",
      "Epoch 9/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.6914 - precision: 0.6846\n",
      "Epoch 9: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6954 - precision: 0.6823 - val_loss: 0.9411 - val_precision: 0.6414\n",
      "Epoch 10/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.6795 - precision: 0.6845\n",
      "Epoch 10: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6813 - precision: 0.6842 - val_loss: 0.9844 - val_precision: 0.6361\n",
      "Epoch 11/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.6651 - precision: 0.6898\n",
      "Epoch 11: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6687 - precision: 0.6882 - val_loss: 0.9241 - val_precision: 0.6469\n",
      "Epoch 12/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.6523 - precision: 0.6983\n",
      "Epoch 12: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6498 - precision: 0.6988 - val_loss: 0.9509 - val_precision: 0.6442\n",
      "Epoch 13/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.6426 - precision: 0.6977\n",
      "Epoch 13: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6441 - precision: 0.6988 - val_loss: 0.9597 - val_precision: 0.6376\n",
      "Epoch 14/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.6277 - precision: 0.7017\n",
      "Epoch 14: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6328 - precision: 0.6987 - val_loss: 0.9566 - val_precision: 0.6312\n",
      "Epoch 15/70\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 0.6244 - precision: 0.7092\n",
      "Epoch 15: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6269 - precision: 0.7069 - val_loss: 0.9720 - val_precision: 0.6304\n",
      "Epoch 16/70\n",
      "214/240 [=========================>....] - ETA: 0s - loss: 0.6226 - precision: 0.7032\n",
      "Epoch 16: val_loss did not improve from 0.89686\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6189 - precision: 0.7045 - val_loss: 0.9763 - val_precision: 0.6341\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7135 - precision: 0.7088\n",
      "Combinación 90 = (False, False, False, 32, 0.1) \n",
      " precision train: [0.7135452032089233, 0.7087605595588684]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 92: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 1.1954 - precision: 0.6518\n",
      "Epoch 1: val_loss improved from inf to 1.03945, saving model to model_92.h5\n",
      "240/240 [==============================] - 4s 5ms/step - loss: 1.1936 - precision: 0.6512 - val_loss: 1.0395 - val_precision: 0.6490\n",
      "Epoch 2/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.9061 - precision: 0.6402\n",
      "Epoch 2: val_loss improved from 1.03945 to 0.98845, saving model to model_92.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9074 - precision: 0.6415 - val_loss: 0.9885 - val_precision: 0.6538\n",
      "Epoch 3/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.8534 - precision: 0.6538\n",
      "Epoch 3: val_loss improved from 0.98845 to 0.95914, saving model to model_92.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8565 - precision: 0.6524 - val_loss: 0.9591 - val_precision: 0.6588\n",
      "Epoch 4/70\n",
      "212/240 [=========================>....] - ETA: 0s - loss: 0.8408 - precision: 0.6550\n",
      "Epoch 4: val_loss improved from 0.95914 to 0.95459, saving model to model_92.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8372 - precision: 0.6554 - val_loss: 0.9546 - val_precision: 0.6547\n",
      "Epoch 5/70\n",
      "228/240 [===========================>..] - ETA: 0s - loss: 0.8011 - precision: 0.6625\n",
      "Epoch 5: val_loss improved from 0.95459 to 0.92010, saving model to model_92.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7989 - precision: 0.6622 - val_loss: 0.9201 - val_precision: 0.6587\n",
      "Epoch 6/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.7904 - precision: 0.6692\n",
      "Epoch 6: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.7872 - precision: 0.6690 - val_loss: 0.9611 - val_precision: 0.6496\n",
      "Epoch 7/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7611 - precision: 0.6734\n",
      "Epoch 7: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.7607 - precision: 0.6730 - val_loss: 0.9303 - val_precision: 0.6547\n",
      "Epoch 8/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7550 - precision: 0.6753\n",
      "Epoch 8: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.7517 - precision: 0.6760 - val_loss: 0.9266 - val_precision: 0.6544\n",
      "Epoch 9/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7351 - precision: 0.6856\n",
      "Epoch 9: val_loss did not improve from 0.92010\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.7373 - precision: 0.6860 - val_loss: 0.9314 - val_precision: 0.6539\n",
      "Epoch 10/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.7348 - precision: 0.6800\n",
      "Epoch 10: val_loss improved from 0.92010 to 0.91759, saving model to model_92.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7295 - precision: 0.6816 - val_loss: 0.9176 - val_precision: 0.6536\n",
      "Epoch 11/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7233 - precision: 0.6756\n",
      "Epoch 11: val_loss did not improve from 0.91759\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.7199 - precision: 0.6761 - val_loss: 0.9463 - val_precision: 0.6469\n",
      "Epoch 12/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7056 - precision: 0.6894\n",
      "Epoch 12: val_loss did not improve from 0.91759\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7063 - precision: 0.6900 - val_loss: 0.9680 - val_precision: 0.6419\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6901 - precision: 0.6898\n",
      "Epoch 13: val_loss did not improve from 0.91759\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6898 - precision: 0.6907 - val_loss: 0.9589 - val_precision: 0.6431\n",
      "Epoch 14/70\n",
      "216/240 [==========================>...] - ETA: 0s - loss: 0.6915 - precision: 0.6933\n",
      "Epoch 14: val_loss did not improve from 0.91759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6885 - precision: 0.6914 - val_loss: 0.9555 - val_precision: 0.6389\n",
      "Epoch 15/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.6711 - precision: 0.6970\n",
      "Epoch 15: val_loss did not improve from 0.91759\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6747 - precision: 0.6966 - val_loss: 0.9324 - val_precision: 0.6441\n",
      "Epoch 16/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.6645 - precision: 0.7009\n",
      "Epoch 16: val_loss did not improve from 0.91759\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6674 - precision: 0.6994 - val_loss: 1.0055 - val_precision: 0.6245\n",
      "Epoch 17/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.6601 - precision: 0.6994\n",
      "Epoch 17: val_loss did not improve from 0.91759\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6593 - precision: 0.7008 - val_loss: 1.0183 - val_precision: 0.6317\n",
      "Epoch 18/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.6483 - precision: 0.7026\n",
      "Epoch 18: val_loss did not improve from 0.91759\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6470 - precision: 0.7036 - val_loss: 0.9888 - val_precision: 0.6341\n",
      "Epoch 19/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.6424 - precision: 0.7028\n",
      "Epoch 19: val_loss did not improve from 0.91759\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6439 - precision: 0.7026 - val_loss: 0.9651 - val_precision: 0.6398\n",
      "Epoch 20/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.6361 - precision: 0.7035\n",
      "Epoch 20: val_loss did not improve from 0.91759\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6385 - precision: 0.7016 - val_loss: 0.9692 - val_precision: 0.6352\n",
      "Epoch 20: early stopping\n",
      "300/300 [==============================] - 0s 955us/step - loss: 0.7334 - precision: 0.7083\n",
      "Combinación 91 = (False, False, False, 32, 0.25) \n",
      " precision train: [0.7333791851997375, 0.7083094716072083]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 93: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 1.3277 - precision: 0.6704\n",
      "Epoch 1: val_loss improved from inf to 1.06390, saving model to model_93.h5\n",
      "240/240 [==============================] - 4s 5ms/step - loss: 1.3144 - precision: 0.6643 - val_loss: 1.0639 - val_precision: 0.6667\n",
      "Epoch 2/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.9944 - precision: 0.6397\n",
      "Epoch 2: val_loss improved from 1.06390 to 1.02086, saving model to model_93.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9922 - precision: 0.6391 - val_loss: 1.0209 - val_precision: 0.6525\n",
      "Epoch 3/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.9533 - precision: 0.6438\n",
      "Epoch 3: val_loss improved from 1.02086 to 0.96980, saving model to model_93.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9528 - precision: 0.6415 - val_loss: 0.9698 - val_precision: 0.6595\n",
      "Epoch 4/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.9204 - precision: 0.6485\n",
      "Epoch 4: val_loss did not improve from 0.96980\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9197 - precision: 0.6494 - val_loss: 0.9898 - val_precision: 0.6454\n",
      "Epoch 5/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8983 - precision: 0.6514\n",
      "Epoch 5: val_loss improved from 0.96980 to 0.95773, saving model to model_93.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8983 - precision: 0.6514 - val_loss: 0.9577 - val_precision: 0.6547\n",
      "Epoch 6/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.8694 - precision: 0.6583\n",
      "Epoch 6: val_loss improved from 0.95773 to 0.95460, saving model to model_93.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8716 - precision: 0.6577 - val_loss: 0.9546 - val_precision: 0.6538\n",
      "Epoch 7/70\n",
      "227/240 [===========================>..] - ETA: 0s - loss: 0.8554 - precision: 0.6562\n",
      "Epoch 7: val_loss improved from 0.95460 to 0.94498, saving model to model_93.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8548 - precision: 0.6552 - val_loss: 0.9450 - val_precision: 0.6523\n",
      "Epoch 8/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.8433 - precision: 0.6570\n",
      "Epoch 8: val_loss did not improve from 0.94498\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8381 - precision: 0.6628 - val_loss: 0.9714 - val_precision: 0.6468\n",
      "Epoch 9/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.8386 - precision: 0.6640\n",
      "Epoch 9: val_loss did not improve from 0.94498\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.8364 - precision: 0.6657 - val_loss: 0.9530 - val_precision: 0.6499\n",
      "Epoch 10/70\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.8122 - precision: 0.6683\n",
      "Epoch 10: val_loss improved from 0.94498 to 0.93620, saving model to model_93.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8126 - precision: 0.6683 - val_loss: 0.9362 - val_precision: 0.6534\n",
      "Epoch 11/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.8133 - precision: 0.6728\n",
      "Epoch 11: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8141 - precision: 0.6710 - val_loss: 0.9599 - val_precision: 0.6451\n",
      "Epoch 12/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.8128 - precision: 0.6682\n",
      "Epoch 12: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8106 - precision: 0.6699 - val_loss: 0.9633 - val_precision: 0.6471\n",
      "Epoch 13/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7983 - precision: 0.6702\n",
      "Epoch 13: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7938 - precision: 0.6741 - val_loss: 0.9433 - val_precision: 0.6503\n",
      "Epoch 14/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.7986 - precision: 0.6747\n",
      "Epoch 14: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7922 - precision: 0.6743 - val_loss: 0.9562 - val_precision: 0.6492\n",
      "Epoch 15/70\n",
      "214/240 [=========================>....] - ETA: 0s - loss: 0.7780 - precision: 0.6802\n",
      "Epoch 15: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7829 - precision: 0.6802 - val_loss: 0.9643 - val_precision: 0.6453\n",
      "Epoch 16/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.7749 - precision: 0.6754\n",
      "Epoch 16: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7750 - precision: 0.6781 - val_loss: 0.9610 - val_precision: 0.6498\n",
      "Epoch 17/70\n",
      "215/240 [=========================>....] - ETA: 0s - loss: 0.7674 - precision: 0.6803\n",
      "Epoch 17: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7676 - precision: 0.6805 - val_loss: 0.9485 - val_precision: 0.6489\n",
      "Epoch 18/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7674 - precision: 0.6796\n",
      "Epoch 18: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7667 - precision: 0.6807 - val_loss: 0.9554 - val_precision: 0.6475\n",
      "Epoch 19/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.7595 - precision: 0.6817\n",
      "Epoch 19: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7589 - precision: 0.6820 - val_loss: 0.9716 - val_precision: 0.6376\n",
      "Epoch 20/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.7506 - precision: 0.6853\n",
      "Epoch 20: val_loss did not improve from 0.93620\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7504 - precision: 0.6848 - val_loss: 0.9457 - val_precision: 0.6449\n",
      "Epoch 20: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7912 - precision: 0.6906\n",
      "Combinación 92 = (False, False, False, 32, 0.5) \n",
      " precision train: [0.7911925911903381, 0.6906006932258606]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 94: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 1.1012 - precision: 0.6315\n",
      "Epoch 1: val_loss improved from inf to 1.00130, saving model to model_94.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.0993 - precision: 0.6316 - val_loss: 1.0013 - val_precision: 0.6519\n",
      "Epoch 2/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.8344 - precision: 0.6470\n",
      "Epoch 2: val_loss improved from 1.00130 to 0.97549, saving model to model_94.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8363 - precision: 0.6468 - val_loss: 0.9755 - val_precision: 0.6421\n",
      "Epoch 3/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7848 - precision: 0.6548\n",
      "Epoch 3: val_loss improved from 0.97549 to 0.94996, saving model to model_94.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7861 - precision: 0.6572 - val_loss: 0.9500 - val_precision: 0.6483\n",
      "Epoch 4/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7543 - precision: 0.6657\n",
      "Epoch 4: val_loss improved from 0.94996 to 0.92168, saving model to model_94.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7534 - precision: 0.6653 - val_loss: 0.9217 - val_precision: 0.6546\n",
      "Epoch 5/70\n",
      "229/240 [===========================>..] - ETA: 0s - loss: 0.7210 - precision: 0.6698\n",
      "Epoch 5: val_loss did not improve from 0.92168\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7212 - precision: 0.6711 - val_loss: 0.9443 - val_precision: 0.6470\n",
      "Epoch 6/70\n",
      "226/240 [===========================>..] - ETA: 0s - loss: 0.7013 - precision: 0.6758\n",
      "Epoch 6: val_loss did not improve from 0.92168\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7019 - precision: 0.6748 - val_loss: 0.9649 - val_precision: 0.6370\n",
      "Epoch 7/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.6891 - precision: 0.6763\n",
      "Epoch 7: val_loss did not improve from 0.92168\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6906 - precision: 0.6761 - val_loss: 0.9458 - val_precision: 0.6390\n",
      "Epoch 8/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.6744 - precision: 0.6816\n",
      "Epoch 8: val_loss improved from 0.92168 to 0.90777, saving model to model_94.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6744 - precision: 0.6816 - val_loss: 0.9078 - val_precision: 0.6526\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6560 - precision: 0.6849\n",
      "Epoch 9: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6553 - precision: 0.6858 - val_loss: 0.9395 - val_precision: 0.6434\n",
      "Epoch 10/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6497 - precision: 0.6871\n",
      "Epoch 10: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6498 - precision: 0.6877 - val_loss: 0.9634 - val_precision: 0.6428\n",
      "Epoch 11/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.6265 - precision: 0.6978\n",
      "Epoch 11: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6312 - precision: 0.6971 - val_loss: 1.0003 - val_precision: 0.6338\n",
      "Epoch 12/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6260 - precision: 0.6980\n",
      "Epoch 12: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6273 - precision: 0.6970 - val_loss: 0.9943 - val_precision: 0.6301\n",
      "Epoch 13/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6089 - precision: 0.6985\n",
      "Epoch 13: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6095 - precision: 0.6982 - val_loss: 1.0275 - val_precision: 0.6304\n",
      "Epoch 14/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.5909 - precision: 0.7098\n",
      "Epoch 14: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.5921 - precision: 0.7094 - val_loss: 0.9923 - val_precision: 0.6327\n",
      "Epoch 15/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.5757 - precision: 0.7109\n",
      "Epoch 15: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.5789 - precision: 0.7092 - val_loss: 1.0083 - val_precision: 0.6306\n",
      "Epoch 16/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.5677 - precision: 0.7194\n",
      "Epoch 16: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.5687 - precision: 0.7195 - val_loss: 1.0542 - val_precision: 0.6208\n",
      "Epoch 17/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.5607 - precision: 0.7222\n",
      "Epoch 17: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.5602 - precision: 0.7218 - val_loss: 1.0801 - val_precision: 0.6161\n",
      "Epoch 18/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.5469 - precision: 0.7232\n",
      "Epoch 18: val_loss did not improve from 0.90777\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.5479 - precision: 0.7224 - val_loss: 1.0376 - val_precision: 0.6133\n",
      "Epoch 18: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.6897 - precision: 0.7243\n",
      "Combinación 93 = (False, False, False, 64, 0.1) \n",
      " precision train: [0.6896501779556274, 0.7242774963378906]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 95: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/240 [===========================>..] - ETA: 0s - loss: 1.1344 - precision: 0.6412\n",
      "Epoch 1: val_loss improved from inf to 0.99564, saving model to model_95.h5\n",
      "240/240 [==============================] - 4s 6ms/step - loss: 1.1248 - precision: 0.6378 - val_loss: 0.9956 - val_precision: 0.6536\n",
      "Epoch 2/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.8583 - precision: 0.6485\n",
      "Epoch 2: val_loss improved from 0.99564 to 0.96377, saving model to model_95.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8587 - precision: 0.6476 - val_loss: 0.9638 - val_precision: 0.6525\n",
      "Epoch 3/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.8119 - precision: 0.6630\n",
      "Epoch 3: val_loss improved from 0.96377 to 0.93627, saving model to model_95.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.8105 - precision: 0.6628 - val_loss: 0.9363 - val_precision: 0.6533\n",
      "Epoch 4/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7764 - precision: 0.6643\n",
      "Epoch 4: val_loss improved from 0.93627 to 0.92099, saving model to model_95.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7772 - precision: 0.6635 - val_loss: 0.9210 - val_precision: 0.6568\n",
      "Epoch 5/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.7490 - precision: 0.6665\n",
      "Epoch 5: val_loss did not improve from 0.92099\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7485 - precision: 0.6677 - val_loss: 0.9336 - val_precision: 0.6499\n",
      "Epoch 6/70\n",
      "234/240 [============================>.] - ETA: 0s - loss: 0.7380 - precision: 0.6712\n",
      "Epoch 6: val_loss improved from 0.92099 to 0.89507, saving model to model_95.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7363 - precision: 0.6721 - val_loss: 0.8951 - val_precision: 0.6629\n",
      "Epoch 7/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.7237 - precision: 0.6701\n",
      "Epoch 7: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7191 - precision: 0.6729 - val_loss: 0.9296 - val_precision: 0.6455\n",
      "Epoch 8/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.7041 - precision: 0.6763\n",
      "Epoch 8: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7035 - precision: 0.6773 - val_loss: 0.9504 - val_precision: 0.6397\n",
      "Epoch 9/70\n",
      "232/240 [============================>.] - ETA: 0s - loss: 0.6880 - precision: 0.6828\n",
      "Epoch 9: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6892 - precision: 0.6813 - val_loss: 0.9280 - val_precision: 0.6505\n",
      "Epoch 10/70\n",
      "237/240 [============================>.] - ETA: 0s - loss: 0.6824 - precision: 0.6820\n",
      "Epoch 10: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6812 - precision: 0.6829 - val_loss: 0.9753 - val_precision: 0.6392\n",
      "Epoch 11/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.6625 - precision: 0.6873\n",
      "Epoch 11: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6686 - precision: 0.6861 - val_loss: 0.9414 - val_precision: 0.6425\n",
      "Epoch 12/70\n",
      "235/240 [============================>.] - ETA: 0s - loss: 0.6580 - precision: 0.6929\n",
      "Epoch 12: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6591 - precision: 0.6923 - val_loss: 0.9441 - val_precision: 0.6451\n",
      "Epoch 13/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6397 - precision: 0.6963\n",
      "Epoch 13: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6401 - precision: 0.6957 - val_loss: 0.9569 - val_precision: 0.6410\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.6353 - precision: 0.6964\n",
      "Epoch 14: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6346 - precision: 0.6971 - val_loss: 1.0083 - val_precision: 0.6335\n",
      "Epoch 15/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6258 - precision: 0.7008\n",
      "Epoch 15: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6262 - precision: 0.7008 - val_loss: 1.0317 - val_precision: 0.6239\n",
      "Epoch 16/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.6174 - precision: 0.7011\n",
      "Epoch 16: val_loss did not improve from 0.89507\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6176 - precision: 0.7011 - val_loss: 0.9829 - val_precision: 0.6343\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7166 - precision: 0.7048\n",
      "Combinación 94 = (False, False, False, 64, 0.25) \n",
      " precision train: [0.716582715511322, 0.7048417925834656]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 96: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 1.2150 - precision: 0.6454\n",
      "Epoch 1: val_loss improved from inf to 1.04066, saving model to model_96.h5\n",
      "240/240 [==============================] - 4s 5ms/step - loss: 1.1917 - precision: 0.6459 - val_loss: 1.0407 - val_precision: 0.6516\n",
      "Epoch 2/70\n",
      "231/240 [===========================>..] - ETA: 0s - loss: 0.9198 - precision: 0.6378\n",
      "Epoch 2: val_loss improved from 1.04066 to 0.98638, saving model to model_96.h5\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.9214 - precision: 0.6372 - val_loss: 0.9864 - val_precision: 0.6454\n",
      "Epoch 3/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.8740 - precision: 0.6469\n",
      "Epoch 3: val_loss improved from 0.98638 to 0.94705, saving model to model_96.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8785 - precision: 0.6457 - val_loss: 0.9471 - val_precision: 0.6589\n",
      "Epoch 4/70\n",
      "219/240 [==========================>...] - ETA: 0s - loss: 0.8387 - precision: 0.6536\n",
      "Epoch 4: val_loss improved from 0.94705 to 0.91959, saving model to model_96.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8413 - precision: 0.6520 - val_loss: 0.9196 - val_precision: 0.6613\n",
      "Epoch 5/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.8123 - precision: 0.6613\n",
      "Epoch 5: val_loss did not improve from 0.91959\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8163 - precision: 0.6603 - val_loss: 0.9530 - val_precision: 0.6485\n",
      "Epoch 6/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7970 - precision: 0.6563\n",
      "Epoch 6: val_loss did not improve from 0.91959\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.8010 - precision: 0.6548 - val_loss: 0.9377 - val_precision: 0.6493\n",
      "Epoch 7/70\n",
      "221/240 [==========================>...] - ETA: 0s - loss: 0.7860 - precision: 0.6609\n",
      "Epoch 7: val_loss did not improve from 0.91959\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7853 - precision: 0.6618 - val_loss: 0.9333 - val_precision: 0.6540\n",
      "Epoch 8/70\n",
      "222/240 [==========================>...] - ETA: 0s - loss: 0.7666 - precision: 0.6622\n",
      "Epoch 8: val_loss did not improve from 0.91959\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7693 - precision: 0.6629 - val_loss: 0.9861 - val_precision: 0.6343\n",
      "Epoch 9/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7668 - precision: 0.6632\n",
      "Epoch 9: val_loss improved from 0.91959 to 0.91205, saving model to model_96.h5\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7657 - precision: 0.6628 - val_loss: 0.9120 - val_precision: 0.6585\n",
      "Epoch 10/70\n",
      "223/240 [==========================>...] - ETA: 0s - loss: 0.7609 - precision: 0.6668\n",
      "Epoch 10: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.7587 - precision: 0.6666 - val_loss: 0.9302 - val_precision: 0.6518\n",
      "Epoch 11/70\n",
      "236/240 [============================>.] - ETA: 0s - loss: 0.7345 - precision: 0.6760\n",
      "Epoch 11: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7347 - precision: 0.6759 - val_loss: 0.9439 - val_precision: 0.6508\n",
      "Epoch 12/70\n",
      "225/240 [===========================>..] - ETA: 0s - loss: 0.7243 - precision: 0.6779\n",
      "Epoch 12: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7299 - precision: 0.6772 - val_loss: 0.9407 - val_precision: 0.6440\n",
      "Epoch 13/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.7284 - precision: 0.6794\n",
      "Epoch 13: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7248 - precision: 0.6769 - val_loss: 0.9165 - val_precision: 0.6497\n",
      "Epoch 14/70\n",
      "217/240 [==========================>...] - ETA: 0s - loss: 0.7144 - precision: 0.6809\n",
      "Epoch 14: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7134 - precision: 0.6808 - val_loss: 0.9402 - val_precision: 0.6524\n",
      "Epoch 15/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.6979 - precision: 0.6855\n",
      "Epoch 15: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.7005 - precision: 0.6859 - val_loss: 0.9398 - val_precision: 0.6413\n",
      "Epoch 16/70\n",
      "220/240 [==========================>...] - ETA: 0s - loss: 0.6962 - precision: 0.6854\n",
      "Epoch 16: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6949 - precision: 0.6855 - val_loss: 0.9379 - val_precision: 0.6423\n",
      "Epoch 17/70\n",
      "233/240 [============================>.] - ETA: 0s - loss: 0.6932 - precision: 0.6842\n",
      "Epoch 17: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6921 - precision: 0.6838 - val_loss: 0.9251 - val_precision: 0.6458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/70\n",
      "218/240 [==========================>...] - ETA: 0s - loss: 0.6687 - precision: 0.6981\n",
      "Epoch 18: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.6742 - precision: 0.6976 - val_loss: 0.9362 - val_precision: 0.6444\n",
      "Epoch 19/70\n",
      "238/240 [============================>.] - ETA: 0s - loss: 0.6722 - precision: 0.6883\n",
      "Epoch 19: val_loss did not improve from 0.91205\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.6721 - precision: 0.6884 - val_loss: 0.9582 - val_precision: 0.6384\n",
      "Epoch 19: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7585 - precision: 0.6930\n",
      "Combinación 95 = (False, False, False, 64, 0.5) \n",
      " precision train: [0.7584602236747742, 0.6929924488067627]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "config = [[True, False], [True, False], [True, False], [8, 16, 32, 64], [0.1, 0.25, 0.5]]  \n",
    "hist = LSTM_hiperparametros(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3a5cd",
   "metadata": {},
   "source": [
    "Veamos cuál fue el modelo con mejores desempeños:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e2f85c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>model_94.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x1a139ce50&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.6896501779556274, 0.7242774963378906]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>model_82.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x19c36abb0&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.6989232301712036, 0.7173121571540833]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>model_22.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x1708587f0&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.7090219855308533, 0.7198400497436523]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>model_70.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x19398c8b0&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.712011456489563, 0.7133584022521973]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>model_91.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x19fb30550&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.7135452032089233, 0.7087605595588684]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                1      2  \\\n",
       "93  model_94.h5  <keras.callbacks.History object at 0x1a139ce50>  False   \n",
       "81  model_82.h5  <keras.callbacks.History object at 0x19c36abb0>  False   \n",
       "21  model_22.h5  <keras.callbacks.History object at 0x1708587f0>   True   \n",
       "69  model_70.h5  <keras.callbacks.History object at 0x19398c8b0>  False   \n",
       "90  model_91.h5  <keras.callbacks.History object at 0x19fb30550>  False   \n",
       "\n",
       "        3      4   5    6                                         7  \n",
       "93  False  False  64  0.1  [0.6896501779556274, 0.7242774963378906]  \n",
       "81  False   True  64  0.1  [0.6989232301712036, 0.7173121571540833]  \n",
       "21   True  False  64  0.1  [0.7090219855308533, 0.7198400497436523]  \n",
       "69   True  False  64  0.1   [0.712011456489563, 0.7133584022521973]  \n",
       "90  False  False  32  0.1  [0.7135452032089233, 0.7087605595588684]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(hist)\n",
    "hist = hist.sort_values(by=[7], ascending=True)\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17f65593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinacion: \n",
      " primera_capa_adicional = False\n",
      " segunda_capa_adicional = False\n",
      " tercera_capa_adicional = False\n",
      " n_neuronas = 64\n",
      " dropout = 0.1\n",
      "**************************\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8008 - precision: 0.6908\n",
      "Resultados antes de tuneo con hiperparametros:\n",
      " Train Precision: 0.6908\n",
      "\n",
      "Resultados despues de tuneo con hiperparametros: 0.7243\n",
      "\n",
      "5.0% mejora\n"
     ]
    }
   ],
   "source": [
    "print(f'Mejor combinacion: \\n primera_capa_adicional = {hist.iloc[0, 2]}\\n segunda_capa_adicional = {hist.iloc[0, 3]}\\n tercera_capa_adicional = {hist.iloc[0, 4]}\\n n_neuronas = {hist.iloc[0, 5]}\\n dropout = {hist.iloc[0, 6]}')\n",
    "print('**************************')\n",
    "base = np.round(lstm_base.evaluate(embedded_abstracts_, Y_train_), 4)[1]\n",
    "print(f'Resultados antes de tuneo con hiperparametros:\\n Train Precision: {base}\\n')\n",
    "print(f'Resultados despues de tuneo con hiperparametros: {np.round(hist.iloc[0, -1], 4)[1]}\\n')\n",
    "print(f'{np.abs(np.round((base - hist.iloc[0, -1][1])*100/np.round(base, 4)))}% mejora')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0610e2",
   "metadata": {},
   "source": [
    "Vemos entonces que el modelo con mejores métricas para este caso fue el que no escogió ninguna capa adicional, pero que tenía 64 neuronas en cada una de las 5 capas consideradas, con una tasa de pérdida de 0.1 (la más baja). Podemos ver que este modelo corresponde al añmacenado en el archivo ```modelo_94.h5```.\n",
    "\n",
    "Finalmente, veamos las métricas de precisión y pérdida para este modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbc3a22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a69a79a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,7))\n",
    "fig.add_subplot(121)\n",
    "# Precision\n",
    "best_cv_1 = load_model('model_94.h5')\n",
    "plt.plot(hist.iloc[0, 1].epoch, hist.iloc[0, 1].history['precision'], label = \"precision\")\n",
    "\n",
    "plt.title(\"Precisión\", fontsize=18)\n",
    "plt.xlabel(\"Épocas\", fontsize=15)\n",
    "plt.ylabel(\"Precisión\", fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Pérdida\n",
    "fig.add_subplot(122)\n",
    "\n",
    "plt.plot(hist.iloc[0, 1].epoch, hist.iloc[0, 1].history['loss'], label=\"loss\")\n",
    "\n",
    "plt.title(\"Pérdida\", fontsize=18)\n",
    "plt.xlabel(\"Épocas\", fontsize=15)\n",
    "plt.ylabel(\"Pérdida\", fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b9af8",
   "metadata": {},
   "source": [
    "Podemos ver cómo aumenta la precisión conforme disminuye la pérdida del modelo. Vemos que, al momento de parar, el momento está llegando a una especie de plateau, tal que podemos pensar que NO está haciendo overfitting. No obstante, para determinar esto debemos hacer validación sobre test.\n",
    "\n",
    "Antes de proseguir, veamos el reporte de clasificación para nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffe3fe70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reporte para el modelo construido---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.81      0.78      2103\n",
      "           2       0.52      0.92      0.66       994\n",
      "           3       0.57      0.75      0.65      1280\n",
      "           4       0.70      0.85      0.77      2029\n",
      "           5       0.77      0.35      0.48      3194\n",
      "\n",
      "    accuracy                           0.67      9600\n",
      "   macro avg       0.66      0.74      0.67      9600\n",
      "weighted avg       0.70      0.67      0.65      9600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_cv_1.predict(embedded_abstracts_)\n",
    "y_pred = y_pred.argmax(1) + 1 # Sumamos 1 para que las clases nos queden entre 1 y 5 \n",
    "Y_tr = Y_train_.argmax(1) + 1 # Sumamos 1 para que las clases nos queden entre 1 y 5 \n",
    "\n",
    "\n",
    "print('---Reporte para el modelo construido---')\n",
    "print(classification_report(Y_tr, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f3c6e",
   "metadata": {},
   "source": [
    "Podemos ver que, en promedio, la precisión de este modelo no es mala. De hecho, para tres de las 5 clases (neoplasias, enfermedades cardiovasculares y patologías generales, se tiene una precisión mayor o igual al 70%. Esperamos poder mejorar esto de alguna forma, para ello, intentamos otras técnicas.\n",
    "\n",
    "Veamos ahora la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4085f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_tr, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels= np.arange(1,6))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77de89f",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que la clase que más se confunde es la 5: esto tiene sentido, pues las palabras que la conforman pueden caber en varias de las otras categorías. De resto, el modelo clasifica bien (sin mucho error) las otras clases. Note que las clases peor clasificadas son las minoritarias, incluso a pesar de que consideramos los pesos en la construcción del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf6534e",
   "metadata": {},
   "source": [
    "### Modelo con ajuste de hiperparámetros usando BioWordVec\n",
    "Lo primero que hacemos es eliminar los datos nulos, pues hay algunas filas que no tuvieron palabras importantes y, por tanto, deben ser eliminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba792db",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_train_not_null = datos_train.copy()\n",
    "datos_train_not_null = datos_train_not_null.dropna(how='any',axis=0) \n",
    "tokenized_entities = datos_train_not_null['tokenized_entities']\n",
    "tokenized_entities_ = tokenized_entities.to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff89cdd9",
   "metadata": {},
   "source": [
    "Usamos la librería de BioWordVec para las palabras de las entidades obtenidas en el preprocesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92bae6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = fasttext.load_model('BioWordVec_PubMed_MIMICIII_d200.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f835379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_train_not_null['embedded'] = 'pre'\n",
    "for i in range(len(datos_train_not_null)):\n",
    "    datos_train_not_null['embedded'].iloc[i] = embedding[datos_train_not_null['tokenized_entities'].iloc[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d7ecd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_entities = np.array([[embedding[datos_train_not_null['tokenized_entities'].iloc[i]]] for i in range(len(datos_train_not_null))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb170bec",
   "metadata": {},
   "source": [
    "Note que los vectores generados son de dimensionalidad 200, mientras que los de Sent2Vec eran de dimensionalidad 700."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8ab6d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200)\n"
     ]
    }
   ],
   "source": [
    "print(embedded_entities[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba31ef3",
   "metadata": {},
   "source": [
    "Ya que hemos cargado el embedding de las palabras, podemos usar la función de hiperparámetros definida previamente, solo que con algunos diferentes (debido a que este conjunto tiene menor dimensionalidad). En este caso, no es necesario hacer un reshape por la forma en que fueron leídos los datos. Pero sí debemos pasar las categorías a OneHot para la interpretación por parte del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3d73cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ent = datos_train_not_null['problems_described']\n",
    "Y_ent = keras.utils.np_utils.to_categorical(Y_ent)[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b548b7cf",
   "metadata": {},
   "source": [
    "Ahora, definimos nuestra grilla de hiperparámetros. Para ello, usamos el mismo número de capas ocultas (máximo 3 + una LSTM de entrada y una LSTM de salida = 5), las mismas tasas de dropout y la misma cantidad de neuronas (excepto que, en este caso, consideramos capas de 128 neuronas también). Asimismo, consideramos como posible salida de la capa de embedding una capa con 128 o 256 neuronas.\n",
    "Para este ejercicio, consideramos la definición de los siguientes hiperparámetros:\n",
    "* **Número de capas:** Le permitimos a la red elegir entre 1, 2 o 3 capas ocultas LSTM. Siempre hay dos capas LSTM iniciales por defecto.\n",
    "* **Número de neuronas:** Permitimos un espacio de búsqueda de 8, 16, 32, y 64 neuronas. Note que, por facilidades computacionales y de implementación, este número de neuronas será utilizado por todas las capas.\n",
    "* **Tasa de Dropout:** Para no sobreaprender y hacer overfitting sobre el conjunto de datos, debemos añadir una capa de dropout para que la red olvide un porcentaje de lo que ha aprendido. \n",
    "\n",
    "Note asimismo que la función parte el conjunto de entrenamiento en entrenamiento-validación y hace la validación de la función de error y de la métrica usando las métricas sobre validación y no entrenamiento, esto hará que los resultados obtenidos tengan menos sobreajuste que si se evaluara sobre train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8781e9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de combinaciones es:  120\n",
      "\n",
      "\n",
      "Combinación 1: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.5750 - precision: 0.4658   \n",
      "Epoch 1: val_loss improved from inf to 1.51458, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.5718 - precision: 0.4242 - val_loss: 1.5146 - val_precision: 0.4300\n",
      "Epoch 2/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3855 - precision: 0.3581\n",
      "Epoch 2: val_loss improved from 1.51458 to 1.41420, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3856 - precision: 0.3559 - val_loss: 1.4142 - val_precision: 0.3911\n",
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.3279 - precision: 0.3556\n",
      "Epoch 3: val_loss improved from 1.41420 to 1.35764, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3259 - precision: 0.3598 - val_loss: 1.3576 - val_precision: 0.6176\n",
      "Epoch 4/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2997 - precision: 0.3971\n",
      "Epoch 4: val_loss improved from 1.35764 to 1.32421, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2992 - precision: 0.4000 - val_loss: 1.3242 - val_precision: 0.5909\n",
      "Epoch 5/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2778 - precision: 0.4652\n",
      "Epoch 5: val_loss improved from 1.32421 to 1.30318, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2743 - precision: 0.4604 - val_loss: 1.3032 - val_precision: 0.5153\n",
      "Epoch 6/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2583 - precision: 0.4887\n",
      "Epoch 6: val_loss improved from 1.30318 to 1.28059, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2555 - precision: 0.4947 - val_loss: 1.2806 - val_precision: 0.5407\n",
      "Epoch 7/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2295 - precision: 0.5608\n",
      "Epoch 7: val_loss improved from 1.28059 to 1.26032, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2297 - precision: 0.5589 - val_loss: 1.2603 - val_precision: 0.6108\n",
      "Epoch 8/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2022 - precision: 0.5600\n",
      "Epoch 8: val_loss improved from 1.26032 to 1.23290, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2012 - precision: 0.5613 - val_loss: 1.2329 - val_precision: 0.6121\n",
      "Epoch 9/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1707 - precision: 0.5822\n",
      "Epoch 9: val_loss improved from 1.23290 to 1.20118, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1702 - precision: 0.5820 - val_loss: 1.2012 - val_precision: 0.6253\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1393 - precision: 0.6035\n",
      "Epoch 10: val_loss improved from 1.20118 to 1.17266, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1393 - precision: 0.6035 - val_loss: 1.1727 - val_precision: 0.6355\n",
      "Epoch 11/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1253 - precision: 0.6053\n",
      "Epoch 11: val_loss improved from 1.17266 to 1.16252, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1249 - precision: 0.6047 - val_loss: 1.1625 - val_precision: 0.6208\n",
      "Epoch 12/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1098 - precision: 0.6040\n",
      "Epoch 12: val_loss improved from 1.16252 to 1.14981, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1108 - precision: 0.6055 - val_loss: 1.1498 - val_precision: 0.6355\n",
      "Epoch 13/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0927 - precision: 0.6001\n",
      "Epoch 13: val_loss improved from 1.14981 to 1.14251, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0927 - precision: 0.6001 - val_loss: 1.1425 - val_precision: 0.6147\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0873 - precision: 0.5899\n",
      "Epoch 14: val_loss improved from 1.14251 to 1.13831, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0857 - precision: 0.5900 - val_loss: 1.1383 - val_precision: 0.5899\n",
      "Epoch 15/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0758 - precision: 0.5778\n",
      "Epoch 15: val_loss improved from 1.13831 to 1.13133, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0769 - precision: 0.5782 - val_loss: 1.1313 - val_precision: 0.5911\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0724 - precision: 0.5816\n",
      "Epoch 16: val_loss improved from 1.13133 to 1.12834, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0687 - precision: 0.5819 - val_loss: 1.1283 - val_precision: 0.5826\n",
      "Epoch 17/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0607 - precision: 0.5821\n",
      "Epoch 17: val_loss improved from 1.12834 to 1.12405, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0600 - precision: 0.5823 - val_loss: 1.1240 - val_precision: 0.5871\n",
      "Epoch 18/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0537 - precision: 0.5748\n",
      "Epoch 18: val_loss improved from 1.12405 to 1.11607, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0537 - precision: 0.5748 - val_loss: 1.1161 - val_precision: 0.5831\n",
      "Epoch 19/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0477 - precision: 0.5818\n",
      "Epoch 19: val_loss did not improve from 1.11607\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0490 - precision: 0.5805 - val_loss: 1.1213 - val_precision: 0.5827\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0425 - precision: 0.5776\n",
      "Epoch 20: val_loss did not improve from 1.11607\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0423 - precision: 0.5773 - val_loss: 1.1209 - val_precision: 0.5774\n",
      "Epoch 21/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0346 - precision: 0.5845\n",
      "Epoch 21: val_loss did not improve from 1.11607\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0394 - precision: 0.5827 - val_loss: 1.1388 - val_precision: 0.5795\n",
      "Epoch 22/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0432 - precision: 0.5742\n",
      "Epoch 22: val_loss did not improve from 1.11607\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0455 - precision: 0.5751 - val_loss: 1.1162 - val_precision: 0.5825\n",
      "Epoch 23/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0376 - precision: 0.5801\n",
      "Epoch 23: val_loss improved from 1.11607 to 1.11217, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0376 - precision: 0.5801 - val_loss: 1.1122 - val_precision: 0.5847\n",
      "Epoch 24/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0254 - precision: 0.5891\n",
      "Epoch 24: val_loss improved from 1.11217 to 1.11200, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0264 - precision: 0.5887 - val_loss: 1.1120 - val_precision: 0.5848\n",
      "Epoch 25/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0304 - precision: 0.5809\n",
      "Epoch 25: val_loss improved from 1.11200 to 1.10279, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0254 - precision: 0.5833 - val_loss: 1.1028 - val_precision: 0.5821\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0215 - precision: 0.5865\n",
      "Epoch 26: val_loss did not improve from 1.10279\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0215 - precision: 0.5865 - val_loss: 1.1142 - val_precision: 0.5889\n",
      "Epoch 27/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0147 - precision: 0.5846\n",
      "Epoch 27: val_loss did not improve from 1.10279\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0146 - precision: 0.5846 - val_loss: 1.1122 - val_precision: 0.5804\n",
      "Epoch 28/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0129 - precision: 0.5901\n",
      "Epoch 28: val_loss did not improve from 1.10279\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0129 - precision: 0.5901 - val_loss: 1.1031 - val_precision: 0.5830\n",
      "Epoch 29/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0130 - precision: 0.5856\n",
      "Epoch 29: val_loss improved from 1.10279 to 1.10108, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0123 - precision: 0.5866 - val_loss: 1.1011 - val_precision: 0.5895\n",
      "Epoch 30/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0104 - precision: 0.5901\n",
      "Epoch 30: val_loss did not improve from 1.10108\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0108 - precision: 0.5897 - val_loss: 1.1053 - val_precision: 0.5873\n",
      "Epoch 31/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0004 - precision: 0.5946\n",
      "Epoch 31: val_loss did not improve from 1.10108\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9998 - precision: 0.5950 - val_loss: 1.1111 - val_precision: 0.5800\n",
      "Epoch 32/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9993 - precision: 0.5912\n",
      "Epoch 32: val_loss did not improve from 1.10108\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9995 - precision: 0.5918 - val_loss: 1.1087 - val_precision: 0.5819\n",
      "Epoch 33/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0077 - precision: 0.5948\n",
      "Epoch 33: val_loss did not improve from 1.10108\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0088 - precision: 0.5930 - val_loss: 1.1063 - val_precision: 0.5776\n",
      "Epoch 34/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0032 - precision: 0.5925\n",
      "Epoch 34: val_loss improved from 1.10108 to 1.10095, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0019 - precision: 0.5930 - val_loss: 1.1010 - val_precision: 0.5850\n",
      "Epoch 35/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0012 - precision: 0.5883\n",
      "Epoch 35: val_loss did not improve from 1.10095\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0012 - precision: 0.5883 - val_loss: 1.1059 - val_precision: 0.5854\n",
      "Epoch 36/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9979 - precision: 0.5924\n",
      "Epoch 36: val_loss improved from 1.10095 to 1.09841, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9961 - precision: 0.5922 - val_loss: 1.0984 - val_precision: 0.5875\n",
      "Epoch 37/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9873 - precision: 0.5882\n",
      "Epoch 37: val_loss improved from 1.09841 to 1.09796, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9878 - precision: 0.5881 - val_loss: 1.0980 - val_precision: 0.5856\n",
      "Epoch 38/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9793 - precision: 0.5973\n",
      "Epoch 38: val_loss improved from 1.09796 to 1.09602, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9829 - precision: 0.5968 - val_loss: 1.0960 - val_precision: 0.5871\n",
      "Epoch 39/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9710 - precision: 0.5974\n",
      "Epoch 39: val_loss improved from 1.09602 to 1.09450, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9773 - precision: 0.5969 - val_loss: 1.0945 - val_precision: 0.5895\n",
      "Epoch 40/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9784 - precision: 0.5950\n",
      "Epoch 40: val_loss did not improve from 1.09450\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9791 - precision: 0.5965 - val_loss: 1.1067 - val_precision: 0.5791\n",
      "Epoch 41/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9741 - precision: 0.5966\n",
      "Epoch 41: val_loss did not improve from 1.09450\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9748 - precision: 0.5961 - val_loss: 1.1045 - val_precision: 0.5812\n",
      "Epoch 42/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9773 - precision: 0.5960\n",
      "Epoch 42: val_loss did not improve from 1.09450\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9780 - precision: 0.5959 - val_loss: 1.0957 - val_precision: 0.5847\n",
      "Epoch 43/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9708 - precision: 0.5941\n",
      "Epoch 43: val_loss did not improve from 1.09450\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9736 - precision: 0.5942 - val_loss: 1.1016 - val_precision: 0.5865\n",
      "Epoch 44/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9687 - precision: 0.5951\n",
      "Epoch 44: val_loss improved from 1.09450 to 1.08863, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9758 - precision: 0.5948 - val_loss: 1.0886 - val_precision: 0.5895\n",
      "Epoch 45/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9622 - precision: 0.6034\n",
      "Epoch 45: val_loss did not improve from 1.08863\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9626 - precision: 0.6027 - val_loss: 1.0951 - val_precision: 0.5874\n",
      "Epoch 46/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9640 - precision: 0.6033\n",
      "Epoch 46: val_loss improved from 1.08863 to 1.08336, saving model to model_ent1.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9635 - precision: 0.6026 - val_loss: 1.0834 - val_precision: 0.5919\n",
      "Epoch 47/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9706 - precision: 0.6016\n",
      "Epoch 47: val_loss did not improve from 1.08336\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9694 - precision: 0.6016 - val_loss: 1.0918 - val_precision: 0.5885\n",
      "Epoch 48/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9678 - precision: 0.5968\n",
      "Epoch 48: val_loss did not improve from 1.08336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9687 - precision: 0.5964 - val_loss: 1.1000 - val_precision: 0.5801\n",
      "Epoch 49/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9586 - precision: 0.6026\n",
      "Epoch 49: val_loss did not improve from 1.08336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9588 - precision: 0.6015 - val_loss: 1.0905 - val_precision: 0.5923\n",
      "Epoch 50/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9595 - precision: 0.6016\n",
      "Epoch 50: val_loss did not improve from 1.08336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9598 - precision: 0.6008 - val_loss: 1.0944 - val_precision: 0.5878\n",
      "Epoch 51/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9548 - precision: 0.6011\n",
      "Epoch 51: val_loss did not improve from 1.08336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9539 - precision: 0.6015 - val_loss: 1.0893 - val_precision: 0.5887\n",
      "Epoch 52/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9597 - precision: 0.5994\n",
      "Epoch 52: val_loss did not improve from 1.08336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9592 - precision: 0.5991 - val_loss: 1.0915 - val_precision: 0.5968\n",
      "Epoch 53/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9506 - precision: 0.6063\n",
      "Epoch 53: val_loss did not improve from 1.08336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9515 - precision: 0.6059 - val_loss: 1.1120 - val_precision: 0.5779\n",
      "Epoch 54/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9610 - precision: 0.5978\n",
      "Epoch 54: val_loss did not improve from 1.08336\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9577 - precision: 0.5988 - val_loss: 1.1060 - val_precision: 0.5836\n",
      "Epoch 55/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9525 - precision: 0.6015\n",
      "Epoch 55: val_loss did not improve from 1.08336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9521 - precision: 0.6027 - val_loss: 1.0893 - val_precision: 0.5911\n",
      "Epoch 56/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9474 - precision: 0.6063\n",
      "Epoch 56: val_loss did not improve from 1.08336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9504 - precision: 0.6064 - val_loss: 1.0974 - val_precision: 0.5848\n",
      "Epoch 56: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0177 - precision: 0.6062\n",
      "Combinación 0 = (True, True, True, 8, 0.1) \n",
      " precision train: [1.0177134275436401, 0.6061726808547974]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 2: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.5759 - precision: 0.8000    \n",
      "Epoch 1: val_loss improved from inf to 1.42196, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.5720 - precision: 0.6667 - val_loss: 1.4220 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.3778 - precision: 0.5294\n",
      "Epoch 2: val_loss improved from 1.42196 to 1.34774, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3779 - precision: 0.5294 - val_loss: 1.3477 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.3311 - precision: 0.5160\n",
      "Epoch 3: val_loss improved from 1.34774 to 1.31283, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3295 - precision: 0.5156 - val_loss: 1.3128 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3107 - precision: 0.5360\n",
      "Epoch 4: val_loss improved from 1.31283 to 1.29912, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3103 - precision: 0.5330 - val_loss: 1.2991 - val_precision: 0.0000e+00\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2903 - precision: 0.5886\n",
      "Epoch 5: val_loss improved from 1.29912 to 1.27603, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2918 - precision: 0.5869 - val_loss: 1.2760 - val_precision: 0.6686\n",
      "Epoch 6/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2716 - precision: 0.6077\n",
      "Epoch 6: val_loss improved from 1.27603 to 1.24769, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2711 - precision: 0.6032 - val_loss: 1.2477 - val_precision: 0.6738\n",
      "Epoch 7/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2587 - precision: 0.6203\n",
      "Epoch 7: val_loss improved from 1.24769 to 1.21366, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2587 - precision: 0.6203 - val_loss: 1.2137 - val_precision: 0.6855\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2309 - precision: 0.6587\n",
      "Epoch 8: val_loss improved from 1.21366 to 1.19050, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2301 - precision: 0.6598 - val_loss: 1.1905 - val_precision: 0.6737\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2089 - precision: 0.6388\n",
      "Epoch 9: val_loss improved from 1.19050 to 1.18934, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2092 - precision: 0.6388 - val_loss: 1.1893 - val_precision: 0.6833\n",
      "Epoch 10/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1998 - precision: 0.6235\n",
      "Epoch 10: val_loss improved from 1.18934 to 1.16242, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1975 - precision: 0.6241 - val_loss: 1.1624 - val_precision: 0.6689\n",
      "Epoch 11/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1843 - precision: 0.6198\n",
      "Epoch 11: val_loss improved from 1.16242 to 1.15531, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1872 - precision: 0.6193 - val_loss: 1.1553 - val_precision: 0.6566\n",
      "Epoch 12/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1720 - precision: 0.6277\n",
      "Epoch 12: val_loss improved from 1.15531 to 1.15316, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1709 - precision: 0.6268 - val_loss: 1.1532 - val_precision: 0.6593\n",
      "Epoch 13/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1599 - precision: 0.6312\n",
      "Epoch 13: val_loss improved from 1.15316 to 1.14432, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1582 - precision: 0.6324 - val_loss: 1.1443 - val_precision: 0.6448\n",
      "Epoch 14/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1599 - precision: 0.6159\n",
      "Epoch 14: val_loss improved from 1.14432 to 1.13273, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1561 - precision: 0.6188 - val_loss: 1.1327 - val_precision: 0.6451\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1463 - precision: 0.6199\n",
      "Epoch 15: val_loss improved from 1.13273 to 1.12898, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1463 - precision: 0.6199 - val_loss: 1.1290 - val_precision: 0.6468\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1398 - precision: 0.6244\n",
      "Epoch 16: val_loss did not improve from 1.12898\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1400 - precision: 0.6239 - val_loss: 1.1404 - val_precision: 0.6297\n",
      "Epoch 17/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1358 - precision: 0.6145\n",
      "Epoch 17: val_loss did not improve from 1.12898\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1380 - precision: 0.6127 - val_loss: 1.1346 - val_precision: 0.6441\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1334 - precision: 0.6237\n",
      "Epoch 18: val_loss improved from 1.12898 to 1.12230, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1351 - precision: 0.6220 - val_loss: 1.1223 - val_precision: 0.6434\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1274 - precision: 0.6175\n",
      "Epoch 19: val_loss did not improve from 1.12230\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1269 - precision: 0.6181 - val_loss: 1.1386 - val_precision: 0.6360\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1243 - precision: 0.6090\n",
      "Epoch 20: val_loss did not improve from 1.12230\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1248 - precision: 0.6087 - val_loss: 1.1264 - val_precision: 0.6368\n",
      "Epoch 21/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1197 - precision: 0.6150\n",
      "Epoch 21: val_loss improved from 1.12230 to 1.10972, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1153 - precision: 0.6163 - val_loss: 1.1097 - val_precision: 0.6455\n",
      "Epoch 22/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1198 - precision: 0.6132\n",
      "Epoch 22: val_loss did not improve from 1.10972\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1193 - precision: 0.6136 - val_loss: 1.1149 - val_precision: 0.6368\n",
      "Epoch 23/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1181 - precision: 0.6174\n",
      "Epoch 23: val_loss did not improve from 1.10972\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1172 - precision: 0.6174 - val_loss: 1.1179 - val_precision: 0.6431\n",
      "Epoch 24/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1067 - precision: 0.6090\n",
      "Epoch 24: val_loss improved from 1.10972 to 1.10901, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1067 - precision: 0.6090 - val_loss: 1.1090 - val_precision: 0.6376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1050 - precision: 0.6099\n",
      "Epoch 25: val_loss improved from 1.10901 to 1.10791, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1043 - precision: 0.6090 - val_loss: 1.1079 - val_precision: 0.6319\n",
      "Epoch 26/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1000 - precision: 0.6091\n",
      "Epoch 26: val_loss improved from 1.10791 to 1.10660, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0992 - precision: 0.6094 - val_loss: 1.1066 - val_precision: 0.6328\n",
      "Epoch 27/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0973 - precision: 0.6110\n",
      "Epoch 27: val_loss improved from 1.10660 to 1.10146, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0976 - precision: 0.6099 - val_loss: 1.1015 - val_precision: 0.6273\n",
      "Epoch 28/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0932 - precision: 0.6093\n",
      "Epoch 28: val_loss did not improve from 1.10146\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0935 - precision: 0.6086 - val_loss: 1.1057 - val_precision: 0.6271\n",
      "Epoch 29/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0850 - precision: 0.6208\n",
      "Epoch 29: val_loss improved from 1.10146 to 1.09336, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0848 - precision: 0.6204 - val_loss: 1.0934 - val_precision: 0.6255\n",
      "Epoch 30/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1003 - precision: 0.6018\n",
      "Epoch 30: val_loss did not improve from 1.09336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0996 - precision: 0.6013 - val_loss: 1.1025 - val_precision: 0.6273\n",
      "Epoch 31/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0855 - precision: 0.6082\n",
      "Epoch 31: val_loss improved from 1.09336 to 1.09294, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0884 - precision: 0.6070 - val_loss: 1.0929 - val_precision: 0.6271\n",
      "Epoch 32/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0839 - precision: 0.6048\n",
      "Epoch 32: val_loss improved from 1.09294 to 1.09040, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0841 - precision: 0.6047 - val_loss: 1.0904 - val_precision: 0.6310\n",
      "Epoch 33/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0802 - precision: 0.6110\n",
      "Epoch 33: val_loss did not improve from 1.09040\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0774 - precision: 0.6129 - val_loss: 1.0996 - val_precision: 0.6183\n",
      "Epoch 34/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0748 - precision: 0.6114\n",
      "Epoch 34: val_loss did not improve from 1.09040\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0773 - precision: 0.6113 - val_loss: 1.1041 - val_precision: 0.6083\n",
      "Epoch 35/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0936 - precision: 0.5977\n",
      "Epoch 35: val_loss did not improve from 1.09040\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0934 - precision: 0.5978 - val_loss: 1.1115 - val_precision: 0.6108\n",
      "Epoch 36/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0860 - precision: 0.6085\n",
      "Epoch 36: val_loss did not improve from 1.09040\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0876 - precision: 0.6089 - val_loss: 1.1021 - val_precision: 0.6103\n",
      "Epoch 37/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0812 - precision: 0.6017\n",
      "Epoch 37: val_loss did not improve from 1.09040\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0811 - precision: 0.6007 - val_loss: 1.1069 - val_precision: 0.6091\n",
      "Epoch 38/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0733 - precision: 0.6049\n",
      "Epoch 38: val_loss did not improve from 1.09040\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0754 - precision: 0.6042 - val_loss: 1.1021 - val_precision: 0.6081\n",
      "Epoch 39/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0743 - precision: 0.6042\n",
      "Epoch 39: val_loss did not improve from 1.09040\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0743 - precision: 0.6042 - val_loss: 1.0925 - val_precision: 0.6166\n",
      "Epoch 40/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0789 - precision: 0.6009\n",
      "Epoch 40: val_loss improved from 1.09040 to 1.08674, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0779 - precision: 0.6002 - val_loss: 1.0867 - val_precision: 0.6145\n",
      "Epoch 41/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0659 - precision: 0.6074\n",
      "Epoch 41: val_loss did not improve from 1.08674\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0658 - precision: 0.6070 - val_loss: 1.0950 - val_precision: 0.6056\n",
      "Epoch 42/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0670 - precision: 0.6090\n",
      "Epoch 42: val_loss did not improve from 1.08674\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0692 - precision: 0.6087 - val_loss: 1.0943 - val_precision: 0.6021\n",
      "Epoch 43/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0662 - precision: 0.6076\n",
      "Epoch 43: val_loss did not improve from 1.08674\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0668 - precision: 0.6077 - val_loss: 1.1009 - val_precision: 0.6064\n",
      "Epoch 44/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0726 - precision: 0.6061\n",
      "Epoch 44: val_loss did not improve from 1.08674\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0710 - precision: 0.6069 - val_loss: 1.0931 - val_precision: 0.6167\n",
      "Epoch 45/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0619 - precision: 0.6072\n",
      "Epoch 45: val_loss did not improve from 1.08674\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0620 - precision: 0.6075 - val_loss: 1.0945 - val_precision: 0.6081\n",
      "Epoch 46/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0691 - precision: 0.6016\n",
      "Epoch 46: val_loss did not improve from 1.08674\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0685 - precision: 0.6013 - val_loss: 1.0900 - val_precision: 0.6165\n",
      "Epoch 47/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0563 - precision: 0.6018\n",
      "Epoch 47: val_loss improved from 1.08674 to 1.08661, saving model to model_ent2.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0561 - precision: 0.6021 - val_loss: 1.0866 - val_precision: 0.6129\n",
      "Epoch 48/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0524 - precision: 0.6080\n",
      "Epoch 48: val_loss did not improve from 1.08661\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0517 - precision: 0.6080 - val_loss: 1.1052 - val_precision: 0.6010\n",
      "Epoch 49/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0584 - precision: 0.6087\n",
      "Epoch 49: val_loss did not improve from 1.08661\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0605 - precision: 0.6084 - val_loss: 1.0947 - val_precision: 0.6047\n",
      "Epoch 50/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0626 - precision: 0.6032\n",
      "Epoch 50: val_loss did not improve from 1.08661\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0628 - precision: 0.6026 - val_loss: 1.0925 - val_precision: 0.6117\n",
      "Epoch 51/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0633 - precision: 0.6053\n",
      "Epoch 51: val_loss did not improve from 1.08661\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0615 - precision: 0.6055 - val_loss: 1.0934 - val_precision: 0.6116\n",
      "Epoch 52/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0573 - precision: 0.6040\n",
      "Epoch 52: val_loss did not improve from 1.08661\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0566 - precision: 0.6044 - val_loss: 1.0954 - val_precision: 0.6017\n",
      "Epoch 53/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0586 - precision: 0.6078\n",
      "Epoch 53: val_loss did not improve from 1.08661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0568 - precision: 0.6084 - val_loss: 1.1012 - val_precision: 0.6006\n",
      "Epoch 54/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0353 - precision: 0.6152\n",
      "Epoch 54: val_loss did not improve from 1.08661\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0356 - precision: 0.6147 - val_loss: 1.1010 - val_precision: 0.5972\n",
      "Epoch 55/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0486 - precision: 0.6051\n",
      "Epoch 55: val_loss did not improve from 1.08661\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0484 - precision: 0.6047 - val_loss: 1.0993 - val_precision: 0.6003\n",
      "Epoch 56/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0513 - precision: 0.6108\n",
      "Epoch 56: val_loss did not improve from 1.08661\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0564 - precision: 0.6103 - val_loss: 1.0989 - val_precision: 0.6014\n",
      "Epoch 57/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0623 - precision: 0.6049\n",
      "Epoch 57: val_loss did not improve from 1.08661\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0623 - precision: 0.6049 - val_loss: 1.0981 - val_precision: 0.5942\n",
      "Epoch 57: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0594 - precision: 0.6079\n",
      "Combinación 1 = (True, True, True, 8, 0.25) \n",
      " precision train: [1.0593783855438232, 0.6079050302505493]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 3: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.6033 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.59137, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 7s 10ms/step - loss: 1.6038 - precision: 0.0000e+00 - val_loss: 1.5914 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.4981 - precision: 0.4504\n",
      "Epoch 2: val_loss improved from 1.59137 to 1.36522, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.4941 - precision: 0.4437 - val_loss: 1.3652 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.3952 - precision: 0.4993\n",
      "Epoch 3: val_loss improved from 1.36522 to 1.34053, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3961 - precision: 0.4978 - val_loss: 1.3405 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3823 - precision: 0.4413\n",
      "Epoch 4: val_loss improved from 1.34053 to 1.33366, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3821 - precision: 0.4382 - val_loss: 1.3337 - val_precision: 0.0000e+00\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.3571 - precision: 0.4313\n",
      "Epoch 5: val_loss improved from 1.33366 to 1.32331, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3571 - precision: 0.4323 - val_loss: 1.3233 - val_precision: 0.0000e+00\n",
      "Epoch 6/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.3558 - precision: 0.4225\n",
      "Epoch 6: val_loss improved from 1.32331 to 1.31839, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3553 - precision: 0.4241 - val_loss: 1.3184 - val_precision: 0.0000e+00\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3507 - precision: 0.4341\n",
      "Epoch 7: val_loss improved from 1.31839 to 1.31304, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3503 - precision: 0.4329 - val_loss: 1.3130 - val_precision: 0.0000e+00\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.3403 - precision: 0.4543\n",
      "Epoch 8: val_loss improved from 1.31304 to 1.31277, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3406 - precision: 0.4550 - val_loss: 1.3128 - val_precision: 0.0000e+00\n",
      "Epoch 9/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3404 - precision: 0.4745\n",
      "Epoch 9: val_loss improved from 1.31277 to 1.30163, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3396 - precision: 0.4763 - val_loss: 1.3016 - val_precision: 0.0000e+00\n",
      "Epoch 10/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3367 - precision: 0.5128\n",
      "Epoch 10: val_loss improved from 1.30163 to 1.29929, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3373 - precision: 0.5145 - val_loss: 1.2993 - val_precision: 0.6910\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.3301 - precision: 0.5072\n",
      "Epoch 11: val_loss improved from 1.29929 to 1.28935, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3301 - precision: 0.5071 - val_loss: 1.2894 - val_precision: 0.6995\n",
      "Epoch 12/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.3329 - precision: 0.5275\n",
      "Epoch 12: val_loss did not improve from 1.28935\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3322 - precision: 0.5299 - val_loss: 1.2909 - val_precision: 0.6554\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3196 - precision: 0.5366\n",
      "Epoch 13: val_loss improved from 1.28935 to 1.28386, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3207 - precision: 0.5337 - val_loss: 1.2839 - val_precision: 0.6509\n",
      "Epoch 14/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3179 - precision: 0.5489\n",
      "Epoch 14: val_loss did not improve from 1.28386\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3198 - precision: 0.5465 - val_loss: 1.2894 - val_precision: 0.6468\n",
      "Epoch 15/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.3129 - precision: 0.5413\n",
      "Epoch 15: val_loss improved from 1.28386 to 1.27454, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3147 - precision: 0.5383 - val_loss: 1.2745 - val_precision: 0.6530\n",
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3060 - precision: 0.5623\n",
      "Epoch 16: val_loss did not improve from 1.27454\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3073 - precision: 0.5614 - val_loss: 1.2815 - val_precision: 0.6579\n",
      "Epoch 17/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.3099 - precision: 0.5993\n",
      "Epoch 17: val_loss did not improve from 1.27454\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3082 - precision: 0.5982 - val_loss: 1.2755 - val_precision: 0.6505\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.3053 - precision: 0.5581\n",
      "Epoch 18: val_loss improved from 1.27454 to 1.27019, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3049 - precision: 0.5589 - val_loss: 1.2702 - val_precision: 0.6568\n",
      "Epoch 19/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3005 - precision: 0.5761\n",
      "Epoch 19: val_loss improved from 1.27019 to 1.26935, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3012 - precision: 0.5768 - val_loss: 1.2694 - val_precision: 0.6659\n",
      "Epoch 20/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3030 - precision: 0.6114\n",
      "Epoch 20: val_loss improved from 1.26935 to 1.26480, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3023 - precision: 0.6124 - val_loss: 1.2648 - val_precision: 0.6581\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2926 - precision: 0.6091\n",
      "Epoch 21: val_loss did not improve from 1.26480\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2912 - precision: 0.6102 - val_loss: 1.2688 - val_precision: 0.6477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2941 - precision: 0.6022\n",
      "Epoch 22: val_loss did not improve from 1.26480\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2937 - precision: 0.6025 - val_loss: 1.2730 - val_precision: 0.6643\n",
      "Epoch 23/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2975 - precision: 0.5912\n",
      "Epoch 23: val_loss improved from 1.26480 to 1.26224, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2980 - precision: 0.5921 - val_loss: 1.2622 - val_precision: 0.6597\n",
      "Epoch 24/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2963 - precision: 0.5856\n",
      "Epoch 24: val_loss did not improve from 1.26224\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2945 - precision: 0.5843 - val_loss: 1.2659 - val_precision: 0.6628\n",
      "Epoch 25/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2882 - precision: 0.6080\n",
      "Epoch 25: val_loss did not improve from 1.26224\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2875 - precision: 0.6086 - val_loss: 1.2667 - val_precision: 0.6580\n",
      "Epoch 26/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2800 - precision: 0.5992\n",
      "Epoch 26: val_loss improved from 1.26224 to 1.26117, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2807 - precision: 0.6002 - val_loss: 1.2612 - val_precision: 0.6636\n",
      "Epoch 27/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2946 - precision: 0.6017\n",
      "Epoch 27: val_loss improved from 1.26117 to 1.25579, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2925 - precision: 0.6010 - val_loss: 1.2558 - val_precision: 0.6605\n",
      "Epoch 28/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2706 - precision: 0.6086\n",
      "Epoch 28: val_loss did not improve from 1.25579\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2722 - precision: 0.6066 - val_loss: 1.2624 - val_precision: 0.6578\n",
      "Epoch 29/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2800 - precision: 0.6099\n",
      "Epoch 29: val_loss did not improve from 1.25579\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2799 - precision: 0.6087 - val_loss: 1.2648 - val_precision: 0.6519\n",
      "Epoch 30/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2870 - precision: 0.6081\n",
      "Epoch 30: val_loss improved from 1.25579 to 1.25244, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2839 - precision: 0.6109 - val_loss: 1.2524 - val_precision: 0.6606\n",
      "Epoch 31/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2831 - precision: 0.6261\n",
      "Epoch 31: val_loss did not improve from 1.25244\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2818 - precision: 0.6271 - val_loss: 1.2552 - val_precision: 0.6731\n",
      "Epoch 32/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2767 - precision: 0.6108\n",
      "Epoch 32: val_loss did not improve from 1.25244\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2771 - precision: 0.6115 - val_loss: 1.2543 - val_precision: 0.6605\n",
      "Epoch 33/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2904 - precision: 0.6245\n",
      "Epoch 33: val_loss improved from 1.25244 to 1.25241, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2877 - precision: 0.6252 - val_loss: 1.2524 - val_precision: 0.6659\n",
      "Epoch 34/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2750 - precision: 0.6059\n",
      "Epoch 34: val_loss improved from 1.25241 to 1.24998, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2746 - precision: 0.6060 - val_loss: 1.2500 - val_precision: 0.6637\n",
      "Epoch 35/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2834 - precision: 0.6064\n",
      "Epoch 35: val_loss improved from 1.24998 to 1.24705, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2828 - precision: 0.6094 - val_loss: 1.2471 - val_precision: 0.6667\n",
      "Epoch 36/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2738 - precision: 0.6116\n",
      "Epoch 36: val_loss did not improve from 1.24705\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2763 - precision: 0.6100 - val_loss: 1.2508 - val_precision: 0.6659\n",
      "Epoch 37/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2735 - precision: 0.6197\n",
      "Epoch 37: val_loss did not improve from 1.24705\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2715 - precision: 0.6183 - val_loss: 1.2907 - val_precision: 0.6767\n",
      "Epoch 38/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2810 - precision: 0.6051\n",
      "Epoch 38: val_loss did not improve from 1.24705\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2793 - precision: 0.6062 - val_loss: 1.2486 - val_precision: 0.6594\n",
      "Epoch 39/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2698 - precision: 0.6288\n",
      "Epoch 39: val_loss did not improve from 1.24705\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2697 - precision: 0.6295 - val_loss: 1.2473 - val_precision: 0.6584\n",
      "Epoch 40/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2742 - precision: 0.6360\n",
      "Epoch 40: val_loss improved from 1.24705 to 1.24256, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2753 - precision: 0.6417 - val_loss: 1.2426 - val_precision: 0.6651\n",
      "Epoch 41/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2690 - precision: 0.6361\n",
      "Epoch 41: val_loss improved from 1.24256 to 1.24223, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2693 - precision: 0.6337 - val_loss: 1.2422 - val_precision: 0.6577\n",
      "Epoch 42/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2791 - precision: 0.6312\n",
      "Epoch 42: val_loss did not improve from 1.24223\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2764 - precision: 0.6323 - val_loss: 1.2485 - val_precision: 0.6691\n",
      "Epoch 43/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2654 - precision: 0.6089\n",
      "Epoch 43: val_loss improved from 1.24223 to 1.23707, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2668 - precision: 0.6099 - val_loss: 1.2371 - val_precision: 0.6621\n",
      "Epoch 44/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2669 - precision: 0.6286\n",
      "Epoch 44: val_loss did not improve from 1.23707\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2669 - precision: 0.6286 - val_loss: 1.2536 - val_precision: 0.6742\n",
      "Epoch 45/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2649 - precision: 0.6301\n",
      "Epoch 45: val_loss did not improve from 1.23707\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2649 - precision: 0.6301 - val_loss: 1.2441 - val_precision: 0.6581\n",
      "Epoch 46/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2623 - precision: 0.6176\n",
      "Epoch 46: val_loss did not improve from 1.23707\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2627 - precision: 0.6171 - val_loss: 1.2407 - val_precision: 0.6552\n",
      "Epoch 47/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2717 - precision: 0.6090\n",
      "Epoch 47: val_loss did not improve from 1.23707\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2701 - precision: 0.6107 - val_loss: 1.2442 - val_precision: 0.6599\n",
      "Epoch 48/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2588 - precision: 0.5982\n",
      "Epoch 48: val_loss did not improve from 1.23707\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2620 - precision: 0.5981 - val_loss: 1.2464 - val_precision: 0.6612\n",
      "Epoch 49/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2527 - precision: 0.5840\n",
      "Epoch 49: val_loss did not improve from 1.23707\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2523 - precision: 0.5870 - val_loss: 1.2456 - val_precision: 0.6549\n",
      "Epoch 50/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2636 - precision: 0.5732\n",
      "Epoch 50: val_loss did not improve from 1.23707\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2641 - precision: 0.5722 - val_loss: 1.2421 - val_precision: 0.6629\n",
      "Epoch 51/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2674 - precision: 0.5856\n",
      "Epoch 51: val_loss did not improve from 1.23707\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2672 - precision: 0.5879 - val_loss: 1.2375 - val_precision: 0.6629\n",
      "Epoch 52/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2606 - precision: 0.5753\n",
      "Epoch 52: val_loss did not improve from 1.23707\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2669 - precision: 0.5724 - val_loss: 1.2382 - val_precision: 0.6576\n",
      "Epoch 53/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2644 - precision: 0.5747\n",
      "Epoch 53: val_loss improved from 1.23707 to 1.23637, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2652 - precision: 0.5743 - val_loss: 1.2364 - val_precision: 0.6579\n",
      "Epoch 54/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2622 - precision: 0.5824\n",
      "Epoch 54: val_loss did not improve from 1.23637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2621 - precision: 0.5824 - val_loss: 1.2413 - val_precision: 0.6442\n",
      "Epoch 55/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2610 - precision: 0.5803\n",
      "Epoch 55: val_loss did not improve from 1.23637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2596 - precision: 0.5835 - val_loss: 1.2399 - val_precision: 0.6547\n",
      "Epoch 56/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2526 - precision: 0.5714\n",
      "Epoch 56: val_loss did not improve from 1.23637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2519 - precision: 0.5754 - val_loss: 1.2394 - val_precision: 0.6594\n",
      "Epoch 57/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2660 - precision: 0.5678\n",
      "Epoch 57: val_loss did not improve from 1.23637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2668 - precision: 0.5668 - val_loss: 1.2513 - val_precision: 0.6635\n",
      "Epoch 58/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2651 - precision: 0.5783\n",
      "Epoch 58: val_loss improved from 1.23637 to 1.23606, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2657 - precision: 0.5779 - val_loss: 1.2361 - val_precision: 0.6534\n",
      "Epoch 59/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2609 - precision: 0.5911\n",
      "Epoch 59: val_loss did not improve from 1.23606\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2600 - precision: 0.5910 - val_loss: 1.2423 - val_precision: 0.6732\n",
      "Epoch 60/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2646 - precision: 0.5976\n",
      "Epoch 60: val_loss improved from 1.23606 to 1.23262, saving model to model_ent3.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2637 - precision: 0.5954 - val_loss: 1.2326 - val_precision: 0.6533\n",
      "Epoch 61/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2638 - precision: 0.5786\n",
      "Epoch 61: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2652 - precision: 0.5795 - val_loss: 1.2329 - val_precision: 0.6595\n",
      "Epoch 62/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2623 - precision: 0.5578\n",
      "Epoch 62: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2629 - precision: 0.5567 - val_loss: 1.2411 - val_precision: 0.6556\n",
      "Epoch 63/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2742 - precision: 0.5635\n",
      "Epoch 63: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2742 - precision: 0.5634 - val_loss: 1.2334 - val_precision: 0.6577\n",
      "Epoch 64/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2575 - precision: 0.5810\n",
      "Epoch 64: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2571 - precision: 0.5780 - val_loss: 1.2440 - val_precision: 0.6636\n",
      "Epoch 65/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2544 - precision: 0.5588\n",
      "Epoch 65: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2549 - precision: 0.5593 - val_loss: 1.2388 - val_precision: 0.6535\n",
      "Epoch 66/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2521 - precision: 0.5560\n",
      "Epoch 66: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2528 - precision: 0.5562 - val_loss: 1.2397 - val_precision: 0.6518\n",
      "Epoch 67/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2625 - precision: 0.5533\n",
      "Epoch 67: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2625 - precision: 0.5533 - val_loss: 1.2371 - val_precision: 0.6536\n",
      "Epoch 68/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2481 - precision: 0.5718\n",
      "Epoch 68: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2475 - precision: 0.5715 - val_loss: 1.2452 - val_precision: 0.6475\n",
      "Epoch 69/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2515 - precision: 0.5470\n",
      "Epoch 69: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2511 - precision: 0.5470 - val_loss: 1.2398 - val_precision: 0.6448\n",
      "Epoch 70/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2543 - precision: 0.5418\n",
      "Epoch 70: val_loss did not improve from 1.23262\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2519 - precision: 0.5436 - val_loss: 1.2429 - val_precision: 0.6480\n",
      "Epoch 70: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.2218 - precision: 0.6461\n",
      "Combinación 2 = (True, True, True, 8, 0.5) \n",
      " precision train: [1.221777081489563, 0.6460788249969482]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 4: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.5017 - precision: 0.6220\n",
      "Epoch 1: val_loss improved from inf to 1.34201, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.5017 - precision: 0.6220 - val_loss: 1.3420 - val_precision: 0.6675\n",
      "Epoch 2/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2496 - precision: 0.5674\n",
      "Epoch 2: val_loss improved from 1.34201 to 1.24696, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2504 - precision: 0.5680 - val_loss: 1.2470 - val_precision: 0.6637\n",
      "Epoch 3/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1761 - precision: 0.5486\n",
      "Epoch 3: val_loss improved from 1.24696 to 1.19840, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1771 - precision: 0.5488 - val_loss: 1.1984 - val_precision: 0.5708\n",
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1246 - precision: 0.5366\n",
      "Epoch 4: val_loss improved from 1.19840 to 1.13911, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1232 - precision: 0.5377 - val_loss: 1.1391 - val_precision: 0.5968\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0676 - precision: 0.5779\n",
      "Epoch 5: val_loss improved from 1.13911 to 1.10535, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0664 - precision: 0.5768 - val_loss: 1.1054 - val_precision: 0.5905\n",
      "Epoch 6/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0368 - precision: 0.5872\n",
      "Epoch 6: val_loss improved from 1.10535 to 1.09802, saving model to model_ent4.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0336 - precision: 0.5884 - val_loss: 1.0980 - val_precision: 0.5911\n",
      "Epoch 7/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0226 - precision: 0.5876\n",
      "Epoch 7: val_loss improved from 1.09802 to 1.07582, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0211 - precision: 0.5885 - val_loss: 1.0758 - val_precision: 0.6073\n",
      "Epoch 8/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0044 - precision: 0.5963\n",
      "Epoch 8: val_loss did not improve from 1.07582\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0065 - precision: 0.5949 - val_loss: 1.0850 - val_precision: 0.6007\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0023 - precision: 0.5979\n",
      "Epoch 9: val_loss improved from 1.07582 to 1.07211, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0033 - precision: 0.5976 - val_loss: 1.0721 - val_precision: 0.6075\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9975 - precision: 0.6020\n",
      "Epoch 10: val_loss improved from 1.07211 to 1.05811, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9954 - precision: 0.6023 - val_loss: 1.0581 - val_precision: 0.6138\n",
      "Epoch 11/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9932 - precision: 0.6034\n",
      "Epoch 11: val_loss improved from 1.05811 to 1.05497, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9899 - precision: 0.6051 - val_loss: 1.0550 - val_precision: 0.6190\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9883 - precision: 0.6044\n",
      "Epoch 12: val_loss did not improve from 1.05497\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9899 - precision: 0.6032 - val_loss: 1.0620 - val_precision: 0.6172\n",
      "Epoch 13/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9773 - precision: 0.6088\n",
      "Epoch 13: val_loss did not improve from 1.05497\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9745 - precision: 0.6105 - val_loss: 1.0643 - val_precision: 0.6179\n",
      "Epoch 14/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9740 - precision: 0.6119\n",
      "Epoch 14: val_loss did not improve from 1.05497\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9745 - precision: 0.6118 - val_loss: 1.0594 - val_precision: 0.6185\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9697 - precision: 0.6110\n",
      "Epoch 15: val_loss did not improve from 1.05497\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9705 - precision: 0.6095 - val_loss: 1.0560 - val_precision: 0.6193\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9655 - precision: 0.6110\n",
      "Epoch 16: val_loss did not improve from 1.05497\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9649 - precision: 0.6108 - val_loss: 1.0564 - val_precision: 0.6253\n",
      "Epoch 17/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9612 - precision: 0.6137\n",
      "Epoch 17: val_loss did not improve from 1.05497\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9625 - precision: 0.6148 - val_loss: 1.0591 - val_precision: 0.6184\n",
      "Epoch 18/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9604 - precision: 0.6090\n",
      "Epoch 18: val_loss improved from 1.05497 to 1.05325, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9592 - precision: 0.6097 - val_loss: 1.0533 - val_precision: 0.6166\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9534 - precision: 0.6103\n",
      "Epoch 19: val_loss improved from 1.05325 to 1.04704, saving model to model_ent4.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9550 - precision: 0.6107 - val_loss: 1.0470 - val_precision: 0.6186\n",
      "Epoch 20/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9488 - precision: 0.6195\n",
      "Epoch 20: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9483 - precision: 0.6174 - val_loss: 1.0510 - val_precision: 0.6119\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9466 - precision: 0.6143\n",
      "Epoch 21: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9457 - precision: 0.6146 - val_loss: 1.0695 - val_precision: 0.6091\n",
      "Epoch 22/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9408 - precision: 0.6152\n",
      "Epoch 22: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9430 - precision: 0.6150 - val_loss: 1.0698 - val_precision: 0.5984\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9341 - precision: 0.6134\n",
      "Epoch 23: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9338 - precision: 0.6146 - val_loss: 1.0561 - val_precision: 0.6152\n",
      "Epoch 24/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9308 - precision: 0.6170\n",
      "Epoch 24: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9321 - precision: 0.6158 - val_loss: 1.0616 - val_precision: 0.6053\n",
      "Epoch 25/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9289 - precision: 0.6135\n",
      "Epoch 25: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9278 - precision: 0.6134 - val_loss: 1.0506 - val_precision: 0.6076\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9251 - precision: 0.6239\n",
      "Epoch 26: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9251 - precision: 0.6239 - val_loss: 1.0681 - val_precision: 0.6022\n",
      "Epoch 27/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9250 - precision: 0.6210\n",
      "Epoch 27: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9225 - precision: 0.6213 - val_loss: 1.0552 - val_precision: 0.6115\n",
      "Epoch 28/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9131 - precision: 0.6262\n",
      "Epoch 28: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9146 - precision: 0.6253 - val_loss: 1.0712 - val_precision: 0.5977\n",
      "Epoch 29/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9069 - precision: 0.6226\n",
      "Epoch 29: val_loss did not improve from 1.04704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9068 - precision: 0.6214 - val_loss: 1.0512 - val_precision: 0.6130\n",
      "Epoch 29: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9840 - precision: 0.6320\n",
      "Combinación 3 = (True, True, True, 16, 0.1) \n",
      " precision train: [0.9840189218521118, 0.6319738030433655]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 5: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.5125 - precision: 0.6250\n",
      "Epoch 1: val_loss improved from inf to 1.38330, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 7s 10ms/step - loss: 1.5111 - precision: 0.5789 - val_loss: 1.3833 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.3371 - precision: 0.5316\n",
      "Epoch 2: val_loss improved from 1.38330 to 1.32883, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3364 - precision: 0.5276 - val_loss: 1.3288 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2929 - precision: 0.5687\n",
      "Epoch 3: val_loss improved from 1.32883 to 1.28428, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2932 - precision: 0.5695 - val_loss: 1.2843 - val_precision: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2533 - precision: 0.6329\n",
      "Epoch 4: val_loss improved from 1.28428 to 1.24446, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2541 - precision: 0.6336 - val_loss: 1.2445 - val_precision: 0.6732\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2238 - precision: 0.6421\n",
      "Epoch 5: val_loss improved from 1.24446 to 1.21967, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2235 - precision: 0.6431 - val_loss: 1.2197 - val_precision: 0.7053\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2035 - precision: 0.6684\n",
      "Epoch 6: val_loss improved from 1.21967 to 1.19068, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2029 - precision: 0.6680 - val_loss: 1.1907 - val_precision: 0.6901\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1871 - precision: 0.6712\n",
      "Epoch 7: val_loss improved from 1.19068 to 1.18041, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1851 - precision: 0.6709 - val_loss: 1.1804 - val_precision: 0.6972\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1660 - precision: 0.6528\n",
      "Epoch 8: val_loss improved from 1.18041 to 1.17564, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1659 - precision: 0.6525 - val_loss: 1.1756 - val_precision: 0.6929\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1526 - precision: 0.6291\n",
      "Epoch 9: val_loss improved from 1.17564 to 1.17482, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1525 - precision: 0.6288 - val_loss: 1.1748 - val_precision: 0.6340\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1307 - precision: 0.6146\n",
      "Epoch 10: val_loss improved from 1.17482 to 1.15830, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1323 - precision: 0.6149 - val_loss: 1.1583 - val_precision: 0.6328\n",
      "Epoch 11/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1255 - precision: 0.6064\n",
      "Epoch 11: val_loss improved from 1.15830 to 1.15305, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1258 - precision: 0.6047 - val_loss: 1.1530 - val_precision: 0.6169\n",
      "Epoch 12/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1120 - precision: 0.5898\n",
      "Epoch 12: val_loss improved from 1.15305 to 1.14929, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1114 - precision: 0.5903 - val_loss: 1.1493 - val_precision: 0.5953\n",
      "Epoch 13/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0944 - precision: 0.5853\n",
      "Epoch 13: val_loss improved from 1.14929 to 1.14567, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0955 - precision: 0.5861 - val_loss: 1.1457 - val_precision: 0.5993\n",
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0932 - precision: 0.5859\n",
      "Epoch 14: val_loss improved from 1.14567 to 1.13418, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0933 - precision: 0.5861 - val_loss: 1.1342 - val_precision: 0.5974\n",
      "Epoch 15/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0863 - precision: 0.5878\n",
      "Epoch 15: val_loss did not improve from 1.13418\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0882 - precision: 0.5881 - val_loss: 1.1410 - val_precision: 0.5990\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0873 - precision: 0.5871\n",
      "Epoch 16: val_loss did not improve from 1.13418\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0867 - precision: 0.5868 - val_loss: 1.1349 - val_precision: 0.6010\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0864 - precision: 0.5902\n",
      "Epoch 17: val_loss improved from 1.13418 to 1.13062, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0869 - precision: 0.5891 - val_loss: 1.1306 - val_precision: 0.5942\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0769 - precision: 0.5867\n",
      "Epoch 18: val_loss improved from 1.13062 to 1.12679, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0756 - precision: 0.5878 - val_loss: 1.1268 - val_precision: 0.5971\n",
      "Epoch 19/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0818 - precision: 0.5903\n",
      "Epoch 19: val_loss improved from 1.12679 to 1.12256, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0807 - precision: 0.5907 - val_loss: 1.1226 - val_precision: 0.5970\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0618 - precision: 0.5871\n",
      "Epoch 20: val_loss did not improve from 1.12256\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0629 - precision: 0.5873 - val_loss: 1.1342 - val_precision: 0.5866\n",
      "Epoch 21/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0507 - precision: 0.5861\n",
      "Epoch 21: val_loss improved from 1.12256 to 1.11750, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0491 - precision: 0.5878 - val_loss: 1.1175 - val_precision: 0.5965\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0537 - precision: 0.5836\n",
      "Epoch 22: val_loss did not improve from 1.11750\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0535 - precision: 0.5833 - val_loss: 1.1193 - val_precision: 0.5958\n",
      "Epoch 23/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0515 - precision: 0.5911\n",
      "Epoch 23: val_loss improved from 1.11750 to 1.11158, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0526 - precision: 0.5895 - val_loss: 1.1116 - val_precision: 0.5903\n",
      "Epoch 24/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0463 - precision: 0.5911\n",
      "Epoch 24: val_loss did not improve from 1.11158\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0463 - precision: 0.5911 - val_loss: 1.1186 - val_precision: 0.5862\n",
      "Epoch 25/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0370 - precision: 0.5926\n",
      "Epoch 25: val_loss improved from 1.11158 to 1.10954, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0387 - precision: 0.5908 - val_loss: 1.1095 - val_precision: 0.5851\n",
      "Epoch 26/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0378 - precision: 0.5855\n",
      "Epoch 26: val_loss improved from 1.10954 to 1.10019, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0372 - precision: 0.5865 - val_loss: 1.1002 - val_precision: 0.6022\n",
      "Epoch 27/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0287 - precision: 0.5892\n",
      "Epoch 27: val_loss did not improve from 1.10019\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0295 - precision: 0.5892 - val_loss: 1.1095 - val_precision: 0.5936\n",
      "Epoch 28/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0326 - precision: 0.5935\n",
      "Epoch 28: val_loss improved from 1.10019 to 1.09457, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0311 - precision: 0.5947 - val_loss: 1.0946 - val_precision: 0.6027\n",
      "Epoch 29/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0212 - precision: 0.5955\n",
      "Epoch 29: val_loss did not improve from 1.09457\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0187 - precision: 0.5969 - val_loss: 1.1029 - val_precision: 0.5943\n",
      "Epoch 30/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0193 - precision: 0.5965\n",
      "Epoch 30: val_loss did not improve from 1.09457\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0184 - precision: 0.5964 - val_loss: 1.1090 - val_precision: 0.5976\n",
      "Epoch 31/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/236 [============================>.] - ETA: 0s - loss: 1.0209 - precision: 0.5950\n",
      "Epoch 31: val_loss did not improve from 1.09457\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0205 - precision: 0.5951 - val_loss: 1.0976 - val_precision: 0.5948\n",
      "Epoch 32/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0157 - precision: 0.5981\n",
      "Epoch 32: val_loss did not improve from 1.09457\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0158 - precision: 0.5985 - val_loss: 1.1023 - val_precision: 0.5873\n",
      "Epoch 33/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0076 - precision: 0.5997\n",
      "Epoch 33: val_loss did not improve from 1.09457\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0072 - precision: 0.6013 - val_loss: 1.1234 - val_precision: 0.5823\n",
      "Epoch 34/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0176 - precision: 0.5952\n",
      "Epoch 34: val_loss did not improve from 1.09457\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0143 - precision: 0.5969 - val_loss: 1.1003 - val_precision: 0.5930\n",
      "Epoch 35/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0000 - precision: 0.6034\n",
      "Epoch 35: val_loss improved from 1.09457 to 1.09413, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0011 - precision: 0.6026 - val_loss: 1.0941 - val_precision: 0.6054\n",
      "Epoch 36/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9999 - precision: 0.6060\n",
      "Epoch 36: val_loss improved from 1.09413 to 1.09306, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0023 - precision: 0.6052 - val_loss: 1.0931 - val_precision: 0.5960\n",
      "Epoch 37/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0012 - precision: 0.6022\n",
      "Epoch 37: val_loss did not improve from 1.09306\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0006 - precision: 0.6023 - val_loss: 1.0950 - val_precision: 0.6019\n",
      "Epoch 38/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9985 - precision: 0.6055\n",
      "Epoch 38: val_loss did not improve from 1.09306\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0009 - precision: 0.6038 - val_loss: 1.1073 - val_precision: 0.5893\n",
      "Epoch 39/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9980 - precision: 0.6024\n",
      "Epoch 39: val_loss did not improve from 1.09306\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9985 - precision: 0.6016 - val_loss: 1.0932 - val_precision: 0.5975\n",
      "Epoch 40/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9923 - precision: 0.6022\n",
      "Epoch 40: val_loss did not improve from 1.09306\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9923 - precision: 0.6029 - val_loss: 1.1011 - val_precision: 0.5850\n",
      "Epoch 41/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9939 - precision: 0.6020\n",
      "Epoch 41: val_loss did not improve from 1.09306\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9914 - precision: 0.6021 - val_loss: 1.0939 - val_precision: 0.5952\n",
      "Epoch 42/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9869 - precision: 0.6084\n",
      "Epoch 42: val_loss improved from 1.09306 to 1.08825, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9877 - precision: 0.6079 - val_loss: 1.0883 - val_precision: 0.5915\n",
      "Epoch 43/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9880 - precision: 0.6053\n",
      "Epoch 43: val_loss did not improve from 1.08825\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9871 - precision: 0.6055 - val_loss: 1.0941 - val_precision: 0.5923\n",
      "Epoch 44/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9824 - precision: 0.6044\n",
      "Epoch 44: val_loss did not improve from 1.08825\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9814 - precision: 0.6060 - val_loss: 1.1107 - val_precision: 0.5785\n",
      "Epoch 45/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9718 - precision: 0.6063\n",
      "Epoch 45: val_loss improved from 1.08825 to 1.08017, saving model to model_ent5.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9710 - precision: 0.6068 - val_loss: 1.0802 - val_precision: 0.6029\n",
      "Epoch 46/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9815 - precision: 0.6027\n",
      "Epoch 46: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9819 - precision: 0.6027 - val_loss: 1.0945 - val_precision: 0.5942\n",
      "Epoch 47/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9793 - precision: 0.6067\n",
      "Epoch 47: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9780 - precision: 0.6074 - val_loss: 1.0965 - val_precision: 0.5862\n",
      "Epoch 48/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9809 - precision: 0.6105\n",
      "Epoch 48: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9813 - precision: 0.6102 - val_loss: 1.1039 - val_precision: 0.5860\n",
      "Epoch 49/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9759 - precision: 0.6082\n",
      "Epoch 49: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9759 - precision: 0.6080 - val_loss: 1.0818 - val_precision: 0.5960\n",
      "Epoch 50/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9764 - precision: 0.6047\n",
      "Epoch 50: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9764 - precision: 0.6047 - val_loss: 1.0859 - val_precision: 0.5926\n",
      "Epoch 51/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9650 - precision: 0.6083\n",
      "Epoch 51: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9642 - precision: 0.6074 - val_loss: 1.0885 - val_precision: 0.5861\n",
      "Epoch 52/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9565 - precision: 0.6128\n",
      "Epoch 52: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9566 - precision: 0.6124 - val_loss: 1.1010 - val_precision: 0.5831\n",
      "Epoch 53/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9731 - precision: 0.6058\n",
      "Epoch 53: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9725 - precision: 0.6066 - val_loss: 1.0896 - val_precision: 0.5888\n",
      "Epoch 54/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9707 - precision: 0.6080\n",
      "Epoch 54: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9705 - precision: 0.6071 - val_loss: 1.0845 - val_precision: 0.5941\n",
      "Epoch 55/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9598 - precision: 0.6094\n",
      "Epoch 55: val_loss did not improve from 1.08017\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9588 - precision: 0.6085 - val_loss: 1.0870 - val_precision: 0.5964\n",
      "Epoch 55: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0195 - precision: 0.6134\n",
      "Combinación 4 = (True, True, True, 16, 0.25) \n",
      " precision train: [1.0195062160491943, 0.6134007573127747]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 6: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.5909 - precision: 0.6000  \n",
      "Epoch 1: val_loss improved from inf to 1.40708, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 9s 11ms/step - loss: 1.5837 - precision: 0.5556 - val_loss: 1.4071 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3814 - precision: 0.5052\n",
      "Epoch 2: val_loss improved from 1.40708 to 1.34240, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.3824 - precision: 0.5014 - val_loss: 1.3424 - val_precision: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.3464 - precision: 0.4783\n",
      "Epoch 3: val_loss improved from 1.34240 to 1.31946, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.3459 - precision: 0.4798 - val_loss: 1.3195 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.3118 - precision: 0.5189\n",
      "Epoch 4: val_loss improved from 1.31946 to 1.30933, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3140 - precision: 0.5202 - val_loss: 1.3093 - val_precision: 0.0000e+00\n",
      "Epoch 5/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3154 - precision: 0.5429\n",
      "Epoch 5: val_loss improved from 1.30933 to 1.28415, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3134 - precision: 0.5450 - val_loss: 1.2842 - val_precision: 0.6742\n",
      "Epoch 6/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2982 - precision: 0.5833\n",
      "Epoch 6: val_loss improved from 1.28415 to 1.26907, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.3004 - precision: 0.5835 - val_loss: 1.2691 - val_precision: 0.6789\n",
      "Epoch 7/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2847 - precision: 0.6014\n",
      "Epoch 7: val_loss improved from 1.26907 to 1.26344, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2853 - precision: 0.5999 - val_loss: 1.2634 - val_precision: 0.6731\n",
      "Epoch 8/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2815 - precision: 0.6167\n",
      "Epoch 8: val_loss improved from 1.26344 to 1.25131, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2831 - precision: 0.6127 - val_loss: 1.2513 - val_precision: 0.6697\n",
      "Epoch 9/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2759 - precision: 0.6060\n",
      "Epoch 9: val_loss did not improve from 1.25131\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2774 - precision: 0.6055 - val_loss: 1.2522 - val_precision: 0.6765\n",
      "Epoch 10/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2614 - precision: 0.6172\n",
      "Epoch 10: val_loss improved from 1.25131 to 1.24013, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2576 - precision: 0.6213 - val_loss: 1.2401 - val_precision: 0.6623\n",
      "Epoch 11/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2557 - precision: 0.6272\n",
      "Epoch 11: val_loss improved from 1.24013 to 1.23516, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2555 - precision: 0.6271 - val_loss: 1.2352 - val_precision: 0.6652\n",
      "Epoch 12/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2489 - precision: 0.6350\n",
      "Epoch 12: val_loss improved from 1.23516 to 1.22782, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2487 - precision: 0.6345 - val_loss: 1.2278 - val_precision: 0.6659\n",
      "Epoch 13/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2413 - precision: 0.6246\n",
      "Epoch 13: val_loss did not improve from 1.22782\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2442 - precision: 0.6256 - val_loss: 1.2281 - val_precision: 0.6854\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2416 - precision: 0.6291\n",
      "Epoch 14: val_loss improved from 1.22782 to 1.22078, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2416 - precision: 0.6291 - val_loss: 1.2208 - val_precision: 0.6734\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2432 - precision: 0.6165\n",
      "Epoch 15: val_loss did not improve from 1.22078\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2432 - precision: 0.6165 - val_loss: 1.2230 - val_precision: 0.6674\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2350 - precision: 0.6309\n",
      "Epoch 16: val_loss improved from 1.22078 to 1.21232, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2360 - precision: 0.6315 - val_loss: 1.2123 - val_precision: 0.6959\n",
      "Epoch 17/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2366 - precision: 0.6224\n",
      "Epoch 17: val_loss improved from 1.21232 to 1.20781, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2337 - precision: 0.6252 - val_loss: 1.2078 - val_precision: 0.7009\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2241 - precision: 0.6409\n",
      "Epoch 18: val_loss improved from 1.20781 to 1.20144, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2249 - precision: 0.6388 - val_loss: 1.2014 - val_precision: 0.6955\n",
      "Epoch 19/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2220 - precision: 0.6372\n",
      "Epoch 19: val_loss improved from 1.20144 to 1.19234, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2218 - precision: 0.6391 - val_loss: 1.1923 - val_precision: 0.6999\n",
      "Epoch 20/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2224 - precision: 0.6283\n",
      "Epoch 20: val_loss improved from 1.19234 to 1.18361, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2216 - precision: 0.6295 - val_loss: 1.1836 - val_precision: 0.6901\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2087 - precision: 0.6331\n",
      "Epoch 21: val_loss improved from 1.18361 to 1.18152, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2086 - precision: 0.6339 - val_loss: 1.1815 - val_precision: 0.6865\n",
      "Epoch 22/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2052 - precision: 0.6267\n",
      "Epoch 22: val_loss improved from 1.18152 to 1.17718, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2044 - precision: 0.6247 - val_loss: 1.1772 - val_precision: 0.6983\n",
      "Epoch 23/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1976 - precision: 0.6259\n",
      "Epoch 23: val_loss improved from 1.17718 to 1.16759, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1971 - precision: 0.6268 - val_loss: 1.1676 - val_precision: 0.6910\n",
      "Epoch 24/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1924 - precision: 0.6149\n",
      "Epoch 24: val_loss improved from 1.16759 to 1.16044, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1943 - precision: 0.6132 - val_loss: 1.1604 - val_precision: 0.6701\n",
      "Epoch 25/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1979 - precision: 0.6037\n",
      "Epoch 25: val_loss did not improve from 1.16044\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1955 - precision: 0.6087 - val_loss: 1.1629 - val_precision: 0.6650\n",
      "Epoch 26/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1814 - precision: 0.6120\n",
      "Epoch 26: val_loss improved from 1.16044 to 1.16038, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1844 - precision: 0.6130 - val_loss: 1.1604 - val_precision: 0.6491\n",
      "Epoch 27/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1839 - precision: 0.6084\n",
      "Epoch 27: val_loss improved from 1.16038 to 1.15554, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1828 - precision: 0.6098 - val_loss: 1.1555 - val_precision: 0.6435\n",
      "Epoch 28/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1730 - precision: 0.6172\n",
      "Epoch 28: val_loss did not improve from 1.15554\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1719 - precision: 0.6181 - val_loss: 1.1577 - val_precision: 0.6293\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1705 - precision: 0.6167\n",
      "Epoch 29: val_loss improved from 1.15554 to 1.15529, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1704 - precision: 0.6172 - val_loss: 1.1553 - val_precision: 0.6301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1681 - precision: 0.6002\n",
      "Epoch 30: val_loss improved from 1.15529 to 1.14691, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1674 - precision: 0.5997 - val_loss: 1.1469 - val_precision: 0.6279\n",
      "Epoch 31/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1602 - precision: 0.5963\n",
      "Epoch 31: val_loss did not improve from 1.14691\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1593 - precision: 0.5972 - val_loss: 1.1476 - val_precision: 0.6246\n",
      "Epoch 32/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1599 - precision: 0.5957\n",
      "Epoch 32: val_loss did not improve from 1.14691\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1589 - precision: 0.5956 - val_loss: 1.1514 - val_precision: 0.6187\n",
      "Epoch 33/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1564 - precision: 0.6094\n",
      "Epoch 33: val_loss did not improve from 1.14691\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1550 - precision: 0.6099 - val_loss: 1.1484 - val_precision: 0.6223\n",
      "Epoch 34/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1667 - precision: 0.6006\n",
      "Epoch 34: val_loss improved from 1.14691 to 1.14547, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1635 - precision: 0.6013 - val_loss: 1.1455 - val_precision: 0.6295\n",
      "Epoch 35/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1610 - precision: 0.5978\n",
      "Epoch 35: val_loss improved from 1.14547 to 1.14325, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1605 - precision: 0.5982 - val_loss: 1.1433 - val_precision: 0.6212\n",
      "Epoch 36/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1475 - precision: 0.6037\n",
      "Epoch 36: val_loss did not improve from 1.14325\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1475 - precision: 0.6037 - val_loss: 1.1464 - val_precision: 0.6309\n",
      "Epoch 37/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1543 - precision: 0.5976\n",
      "Epoch 37: val_loss improved from 1.14325 to 1.13854, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1545 - precision: 0.5978 - val_loss: 1.1385 - val_precision: 0.6293\n",
      "Epoch 38/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1477 - precision: 0.6107\n",
      "Epoch 38: val_loss did not improve from 1.13854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1488 - precision: 0.6096 - val_loss: 1.1429 - val_precision: 0.6250\n",
      "Epoch 39/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1580 - precision: 0.5897\n",
      "Epoch 39: val_loss did not improve from 1.13854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1608 - precision: 0.5896 - val_loss: 1.1471 - val_precision: 0.6191\n",
      "Epoch 40/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1490 - precision: 0.5946\n",
      "Epoch 40: val_loss did not improve from 1.13854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1500 - precision: 0.5942 - val_loss: 1.1548 - val_precision: 0.6151\n",
      "Epoch 41/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1547 - precision: 0.5882\n",
      "Epoch 41: val_loss did not improve from 1.13854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1518 - precision: 0.5894 - val_loss: 1.1475 - val_precision: 0.6196\n",
      "Epoch 42/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1401 - precision: 0.5866\n",
      "Epoch 42: val_loss did not improve from 1.13854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1385 - precision: 0.5889 - val_loss: 1.1508 - val_precision: 0.6202\n",
      "Epoch 43/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1421 - precision: 0.5867\n",
      "Epoch 43: val_loss did not improve from 1.13854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1420 - precision: 0.5895 - val_loss: 1.1522 - val_precision: 0.6199\n",
      "Epoch 44/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1439 - precision: 0.5883\n",
      "Epoch 44: val_loss did not improve from 1.13854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1423 - precision: 0.5896 - val_loss: 1.1386 - val_precision: 0.6216\n",
      "Epoch 45/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1323 - precision: 0.5977\n",
      "Epoch 45: val_loss did not improve from 1.13854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1295 - precision: 0.5970 - val_loss: 1.1418 - val_precision: 0.6193\n",
      "Epoch 46/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1352 - precision: 0.5919\n",
      "Epoch 46: val_loss did not improve from 1.13854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1333 - precision: 0.5928 - val_loss: 1.1460 - val_precision: 0.6108\n",
      "Epoch 47/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1333 - precision: 0.5942\n",
      "Epoch 47: val_loss improved from 1.13854 to 1.13852, saving model to model_ent6.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1376 - precision: 0.5903 - val_loss: 1.1385 - val_precision: 0.6180\n",
      "Epoch 48/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1341 - precision: 0.5872\n",
      "Epoch 48: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1343 - precision: 0.5874 - val_loss: 1.1471 - val_precision: 0.6085\n",
      "Epoch 49/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1436 - precision: 0.5812\n",
      "Epoch 49: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1402 - precision: 0.5809 - val_loss: 1.1436 - val_precision: 0.6117\n",
      "Epoch 50/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1336 - precision: 0.5747\n",
      "Epoch 50: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1326 - precision: 0.5749 - val_loss: 1.1392 - val_precision: 0.6126\n",
      "Epoch 51/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1374 - precision: 0.5850\n",
      "Epoch 51: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1346 - precision: 0.5863 - val_loss: 1.1392 - val_precision: 0.6220\n",
      "Epoch 52/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1286 - precision: 0.5845\n",
      "Epoch 52: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1284 - precision: 0.5859 - val_loss: 1.1395 - val_precision: 0.6178\n",
      "Epoch 53/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1221 - precision: 0.5897\n",
      "Epoch 53: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1209 - precision: 0.5935 - val_loss: 1.1485 - val_precision: 0.6158\n",
      "Epoch 54/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1229 - precision: 0.5783\n",
      "Epoch 54: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1284 - precision: 0.5790 - val_loss: 1.1542 - val_precision: 0.6059\n",
      "Epoch 55/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1315 - precision: 0.5753\n",
      "Epoch 55: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1299 - precision: 0.5761 - val_loss: 1.1446 - val_precision: 0.6232\n",
      "Epoch 56/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1287 - precision: 0.5730\n",
      "Epoch 56: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1289 - precision: 0.5734 - val_loss: 1.1465 - val_precision: 0.6169\n",
      "Epoch 57/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1165 - precision: 0.5871\n",
      "Epoch 57: val_loss did not improve from 1.13852\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1173 - precision: 0.5862 - val_loss: 1.1449 - val_precision: 0.6110\n",
      "Epoch 57: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.1064 - precision: 0.6255\n",
      "Combinación 5 = (True, True, True, 16, 0.5) \n",
      " precision train: [1.1063594818115234, 0.6255031228065491]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 7: \n",
      "\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.4342 - precision: 0.5844\n",
      "Epoch 1: val_loss improved from inf to 1.30559, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 7s 10ms/step - loss: 1.4299 - precision: 0.5835 - val_loss: 1.3056 - val_precision: 0.7026\n",
      "Epoch 2/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2010 - precision: 0.6495\n",
      "Epoch 2: val_loss improved from 1.30559 to 1.14813, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2007 - precision: 0.6480 - val_loss: 1.1481 - val_precision: 0.6137\n",
      "Epoch 3/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0779 - precision: 0.5900\n",
      "Epoch 3: val_loss improved from 1.14813 to 1.11912, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0771 - precision: 0.5899 - val_loss: 1.1191 - val_precision: 0.6020\n",
      "Epoch 4/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0434 - precision: 0.5892\n",
      "Epoch 4: val_loss did not improve from 1.11912\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0440 - precision: 0.5882 - val_loss: 1.1240 - val_precision: 0.5940\n",
      "Epoch 5/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0298 - precision: 0.5934\n",
      "Epoch 5: val_loss improved from 1.11912 to 1.07499, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0293 - precision: 0.5930 - val_loss: 1.0750 - val_precision: 0.6164\n",
      "Epoch 6/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0136 - precision: 0.5985\n",
      "Epoch 6: val_loss improved from 1.07499 to 1.07247, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0127 - precision: 0.5965 - val_loss: 1.0725 - val_precision: 0.6279\n",
      "Epoch 7/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0023 - precision: 0.6048\n",
      "Epoch 7: val_loss did not improve from 1.07247\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0011 - precision: 0.6055 - val_loss: 1.0845 - val_precision: 0.6037\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9969 - precision: 0.6010\n",
      "Epoch 8: val_loss did not improve from 1.07247\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9963 - precision: 0.6010 - val_loss: 1.0760 - val_precision: 0.6206\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9822 - precision: 0.6113\n",
      "Epoch 9: val_loss improved from 1.07247 to 1.06541, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9816 - precision: 0.6117 - val_loss: 1.0654 - val_precision: 0.6180\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9722 - precision: 0.6109\n",
      "Epoch 10: val_loss did not improve from 1.06541\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9702 - precision: 0.6121 - val_loss: 1.0724 - val_precision: 0.6102\n",
      "Epoch 11/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9735 - precision: 0.6071\n",
      "Epoch 11: val_loss did not improve from 1.06541\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9728 - precision: 0.6081 - val_loss: 1.0661 - val_precision: 0.6134\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9578 - precision: 0.6112\n",
      "Epoch 12: val_loss improved from 1.06541 to 1.04701, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9566 - precision: 0.6121 - val_loss: 1.0470 - val_precision: 0.6214\n",
      "Epoch 13/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9529 - precision: 0.6159\n",
      "Epoch 13: val_loss did not improve from 1.04701\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9521 - precision: 0.6161 - val_loss: 1.0533 - val_precision: 0.6163\n",
      "Epoch 14/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9419 - precision: 0.6146\n",
      "Epoch 14: val_loss did not improve from 1.04701\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9430 - precision: 0.6138 - val_loss: 1.0598 - val_precision: 0.6083\n",
      "Epoch 15/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9373 - precision: 0.6123\n",
      "Epoch 15: val_loss did not improve from 1.04701\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9351 - precision: 0.6114 - val_loss: 1.0625 - val_precision: 0.6068\n",
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9270 - precision: 0.6165\n",
      "Epoch 16: val_loss improved from 1.04701 to 1.03204, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9287 - precision: 0.6154 - val_loss: 1.0320 - val_precision: 0.6204\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9132 - precision: 0.6143\n",
      "Epoch 17: val_loss did not improve from 1.03204\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9135 - precision: 0.6141 - val_loss: 1.0455 - val_precision: 0.6068\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9143 - precision: 0.6163\n",
      "Epoch 18: val_loss did not improve from 1.03204\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9149 - precision: 0.6162 - val_loss: 1.0418 - val_precision: 0.6070\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9006 - precision: 0.6175\n",
      "Epoch 19: val_loss improved from 1.03204 to 1.02928, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9028 - precision: 0.6166 - val_loss: 1.0293 - val_precision: 0.6170\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8962 - precision: 0.6184\n",
      "Epoch 20: val_loss improved from 1.02928 to 1.02165, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8963 - precision: 0.6183 - val_loss: 1.0216 - val_precision: 0.6224\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8887 - precision: 0.6175\n",
      "Epoch 21: val_loss did not improve from 1.02165\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8884 - precision: 0.6178 - val_loss: 1.0287 - val_precision: 0.6075\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8897 - precision: 0.6206\n",
      "Epoch 22: val_loss did not improve from 1.02165\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8890 - precision: 0.6212 - val_loss: 1.0335 - val_precision: 0.6118\n",
      "Epoch 23/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8782 - precision: 0.6181\n",
      "Epoch 23: val_loss did not improve from 1.02165\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8787 - precision: 0.6182 - val_loss: 1.0449 - val_precision: 0.6010\n",
      "Epoch 24/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8723 - precision: 0.6189\n",
      "Epoch 24: val_loss improved from 1.02165 to 1.01517, saving model to model_ent7.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8712 - precision: 0.6195 - val_loss: 1.0152 - val_precision: 0.6263\n",
      "Epoch 25/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8632 - precision: 0.6267\n",
      "Epoch 25: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8638 - precision: 0.6269 - val_loss: 1.0503 - val_precision: 0.5987\n",
      "Epoch 26/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8618 - precision: 0.6210\n",
      "Epoch 26: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8620 - precision: 0.6212 - val_loss: 1.0579 - val_precision: 0.5959\n",
      "Epoch 27/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8554 - precision: 0.6264\n",
      "Epoch 27: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8550 - precision: 0.6268 - val_loss: 1.0337 - val_precision: 0.6049\n",
      "Epoch 28/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8530 - precision: 0.6252\n",
      "Epoch 28: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8525 - precision: 0.6272 - val_loss: 1.0414 - val_precision: 0.6044\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8515 - precision: 0.6227\n",
      "Epoch 29: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8509 - precision: 0.6230 - val_loss: 1.0429 - val_precision: 0.6039\n",
      "Epoch 30/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8402 - precision: 0.6275\n",
      "Epoch 30: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8395 - precision: 0.6274 - val_loss: 1.0393 - val_precision: 0.6078\n",
      "Epoch 31/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8316 - precision: 0.6302\n",
      "Epoch 31: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8298 - precision: 0.6308 - val_loss: 1.0396 - val_precision: 0.6089\n",
      "Epoch 32/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8329 - precision: 0.6337\n",
      "Epoch 32: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8320 - precision: 0.6344 - val_loss: 1.0414 - val_precision: 0.6011\n",
      "Epoch 33/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8352 - precision: 0.6289\n",
      "Epoch 33: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8325 - precision: 0.6310 - val_loss: 1.0491 - val_precision: 0.5962\n",
      "Epoch 34/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8256 - precision: 0.6337\n",
      "Epoch 34: val_loss did not improve from 1.01517\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8259 - precision: 0.6332 - val_loss: 1.0612 - val_precision: 0.5909\n",
      "Epoch 34: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9433 - precision: 0.6279\n",
      "Combinación 6 = (True, True, True, 32, 0.1) \n",
      " precision train: [0.9433465003967285, 0.6278688311576843]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 8: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.4574 - precision: 0.5253\n",
      "Epoch 1: val_loss improved from inf to 1.31174, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.4516 - precision: 0.5241 - val_loss: 1.3117 - val_precision: 0.6250\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2770 - precision: 0.6084\n",
      "Epoch 2: val_loss improved from 1.31174 to 1.24244, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2746 - precision: 0.6102 - val_loss: 1.2424 - val_precision: 0.6862\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2302 - precision: 0.6410\n",
      "Epoch 3: val_loss improved from 1.24244 to 1.21677, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2293 - precision: 0.6436 - val_loss: 1.2168 - val_precision: 0.6779\n",
      "Epoch 4/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1996 - precision: 0.6486\n",
      "Epoch 4: val_loss improved from 1.21677 to 1.20741, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1997 - precision: 0.6462 - val_loss: 1.2074 - val_precision: 0.6947\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1763 - precision: 0.6382\n",
      "Epoch 5: val_loss improved from 1.20741 to 1.18186, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1767 - precision: 0.6382 - val_loss: 1.1819 - val_precision: 0.6429\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1340 - precision: 0.6119\n",
      "Epoch 6: val_loss improved from 1.18186 to 1.15955, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1340 - precision: 0.6119 - val_loss: 1.1596 - val_precision: 0.6188\n",
      "Epoch 7/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0960 - precision: 0.5882\n",
      "Epoch 7: val_loss improved from 1.15955 to 1.12633, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0908 - precision: 0.5903 - val_loss: 1.1263 - val_precision: 0.5846\n",
      "Epoch 8/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0651 - precision: 0.5796\n",
      "Epoch 8: val_loss did not improve from 1.12633\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0631 - precision: 0.5813 - val_loss: 1.1367 - val_precision: 0.5760\n",
      "Epoch 9/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0525 - precision: 0.5834\n",
      "Epoch 9: val_loss improved from 1.12633 to 1.10259, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0521 - precision: 0.5826 - val_loss: 1.1026 - val_precision: 0.5955\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0327 - precision: 0.5922\n",
      "Epoch 10: val_loss did not improve from 1.10259\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0327 - precision: 0.5922 - val_loss: 1.1075 - val_precision: 0.5944\n",
      "Epoch 11/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0226 - precision: 0.5921\n",
      "Epoch 11: val_loss did not improve from 1.10259\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0214 - precision: 0.5925 - val_loss: 1.1193 - val_precision: 0.5841\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0208 - precision: 0.5990\n",
      "Epoch 12: val_loss improved from 1.10259 to 1.09115, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0191 - precision: 0.5999 - val_loss: 1.0911 - val_precision: 0.6007\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0158 - precision: 0.5962\n",
      "Epoch 13: val_loss improved from 1.09115 to 1.07882, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0161 - precision: 0.5968 - val_loss: 1.0788 - val_precision: 0.6085\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0052 - precision: 0.5968\n",
      "Epoch 14: val_loss did not improve from 1.07882\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0031 - precision: 0.5980 - val_loss: 1.0867 - val_precision: 0.5974\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0015 - precision: 0.5963\n",
      "Epoch 15: val_loss did not improve from 1.07882\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0018 - precision: 0.5963 - val_loss: 1.0889 - val_precision: 0.5919\n",
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9943 - precision: 0.6029\n",
      "Epoch 16: val_loss improved from 1.07882 to 1.07577, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9940 - precision: 0.6013 - val_loss: 1.0758 - val_precision: 0.5968\n",
      "Epoch 17/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9814 - precision: 0.6041\n",
      "Epoch 17: val_loss did not improve from 1.07577\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9804 - precision: 0.6047 - val_loss: 1.0809 - val_precision: 0.5921\n",
      "Epoch 18/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9727 - precision: 0.6054\n",
      "Epoch 18: val_loss improved from 1.07577 to 1.06816, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9758 - precision: 0.6057 - val_loss: 1.0682 - val_precision: 0.6027\n",
      "Epoch 19/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9709 - precision: 0.6038\n",
      "Epoch 19: val_loss improved from 1.06816 to 1.06354, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9709 - precision: 0.6038 - val_loss: 1.0635 - val_precision: 0.6018\n",
      "Epoch 20/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9656 - precision: 0.6060\n",
      "Epoch 20: val_loss improved from 1.06354 to 1.06258, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9649 - precision: 0.6059 - val_loss: 1.0626 - val_precision: 0.5934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9600 - precision: 0.6044\n",
      "Epoch 21: val_loss improved from 1.06258 to 1.05765, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9600 - precision: 0.6044 - val_loss: 1.0577 - val_precision: 0.6014\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9515 - precision: 0.6119\n",
      "Epoch 22: val_loss did not improve from 1.05765\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9512 - precision: 0.6117 - val_loss: 1.0586 - val_precision: 0.5983\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9507 - precision: 0.6086\n",
      "Epoch 23: val_loss improved from 1.05765 to 1.05535, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9508 - precision: 0.6072 - val_loss: 1.0554 - val_precision: 0.5976\n",
      "Epoch 24/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9458 - precision: 0.6080\n",
      "Epoch 24: val_loss did not improve from 1.05535\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9472 - precision: 0.6081 - val_loss: 1.0579 - val_precision: 0.5936\n",
      "Epoch 25/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9349 - precision: 0.6105\n",
      "Epoch 25: val_loss improved from 1.05535 to 1.05286, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9354 - precision: 0.6103 - val_loss: 1.0529 - val_precision: 0.6016\n",
      "Epoch 26/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9293 - precision: 0.6099\n",
      "Epoch 26: val_loss improved from 1.05286 to 1.04973, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9305 - precision: 0.6092 - val_loss: 1.0497 - val_precision: 0.5949\n",
      "Epoch 27/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9238 - precision: 0.6111\n",
      "Epoch 27: val_loss did not improve from 1.04973\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9241 - precision: 0.6110 - val_loss: 1.0497 - val_precision: 0.5975\n",
      "Epoch 28/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9172 - precision: 0.6111\n",
      "Epoch 28: val_loss did not improve from 1.04973\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9223 - precision: 0.6095 - val_loss: 1.0667 - val_precision: 0.5880\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9228 - precision: 0.6120\n",
      "Epoch 29: val_loss did not improve from 1.04973\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9238 - precision: 0.6122 - val_loss: 1.0503 - val_precision: 0.5976\n",
      "Epoch 30/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9179 - precision: 0.6087\n",
      "Epoch 30: val_loss improved from 1.04973 to 1.04246, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9177 - precision: 0.6087 - val_loss: 1.0425 - val_precision: 0.6073\n",
      "Epoch 31/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9083 - precision: 0.6155\n",
      "Epoch 31: val_loss did not improve from 1.04246\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9080 - precision: 0.6157 - val_loss: 1.0439 - val_precision: 0.5993\n",
      "Epoch 32/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9032 - precision: 0.6108\n",
      "Epoch 32: val_loss improved from 1.04246 to 1.04227, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9068 - precision: 0.6119 - val_loss: 1.0423 - val_precision: 0.6080\n",
      "Epoch 33/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9066 - precision: 0.6141\n",
      "Epoch 33: val_loss did not improve from 1.04227\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9077 - precision: 0.6140 - val_loss: 1.0455 - val_precision: 0.6007\n",
      "Epoch 34/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9073 - precision: 0.6122\n",
      "Epoch 34: val_loss did not improve from 1.04227\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9058 - precision: 0.6119 - val_loss: 1.0437 - val_precision: 0.5968\n",
      "Epoch 35/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8992 - precision: 0.6140\n",
      "Epoch 35: val_loss did not improve from 1.04227\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8990 - precision: 0.6143 - val_loss: 1.0497 - val_precision: 0.5955\n",
      "Epoch 36/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8858 - precision: 0.6158\n",
      "Epoch 36: val_loss did not improve from 1.04227\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8866 - precision: 0.6158 - val_loss: 1.0511 - val_precision: 0.5930\n",
      "Epoch 37/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8863 - precision: 0.6188\n",
      "Epoch 37: val_loss did not improve from 1.04227\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8871 - precision: 0.6189 - val_loss: 1.0445 - val_precision: 0.5965\n",
      "Epoch 38/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8856 - precision: 0.6224\n",
      "Epoch 38: val_loss did not improve from 1.04227\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8840 - precision: 0.6224 - val_loss: 1.0520 - val_precision: 0.5955\n",
      "Epoch 39/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8828 - precision: 0.6181\n",
      "Epoch 39: val_loss did not improve from 1.04227\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8807 - precision: 0.6189 - val_loss: 1.0461 - val_precision: 0.5971\n",
      "Epoch 40/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8840 - precision: 0.6165\n",
      "Epoch 40: val_loss did not improve from 1.04227\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8833 - precision: 0.6174 - val_loss: 1.0613 - val_precision: 0.5935\n",
      "Epoch 41/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8772 - precision: 0.6190\n",
      "Epoch 41: val_loss improved from 1.04227 to 1.03386, saving model to model_ent8.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8762 - precision: 0.6196 - val_loss: 1.0339 - val_precision: 0.6113\n",
      "Epoch 42/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8789 - precision: 0.6216\n",
      "Epoch 42: val_loss did not improve from 1.03386\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8793 - precision: 0.6216 - val_loss: 1.0544 - val_precision: 0.5903\n",
      "Epoch 43/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8654 - precision: 0.6216\n",
      "Epoch 43: val_loss did not improve from 1.03386\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8680 - precision: 0.6211 - val_loss: 1.0632 - val_precision: 0.5830\n",
      "Epoch 44/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8609 - precision: 0.6259\n",
      "Epoch 44: val_loss did not improve from 1.03386\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8627 - precision: 0.6252 - val_loss: 1.0518 - val_precision: 0.5940\n",
      "Epoch 45/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8602 - precision: 0.6231\n",
      "Epoch 45: val_loss did not improve from 1.03386\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8604 - precision: 0.6245 - val_loss: 1.0796 - val_precision: 0.5810\n",
      "Epoch 46/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8618 - precision: 0.6183\n",
      "Epoch 46: val_loss did not improve from 1.03386\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8613 - precision: 0.6185 - val_loss: 1.0470 - val_precision: 0.5991\n",
      "Epoch 47/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8592 - precision: 0.6218\n",
      "Epoch 47: val_loss did not improve from 1.03386\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8597 - precision: 0.6221 - val_loss: 1.0479 - val_precision: 0.5927\n",
      "Epoch 48/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8512 - precision: 0.6241\n",
      "Epoch 48: val_loss did not improve from 1.03386\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8513 - precision: 0.6235 - val_loss: 1.0655 - val_precision: 0.5976\n",
      "Epoch 49/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8513 - precision: 0.6240\n",
      "Epoch 49: val_loss did not improve from 1.03386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8514 - precision: 0.6240 - val_loss: 1.0897 - val_precision: 0.5849\n",
      "Epoch 50/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8581 - precision: 0.6249\n",
      "Epoch 50: val_loss did not improve from 1.03386\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8571 - precision: 0.6252 - val_loss: 1.0650 - val_precision: 0.5869\n",
      "Epoch 51/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8461 - precision: 0.6285\n",
      "Epoch 51: val_loss did not improve from 1.03386\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8447 - precision: 0.6284 - val_loss: 1.0799 - val_precision: 0.5778\n",
      "Epoch 51: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9546 - precision: 0.6186\n",
      "Combinación 7 = (True, True, True, 32, 0.25) \n",
      " precision train: [0.9545841813087463, 0.618643045425415]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 9: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.5121 - precision: 0.4929\n",
      "Epoch 1: val_loss improved from inf to 1.34557, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.5121 - precision: 0.4929 - val_loss: 1.3456 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3270 - precision: 0.5006\n",
      "Epoch 2: val_loss improved from 1.34557 to 1.29758, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.3253 - precision: 0.5030 - val_loss: 1.2976 - val_precision: 0.7083\n",
      "Epoch 3/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2840 - precision: 0.5838\n",
      "Epoch 3: val_loss improved from 1.29758 to 1.25226, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2832 - precision: 0.5851 - val_loss: 1.2523 - val_precision: 0.6658\n",
      "Epoch 4/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2616 - precision: 0.6289\n",
      "Epoch 4: val_loss improved from 1.25226 to 1.22237, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2600 - precision: 0.6294 - val_loss: 1.2224 - val_precision: 0.6847\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2383 - precision: 0.6281\n",
      "Epoch 5: val_loss improved from 1.22237 to 1.21223, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2373 - precision: 0.6290 - val_loss: 1.2122 - val_precision: 0.6769\n",
      "Epoch 6/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2337 - precision: 0.6366\n",
      "Epoch 6: val_loss improved from 1.21223 to 1.19455, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2330 - precision: 0.6392 - val_loss: 1.1945 - val_precision: 0.7037\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2020 - precision: 0.6458\n",
      "Epoch 7: val_loss improved from 1.19455 to 1.17174, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2032 - precision: 0.6430 - val_loss: 1.1717 - val_precision: 0.6858\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1896 - precision: 0.6350\n",
      "Epoch 8: val_loss did not improve from 1.17174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1896 - precision: 0.6352 - val_loss: 1.1722 - val_precision: 0.6919\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1744 - precision: 0.6183\n",
      "Epoch 9: val_loss improved from 1.17174 to 1.15210, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1759 - precision: 0.6176 - val_loss: 1.1521 - val_precision: 0.6654\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1530 - precision: 0.6073\n",
      "Epoch 10: val_loss improved from 1.15210 to 1.14505, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1511 - precision: 0.6052 - val_loss: 1.1450 - val_precision: 0.6200\n",
      "Epoch 11/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1450 - precision: 0.5942\n",
      "Epoch 11: val_loss did not improve from 1.14505\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1442 - precision: 0.5937 - val_loss: 1.1524 - val_precision: 0.6133\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1313 - precision: 0.5879\n",
      "Epoch 12: val_loss improved from 1.14505 to 1.13389, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1322 - precision: 0.5879 - val_loss: 1.1339 - val_precision: 0.6329\n",
      "Epoch 13/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1237 - precision: 0.5729\n",
      "Epoch 13: val_loss improved from 1.13389 to 1.11659, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1247 - precision: 0.5739 - val_loss: 1.1166 - val_precision: 0.6078\n",
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1187 - precision: 0.5811\n",
      "Epoch 14: val_loss did not improve from 1.11659\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1185 - precision: 0.5813 - val_loss: 1.1211 - val_precision: 0.6086\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1007 - precision: 0.5962\n",
      "Epoch 15: val_loss did not improve from 1.11659\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1017 - precision: 0.5943 - val_loss: 1.1387 - val_precision: 0.5921\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1059 - precision: 0.5875\n",
      "Epoch 16: val_loss improved from 1.11659 to 1.10646, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1044 - precision: 0.5892 - val_loss: 1.1065 - val_precision: 0.6060\n",
      "Epoch 17/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0901 - precision: 0.5899\n",
      "Epoch 17: val_loss improved from 1.10646 to 1.10272, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0906 - precision: 0.5897 - val_loss: 1.1027 - val_precision: 0.6073\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0867 - precision: 0.5926\n",
      "Epoch 18: val_loss did not improve from 1.10272\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0878 - precision: 0.5926 - val_loss: 1.1063 - val_precision: 0.6065\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0678 - precision: 0.5971\n",
      "Epoch 19: val_loss improved from 1.10272 to 1.10026, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0682 - precision: 0.5967 - val_loss: 1.1003 - val_precision: 0.5978\n",
      "Epoch 20/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0749 - precision: 0.5897\n",
      "Epoch 20: val_loss improved from 1.10026 to 1.09699, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0741 - precision: 0.5907 - val_loss: 1.0970 - val_precision: 0.6048\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0584 - precision: 0.6012\n",
      "Epoch 21: val_loss did not improve from 1.09699\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0569 - precision: 0.6018 - val_loss: 1.1179 - val_precision: 0.5929\n",
      "Epoch 22/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0690 - precision: 0.5979\n",
      "Epoch 22: val_loss did not improve from 1.09699\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0690 - precision: 0.5979 - val_loss: 1.1119 - val_precision: 0.5955\n",
      "Epoch 23/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0721 - precision: 0.5996\n",
      "Epoch 23: val_loss did not improve from 1.09699\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0718 - precision: 0.5991 - val_loss: 1.1013 - val_precision: 0.6037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0580 - precision: 0.6040\n",
      "Epoch 24: val_loss did not improve from 1.09699\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0588 - precision: 0.6042 - val_loss: 1.1030 - val_precision: 0.6007\n",
      "Epoch 25/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0550 - precision: 0.6001\n",
      "Epoch 25: val_loss did not improve from 1.09699\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0569 - precision: 0.6005 - val_loss: 1.1170 - val_precision: 0.5883\n",
      "Epoch 26/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0599 - precision: 0.5993\n",
      "Epoch 26: val_loss did not improve from 1.09699\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0591 - precision: 0.5994 - val_loss: 1.1027 - val_precision: 0.5999\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0511 - precision: 0.6040\n",
      "Epoch 27: val_loss improved from 1.09699 to 1.09174, saving model to model_ent9.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0536 - precision: 0.6024 - val_loss: 1.0917 - val_precision: 0.6120\n",
      "Epoch 28/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0528 - precision: 0.6039\n",
      "Epoch 28: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0528 - precision: 0.6039 - val_loss: 1.1083 - val_precision: 0.6004\n",
      "Epoch 29/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0562 - precision: 0.6036\n",
      "Epoch 29: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0567 - precision: 0.6028 - val_loss: 1.1026 - val_precision: 0.6015\n",
      "Epoch 30/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0524 - precision: 0.6002\n",
      "Epoch 30: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0511 - precision: 0.5994 - val_loss: 1.1014 - val_precision: 0.6010\n",
      "Epoch 31/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0544 - precision: 0.6015\n",
      "Epoch 31: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0526 - precision: 0.6022 - val_loss: 1.0966 - val_precision: 0.6075\n",
      "Epoch 32/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0324 - precision: 0.6056\n",
      "Epoch 32: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0335 - precision: 0.6054 - val_loss: 1.1141 - val_precision: 0.5858\n",
      "Epoch 33/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0403 - precision: 0.5977\n",
      "Epoch 33: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0387 - precision: 0.6002 - val_loss: 1.1156 - val_precision: 0.5919\n",
      "Epoch 34/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0373 - precision: 0.6040\n",
      "Epoch 34: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0366 - precision: 0.6042 - val_loss: 1.1017 - val_precision: 0.5995\n",
      "Epoch 35/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0378 - precision: 0.5996\n",
      "Epoch 35: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0384 - precision: 0.5992 - val_loss: 1.0993 - val_precision: 0.5987\n",
      "Epoch 36/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0271 - precision: 0.6065\n",
      "Epoch 36: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0294 - precision: 0.6071 - val_loss: 1.1153 - val_precision: 0.5876\n",
      "Epoch 37/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0328 - precision: 0.6073\n",
      "Epoch 37: val_loss did not improve from 1.09174\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0317 - precision: 0.6069 - val_loss: 1.1063 - val_precision: 0.5967\n",
      "Epoch 37: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0685 - precision: 0.6067\n",
      "Combinación 8 = (True, True, True, 32, 0.5) \n",
      " precision train: [1.0684677362442017, 0.6067033410072327]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 10: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.3783 - precision: 0.6259\n",
      "Epoch 1: val_loss improved from inf to 1.24255, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.3742 - precision: 0.6329 - val_loss: 1.2425 - val_precision: 0.6835\n",
      "Epoch 2/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1346 - precision: 0.6474\n",
      "Epoch 2: val_loss improved from 1.24255 to 1.11257, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1348 - precision: 0.6461 - val_loss: 1.1126 - val_precision: 0.6584\n",
      "Epoch 3/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0338 - precision: 0.5964\n",
      "Epoch 3: val_loss improved from 1.11257 to 1.08568, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0317 - precision: 0.5961 - val_loss: 1.0857 - val_precision: 0.6098\n",
      "Epoch 4/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9955 - precision: 0.5924\n",
      "Epoch 4: val_loss did not improve from 1.08568\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9936 - precision: 0.5933 - val_loss: 1.0879 - val_precision: 0.5960\n",
      "Epoch 5/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9786 - precision: 0.5894\n",
      "Epoch 5: val_loss improved from 1.08568 to 1.07762, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9761 - precision: 0.5908 - val_loss: 1.0776 - val_precision: 0.6060\n",
      "Epoch 6/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9706 - precision: 0.5963\n",
      "Epoch 6: val_loss improved from 1.07762 to 1.05774, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9640 - precision: 0.5998 - val_loss: 1.0577 - val_precision: 0.6011\n",
      "Epoch 7/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9534 - precision: 0.6012\n",
      "Epoch 7: val_loss improved from 1.05774 to 1.05390, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9536 - precision: 0.6015 - val_loss: 1.0539 - val_precision: 0.6038\n",
      "Epoch 8/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9405 - precision: 0.6018\n",
      "Epoch 8: val_loss improved from 1.05390 to 1.04884, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9401 - precision: 0.6017 - val_loss: 1.0488 - val_precision: 0.6050\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9297 - precision: 0.6066\n",
      "Epoch 9: val_loss improved from 1.04884 to 1.03367, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9290 - precision: 0.6066 - val_loss: 1.0337 - val_precision: 0.6210\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9205 - precision: 0.6078\n",
      "Epoch 10: val_loss did not improve from 1.03367\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9220 - precision: 0.6076 - val_loss: 1.0489 - val_precision: 0.6100\n",
      "Epoch 11/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9142 - precision: 0.6046\n",
      "Epoch 11: val_loss did not improve from 1.03367\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9176 - precision: 0.6042 - val_loss: 1.0344 - val_precision: 0.6127\n",
      "Epoch 12/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9040 - precision: 0.6105\n",
      "Epoch 12: val_loss did not improve from 1.03367\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9034 - precision: 0.6120 - val_loss: 1.0367 - val_precision: 0.6092\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8952 - precision: 0.6123\n",
      "Epoch 13: val_loss did not improve from 1.03367\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8945 - precision: 0.6126 - val_loss: 1.0501 - val_precision: 0.6110\n",
      "Epoch 14/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8886 - precision: 0.6134\n",
      "Epoch 14: val_loss did not improve from 1.03367\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8884 - precision: 0.6133 - val_loss: 1.0591 - val_precision: 0.5983\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8756 - precision: 0.6187\n",
      "Epoch 15: val_loss improved from 1.03367 to 1.01800, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8779 - precision: 0.6184 - val_loss: 1.0180 - val_precision: 0.6237\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8804 - precision: 0.6169\n",
      "Epoch 16: val_loss did not improve from 1.01800\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8803 - precision: 0.6159 - val_loss: 1.0244 - val_precision: 0.6329\n",
      "Epoch 17/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8662 - precision: 0.6184\n",
      "Epoch 17: val_loss did not improve from 1.01800\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8662 - precision: 0.6192 - val_loss: 1.0262 - val_precision: 0.6080\n",
      "Epoch 18/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8554 - precision: 0.6208\n",
      "Epoch 18: val_loss did not improve from 1.01800\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8550 - precision: 0.6213 - val_loss: 1.0355 - val_precision: 0.6052\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8522 - precision: 0.6252\n",
      "Epoch 19: val_loss did not improve from 1.01800\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8525 - precision: 0.6236 - val_loss: 1.0314 - val_precision: 0.6034\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8477 - precision: 0.6225\n",
      "Epoch 20: val_loss improved from 1.01800 to 1.01191, saving model to model_ent10.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8487 - precision: 0.6227 - val_loss: 1.0119 - val_precision: 0.6200\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8375 - precision: 0.6247\n",
      "Epoch 21: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8378 - precision: 0.6238 - val_loss: 1.0348 - val_precision: 0.6016\n",
      "Epoch 22/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8329 - precision: 0.6302\n",
      "Epoch 22: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8329 - precision: 0.6302 - val_loss: 1.0569 - val_precision: 0.5990\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8269 - precision: 0.6284\n",
      "Epoch 23: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8267 - precision: 0.6286 - val_loss: 1.0457 - val_precision: 0.6006\n",
      "Epoch 24/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8156 - precision: 0.6359\n",
      "Epoch 24: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8166 - precision: 0.6360 - val_loss: 1.0386 - val_precision: 0.6106\n",
      "Epoch 25/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8143 - precision: 0.6318\n",
      "Epoch 25: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8158 - precision: 0.6318 - val_loss: 1.0414 - val_precision: 0.6058\n",
      "Epoch 26/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8127 - precision: 0.6366\n",
      "Epoch 26: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8124 - precision: 0.6369 - val_loss: 1.0502 - val_precision: 0.6026\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.7979 - precision: 0.6387\n",
      "Epoch 27: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7969 - precision: 0.6400 - val_loss: 1.0764 - val_precision: 0.5833\n",
      "Epoch 28/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.7925 - precision: 0.6409\n",
      "Epoch 28: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7925 - precision: 0.6409 - val_loss: 1.0378 - val_precision: 0.6064\n",
      "Epoch 29/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.7846 - precision: 0.6421\n",
      "Epoch 29: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7840 - precision: 0.6420 - val_loss: 1.0686 - val_precision: 0.5937\n",
      "Epoch 30/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.7790 - precision: 0.6432\n",
      "Epoch 30: val_loss did not improve from 1.01191\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7778 - precision: 0.6450 - val_loss: 1.0553 - val_precision: 0.5994\n",
      "Epoch 30: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 0.8905 - precision: 0.6469\n",
      "Combinación 9 = (True, True, True, 64, 0.1) \n",
      " precision train: [0.8904522061347961, 0.6468642950057983]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 11: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.3956 - precision: 0.5640\n",
      "Epoch 1: val_loss improved from inf to 1.20480, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 9s 11ms/step - loss: 1.3893 - precision: 0.5655 - val_loss: 1.2048 - val_precision: 0.6510\n",
      "Epoch 2/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0773 - precision: 0.6020\n",
      "Epoch 2: val_loss improved from 1.20480 to 1.08832, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0736 - precision: 0.6033 - val_loss: 1.0883 - val_precision: 0.6148\n",
      "Epoch 3/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0287 - precision: 0.5917\n",
      "Epoch 3: val_loss improved from 1.08832 to 1.08513, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0279 - precision: 0.5918 - val_loss: 1.0851 - val_precision: 0.6147\n",
      "Epoch 4/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0061 - precision: 0.5960\n",
      "Epoch 4: val_loss improved from 1.08513 to 1.06965, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0078 - precision: 0.5967 - val_loss: 1.0697 - val_precision: 0.6084\n",
      "Epoch 5/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9998 - precision: 0.6033\n",
      "Epoch 5: val_loss did not improve from 1.06965\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9966 - precision: 0.6047 - val_loss: 1.0737 - val_precision: 0.6131\n",
      "Epoch 6/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9947 - precision: 0.5975\n",
      "Epoch 6: val_loss improved from 1.06965 to 1.06110, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9949 - precision: 0.5973 - val_loss: 1.0611 - val_precision: 0.6120\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9782 - precision: 0.6023\n",
      "Epoch 7: val_loss improved from 1.06110 to 1.04682, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9775 - precision: 0.6028 - val_loss: 1.0468 - val_precision: 0.6270\n",
      "Epoch 8/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9736 - precision: 0.6021\n",
      "Epoch 8: val_loss did not improve from 1.04682\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9762 - precision: 0.6003 - val_loss: 1.0521 - val_precision: 0.6082\n",
      "Epoch 9/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9581 - precision: 0.6095\n",
      "Epoch 9: val_loss did not improve from 1.04682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9621 - precision: 0.6071 - val_loss: 1.0700 - val_precision: 0.6072\n",
      "Epoch 10/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9659 - precision: 0.6036\n",
      "Epoch 10: val_loss improved from 1.04682 to 1.04558, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9644 - precision: 0.6043 - val_loss: 1.0456 - val_precision: 0.6189\n",
      "Epoch 11/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9581 - precision: 0.6073\n",
      "Epoch 11: val_loss did not improve from 1.04558\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9586 - precision: 0.6063 - val_loss: 1.0545 - val_precision: 0.6138\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9467 - precision: 0.6052\n",
      "Epoch 12: val_loss did not improve from 1.04558\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9467 - precision: 0.6052 - val_loss: 1.0629 - val_precision: 0.6001\n",
      "Epoch 13/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9486 - precision: 0.6105\n",
      "Epoch 13: val_loss improved from 1.04558 to 1.04204, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9493 - precision: 0.6102 - val_loss: 1.0420 - val_precision: 0.6121\n",
      "Epoch 14/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9389 - precision: 0.6043\n",
      "Epoch 14: val_loss improved from 1.04204 to 1.04071, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9371 - precision: 0.6045 - val_loss: 1.0407 - val_precision: 0.6104\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9300 - precision: 0.6081\n",
      "Epoch 15: val_loss improved from 1.04071 to 1.02464, saving model to model_ent11.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9308 - precision: 0.6076 - val_loss: 1.0246 - val_precision: 0.6215\n",
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9259 - precision: 0.6100\n",
      "Epoch 16: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9258 - precision: 0.6103 - val_loss: 1.0377 - val_precision: 0.6188\n",
      "Epoch 17/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9222 - precision: 0.6130\n",
      "Epoch 17: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9215 - precision: 0.6146 - val_loss: 1.0493 - val_precision: 0.6055\n",
      "Epoch 18/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9138 - precision: 0.6134\n",
      "Epoch 18: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9138 - precision: 0.6134 - val_loss: 1.0566 - val_precision: 0.6181\n",
      "Epoch 19/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9072 - precision: 0.6166\n",
      "Epoch 19: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9064 - precision: 0.6161 - val_loss: 1.0485 - val_precision: 0.6079\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8999 - precision: 0.6130\n",
      "Epoch 20: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9008 - precision: 0.6135 - val_loss: 1.0411 - val_precision: 0.6097\n",
      "Epoch 21/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8950 - precision: 0.6206\n",
      "Epoch 21: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8962 - precision: 0.6197 - val_loss: 1.0368 - val_precision: 0.6078\n",
      "Epoch 22/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8899 - precision: 0.6129\n",
      "Epoch 22: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8918 - precision: 0.6127 - val_loss: 1.0544 - val_precision: 0.6051\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8970 - precision: 0.6186\n",
      "Epoch 23: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8964 - precision: 0.6193 - val_loss: 1.0295 - val_precision: 0.6156\n",
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8829 - precision: 0.6161\n",
      "Epoch 24: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8820 - precision: 0.6168 - val_loss: 1.0393 - val_precision: 0.6199\n",
      "Epoch 25/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8803 - precision: 0.6197\n",
      "Epoch 25: val_loss did not improve from 1.02464\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8791 - precision: 0.6199 - val_loss: 1.0452 - val_precision: 0.6110\n",
      "Epoch 25: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 0.9734 - precision: 0.6236\n",
      "Combinación 10 = (True, True, True, 64, 0.25) \n",
      " precision train: [0.9734463095664978, 0.6235691905021667]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 12: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.4576 - precision: 0.5114\n",
      "Epoch 1: val_loss improved from inf to 1.30616, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 10s 11ms/step - loss: 1.4548 - precision: 0.5139 - val_loss: 1.3062 - val_precision: 0.6758\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2761 - precision: 0.5707\n",
      "Epoch 2: val_loss improved from 1.30616 to 1.27346, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2750 - precision: 0.5724 - val_loss: 1.2735 - val_precision: 0.6968\n",
      "Epoch 3/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2287 - precision: 0.5842\n",
      "Epoch 3: val_loss improved from 1.27346 to 1.23110, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2289 - precision: 0.5790 - val_loss: 1.2311 - val_precision: 0.6060\n",
      "Epoch 4/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1768 - precision: 0.5646\n",
      "Epoch 4: val_loss improved from 1.23110 to 1.13803, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1770 - precision: 0.5647 - val_loss: 1.1380 - val_precision: 0.6198\n",
      "Epoch 5/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0795 - precision: 0.5992\n",
      "Epoch 5: val_loss improved from 1.13803 to 1.09133, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0790 - precision: 0.5972 - val_loss: 1.0913 - val_precision: 0.5979\n",
      "Epoch 6/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0632 - precision: 0.5895\n",
      "Epoch 6: val_loss improved from 1.09133 to 1.08282, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0580 - precision: 0.5897 - val_loss: 1.0828 - val_precision: 0.6026\n",
      "Epoch 7/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0437 - precision: 0.5954\n",
      "Epoch 7: val_loss improved from 1.08282 to 1.06846, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0417 - precision: 0.5950 - val_loss: 1.0685 - val_precision: 0.6095\n",
      "Epoch 8/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0335 - precision: 0.6000\n",
      "Epoch 8: val_loss did not improve from 1.06846\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0300 - precision: 0.5998 - val_loss: 1.0755 - val_precision: 0.6043\n",
      "Epoch 9/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0209 - precision: 0.6009\n",
      "Epoch 9: val_loss did not improve from 1.06846\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0208 - precision: 0.6005 - val_loss: 1.0693 - val_precision: 0.6049\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0231 - precision: 0.5943\n",
      "Epoch 10: val_loss improved from 1.06846 to 1.05838, saving model to model_ent12.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0236 - precision: 0.5950 - val_loss: 1.0584 - val_precision: 0.6087\n",
      "Epoch 11/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0070 - precision: 0.6003\n",
      "Epoch 11: val_loss improved from 1.05838 to 1.05777, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0092 - precision: 0.6003 - val_loss: 1.0578 - val_precision: 0.6083\n",
      "Epoch 12/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0138 - precision: 0.5983\n",
      "Epoch 12: val_loss did not improve from 1.05777\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0140 - precision: 0.5984 - val_loss: 1.0777 - val_precision: 0.6038\n",
      "Epoch 13/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0056 - precision: 0.5980\n",
      "Epoch 13: val_loss improved from 1.05777 to 1.05608, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0065 - precision: 0.5976 - val_loss: 1.0561 - val_precision: 0.6093\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0006 - precision: 0.5966\n",
      "Epoch 14: val_loss did not improve from 1.05608\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0003 - precision: 0.5967 - val_loss: 1.0642 - val_precision: 0.6090\n",
      "Epoch 15/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9924 - precision: 0.6003\n",
      "Epoch 15: val_loss improved from 1.05608 to 1.05207, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9925 - precision: 0.6013 - val_loss: 1.0521 - val_precision: 0.6163\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9848 - precision: 0.6080\n",
      "Epoch 16: val_loss did not improve from 1.05207\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9850 - precision: 0.6081 - val_loss: 1.0748 - val_precision: 0.5978\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9839 - precision: 0.6066\n",
      "Epoch 17: val_loss did not improve from 1.05207\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9838 - precision: 0.6072 - val_loss: 1.0596 - val_precision: 0.6104\n",
      "Epoch 18/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9818 - precision: 0.5968\n",
      "Epoch 18: val_loss did not improve from 1.05207\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9818 - precision: 0.5968 - val_loss: 1.0585 - val_precision: 0.6040\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9821 - precision: 0.6018\n",
      "Epoch 19: val_loss did not improve from 1.05207\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9816 - precision: 0.6019 - val_loss: 1.0587 - val_precision: 0.6097\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9767 - precision: 0.6081\n",
      "Epoch 20: val_loss did not improve from 1.05207\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9761 - precision: 0.6086 - val_loss: 1.0649 - val_precision: 0.6027\n",
      "Epoch 21/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9823 - precision: 0.5978\n",
      "Epoch 21: val_loss improved from 1.05207 to 1.04669, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9797 - precision: 0.5993 - val_loss: 1.0467 - val_precision: 0.6142\n",
      "Epoch 22/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9784 - precision: 0.6047\n",
      "Epoch 22: val_loss did not improve from 1.04669\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9804 - precision: 0.6021 - val_loss: 1.0496 - val_precision: 0.6047\n",
      "Epoch 23/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9675 - precision: 0.6044\n",
      "Epoch 23: val_loss did not improve from 1.04669\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9678 - precision: 0.6040 - val_loss: 1.0744 - val_precision: 0.5988\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9673 - precision: 0.6054\n",
      "Epoch 24: val_loss did not improve from 1.04669\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9678 - precision: 0.6049 - val_loss: 1.0517 - val_precision: 0.6087\n",
      "Epoch 25/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9712 - precision: 0.6075\n",
      "Epoch 25: val_loss improved from 1.04669 to 1.04425, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9682 - precision: 0.6080 - val_loss: 1.0443 - val_precision: 0.6095\n",
      "Epoch 26/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9540 - precision: 0.6076\n",
      "Epoch 26: val_loss did not improve from 1.04425\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9538 - precision: 0.6086 - val_loss: 1.0479 - val_precision: 0.6093\n",
      "Epoch 27/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9510 - precision: 0.6070\n",
      "Epoch 27: val_loss did not improve from 1.04425\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9519 - precision: 0.6058 - val_loss: 1.0445 - val_precision: 0.6089\n",
      "Epoch 28/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9560 - precision: 0.6091\n",
      "Epoch 28: val_loss did not improve from 1.04425\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9562 - precision: 0.6092 - val_loss: 1.0503 - val_precision: 0.6040\n",
      "Epoch 29/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9462 - precision: 0.6093\n",
      "Epoch 29: val_loss did not improve from 1.04425\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9475 - precision: 0.6088 - val_loss: 1.0637 - val_precision: 0.5974\n",
      "Epoch 30/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9518 - precision: 0.6040\n",
      "Epoch 30: val_loss improved from 1.04425 to 1.03901, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9504 - precision: 0.6027 - val_loss: 1.0390 - val_precision: 0.6055\n",
      "Epoch 31/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9349 - precision: 0.6119\n",
      "Epoch 31: val_loss did not improve from 1.03901\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9352 - precision: 0.6109 - val_loss: 1.0439 - val_precision: 0.6018\n",
      "Epoch 32/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9345 - precision: 0.6093\n",
      "Epoch 32: val_loss did not improve from 1.03901\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9340 - precision: 0.6095 - val_loss: 1.0442 - val_precision: 0.5991\n",
      "Epoch 33/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9323 - precision: 0.6103\n",
      "Epoch 33: val_loss did not improve from 1.03901\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9323 - precision: 0.6103 - val_loss: 1.0540 - val_precision: 0.5905\n",
      "Epoch 34/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9346 - precision: 0.6105\n",
      "Epoch 34: val_loss did not improve from 1.03901\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9337 - precision: 0.6104 - val_loss: 1.0435 - val_precision: 0.6043\n",
      "Epoch 35/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9336 - precision: 0.6093\n",
      "Epoch 35: val_loss improved from 1.03901 to 1.03748, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9336 - precision: 0.6088 - val_loss: 1.0375 - val_precision: 0.6022\n",
      "Epoch 36/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9224 - precision: 0.6156\n",
      "Epoch 36: val_loss did not improve from 1.03748\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9224 - precision: 0.6156 - val_loss: 1.0607 - val_precision: 0.5993\n",
      "Epoch 37/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9143 - precision: 0.6129\n",
      "Epoch 37: val_loss did not improve from 1.03748\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9179 - precision: 0.6107 - val_loss: 1.0620 - val_precision: 0.5923\n",
      "Epoch 38/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9269 - precision: 0.6152\n",
      "Epoch 38: val_loss improved from 1.03748 to 1.03668, saving model to model_ent12.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9275 - precision: 0.6152 - val_loss: 1.0367 - val_precision: 0.6013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9293 - precision: 0.6099\n",
      "Epoch 39: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9293 - precision: 0.6099 - val_loss: 1.0519 - val_precision: 0.5941\n",
      "Epoch 40/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9181 - precision: 0.6111\n",
      "Epoch 40: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9131 - precision: 0.6117 - val_loss: 1.0575 - val_precision: 0.5914\n",
      "Epoch 41/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9177 - precision: 0.6094\n",
      "Epoch 41: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9189 - precision: 0.6089 - val_loss: 1.0426 - val_precision: 0.5971\n",
      "Epoch 42/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9100 - precision: 0.6188\n",
      "Epoch 42: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9098 - precision: 0.6187 - val_loss: 1.0451 - val_precision: 0.6004\n",
      "Epoch 43/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9062 - precision: 0.6126\n",
      "Epoch 43: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9056 - precision: 0.6129 - val_loss: 1.0636 - val_precision: 0.5889\n",
      "Epoch 44/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9102 - precision: 0.6129\n",
      "Epoch 44: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9102 - precision: 0.6122 - val_loss: 1.0798 - val_precision: 0.5826\n",
      "Epoch 45/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9081 - precision: 0.6115\n",
      "Epoch 45: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9077 - precision: 0.6119 - val_loss: 1.0382 - val_precision: 0.6017\n",
      "Epoch 46/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9022 - precision: 0.6179\n",
      "Epoch 46: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9011 - precision: 0.6182 - val_loss: 1.0618 - val_precision: 0.5834\n",
      "Epoch 47/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8957 - precision: 0.6139\n",
      "Epoch 47: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8955 - precision: 0.6142 - val_loss: 1.0387 - val_precision: 0.5952\n",
      "Epoch 48/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9028 - precision: 0.6164\n",
      "Epoch 48: val_loss did not improve from 1.03668\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9021 - precision: 0.6156 - val_loss: 1.0640 - val_precision: 0.5883\n",
      "Epoch 48: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9901 - precision: 0.6106\n",
      "Combinación 11 = (True, True, True, 64, 0.5) \n",
      " precision train: [0.9900753498077393, 0.610612690448761]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 13: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3475 - precision: 0.6660\n",
      "Epoch 1: val_loss improved from inf to 1.16859, saving model to model_ent13.h5\n",
      "236/236 [==============================] - 10s 13ms/step - loss: 1.3414 - precision: 0.6664 - val_loss: 1.1686 - val_precision: 0.6877\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0532 - precision: 0.6084\n",
      "Epoch 2: val_loss improved from 1.16859 to 1.08344, saving model to model_ent13.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0532 - precision: 0.6084 - val_loss: 1.0834 - val_precision: 0.6030\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9800 - precision: 0.5957\n",
      "Epoch 3: val_loss improved from 1.08344 to 1.05187, saving model to model_ent13.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9790 - precision: 0.5956 - val_loss: 1.0519 - val_precision: 0.6159\n",
      "Epoch 4/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9610 - precision: 0.5943\n",
      "Epoch 4: val_loss improved from 1.05187 to 1.04130, saving model to model_ent13.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9603 - precision: 0.5961 - val_loss: 1.0413 - val_precision: 0.6236\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9423 - precision: 0.6033\n",
      "Epoch 5: val_loss did not improve from 1.04130\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9423 - precision: 0.6030 - val_loss: 1.0493 - val_precision: 0.6104\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9314 - precision: 0.6020\n",
      "Epoch 6: val_loss improved from 1.04130 to 1.02714, saving model to model_ent13.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9314 - precision: 0.6020 - val_loss: 1.0271 - val_precision: 0.6232\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9289 - precision: 0.6000\n",
      "Epoch 7: val_loss did not improve from 1.02714\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9283 - precision: 0.6001 - val_loss: 1.0465 - val_precision: 0.6145\n",
      "Epoch 8/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9150 - precision: 0.6081\n",
      "Epoch 8: val_loss did not improve from 1.02714\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9157 - precision: 0.6090 - val_loss: 1.0391 - val_precision: 0.6161\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9062 - precision: 0.6088\n",
      "Epoch 9: val_loss did not improve from 1.02714\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9066 - precision: 0.6079 - val_loss: 1.0767 - val_precision: 0.6049\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8916 - precision: 0.6120\n",
      "Epoch 10: val_loss improved from 1.02714 to 1.02265, saving model to model_ent13.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8926 - precision: 0.6112 - val_loss: 1.0227 - val_precision: 0.6213\n",
      "Epoch 11/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8875 - precision: 0.6143\n",
      "Epoch 11: val_loss did not improve from 1.02265\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8878 - precision: 0.6132 - val_loss: 1.0461 - val_precision: 0.6131\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8810 - precision: 0.6123\n",
      "Epoch 12: val_loss did not improve from 1.02265\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8806 - precision: 0.6114 - val_loss: 1.0467 - val_precision: 0.5960\n",
      "Epoch 13/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8697 - precision: 0.6171\n",
      "Epoch 13: val_loss did not improve from 1.02265\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8689 - precision: 0.6185 - val_loss: 1.0295 - val_precision: 0.6159\n",
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8627 - precision: 0.6202\n",
      "Epoch 14: val_loss did not improve from 1.02265\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8623 - precision: 0.6198 - val_loss: 1.0263 - val_precision: 0.6090\n",
      "Epoch 15/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8541 - precision: 0.6196\n",
      "Epoch 15: val_loss did not improve from 1.02265\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8541 - precision: 0.6197 - val_loss: 1.0379 - val_precision: 0.6082\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8411 - precision: 0.6231\n",
      "Epoch 16: val_loss improved from 1.02265 to 1.02229, saving model to model_ent13.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8420 - precision: 0.6231 - val_loss: 1.0223 - val_precision: 0.6059\n",
      "Epoch 17/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8338 - precision: 0.6229\n",
      "Epoch 17: val_loss did not improve from 1.02229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8328 - precision: 0.6233 - val_loss: 1.0716 - val_precision: 0.5953\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8335 - precision: 0.6198\n",
      "Epoch 18: val_loss did not improve from 1.02229\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8317 - precision: 0.6219 - val_loss: 1.0502 - val_precision: 0.6040\n",
      "Epoch 19/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8132 - precision: 0.6283\n",
      "Epoch 19: val_loss did not improve from 1.02229\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8138 - precision: 0.6279 - val_loss: 1.0394 - val_precision: 0.5946\n",
      "Epoch 20/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8084 - precision: 0.6287\n",
      "Epoch 20: val_loss did not improve from 1.02229\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8076 - precision: 0.6300 - val_loss: 1.0727 - val_precision: 0.5938\n",
      "Epoch 21/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8036 - precision: 0.6354\n",
      "Epoch 21: val_loss did not improve from 1.02229\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8026 - precision: 0.6362 - val_loss: 1.0456 - val_precision: 0.6101\n",
      "Epoch 22/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7880 - precision: 0.6348\n",
      "Epoch 22: val_loss did not improve from 1.02229\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7879 - precision: 0.6349 - val_loss: 1.0701 - val_precision: 0.6009\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.7837 - precision: 0.6373\n",
      "Epoch 23: val_loss did not improve from 1.02229\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7835 - precision: 0.6385 - val_loss: 1.0507 - val_precision: 0.6086\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7718 - precision: 0.6423\n",
      "Epoch 24: val_loss did not improve from 1.02229\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7710 - precision: 0.6430 - val_loss: 1.0882 - val_precision: 0.6000\n",
      "Epoch 25/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.7752 - precision: 0.6422\n",
      "Epoch 25: val_loss did not improve from 1.02229\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7740 - precision: 0.6436 - val_loss: 1.1144 - val_precision: 0.5751\n",
      "Epoch 26/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.7542 - precision: 0.6463\n",
      "Epoch 26: val_loss did not improve from 1.02229\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7544 - precision: 0.6468 - val_loss: 1.0690 - val_precision: 0.6021\n",
      "Epoch 26: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.8687 - precision: 0.6613\n",
      "Combinación 12 = (True, True, True, 128, 0.1) \n",
      " precision train: [0.8687023520469666, 0.6613000631332397]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 14: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.3482 - precision: 0.6503\n",
      "Epoch 1: val_loss improved from inf to 1.20324, saving model to model_ent14.h5\n",
      "236/236 [==============================] - 10s 13ms/step - loss: 1.3454 - precision: 0.6500 - val_loss: 1.2032 - val_precision: 0.6559\n",
      "Epoch 2/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0881 - precision: 0.6160\n",
      "Epoch 2: val_loss improved from 1.20324 to 1.15046, saving model to model_ent14.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0859 - precision: 0.6167 - val_loss: 1.1505 - val_precision: 0.5923\n",
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0262 - precision: 0.5991\n",
      "Epoch 3: val_loss improved from 1.15046 to 1.07158, saving model to model_ent14.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0259 - precision: 0.5984 - val_loss: 1.0716 - val_precision: 0.6248\n",
      "Epoch 4/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9987 - precision: 0.5999\n",
      "Epoch 4: val_loss improved from 1.07158 to 1.05926, saving model to model_ent14.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9987 - precision: 0.5999 - val_loss: 1.0593 - val_precision: 0.6185\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9670 - precision: 0.6003\n",
      "Epoch 5: val_loss improved from 1.05926 to 1.05490, saving model to model_ent14.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9678 - precision: 0.6004 - val_loss: 1.0549 - val_precision: 0.6085\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9594 - precision: 0.6030\n",
      "Epoch 6: val_loss improved from 1.05490 to 1.02759, saving model to model_ent14.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9591 - precision: 0.6033 - val_loss: 1.0276 - val_precision: 0.6157\n",
      "Epoch 7/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9465 - precision: 0.5994\n",
      "Epoch 7: val_loss did not improve from 1.02759\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9465 - precision: 0.5994 - val_loss: 1.0345 - val_precision: 0.6151\n",
      "Epoch 8/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9379 - precision: 0.6045\n",
      "Epoch 8: val_loss did not improve from 1.02759\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9366 - precision: 0.6042 - val_loss: 1.0485 - val_precision: 0.6061\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9331 - precision: 0.6050\n",
      "Epoch 9: val_loss did not improve from 1.02759\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.9331 - precision: 0.6051 - val_loss: 1.0374 - val_precision: 0.6149\n",
      "Epoch 10/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9233 - precision: 0.6039\n",
      "Epoch 10: val_loss did not improve from 1.02759\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9218 - precision: 0.6051 - val_loss: 1.0305 - val_precision: 0.6206\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9128 - precision: 0.6063\n",
      "Epoch 11: val_loss improved from 1.02759 to 1.02173, saving model to model_ent14.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9121 - precision: 0.6064 - val_loss: 1.0217 - val_precision: 0.6202\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9119 - precision: 0.6012\n",
      "Epoch 12: val_loss did not improve from 1.02173\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9120 - precision: 0.6021 - val_loss: 1.0345 - val_precision: 0.6165\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9005 - precision: 0.6112\n",
      "Epoch 13: val_loss did not improve from 1.02173\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9014 - precision: 0.6101 - val_loss: 1.0267 - val_precision: 0.6203\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8959 - precision: 0.6071\n",
      "Epoch 14: val_loss did not improve from 1.02173\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8954 - precision: 0.6076 - val_loss: 1.0368 - val_precision: 0.6133\n",
      "Epoch 15/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8825 - precision: 0.6138\n",
      "Epoch 15: val_loss improved from 1.02173 to 1.01894, saving model to model_ent14.h5\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8825 - precision: 0.6137 - val_loss: 1.0189 - val_precision: 0.6182\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8778 - precision: 0.6154\n",
      "Epoch 16: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8814 - precision: 0.6144 - val_loss: 1.0365 - val_precision: 0.6088\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8751 - precision: 0.6176\n",
      "Epoch 17: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8743 - precision: 0.6171 - val_loss: 1.0365 - val_precision: 0.5987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8677 - precision: 0.6128\n",
      "Epoch 18: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8660 - precision: 0.6142 - val_loss: 1.0332 - val_precision: 0.6044\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8653 - precision: 0.6161\n",
      "Epoch 19: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8647 - precision: 0.6163 - val_loss: 1.0458 - val_precision: 0.5999\n",
      "Epoch 20/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8502 - precision: 0.6196\n",
      "Epoch 20: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8515 - precision: 0.6197 - val_loss: 1.0612 - val_precision: 0.5873\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8484 - precision: 0.6242\n",
      "Epoch 21: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8485 - precision: 0.6242 - val_loss: 1.0424 - val_precision: 0.5964\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8477 - precision: 0.6207\n",
      "Epoch 22: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8484 - precision: 0.6208 - val_loss: 1.0580 - val_precision: 0.5927\n",
      "Epoch 23/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8346 - precision: 0.6259\n",
      "Epoch 23: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8333 - precision: 0.6257 - val_loss: 1.0250 - val_precision: 0.6176\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8297 - precision: 0.6237\n",
      "Epoch 24: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8295 - precision: 0.6236 - val_loss: 1.0471 - val_precision: 0.6005\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8178 - precision: 0.6270\n",
      "Epoch 25: val_loss did not improve from 1.01894\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8183 - precision: 0.6271 - val_loss: 1.0477 - val_precision: 0.6055\n",
      "Epoch 25: early stopping\n",
      "295/295 [==============================] - 1s 3ms/step - loss: 0.9362 - precision: 0.6305\n",
      "Combinación 13 = (True, True, True, 128, 0.25) \n",
      " precision train: [0.9362028241157532, 0.6304867267608643]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 15: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.3996 - precision: 0.5863\n",
      "Epoch 1: val_loss improved from inf to 1.27516, saving model to model_ent15.h5\n",
      "236/236 [==============================] - 12s 20ms/step - loss: 1.3996 - precision: 0.5840 - val_loss: 1.2752 - val_precision: 0.6832\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2245 - precision: 0.6475\n",
      "Epoch 2: val_loss improved from 1.27516 to 1.12599, saving model to model_ent15.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 1.2231 - precision: 0.6454 - val_loss: 1.1260 - val_precision: 0.6616\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0900 - precision: 0.6112\n",
      "Epoch 3: val_loss improved from 1.12599 to 1.08854, saving model to model_ent15.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0902 - precision: 0.6107 - val_loss: 1.0885 - val_precision: 0.6230\n",
      "Epoch 4/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0504 - precision: 0.6068\n",
      "Epoch 4: val_loss did not improve from 1.08854\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0509 - precision: 0.6076 - val_loss: 1.1061 - val_precision: 0.6011\n",
      "Epoch 5/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0159 - precision: 0.6045\n",
      "Epoch 5: val_loss improved from 1.08854 to 1.04535, saving model to model_ent15.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0186 - precision: 0.6034 - val_loss: 1.0453 - val_precision: 0.6179\n",
      "Epoch 6/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0053 - precision: 0.5970\n",
      "Epoch 6: val_loss did not improve from 1.04535\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0059 - precision: 0.5957 - val_loss: 1.0592 - val_precision: 0.6071\n",
      "Epoch 7/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9947 - precision: 0.5962\n",
      "Epoch 7: val_loss improved from 1.04535 to 1.04347, saving model to model_ent15.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9947 - precision: 0.5962 - val_loss: 1.0435 - val_precision: 0.6139\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9831 - precision: 0.5950\n",
      "Epoch 8: val_loss did not improve from 1.04347\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9836 - precision: 0.5954 - val_loss: 1.0483 - val_precision: 0.6045\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9703 - precision: 0.6020\n",
      "Epoch 9: val_loss did not improve from 1.04347\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9695 - precision: 0.6018 - val_loss: 1.0540 - val_precision: 0.6039\n",
      "Epoch 10/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9700 - precision: 0.5984\n",
      "Epoch 10: val_loss did not improve from 1.04347\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.9715 - precision: 0.5974 - val_loss: 1.0449 - val_precision: 0.6088\n",
      "Epoch 11/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9631 - precision: 0.6048\n",
      "Epoch 11: val_loss improved from 1.04347 to 1.04224, saving model to model_ent15.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9629 - precision: 0.6046 - val_loss: 1.0422 - val_precision: 0.6139\n",
      "Epoch 12/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9630 - precision: 0.6027\n",
      "Epoch 12: val_loss did not improve from 1.04224\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9659 - precision: 0.6010 - val_loss: 1.0515 - val_precision: 0.6062\n",
      "Epoch 13/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9505 - precision: 0.6073\n",
      "Epoch 13: val_loss did not improve from 1.04224\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9505 - precision: 0.6073 - val_loss: 1.0479 - val_precision: 0.6060\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9467 - precision: 0.6008\n",
      "Epoch 14: val_loss improved from 1.04224 to 1.03353, saving model to model_ent15.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9461 - precision: 0.6012 - val_loss: 1.0335 - val_precision: 0.6129\n",
      "Epoch 15/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9405 - precision: 0.6016\n",
      "Epoch 15: val_loss did not improve from 1.03353\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9391 - precision: 0.6026 - val_loss: 1.0345 - val_precision: 0.6120\n",
      "Epoch 16/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9377 - precision: 0.6013\n",
      "Epoch 16: val_loss did not improve from 1.03353\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9377 - precision: 0.6013 - val_loss: 1.0514 - val_precision: 0.5986\n",
      "Epoch 17/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9347 - precision: 0.6011\n",
      "Epoch 17: val_loss did not improve from 1.03353\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.9346 - precision: 0.6011 - val_loss: 1.0339 - val_precision: 0.6088\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9336 - precision: 0.6048\n",
      "Epoch 18: val_loss did not improve from 1.03353\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.9338 - precision: 0.6044 - val_loss: 1.0477 - val_precision: 0.6055\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9263 - precision: 0.6044\n",
      "Epoch 19: val_loss did not improve from 1.03353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9266 - precision: 0.6040 - val_loss: 1.0381 - val_precision: 0.6073\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9221 - precision: 0.6047\n",
      "Epoch 20: val_loss improved from 1.03353 to 1.02228, saving model to model_ent15.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9232 - precision: 0.6051 - val_loss: 1.0223 - val_precision: 0.6190\n",
      "Epoch 21/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9149 - precision: 0.6090\n",
      "Epoch 21: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9149 - precision: 0.6090 - val_loss: 1.0251 - val_precision: 0.6144\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9094 - precision: 0.6098\n",
      "Epoch 22: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9093 - precision: 0.6098 - val_loss: 1.0342 - val_precision: 0.6123\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9106 - precision: 0.6058\n",
      "Epoch 23: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9076 - precision: 0.6073 - val_loss: 1.0422 - val_precision: 0.6106\n",
      "Epoch 24/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9012 - precision: 0.6106\n",
      "Epoch 24: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9037 - precision: 0.6094 - val_loss: 1.0287 - val_precision: 0.6090\n",
      "Epoch 25/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9107 - precision: 0.6118\n",
      "Epoch 25: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9102 - precision: 0.6123 - val_loss: 1.0251 - val_precision: 0.6107\n",
      "Epoch 26/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9024 - precision: 0.6104\n",
      "Epoch 26: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9032 - precision: 0.6101 - val_loss: 1.0506 - val_precision: 0.6040\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8944 - precision: 0.6161\n",
      "Epoch 27: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8948 - precision: 0.6162 - val_loss: 1.0318 - val_precision: 0.6059\n",
      "Epoch 28/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8807 - precision: 0.6145\n",
      "Epoch 28: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8846 - precision: 0.6143 - val_loss: 1.0408 - val_precision: 0.6089\n",
      "Epoch 29/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8892 - precision: 0.6147\n",
      "Epoch 29: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8892 - precision: 0.6147 - val_loss: 1.0305 - val_precision: 0.6021\n",
      "Epoch 30/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8845 - precision: 0.6115\n",
      "Epoch 30: val_loss did not improve from 1.02228\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8834 - precision: 0.6118 - val_loss: 1.0385 - val_precision: 0.5951\n",
      "Epoch 30: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9602 - precision: 0.6154\n",
      "Combinación 14 = (True, True, True, 128, 0.5) \n",
      " precision train: [0.9601531028747559, 0.6154046058654785]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 16: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.5446 - precision: 0.3422 \n",
      "Epoch 1: val_loss improved from inf to 1.49156, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 8s 9ms/step - loss: 1.5429 - precision: 0.3333 - val_loss: 1.4916 - val_precision: 0.4618\n",
      "Epoch 2/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.3560 - precision: 0.3976\n",
      "Epoch 2: val_loss improved from 1.49156 to 1.38782, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3560 - precision: 0.3976 - val_loss: 1.3878 - val_precision: 0.4521\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2916 - precision: 0.4770\n",
      "Epoch 3: val_loss improved from 1.38782 to 1.32023, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2913 - precision: 0.4779 - val_loss: 1.3202 - val_precision: 0.4957\n",
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2477 - precision: 0.5230\n",
      "Epoch 4: val_loss improved from 1.32023 to 1.26481, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2480 - precision: 0.5221 - val_loss: 1.2648 - val_precision: 0.5537\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2034 - precision: 0.5420\n",
      "Epoch 5: val_loss improved from 1.26481 to 1.22049, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2033 - precision: 0.5428 - val_loss: 1.2205 - val_precision: 0.6088\n",
      "Epoch 6/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1654 - precision: 0.5870\n",
      "Epoch 6: val_loss improved from 1.22049 to 1.17799, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1658 - precision: 0.5866 - val_loss: 1.1780 - val_precision: 0.6500\n",
      "Epoch 7/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1285 - precision: 0.6090\n",
      "Epoch 7: val_loss improved from 1.17799 to 1.15201, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1287 - precision: 0.6091 - val_loss: 1.1520 - val_precision: 0.6453\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1007 - precision: 0.6151\n",
      "Epoch 8: val_loss improved from 1.15201 to 1.12145, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1002 - precision: 0.6148 - val_loss: 1.1214 - val_precision: 0.6401\n",
      "Epoch 9/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0769 - precision: 0.6229\n",
      "Epoch 9: val_loss improved from 1.12145 to 1.10530, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0749 - precision: 0.6243 - val_loss: 1.1053 - val_precision: 0.6470\n",
      "Epoch 10/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0547 - precision: 0.6252\n",
      "Epoch 10: val_loss improved from 1.10530 to 1.09521, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0516 - precision: 0.6232 - val_loss: 1.0952 - val_precision: 0.6527\n",
      "Epoch 11/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0419 - precision: 0.6151\n",
      "Epoch 11: val_loss improved from 1.09521 to 1.09002, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0419 - precision: 0.6151 - val_loss: 1.0900 - val_precision: 0.6336\n",
      "Epoch 12/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0277 - precision: 0.6089\n",
      "Epoch 12: val_loss did not improve from 1.09002\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0283 - precision: 0.6068 - val_loss: 1.0914 - val_precision: 0.6198\n",
      "Epoch 13/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0262 - precision: 0.6004\n",
      "Epoch 13: val_loss improved from 1.09002 to 1.08237, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0259 - precision: 0.6018 - val_loss: 1.0824 - val_precision: 0.6174\n",
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0169 - precision: 0.5993\n",
      "Epoch 14: val_loss improved from 1.08237 to 1.07274, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0172 - precision: 0.5990 - val_loss: 1.0727 - val_precision: 0.6222\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0079 - precision: 0.6064\n",
      "Epoch 15: val_loss did not improve from 1.07274\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0079 - precision: 0.6064 - val_loss: 1.0780 - val_precision: 0.6092\n",
      "Epoch 16/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9999 - precision: 0.6090\n",
      "Epoch 16: val_loss did not improve from 1.07274\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0012 - precision: 0.6057 - val_loss: 1.0771 - val_precision: 0.6217\n",
      "Epoch 17/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0068 - precision: 0.6019\n",
      "Epoch 17: val_loss improved from 1.07274 to 1.06577, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0021 - precision: 0.6033 - val_loss: 1.0658 - val_precision: 0.6233\n",
      "Epoch 18/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9956 - precision: 0.6086\n",
      "Epoch 18: val_loss did not improve from 1.06577\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9921 - precision: 0.6072 - val_loss: 1.0693 - val_precision: 0.6172\n",
      "Epoch 19/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9899 - precision: 0.6081\n",
      "Epoch 19: val_loss did not improve from 1.06577\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9907 - precision: 0.6064 - val_loss: 1.0782 - val_precision: 0.6110\n",
      "Epoch 20/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9853 - precision: 0.6070\n",
      "Epoch 20: val_loss did not improve from 1.06577\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9868 - precision: 0.6080 - val_loss: 1.0702 - val_precision: 0.6168\n",
      "Epoch 21/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9769 - precision: 0.6084\n",
      "Epoch 21: val_loss improved from 1.06577 to 1.06212, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9811 - precision: 0.6081 - val_loss: 1.0621 - val_precision: 0.6256\n",
      "Epoch 22/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9806 - precision: 0.6052\n",
      "Epoch 22: val_loss did not improve from 1.06212\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9806 - precision: 0.6052 - val_loss: 1.0688 - val_precision: 0.6089\n",
      "Epoch 23/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9821 - precision: 0.6076\n",
      "Epoch 23: val_loss did not improve from 1.06212\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9834 - precision: 0.6068 - val_loss: 1.0660 - val_precision: 0.6140\n",
      "Epoch 24/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9743 - precision: 0.6069\n",
      "Epoch 24: val_loss improved from 1.06212 to 1.05814, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9736 - precision: 0.6065 - val_loss: 1.0581 - val_precision: 0.6178\n",
      "Epoch 25/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9721 - precision: 0.6041\n",
      "Epoch 25: val_loss improved from 1.05814 to 1.05767, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9673 - precision: 0.6051 - val_loss: 1.0577 - val_precision: 0.6212\n",
      "Epoch 26/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9692 - precision: 0.6129\n",
      "Epoch 26: val_loss did not improve from 1.05767\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9707 - precision: 0.6120 - val_loss: 1.0655 - val_precision: 0.6094\n",
      "Epoch 27/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9674 - precision: 0.6115\n",
      "Epoch 27: val_loss did not improve from 1.05767\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9654 - precision: 0.6137 - val_loss: 1.0670 - val_precision: 0.6124\n",
      "Epoch 28/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9610 - precision: 0.6114\n",
      "Epoch 28: val_loss did not improve from 1.05767\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9617 - precision: 0.6114 - val_loss: 1.0665 - val_precision: 0.6149\n",
      "Epoch 29/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9556 - precision: 0.6120\n",
      "Epoch 29: val_loss improved from 1.05767 to 1.05691, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9573 - precision: 0.6138 - val_loss: 1.0569 - val_precision: 0.6178\n",
      "Epoch 30/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9513 - precision: 0.6178\n",
      "Epoch 30: val_loss did not improve from 1.05691\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9503 - precision: 0.6177 - val_loss: 1.0648 - val_precision: 0.6169\n",
      "Epoch 31/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9453 - precision: 0.6181\n",
      "Epoch 31: val_loss did not improve from 1.05691\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9511 - precision: 0.6150 - val_loss: 1.0616 - val_precision: 0.6083\n",
      "Epoch 32/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9537 - precision: 0.6139\n",
      "Epoch 32: val_loss did not improve from 1.05691\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9577 - precision: 0.6126 - val_loss: 1.0619 - val_precision: 0.6136\n",
      "Epoch 33/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9476 - precision: 0.6142\n",
      "Epoch 33: val_loss did not improve from 1.05691\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9469 - precision: 0.6136 - val_loss: 1.0598 - val_precision: 0.6143\n",
      "Epoch 34/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9466 - precision: 0.6179\n",
      "Epoch 34: val_loss did not improve from 1.05691\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9466 - precision: 0.6179 - val_loss: 1.0605 - val_precision: 0.6116\n",
      "Epoch 35/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9391 - precision: 0.6185\n",
      "Epoch 35: val_loss did not improve from 1.05691\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9438 - precision: 0.6189 - val_loss: 1.0611 - val_precision: 0.6112\n",
      "Epoch 36/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9452 - precision: 0.6087\n",
      "Epoch 36: val_loss did not improve from 1.05691\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9428 - precision: 0.6100 - val_loss: 1.0657 - val_precision: 0.6090\n",
      "Epoch 37/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9479 - precision: 0.6147\n",
      "Epoch 37: val_loss did not improve from 1.05691\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9466 - precision: 0.6138 - val_loss: 1.0605 - val_precision: 0.6135\n",
      "Epoch 38/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9470 - precision: 0.6178\n",
      "Epoch 38: val_loss did not improve from 1.05691\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9470 - precision: 0.6178 - val_loss: 1.0670 - val_precision: 0.6038\n",
      "Epoch 39/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9422 - precision: 0.6098\n",
      "Epoch 39: val_loss improved from 1.05691 to 1.05004, saving model to model_ent16.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9409 - precision: 0.6081 - val_loss: 1.0500 - val_precision: 0.6180\n",
      "Epoch 40/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9364 - precision: 0.6178\n",
      "Epoch 40: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9381 - precision: 0.6182 - val_loss: 1.0611 - val_precision: 0.6093\n",
      "Epoch 41/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9368 - precision: 0.6128\n",
      "Epoch 41: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9364 - precision: 0.6142 - val_loss: 1.0528 - val_precision: 0.6211\n",
      "Epoch 42/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9342 - precision: 0.6117\n",
      "Epoch 42: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9342 - precision: 0.6119 - val_loss: 1.0523 - val_precision: 0.6239\n",
      "Epoch 43/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9347 - precision: 0.6139\n",
      "Epoch 43: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9357 - precision: 0.6136 - val_loss: 1.0587 - val_precision: 0.6152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9304 - precision: 0.6219\n",
      "Epoch 44: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9305 - precision: 0.6207 - val_loss: 1.0663 - val_precision: 0.6076\n",
      "Epoch 45/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9235 - precision: 0.6219\n",
      "Epoch 45: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9245 - precision: 0.6182 - val_loss: 1.0649 - val_precision: 0.6117\n",
      "Epoch 46/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9349 - precision: 0.6144\n",
      "Epoch 46: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9341 - precision: 0.6145 - val_loss: 1.0614 - val_precision: 0.6074\n",
      "Epoch 47/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9151 - precision: 0.6248\n",
      "Epoch 47: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9163 - precision: 0.6235 - val_loss: 1.0599 - val_precision: 0.6106\n",
      "Epoch 48/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9230 - precision: 0.6145\n",
      "Epoch 48: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9194 - precision: 0.6161 - val_loss: 1.0674 - val_precision: 0.6067\n",
      "Epoch 49/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9184 - precision: 0.6165\n",
      "Epoch 49: val_loss did not improve from 1.05004\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9202 - precision: 0.6169 - val_loss: 1.0598 - val_precision: 0.6106\n",
      "Epoch 49: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9823 - precision: 0.6295\n",
      "Combinación 15 = (True, True, False, 8, 0.1) \n",
      " precision train: [0.9822942614555359, 0.6295156478881836]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 17: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.5429 - precision: 0.5658\n",
      "Epoch 1: val_loss improved from inf to 1.39747, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 7s 11ms/step - loss: 1.5369 - precision: 0.5621 - val_loss: 1.3975 - val_precision: 0.5000\n",
      "Epoch 2/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.3609 - precision: 0.5568\n",
      "Epoch 2: val_loss improved from 1.39747 to 1.34897, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3596 - precision: 0.5540 - val_loss: 1.3490 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.3261 - precision: 0.5616\n",
      "Epoch 3: val_loss improved from 1.34897 to 1.33068, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3271 - precision: 0.5470 - val_loss: 1.3307 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.3104 - precision: 0.5432\n",
      "Epoch 4: val_loss improved from 1.33068 to 1.31395, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3106 - precision: 0.5504 - val_loss: 1.3140 - val_precision: 0.0000e+00\n",
      "Epoch 5/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3102 - precision: 0.5164\n",
      "Epoch 5: val_loss improved from 1.31395 to 1.30603, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3085 - precision: 0.5249 - val_loss: 1.3060 - val_precision: 0.0000e+00\n",
      "Epoch 6/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2896 - precision: 0.6171\n",
      "Epoch 6: val_loss improved from 1.30603 to 1.28772, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2900 - precision: 0.6060 - val_loss: 1.2877 - val_precision: 0.5455\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2800 - precision: 0.5990\n",
      "Epoch 7: val_loss improved from 1.28772 to 1.26797, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2790 - precision: 0.5990 - val_loss: 1.2680 - val_precision: 0.7043\n",
      "Epoch 8/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2617 - precision: 0.6416\n",
      "Epoch 8: val_loss improved from 1.26797 to 1.25091, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2611 - precision: 0.6431 - val_loss: 1.2509 - val_precision: 0.7006\n",
      "Epoch 9/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2476 - precision: 0.6340\n",
      "Epoch 9: val_loss improved from 1.25091 to 1.24201, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2475 - precision: 0.6367 - val_loss: 1.2420 - val_precision: 0.6998\n",
      "Epoch 10/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.2372 - precision: 0.6621\n",
      "Epoch 10: val_loss improved from 1.24201 to 1.22482, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2367 - precision: 0.6609 - val_loss: 1.2248 - val_precision: 0.6983\n",
      "Epoch 11/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2265 - precision: 0.6549\n",
      "Epoch 11: val_loss improved from 1.22482 to 1.21296, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2268 - precision: 0.6568 - val_loss: 1.2130 - val_precision: 0.6924\n",
      "Epoch 12/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2117 - precision: 0.6653\n",
      "Epoch 12: val_loss improved from 1.21296 to 1.19750, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2103 - precision: 0.6646 - val_loss: 1.1975 - val_precision: 0.6925\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1934 - precision: 0.6545\n",
      "Epoch 13: val_loss improved from 1.19750 to 1.18501, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1932 - precision: 0.6537 - val_loss: 1.1850 - val_precision: 0.6896\n",
      "Epoch 14/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1788 - precision: 0.6561\n",
      "Epoch 14: val_loss improved from 1.18501 to 1.17890, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1841 - precision: 0.6556 - val_loss: 1.1789 - val_precision: 0.6832\n",
      "Epoch 15/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1783 - precision: 0.6516\n",
      "Epoch 15: val_loss did not improve from 1.17890\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1792 - precision: 0.6515 - val_loss: 1.1831 - val_precision: 0.6975\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1689 - precision: 0.6347\n",
      "Epoch 16: val_loss improved from 1.17890 to 1.16201, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1710 - precision: 0.6343 - val_loss: 1.1620 - val_precision: 0.6598\n",
      "Epoch 17/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.1609 - precision: 0.6356\n",
      "Epoch 17: val_loss did not improve from 1.16201\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1619 - precision: 0.6345 - val_loss: 1.1653 - val_precision: 0.6402\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1600 - precision: 0.6203\n",
      "Epoch 18: val_loss improved from 1.16201 to 1.15946, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1614 - precision: 0.6202 - val_loss: 1.1595 - val_precision: 0.6547\n",
      "Epoch 19/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1553 - precision: 0.6301\n",
      "Epoch 19: val_loss did not improve from 1.15946\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1567 - precision: 0.6276 - val_loss: 1.1617 - val_precision: 0.6228\n",
      "Epoch 20/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1425 - precision: 0.6187\n",
      "Epoch 20: val_loss improved from 1.15946 to 1.15733, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1436 - precision: 0.6152 - val_loss: 1.1573 - val_precision: 0.6208\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1428 - precision: 0.6110\n",
      "Epoch 21: val_loss did not improve from 1.15733\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1418 - precision: 0.6106 - val_loss: 1.1593 - val_precision: 0.6195\n",
      "Epoch 22/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1359 - precision: 0.6174\n",
      "Epoch 22: val_loss improved from 1.15733 to 1.15185, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1356 - precision: 0.6173 - val_loss: 1.1518 - val_precision: 0.6206\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1295 - precision: 0.6096\n",
      "Epoch 23: val_loss improved from 1.15185 to 1.14784, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1298 - precision: 0.6101 - val_loss: 1.1478 - val_precision: 0.6128\n",
      "Epoch 24/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1276 - precision: 0.6187\n",
      "Epoch 24: val_loss improved from 1.14784 to 1.14589, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1258 - precision: 0.6186 - val_loss: 1.1459 - val_precision: 0.6183\n",
      "Epoch 25/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1285 - precision: 0.6123\n",
      "Epoch 25: val_loss improved from 1.14589 to 1.13918, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1288 - precision: 0.6122 - val_loss: 1.1392 - val_precision: 0.6143\n",
      "Epoch 26/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1240 - precision: 0.6100\n",
      "Epoch 26: val_loss improved from 1.13918 to 1.13712, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1226 - precision: 0.6104 - val_loss: 1.1371 - val_precision: 0.6271\n",
      "Epoch 27/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1225 - precision: 0.5981\n",
      "Epoch 27: val_loss did not improve from 1.13712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1232 - precision: 0.5989 - val_loss: 1.1452 - val_precision: 0.6197\n",
      "Epoch 28/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1162 - precision: 0.6039\n",
      "Epoch 28: val_loss did not improve from 1.13712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1162 - precision: 0.6039 - val_loss: 1.1377 - val_precision: 0.6222\n",
      "Epoch 29/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1146 - precision: 0.6120\n",
      "Epoch 29: val_loss did not improve from 1.13712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1160 - precision: 0.6115 - val_loss: 1.1447 - val_precision: 0.6130\n",
      "Epoch 30/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1209 - precision: 0.5992\n",
      "Epoch 30: val_loss did not improve from 1.13712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1191 - precision: 0.6003 - val_loss: 1.1385 - val_precision: 0.6148\n",
      "Epoch 31/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1089 - precision: 0.6042\n",
      "Epoch 31: val_loss improved from 1.13712 to 1.13339, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1110 - precision: 0.6042 - val_loss: 1.1334 - val_precision: 0.6188\n",
      "Epoch 32/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1123 - precision: 0.5950\n",
      "Epoch 32: val_loss improved from 1.13339 to 1.12983, saving model to model_ent17.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1137 - precision: 0.5940 - val_loss: 1.1298 - val_precision: 0.6200\n",
      "Epoch 33/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1030 - precision: 0.6016\n",
      "Epoch 33: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1044 - precision: 0.6003 - val_loss: 1.1386 - val_precision: 0.6124\n",
      "Epoch 34/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1105 - precision: 0.5964\n",
      "Epoch 34: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1103 - precision: 0.5969 - val_loss: 1.1305 - val_precision: 0.6170\n",
      "Epoch 35/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1044 - precision: 0.5981\n",
      "Epoch 35: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1051 - precision: 0.5980 - val_loss: 1.1337 - val_precision: 0.6195\n",
      "Epoch 36/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1134 - precision: 0.5897\n",
      "Epoch 36: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1116 - precision: 0.5900 - val_loss: 1.1372 - val_precision: 0.6158\n",
      "Epoch 37/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1001 - precision: 0.5897\n",
      "Epoch 37: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0978 - precision: 0.5906 - val_loss: 1.1441 - val_precision: 0.6080\n",
      "Epoch 38/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0956 - precision: 0.5898\n",
      "Epoch 38: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0951 - precision: 0.5902 - val_loss: 1.1321 - val_precision: 0.6161\n",
      "Epoch 39/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0991 - precision: 0.5876\n",
      "Epoch 39: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0981 - precision: 0.5878 - val_loss: 1.1356 - val_precision: 0.6139\n",
      "Epoch 40/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0979 - precision: 0.5965\n",
      "Epoch 40: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0968 - precision: 0.5970 - val_loss: 1.1339 - val_precision: 0.6138\n",
      "Epoch 41/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1046 - precision: 0.5863\n",
      "Epoch 41: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1006 - precision: 0.5870 - val_loss: 1.1312 - val_precision: 0.6153\n",
      "Epoch 42/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0996 - precision: 0.5877\n",
      "Epoch 42: val_loss did not improve from 1.12983\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0989 - precision: 0.5882 - val_loss: 1.1370 - val_precision: 0.6160\n",
      "Epoch 42: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.1033 - precision: 0.6257\n",
      "Combinación 16 = (True, True, False, 8, 0.25) \n",
      " precision train: [1.1033259630203247, 0.6256937384605408]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 18: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.6044 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.59124, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 8s 9ms/step - loss: 1.6031 - precision: 0.0000e+00 - val_loss: 1.5912 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.5070 - precision: 0.6386\n",
      "Epoch 2: val_loss improved from 1.59124 to 1.38527, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.5046 - precision: 0.6375 - val_loss: 1.3853 - val_precision: 0.6512\n",
      "Epoch 3/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.4138 - precision: 0.5833\n",
      "Epoch 3: val_loss improved from 1.38527 to 1.32696, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.4157 - precision: 0.5831 - val_loss: 1.3270 - val_precision: 0.6175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.3899 - precision: 0.5649\n",
      "Epoch 4: val_loss improved from 1.32696 to 1.30709, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3872 - precision: 0.5672 - val_loss: 1.3071 - val_precision: 0.6635\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.3561 - precision: 0.5591\n",
      "Epoch 5: val_loss improved from 1.30709 to 1.28693, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3561 - precision: 0.5591 - val_loss: 1.2869 - val_precision: 0.6644\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.3387 - precision: 0.5615\n",
      "Epoch 6: val_loss improved from 1.28693 to 1.28000, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3387 - precision: 0.5615 - val_loss: 1.2800 - val_precision: 0.6628\n",
      "Epoch 7/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3320 - precision: 0.5298\n",
      "Epoch 7: val_loss improved from 1.28000 to 1.26962, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3322 - precision: 0.5303 - val_loss: 1.2696 - val_precision: 0.6636\n",
      "Epoch 8/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.3219 - precision: 0.5559\n",
      "Epoch 8: val_loss improved from 1.26962 to 1.26272, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3253 - precision: 0.5572 - val_loss: 1.2627 - val_precision: 0.6705\n",
      "Epoch 9/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.3237 - precision: 0.5635\n",
      "Epoch 9: val_loss improved from 1.26272 to 1.25974, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3255 - precision: 0.5637 - val_loss: 1.2597 - val_precision: 0.6579\n",
      "Epoch 10/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.3049 - precision: 0.5726\n",
      "Epoch 10: val_loss did not improve from 1.25974\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3113 - precision: 0.5683 - val_loss: 1.2661 - val_precision: 0.6588\n",
      "Epoch 11/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3133 - precision: 0.5629\n",
      "Epoch 11: val_loss did not improve from 1.25974\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3137 - precision: 0.5622 - val_loss: 1.2604 - val_precision: 0.6737\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3071 - precision: 0.5723\n",
      "Epoch 12: val_loss improved from 1.25974 to 1.25007, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3061 - precision: 0.5758 - val_loss: 1.2501 - val_precision: 0.6631\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3029 - precision: 0.5732\n",
      "Epoch 13: val_loss did not improve from 1.25007\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3044 - precision: 0.5732 - val_loss: 1.2535 - val_precision: 0.6623\n",
      "Epoch 14/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2998 - precision: 0.5846\n",
      "Epoch 14: val_loss did not improve from 1.25007\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2977 - precision: 0.5818 - val_loss: 1.2506 - val_precision: 0.6590\n",
      "Epoch 15/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2888 - precision: 0.5792\n",
      "Epoch 15: val_loss improved from 1.25007 to 1.24838, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2891 - precision: 0.5806 - val_loss: 1.2484 - val_precision: 0.6696\n",
      "Epoch 16/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2808 - precision: 0.5894\n",
      "Epoch 16: val_loss did not improve from 1.24838\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2826 - precision: 0.5899 - val_loss: 1.2546 - val_precision: 0.6644\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2951 - precision: 0.5783\n",
      "Epoch 17: val_loss did not improve from 1.24838\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2956 - precision: 0.5767 - val_loss: 1.2518 - val_precision: 0.6644\n",
      "Epoch 18/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2887 - precision: 0.5935\n",
      "Epoch 18: val_loss did not improve from 1.24838\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2900 - precision: 0.5929 - val_loss: 1.2495 - val_precision: 0.6667\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2893 - precision: 0.5865\n",
      "Epoch 19: val_loss did not improve from 1.24838\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2878 - precision: 0.5879 - val_loss: 1.2543 - val_precision: 0.6731\n",
      "Epoch 20/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2919 - precision: 0.5689\n",
      "Epoch 20: val_loss improved from 1.24838 to 1.24153, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2925 - precision: 0.5699 - val_loss: 1.2415 - val_precision: 0.6601\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2795 - precision: 0.5925\n",
      "Epoch 21: val_loss did not improve from 1.24153\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2809 - precision: 0.5923 - val_loss: 1.2420 - val_precision: 0.6630\n",
      "Epoch 22/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2801 - precision: 0.6121\n",
      "Epoch 22: val_loss did not improve from 1.24153\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2802 - precision: 0.6054 - val_loss: 1.2500 - val_precision: 0.6587\n",
      "Epoch 23/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2803 - precision: 0.5750\n",
      "Epoch 23: val_loss did not improve from 1.24153\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2800 - precision: 0.5747 - val_loss: 1.2566 - val_precision: 0.6652\n",
      "Epoch 24/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2660 - precision: 0.5719\n",
      "Epoch 24: val_loss did not improve from 1.24153\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2654 - precision: 0.5735 - val_loss: 1.2479 - val_precision: 0.6722\n",
      "Epoch 25/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2801 - precision: 0.5932\n",
      "Epoch 25: val_loss improved from 1.24153 to 1.24104, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2787 - precision: 0.5891 - val_loss: 1.2410 - val_precision: 0.6682\n",
      "Epoch 26/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2815 - precision: 0.6040\n",
      "Epoch 26: val_loss did not improve from 1.24104\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2817 - precision: 0.6027 - val_loss: 1.2424 - val_precision: 0.6652\n",
      "Epoch 27/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2805 - precision: 0.5657\n",
      "Epoch 27: val_loss improved from 1.24104 to 1.23944, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2850 - precision: 0.5654 - val_loss: 1.2394 - val_precision: 0.6615\n",
      "Epoch 28/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2762 - precision: 0.6157\n",
      "Epoch 28: val_loss did not improve from 1.23944\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2746 - precision: 0.6157 - val_loss: 1.2435 - val_precision: 0.6705\n",
      "Epoch 29/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2718 - precision: 0.5989\n",
      "Epoch 29: val_loss improved from 1.23944 to 1.23936, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2726 - precision: 0.6000 - val_loss: 1.2394 - val_precision: 0.6539\n",
      "Epoch 30/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2732 - precision: 0.6031\n",
      "Epoch 30: val_loss did not improve from 1.23936\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2724 - precision: 0.6030 - val_loss: 1.2401 - val_precision: 0.6621\n",
      "Epoch 31/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2688 - precision: 0.5981\n",
      "Epoch 31: val_loss improved from 1.23936 to 1.23668, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2686 - precision: 0.5983 - val_loss: 1.2367 - val_precision: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2788 - precision: 0.5991\n",
      "Epoch 32: val_loss did not improve from 1.23668\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2783 - precision: 0.6015 - val_loss: 1.2451 - val_precision: 0.6637\n",
      "Epoch 33/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2754 - precision: 0.5780\n",
      "Epoch 33: val_loss improved from 1.23668 to 1.23657, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2765 - precision: 0.5787 - val_loss: 1.2366 - val_precision: 0.6609\n",
      "Epoch 34/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2631 - precision: 0.5820\n",
      "Epoch 34: val_loss did not improve from 1.23657\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2651 - precision: 0.5823 - val_loss: 1.2367 - val_precision: 0.6608\n",
      "Epoch 35/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2622 - precision: 0.5866\n",
      "Epoch 35: val_loss did not improve from 1.23657\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2630 - precision: 0.5905 - val_loss: 1.2389 - val_precision: 0.6540\n",
      "Epoch 36/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2650 - precision: 0.5771\n",
      "Epoch 36: val_loss did not improve from 1.23657\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2618 - precision: 0.5792 - val_loss: 1.2394 - val_precision: 0.6443\n",
      "Epoch 37/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2658 - precision: 0.5723\n",
      "Epoch 37: val_loss improved from 1.23657 to 1.23493, saving model to model_ent18.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2672 - precision: 0.5689 - val_loss: 1.2349 - val_precision: 0.6534\n",
      "Epoch 38/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2684 - precision: 0.5730\n",
      "Epoch 38: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2688 - precision: 0.5712 - val_loss: 1.2397 - val_precision: 0.6651\n",
      "Epoch 39/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2650 - precision: 0.5655\n",
      "Epoch 39: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2654 - precision: 0.5662 - val_loss: 1.2356 - val_precision: 0.6586\n",
      "Epoch 40/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2573 - precision: 0.5818\n",
      "Epoch 40: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2616 - precision: 0.5749 - val_loss: 1.2357 - val_precision: 0.6502\n",
      "Epoch 41/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2668 - precision: 0.5490\n",
      "Epoch 41: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2628 - precision: 0.5513 - val_loss: 1.2369 - val_precision: 0.6430\n",
      "Epoch 42/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2629 - precision: 0.5686\n",
      "Epoch 42: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2629 - precision: 0.5686 - val_loss: 1.2358 - val_precision: 0.6484\n",
      "Epoch 43/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2663 - precision: 0.5477\n",
      "Epoch 43: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2677 - precision: 0.5529 - val_loss: 1.2352 - val_precision: 0.6466\n",
      "Epoch 44/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2619 - precision: 0.5593\n",
      "Epoch 44: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2619 - precision: 0.5593 - val_loss: 1.2387 - val_precision: 0.6488\n",
      "Epoch 45/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2431 - precision: 0.5562\n",
      "Epoch 45: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2468 - precision: 0.5580 - val_loss: 1.2355 - val_precision: 0.6594\n",
      "Epoch 46/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2564 - precision: 0.5586\n",
      "Epoch 46: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2564 - precision: 0.5586 - val_loss: 1.2395 - val_precision: 0.6504\n",
      "Epoch 47/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2493 - precision: 0.5486\n",
      "Epoch 47: val_loss did not improve from 1.23493\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2471 - precision: 0.5465 - val_loss: 1.2435 - val_precision: 0.6601\n",
      "Epoch 47: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.2345 - precision: 0.6568\n",
      "Combinación 17 = (True, True, False, 8, 0.5) \n",
      " precision train: [1.2345046997070312, 0.6567814946174622]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 19: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.4930 - precision: 0.2692 \n",
      "Epoch 1: val_loss improved from inf to 1.36421, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 7s 8ms/step - loss: 1.4888 - precision: 0.2830 - val_loss: 1.3642 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2465 - precision: 0.6471\n",
      "Epoch 2: val_loss improved from 1.36421 to 1.20346, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2479 - precision: 0.6402 - val_loss: 1.2035 - val_precision: 0.6374\n",
      "Epoch 3/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1296 - precision: 0.6243\n",
      "Epoch 3: val_loss improved from 1.20346 to 1.14638, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1299 - precision: 0.6215 - val_loss: 1.1464 - val_precision: 0.6468\n",
      "Epoch 4/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0745 - precision: 0.6130\n",
      "Epoch 4: val_loss improved from 1.14638 to 1.09213, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0727 - precision: 0.6077 - val_loss: 1.0921 - val_precision: 0.6249\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0342 - precision: 0.5949\n",
      "Epoch 5: val_loss improved from 1.09213 to 1.08125, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0321 - precision: 0.5967 - val_loss: 1.0812 - val_precision: 0.6050\n",
      "Epoch 6/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0182 - precision: 0.5877\n",
      "Epoch 6: val_loss improved from 1.08125 to 1.07676, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0178 - precision: 0.5871 - val_loss: 1.0768 - val_precision: 0.6047\n",
      "Epoch 7/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0079 - precision: 0.5962\n",
      "Epoch 7: val_loss improved from 1.07676 to 1.06887, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0086 - precision: 0.5962 - val_loss: 1.0689 - val_precision: 0.6034\n",
      "Epoch 8/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9962 - precision: 0.5917\n",
      "Epoch 8: val_loss did not improve from 1.06887\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9962 - precision: 0.5917 - val_loss: 1.0690 - val_precision: 0.6032\n",
      "Epoch 9/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9865 - precision: 0.5941\n",
      "Epoch 9: val_loss improved from 1.06887 to 1.06450, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9859 - precision: 0.5966 - val_loss: 1.0645 - val_precision: 0.6031\n",
      "Epoch 10/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9861 - precision: 0.5998\n",
      "Epoch 10: val_loss improved from 1.06450 to 1.05309, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9858 - precision: 0.5999 - val_loss: 1.0531 - val_precision: 0.6176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9782 - precision: 0.6040\n",
      "Epoch 11: val_loss did not improve from 1.05309\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9769 - precision: 0.6042 - val_loss: 1.0673 - val_precision: 0.6004\n",
      "Epoch 12/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9766 - precision: 0.5972\n",
      "Epoch 12: val_loss improved from 1.05309 to 1.04827, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9794 - precision: 0.5982 - val_loss: 1.0483 - val_precision: 0.6112\n",
      "Epoch 13/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9587 - precision: 0.6006\n",
      "Epoch 13: val_loss improved from 1.04827 to 1.04203, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9611 - precision: 0.6011 - val_loss: 1.0420 - val_precision: 0.6198\n",
      "Epoch 14/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9611 - precision: 0.6038\n",
      "Epoch 14: val_loss did not improve from 1.04203\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9602 - precision: 0.6047 - val_loss: 1.0483 - val_precision: 0.6123\n",
      "Epoch 15/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9595 - precision: 0.6093\n",
      "Epoch 15: val_loss improved from 1.04203 to 1.03789, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9576 - precision: 0.6080 - val_loss: 1.0379 - val_precision: 0.6223\n",
      "Epoch 16/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9491 - precision: 0.6125\n",
      "Epoch 16: val_loss did not improve from 1.03789\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9492 - precision: 0.6143 - val_loss: 1.0553 - val_precision: 0.6078\n",
      "Epoch 17/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9507 - precision: 0.6024\n",
      "Epoch 17: val_loss did not improve from 1.03789\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9529 - precision: 0.6021 - val_loss: 1.0467 - val_precision: 0.6085\n",
      "Epoch 18/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9342 - precision: 0.6123\n",
      "Epoch 18: val_loss improved from 1.03789 to 1.03597, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9340 - precision: 0.6118 - val_loss: 1.0360 - val_precision: 0.6261\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9374 - precision: 0.6121\n",
      "Epoch 19: val_loss did not improve from 1.03597\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9370 - precision: 0.6120 - val_loss: 1.0393 - val_precision: 0.6199\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9261 - precision: 0.6181\n",
      "Epoch 20: val_loss did not improve from 1.03597\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9244 - precision: 0.6186 - val_loss: 1.0467 - val_precision: 0.6079\n",
      "Epoch 21/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9280 - precision: 0.6121\n",
      "Epoch 21: val_loss improved from 1.03597 to 1.03177, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9262 - precision: 0.6131 - val_loss: 1.0318 - val_precision: 0.6201\n",
      "Epoch 22/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9191 - precision: 0.6177\n",
      "Epoch 22: val_loss did not improve from 1.03177\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9200 - precision: 0.6167 - val_loss: 1.0361 - val_precision: 0.6201\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9132 - precision: 0.6159\n",
      "Epoch 23: val_loss improved from 1.03177 to 1.03043, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9144 - precision: 0.6151 - val_loss: 1.0304 - val_precision: 0.6176\n",
      "Epoch 24/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9138 - precision: 0.6187\n",
      "Epoch 24: val_loss improved from 1.03043 to 1.02882, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9146 - precision: 0.6186 - val_loss: 1.0288 - val_precision: 0.6180\n",
      "Epoch 25/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9185 - precision: 0.6162\n",
      "Epoch 25: val_loss improved from 1.02882 to 1.02761, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9168 - precision: 0.6148 - val_loss: 1.0276 - val_precision: 0.6179\n",
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9024 - precision: 0.6173\n",
      "Epoch 26: val_loss did not improve from 1.02761\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9054 - precision: 0.6166 - val_loss: 1.0296 - val_precision: 0.6189\n",
      "Epoch 27/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8998 - precision: 0.6212\n",
      "Epoch 27: val_loss improved from 1.02761 to 1.02533, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9018 - precision: 0.6211 - val_loss: 1.0253 - val_precision: 0.6209\n",
      "Epoch 28/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8979 - precision: 0.6220\n",
      "Epoch 28: val_loss did not improve from 1.02533\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8997 - precision: 0.6216 - val_loss: 1.0285 - val_precision: 0.6190\n",
      "Epoch 29/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8997 - precision: 0.6208\n",
      "Epoch 29: val_loss did not improve from 1.02533\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8990 - precision: 0.6198 - val_loss: 1.0418 - val_precision: 0.6108\n",
      "Epoch 30/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8857 - precision: 0.6259\n",
      "Epoch 30: val_loss improved from 1.02533 to 1.02183, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8863 - precision: 0.6254 - val_loss: 1.0218 - val_precision: 0.6175\n",
      "Epoch 31/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8916 - precision: 0.6253\n",
      "Epoch 31: val_loss improved from 1.02183 to 1.01704, saving model to model_ent19.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8902 - precision: 0.6239 - val_loss: 1.0170 - val_precision: 0.6177\n",
      "Epoch 32/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8802 - precision: 0.6215\n",
      "Epoch 32: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8832 - precision: 0.6216 - val_loss: 1.0228 - val_precision: 0.6219\n",
      "Epoch 33/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8754 - precision: 0.6251\n",
      "Epoch 33: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8750 - precision: 0.6252 - val_loss: 1.0382 - val_precision: 0.6130\n",
      "Epoch 34/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8724 - precision: 0.6228\n",
      "Epoch 34: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8708 - precision: 0.6223 - val_loss: 1.0228 - val_precision: 0.6247\n",
      "Epoch 35/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8727 - precision: 0.6270\n",
      "Epoch 35: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8723 - precision: 0.6272 - val_loss: 1.0202 - val_precision: 0.6163\n",
      "Epoch 36/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8626 - precision: 0.6288\n",
      "Epoch 36: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8623 - precision: 0.6291 - val_loss: 1.0263 - val_precision: 0.6192\n",
      "Epoch 37/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8660 - precision: 0.6306\n",
      "Epoch 37: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8654 - precision: 0.6311 - val_loss: 1.0272 - val_precision: 0.6179\n",
      "Epoch 38/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8631 - precision: 0.6316\n",
      "Epoch 38: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8614 - precision: 0.6315 - val_loss: 1.0324 - val_precision: 0.6186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8629 - precision: 0.6262\n",
      "Epoch 39: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8624 - precision: 0.6263 - val_loss: 1.0336 - val_precision: 0.6124\n",
      "Epoch 40/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8519 - precision: 0.6308\n",
      "Epoch 40: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8530 - precision: 0.6305 - val_loss: 1.0311 - val_precision: 0.6163\n",
      "Epoch 41/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8490 - precision: 0.6397\n",
      "Epoch 41: val_loss did not improve from 1.01704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8490 - precision: 0.6397 - val_loss: 1.0525 - val_precision: 0.6034\n",
      "Epoch 41: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9615 - precision: 0.6279\n",
      "Combinación 18 = (True, True, False, 16, 0.1) \n",
      " precision train: [0.9614506363868713, 0.627850353717804]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 20: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.5247 - precision: 0.5976\n",
      "Epoch 1: val_loss improved from inf to 1.36088, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.5171 - precision: 0.6006 - val_loss: 1.3609 - val_precision: 0.6667\n",
      "Epoch 2/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3176 - precision: 0.6265\n",
      "Epoch 2: val_loss improved from 1.36088 to 1.22107, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3171 - precision: 0.6225 - val_loss: 1.2211 - val_precision: 0.6799\n",
      "Epoch 3/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2246 - precision: 0.6480\n",
      "Epoch 3: val_loss improved from 1.22107 to 1.16268, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2213 - precision: 0.6519 - val_loss: 1.1627 - val_precision: 0.6700\n",
      "Epoch 4/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1389 - precision: 0.6389\n",
      "Epoch 4: val_loss improved from 1.16268 to 1.11750, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1357 - precision: 0.6393 - val_loss: 1.1175 - val_precision: 0.6594\n",
      "Epoch 5/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0945 - precision: 0.6165\n",
      "Epoch 5: val_loss improved from 1.11750 to 1.10921, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0961 - precision: 0.6146 - val_loss: 1.1092 - val_precision: 0.6134\n",
      "Epoch 6/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0702 - precision: 0.6032\n",
      "Epoch 6: val_loss improved from 1.10921 to 1.09965, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0693 - precision: 0.6052 - val_loss: 1.0996 - val_precision: 0.6064\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0538 - precision: 0.5995\n",
      "Epoch 7: val_loss improved from 1.09965 to 1.08208, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0530 - precision: 0.5996 - val_loss: 1.0821 - val_precision: 0.6095\n",
      "Epoch 8/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0403 - precision: 0.6060\n",
      "Epoch 8: val_loss improved from 1.08208 to 1.07296, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0423 - precision: 0.6014 - val_loss: 1.0730 - val_precision: 0.6075\n",
      "Epoch 9/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0257 - precision: 0.6053\n",
      "Epoch 9: val_loss improved from 1.07296 to 1.06814, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0258 - precision: 0.6042 - val_loss: 1.0681 - val_precision: 0.6025\n",
      "Epoch 10/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0242 - precision: 0.6002\n",
      "Epoch 10: val_loss did not improve from 1.06814\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0228 - precision: 0.6000 - val_loss: 1.0924 - val_precision: 0.5949\n",
      "Epoch 11/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0165 - precision: 0.5979\n",
      "Epoch 11: val_loss improved from 1.06814 to 1.06667, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0170 - precision: 0.5994 - val_loss: 1.0667 - val_precision: 0.6030\n",
      "Epoch 12/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0121 - precision: 0.6062\n",
      "Epoch 12: val_loss improved from 1.06667 to 1.05974, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0121 - precision: 0.6068 - val_loss: 1.0597 - val_precision: 0.6051\n",
      "Epoch 13/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0077 - precision: 0.5990\n",
      "Epoch 13: val_loss improved from 1.05974 to 1.05204, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0104 - precision: 0.5990 - val_loss: 1.0520 - val_precision: 0.6051\n",
      "Epoch 14/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0065 - precision: 0.6091\n",
      "Epoch 14: val_loss did not improve from 1.05204\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0084 - precision: 0.6082 - val_loss: 1.0610 - val_precision: 0.6024\n",
      "Epoch 15/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0086 - precision: 0.5995\n",
      "Epoch 15: val_loss did not improve from 1.05204\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0077 - precision: 0.6003 - val_loss: 1.0595 - val_precision: 0.6053\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9984 - precision: 0.6053\n",
      "Epoch 16: val_loss did not improve from 1.05204\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9962 - precision: 0.6084 - val_loss: 1.0673 - val_precision: 0.6015\n",
      "Epoch 17/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9918 - precision: 0.5996\n",
      "Epoch 17: val_loss improved from 1.05204 to 1.04637, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9932 - precision: 0.6013 - val_loss: 1.0464 - val_precision: 0.6116\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9877 - precision: 0.6094\n",
      "Epoch 18: val_loss did not improve from 1.04637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9884 - precision: 0.6088 - val_loss: 1.0552 - val_precision: 0.6032\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9883 - precision: 0.6077\n",
      "Epoch 19: val_loss did not improve from 1.04637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9889 - precision: 0.6078 - val_loss: 1.0562 - val_precision: 0.6073\n",
      "Epoch 20/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9801 - precision: 0.6033\n",
      "Epoch 20: val_loss did not improve from 1.04637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9792 - precision: 0.6043 - val_loss: 1.0533 - val_precision: 0.5996\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9730 - precision: 0.6106\n",
      "Epoch 21: val_loss did not improve from 1.04637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9730 - precision: 0.6109 - val_loss: 1.0571 - val_precision: 0.5956\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9648 - precision: 0.6119\n",
      "Epoch 22: val_loss improved from 1.04637 to 1.04453, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9664 - precision: 0.6111 - val_loss: 1.0445 - val_precision: 0.6063\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9718 - precision: 0.6098\n",
      "Epoch 23: val_loss improved from 1.04453 to 1.04060, saving model to model_ent20.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9729 - precision: 0.6091 - val_loss: 1.0406 - val_precision: 0.6090\n",
      "Epoch 24/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9648 - precision: 0.6128\n",
      "Epoch 24: val_loss did not improve from 1.04060\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9658 - precision: 0.6118 - val_loss: 1.0553 - val_precision: 0.6035\n",
      "Epoch 25/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9670 - precision: 0.6071\n",
      "Epoch 25: val_loss did not improve from 1.04060\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9690 - precision: 0.6080 - val_loss: 1.0444 - val_precision: 0.6048\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9653 - precision: 0.6108\n",
      "Epoch 26: val_loss did not improve from 1.04060\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9653 - precision: 0.6108 - val_loss: 1.0426 - val_precision: 0.6063\n",
      "Epoch 27/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9520 - precision: 0.6089\n",
      "Epoch 27: val_loss did not improve from 1.04060\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9508 - precision: 0.6126 - val_loss: 1.0460 - val_precision: 0.6093\n",
      "Epoch 28/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9618 - precision: 0.6093\n",
      "Epoch 28: val_loss improved from 1.04060 to 1.03425, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9616 - precision: 0.6091 - val_loss: 1.0343 - val_precision: 0.6105\n",
      "Epoch 29/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9524 - precision: 0.6149\n",
      "Epoch 29: val_loss did not improve from 1.03425\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9506 - precision: 0.6129 - val_loss: 1.0349 - val_precision: 0.6130\n",
      "Epoch 30/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9503 - precision: 0.6120\n",
      "Epoch 30: val_loss improved from 1.03425 to 1.03370, saving model to model_ent20.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9506 - precision: 0.6115 - val_loss: 1.0337 - val_precision: 0.6097\n",
      "Epoch 31/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9601 - precision: 0.6098\n",
      "Epoch 31: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9560 - precision: 0.6109 - val_loss: 1.0419 - val_precision: 0.6087\n",
      "Epoch 32/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9543 - precision: 0.6064\n",
      "Epoch 32: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9547 - precision: 0.6079 - val_loss: 1.0436 - val_precision: 0.6029\n",
      "Epoch 33/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9425 - precision: 0.6178\n",
      "Epoch 33: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9425 - precision: 0.6178 - val_loss: 1.0457 - val_precision: 0.6040\n",
      "Epoch 34/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9455 - precision: 0.6165\n",
      "Epoch 34: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9432 - precision: 0.6180 - val_loss: 1.0497 - val_precision: 0.5988\n",
      "Epoch 35/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9419 - precision: 0.6159\n",
      "Epoch 35: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9404 - precision: 0.6169 - val_loss: 1.0416 - val_precision: 0.6069\n",
      "Epoch 36/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9327 - precision: 0.6156\n",
      "Epoch 36: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9346 - precision: 0.6143 - val_loss: 1.0521 - val_precision: 0.6008\n",
      "Epoch 37/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9310 - precision: 0.6145\n",
      "Epoch 37: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9305 - precision: 0.6147 - val_loss: 1.0519 - val_precision: 0.5987\n",
      "Epoch 38/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9314 - precision: 0.6132\n",
      "Epoch 38: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9328 - precision: 0.6128 - val_loss: 1.0457 - val_precision: 0.5962\n",
      "Epoch 39/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9406 - precision: 0.6122\n",
      "Epoch 39: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9401 - precision: 0.6122 - val_loss: 1.0454 - val_precision: 0.5995\n",
      "Epoch 40/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9291 - precision: 0.6186\n",
      "Epoch 40: val_loss did not improve from 1.03370\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9300 - precision: 0.6168 - val_loss: 1.0446 - val_precision: 0.6037\n",
      "Epoch 40: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9868 - precision: 0.6170\n",
      "Combinación 19 = (True, True, False, 16, 0.25) \n",
      " precision train: [0.9867609143257141, 0.6170047521591187]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 21: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.5741 - precision: 0.5823   \n",
      "Epoch 1: val_loss improved from inf to 1.35506, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 8s 9ms/step - loss: 1.5661 - precision: 0.6142 - val_loss: 1.3551 - val_precision: 0.6632\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.3691 - precision: 0.5947\n",
      "Epoch 2: val_loss improved from 1.35506 to 1.26769, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3687 - precision: 0.5947 - val_loss: 1.2677 - val_precision: 0.6957\n",
      "Epoch 3/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.3147 - precision: 0.6267\n",
      "Epoch 3: val_loss improved from 1.26769 to 1.23698, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3127 - precision: 0.6286 - val_loss: 1.2370 - val_precision: 0.6907\n",
      "Epoch 4/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2860 - precision: 0.6392\n",
      "Epoch 4: val_loss improved from 1.23698 to 1.22406, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2871 - precision: 0.6381 - val_loss: 1.2241 - val_precision: 0.6869\n",
      "Epoch 5/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2760 - precision: 0.6534\n",
      "Epoch 5: val_loss improved from 1.22406 to 1.20567, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2767 - precision: 0.6512 - val_loss: 1.2057 - val_precision: 0.6784\n",
      "Epoch 6/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2588 - precision: 0.6556\n",
      "Epoch 6: val_loss improved from 1.20567 to 1.20070, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2561 - precision: 0.6566 - val_loss: 1.2007 - val_precision: 0.6884\n",
      "Epoch 7/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2334 - precision: 0.6592\n",
      "Epoch 7: val_loss improved from 1.20070 to 1.18975, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2354 - precision: 0.6553 - val_loss: 1.1897 - val_precision: 0.6946\n",
      "Epoch 8/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2321 - precision: 0.6576\n",
      "Epoch 8: val_loss improved from 1.18975 to 1.16917, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2344 - precision: 0.6563 - val_loss: 1.1692 - val_precision: 0.6938\n",
      "Epoch 9/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2218 - precision: 0.6567\n",
      "Epoch 9: val_loss improved from 1.16917 to 1.15716, saving model to model_ent21.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2227 - precision: 0.6537 - val_loss: 1.1572 - val_precision: 0.6917\n",
      "Epoch 10/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2074 - precision: 0.6434\n",
      "Epoch 10: val_loss improved from 1.15716 to 1.15058, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2095 - precision: 0.6442 - val_loss: 1.1506 - val_precision: 0.6839\n",
      "Epoch 11/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1971 - precision: 0.6360\n",
      "Epoch 11: val_loss improved from 1.15058 to 1.14076, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1939 - precision: 0.6358 - val_loss: 1.1408 - val_precision: 0.6702\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1897 - precision: 0.6306\n",
      "Epoch 12: val_loss improved from 1.14076 to 1.13457, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1897 - precision: 0.6306 - val_loss: 1.1346 - val_precision: 0.6695\n",
      "Epoch 13/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1889 - precision: 0.6248\n",
      "Epoch 13: val_loss did not improve from 1.13457\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1896 - precision: 0.6252 - val_loss: 1.1357 - val_precision: 0.6548\n",
      "Epoch 14/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1722 - precision: 0.6285\n",
      "Epoch 14: val_loss improved from 1.13457 to 1.12672, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1726 - precision: 0.6291 - val_loss: 1.1267 - val_precision: 0.6572\n",
      "Epoch 15/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1622 - precision: 0.6281\n",
      "Epoch 15: val_loss improved from 1.12672 to 1.11927, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1622 - precision: 0.6287 - val_loss: 1.1193 - val_precision: 0.6602\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1491 - precision: 0.6315\n",
      "Epoch 16: val_loss improved from 1.11927 to 1.11315, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1505 - precision: 0.6298 - val_loss: 1.1132 - val_precision: 0.6441\n",
      "Epoch 17/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1502 - precision: 0.6346\n",
      "Epoch 17: val_loss did not improve from 1.11315\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1526 - precision: 0.6338 - val_loss: 1.1191 - val_precision: 0.6537\n",
      "Epoch 18/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1627 - precision: 0.6340\n",
      "Epoch 18: val_loss did not improve from 1.11315\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1607 - precision: 0.6342 - val_loss: 1.1162 - val_precision: 0.6546\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1494 - precision: 0.6210\n",
      "Epoch 19: val_loss did not improve from 1.11315\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1496 - precision: 0.6222 - val_loss: 1.1176 - val_precision: 0.6420\n",
      "Epoch 20/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1381 - precision: 0.6207\n",
      "Epoch 20: val_loss improved from 1.11315 to 1.10608, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1393 - precision: 0.6206 - val_loss: 1.1061 - val_precision: 0.6556\n",
      "Epoch 21/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1328 - precision: 0.6240\n",
      "Epoch 21: val_loss did not improve from 1.10608\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1343 - precision: 0.6221 - val_loss: 1.1124 - val_precision: 0.6496\n",
      "Epoch 22/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1383 - precision: 0.6176\n",
      "Epoch 22: val_loss did not improve from 1.10608\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1356 - precision: 0.6176 - val_loss: 1.1112 - val_precision: 0.6417\n",
      "Epoch 23/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1345 - precision: 0.6221\n",
      "Epoch 23: val_loss did not improve from 1.10608\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1354 - precision: 0.6193 - val_loss: 1.1143 - val_precision: 0.6363\n",
      "Epoch 24/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1291 - precision: 0.6124\n",
      "Epoch 24: val_loss did not improve from 1.10608\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1299 - precision: 0.6109 - val_loss: 1.1127 - val_precision: 0.6330\n",
      "Epoch 25/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1333 - precision: 0.6169\n",
      "Epoch 25: val_loss did not improve from 1.10608\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1354 - precision: 0.6151 - val_loss: 1.1076 - val_precision: 0.6357\n",
      "Epoch 26/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1146 - precision: 0.6126\n",
      "Epoch 26: val_loss improved from 1.10608 to 1.10532, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1142 - precision: 0.6127 - val_loss: 1.1053 - val_precision: 0.6326\n",
      "Epoch 27/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1297 - precision: 0.6071\n",
      "Epoch 27: val_loss did not improve from 1.10532\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1297 - precision: 0.6071 - val_loss: 1.1121 - val_precision: 0.6283\n",
      "Epoch 28/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1225 - precision: 0.6096\n",
      "Epoch 28: val_loss did not improve from 1.10532\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1202 - precision: 0.6078 - val_loss: 1.1085 - val_precision: 0.6278\n",
      "Epoch 29/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1139 - precision: 0.6152\n",
      "Epoch 29: val_loss improved from 1.10532 to 1.09494, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1166 - precision: 0.6123 - val_loss: 1.0949 - val_precision: 0.6395\n",
      "Epoch 30/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1143 - precision: 0.6139\n",
      "Epoch 30: val_loss did not improve from 1.09494\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1140 - precision: 0.6133 - val_loss: 1.1027 - val_precision: 0.6236\n",
      "Epoch 31/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1111 - precision: 0.6149\n",
      "Epoch 31: val_loss did not improve from 1.09494\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1130 - precision: 0.6143 - val_loss: 1.1098 - val_precision: 0.6139\n",
      "Epoch 32/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1124 - precision: 0.6062\n",
      "Epoch 32: val_loss did not improve from 1.09494\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1094 - precision: 0.6058 - val_loss: 1.1022 - val_precision: 0.6248\n",
      "Epoch 33/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0991 - precision: 0.6104\n",
      "Epoch 33: val_loss did not improve from 1.09494\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0985 - precision: 0.6123 - val_loss: 1.0958 - val_precision: 0.6204\n",
      "Epoch 34/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1033 - precision: 0.6112\n",
      "Epoch 34: val_loss did not improve from 1.09494\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1070 - precision: 0.6105 - val_loss: 1.1115 - val_precision: 0.6090\n",
      "Epoch 35/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1013 - precision: 0.6158\n",
      "Epoch 35: val_loss did not improve from 1.09494\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1025 - precision: 0.6132 - val_loss: 1.1103 - val_precision: 0.6141\n",
      "Epoch 36/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1009 - precision: 0.6115\n",
      "Epoch 36: val_loss improved from 1.09494 to 1.09318, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1012 - precision: 0.6095 - val_loss: 1.0932 - val_precision: 0.6238\n",
      "Epoch 37/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1027 - precision: 0.6081\n",
      "Epoch 37: val_loss did not improve from 1.09318\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1000 - precision: 0.6109 - val_loss: 1.1062 - val_precision: 0.6059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1007 - precision: 0.6086\n",
      "Epoch 38: val_loss did not improve from 1.09318\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0979 - precision: 0.6081 - val_loss: 1.1039 - val_precision: 0.6209\n",
      "Epoch 39/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1083 - precision: 0.6021\n",
      "Epoch 39: val_loss did not improve from 1.09318\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1078 - precision: 0.6006 - val_loss: 1.1042 - val_precision: 0.6199\n",
      "Epoch 40/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0944 - precision: 0.6107\n",
      "Epoch 40: val_loss did not improve from 1.09318\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0944 - precision: 0.6107 - val_loss: 1.1041 - val_precision: 0.6104\n",
      "Epoch 41/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0812 - precision: 0.6116\n",
      "Epoch 41: val_loss did not improve from 1.09318\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0816 - precision: 0.6133 - val_loss: 1.1070 - val_precision: 0.6091\n",
      "Epoch 42/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0869 - precision: 0.6150\n",
      "Epoch 42: val_loss did not improve from 1.09318\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0888 - precision: 0.6152 - val_loss: 1.1034 - val_precision: 0.6081\n",
      "Epoch 43/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0809 - precision: 0.6165\n",
      "Epoch 43: val_loss did not improve from 1.09318\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0786 - precision: 0.6146 - val_loss: 1.1049 - val_precision: 0.6048\n",
      "Epoch 44/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0970 - precision: 0.6036\n",
      "Epoch 44: val_loss improved from 1.09318 to 1.09291, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0960 - precision: 0.6043 - val_loss: 1.0929 - val_precision: 0.6228\n",
      "Epoch 45/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0820 - precision: 0.6094\n",
      "Epoch 45: val_loss did not improve from 1.09291\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0820 - precision: 0.6094 - val_loss: 1.1182 - val_precision: 0.5936\n",
      "Epoch 46/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0897 - precision: 0.6133\n",
      "Epoch 46: val_loss did not improve from 1.09291\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0890 - precision: 0.6133 - val_loss: 1.1027 - val_precision: 0.6126\n",
      "Epoch 47/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0839 - precision: 0.6140\n",
      "Epoch 47: val_loss did not improve from 1.09291\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0828 - precision: 0.6156 - val_loss: 1.0992 - val_precision: 0.6102\n",
      "Epoch 48/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0834 - precision: 0.6105\n",
      "Epoch 48: val_loss did not improve from 1.09291\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0802 - precision: 0.6095 - val_loss: 1.1093 - val_precision: 0.6105\n",
      "Epoch 49/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0772 - precision: 0.6035\n",
      "Epoch 49: val_loss did not improve from 1.09291\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0772 - precision: 0.6035 - val_loss: 1.0995 - val_precision: 0.6099\n",
      "Epoch 50/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0898 - precision: 0.6092\n",
      "Epoch 50: val_loss did not improve from 1.09291\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0849 - precision: 0.6092 - val_loss: 1.0956 - val_precision: 0.6175\n",
      "Epoch 51/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0710 - precision: 0.6112\n",
      "Epoch 51: val_loss improved from 1.09291 to 1.09171, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0751 - precision: 0.6094 - val_loss: 1.0917 - val_precision: 0.6159\n",
      "Epoch 52/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0809 - precision: 0.6110\n",
      "Epoch 52: val_loss did not improve from 1.09171\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0790 - precision: 0.6125 - val_loss: 1.1113 - val_precision: 0.6039\n",
      "Epoch 53/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0778 - precision: 0.6069\n",
      "Epoch 53: val_loss did not improve from 1.09171\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0783 - precision: 0.6074 - val_loss: 1.1026 - val_precision: 0.6077\n",
      "Epoch 54/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0735 - precision: 0.6119\n",
      "Epoch 54: val_loss did not improve from 1.09171\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0715 - precision: 0.6138 - val_loss: 1.1029 - val_precision: 0.6121\n",
      "Epoch 55/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0737 - precision: 0.6117\n",
      "Epoch 55: val_loss did not improve from 1.09171\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0723 - precision: 0.6133 - val_loss: 1.0994 - val_precision: 0.6117\n",
      "Epoch 56/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0680 - precision: 0.6135\n",
      "Epoch 56: val_loss improved from 1.09171 to 1.09017, saving model to model_ent21.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0673 - precision: 0.6139 - val_loss: 1.0902 - val_precision: 0.6148\n",
      "Epoch 57/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0756 - precision: 0.6152\n",
      "Epoch 57: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0764 - precision: 0.6147 - val_loss: 1.0974 - val_precision: 0.6106\n",
      "Epoch 58/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0747 - precision: 0.6050\n",
      "Epoch 58: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0704 - precision: 0.6058 - val_loss: 1.1065 - val_precision: 0.6106\n",
      "Epoch 59/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0702 - precision: 0.6188\n",
      "Epoch 59: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0708 - precision: 0.6166 - val_loss: 1.0954 - val_precision: 0.6098\n",
      "Epoch 60/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0622 - precision: 0.6230\n",
      "Epoch 60: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0623 - precision: 0.6247 - val_loss: 1.0956 - val_precision: 0.6095\n",
      "Epoch 61/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0778 - precision: 0.6140\n",
      "Epoch 61: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0743 - precision: 0.6150 - val_loss: 1.0947 - val_precision: 0.6106\n",
      "Epoch 62/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0712 - precision: 0.6067\n",
      "Epoch 62: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0707 - precision: 0.6076 - val_loss: 1.0989 - val_precision: 0.6122\n",
      "Epoch 63/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0658 - precision: 0.6184\n",
      "Epoch 63: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0656 - precision: 0.6193 - val_loss: 1.1056 - val_precision: 0.6064\n",
      "Epoch 64/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0583 - precision: 0.6153\n",
      "Epoch 64: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0548 - precision: 0.6167 - val_loss: 1.1087 - val_precision: 0.6009\n",
      "Epoch 65/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0599 - precision: 0.6209\n",
      "Epoch 65: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0605 - precision: 0.6203 - val_loss: 1.1024 - val_precision: 0.6091\n",
      "Epoch 66/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0600 - precision: 0.6132\n",
      "Epoch 66: val_loss did not improve from 1.09017\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0614 - precision: 0.6134 - val_loss: 1.1052 - val_precision: 0.6008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0587 - precision: 0.6142\n",
      "Combinación 20 = (True, True, False, 16, 0.5) \n",
      " precision train: [1.0587180852890015, 0.6141939163208008]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 22: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.3485 - precision: 0.5897\n",
      "Epoch 1: val_loss improved from inf to 1.17374, saving model to model_ent22.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.3475 - precision: 0.5903 - val_loss: 1.1737 - val_precision: 0.6306\n",
      "Epoch 2/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0567 - precision: 0.6010\n",
      "Epoch 2: val_loss improved from 1.17374 to 1.09677, saving model to model_ent22.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0579 - precision: 0.5999 - val_loss: 1.0968 - val_precision: 0.6073\n",
      "Epoch 3/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0200 - precision: 0.5947\n",
      "Epoch 3: val_loss improved from 1.09677 to 1.07639, saving model to model_ent22.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0201 - precision: 0.5935 - val_loss: 1.0764 - val_precision: 0.6064\n",
      "Epoch 4/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0029 - precision: 0.5998\n",
      "Epoch 4: val_loss improved from 1.07639 to 1.06858, saving model to model_ent22.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0028 - precision: 0.6000 - val_loss: 1.0686 - val_precision: 0.6088\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9911 - precision: 0.6027\n",
      "Epoch 5: val_loss did not improve from 1.06858\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9891 - precision: 0.6035 - val_loss: 1.0721 - val_precision: 0.6102\n",
      "Epoch 6/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9738 - precision: 0.6068\n",
      "Epoch 6: val_loss improved from 1.06858 to 1.05690, saving model to model_ent22.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9754 - precision: 0.6046 - val_loss: 1.0569 - val_precision: 0.6127\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9686 - precision: 0.6067\n",
      "Epoch 7: val_loss did not improve from 1.05690\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9703 - precision: 0.6059 - val_loss: 1.0639 - val_precision: 0.5983\n",
      "Epoch 8/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9640 - precision: 0.6085\n",
      "Epoch 8: val_loss did not improve from 1.05690\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9617 - precision: 0.6091 - val_loss: 1.0596 - val_precision: 0.6072\n",
      "Epoch 9/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9536 - precision: 0.6052\n",
      "Epoch 9: val_loss improved from 1.05690 to 1.04621, saving model to model_ent22.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9499 - precision: 0.6069 - val_loss: 1.0462 - val_precision: 0.6138\n",
      "Epoch 10/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9466 - precision: 0.6100\n",
      "Epoch 10: val_loss did not improve from 1.04621\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9502 - precision: 0.6092 - val_loss: 1.0509 - val_precision: 0.6236\n",
      "Epoch 11/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9364 - precision: 0.6102\n",
      "Epoch 11: val_loss improved from 1.04621 to 1.02282, saving model to model_ent22.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9377 - precision: 0.6109 - val_loss: 1.0228 - val_precision: 0.6362\n",
      "Epoch 12/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9293 - precision: 0.6101\n",
      "Epoch 12: val_loss did not improve from 1.02282\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9309 - precision: 0.6100 - val_loss: 1.0361 - val_precision: 0.6208\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9247 - precision: 0.6143\n",
      "Epoch 13: val_loss did not improve from 1.02282\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9239 - precision: 0.6146 - val_loss: 1.0267 - val_precision: 0.6249\n",
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9200 - precision: 0.6140\n",
      "Epoch 14: val_loss did not improve from 1.02282\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9199 - precision: 0.6140 - val_loss: 1.0354 - val_precision: 0.6211\n",
      "Epoch 15/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9136 - precision: 0.6184\n",
      "Epoch 15: val_loss improved from 1.02282 to 1.01985, saving model to model_ent22.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9135 - precision: 0.6190 - val_loss: 1.0198 - val_precision: 0.6258\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9114 - precision: 0.6124\n",
      "Epoch 16: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9088 - precision: 0.6146 - val_loss: 1.0227 - val_precision: 0.6250\n",
      "Epoch 17/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9039 - precision: 0.6171\n",
      "Epoch 17: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9043 - precision: 0.6174 - val_loss: 1.0486 - val_precision: 0.6148\n",
      "Epoch 18/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8972 - precision: 0.6240\n",
      "Epoch 18: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8959 - precision: 0.6233 - val_loss: 1.0458 - val_precision: 0.6129\n",
      "Epoch 19/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8908 - precision: 0.6176\n",
      "Epoch 19: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8919 - precision: 0.6174 - val_loss: 1.0199 - val_precision: 0.6239\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8881 - precision: 0.6229\n",
      "Epoch 20: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8881 - precision: 0.6236 - val_loss: 1.0286 - val_precision: 0.6216\n",
      "Epoch 21/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8752 - precision: 0.6258\n",
      "Epoch 21: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8806 - precision: 0.6242 - val_loss: 1.0383 - val_precision: 0.6163\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8738 - precision: 0.6199\n",
      "Epoch 22: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8736 - precision: 0.6204 - val_loss: 1.0304 - val_precision: 0.6224\n",
      "Epoch 23/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8751 - precision: 0.6228\n",
      "Epoch 23: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8745 - precision: 0.6233 - val_loss: 1.0271 - val_precision: 0.6203\n",
      "Epoch 24/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8674 - precision: 0.6256\n",
      "Epoch 24: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8654 - precision: 0.6258 - val_loss: 1.0225 - val_precision: 0.6237\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8567 - precision: 0.6271\n",
      "Epoch 25: val_loss did not improve from 1.01985\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8582 - precision: 0.6265 - val_loss: 1.0347 - val_precision: 0.6175\n",
      "Epoch 25: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9667 - precision: 0.6276\n",
      "Combinación 21 = (True, True, False, 32, 0.1) \n",
      " precision train: [0.9666724801063538, 0.6275805234909058]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 23: \n",
      "\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.4174 - precision: 0.5788\n",
      "Epoch 1: val_loss improved from inf to 1.27760, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.4136 - precision: 0.5821 - val_loss: 1.2776 - val_precision: 0.6594\n",
      "Epoch 2/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1832 - precision: 0.6482\n",
      "Epoch 2: val_loss improved from 1.27760 to 1.13334, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1833 - precision: 0.6470 - val_loss: 1.1333 - val_precision: 0.6483\n",
      "Epoch 3/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0744 - precision: 0.6245\n",
      "Epoch 3: val_loss improved from 1.13334 to 1.08283, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0724 - precision: 0.6258 - val_loss: 1.0828 - val_precision: 0.6334\n",
      "Epoch 4/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0420 - precision: 0.5985\n",
      "Epoch 4: val_loss improved from 1.08283 to 1.07496, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0420 - precision: 0.5985 - val_loss: 1.0750 - val_precision: 0.6080\n",
      "Epoch 5/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0232 - precision: 0.5911\n",
      "Epoch 5: val_loss improved from 1.07496 to 1.06313, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0229 - precision: 0.5917 - val_loss: 1.0631 - val_precision: 0.6162\n",
      "Epoch 6/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0066 - precision: 0.5951\n",
      "Epoch 6: val_loss improved from 1.06313 to 1.05406, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0108 - precision: 0.5933 - val_loss: 1.0541 - val_precision: 0.6110\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0015 - precision: 0.5969\n",
      "Epoch 7: val_loss did not improve from 1.05406\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0009 - precision: 0.5965 - val_loss: 1.0555 - val_precision: 0.6040\n",
      "Epoch 8/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9903 - precision: 0.5970\n",
      "Epoch 8: val_loss did not improve from 1.05406\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9886 - precision: 0.5977 - val_loss: 1.0580 - val_precision: 0.6003\n",
      "Epoch 9/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9882 - precision: 0.5981\n",
      "Epoch 9: val_loss improved from 1.05406 to 1.04163, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9872 - precision: 0.5999 - val_loss: 1.0416 - val_precision: 0.6145\n",
      "Epoch 10/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9824 - precision: 0.6027\n",
      "Epoch 10: val_loss did not improve from 1.04163\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9823 - precision: 0.6027 - val_loss: 1.0435 - val_precision: 0.6186\n",
      "Epoch 11/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9746 - precision: 0.5975\n",
      "Epoch 11: val_loss did not improve from 1.04163\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9738 - precision: 0.5979 - val_loss: 1.0601 - val_precision: 0.6079\n",
      "Epoch 12/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9724 - precision: 0.6016\n",
      "Epoch 12: val_loss did not improve from 1.04163\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9685 - precision: 0.6027 - val_loss: 1.0499 - val_precision: 0.6123\n",
      "Epoch 13/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9603 - precision: 0.6062\n",
      "Epoch 13: val_loss improved from 1.04163 to 1.03902, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9576 - precision: 0.6061 - val_loss: 1.0390 - val_precision: 0.6115\n",
      "Epoch 14/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9552 - precision: 0.6042\n",
      "Epoch 14: val_loss improved from 1.03902 to 1.02789, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9562 - precision: 0.6052 - val_loss: 1.0279 - val_precision: 0.6199\n",
      "Epoch 15/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9503 - precision: 0.6016\n",
      "Epoch 15: val_loss did not improve from 1.02789\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9472 - precision: 0.6043 - val_loss: 1.0353 - val_precision: 0.6242\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9492 - precision: 0.6114\n",
      "Epoch 16: val_loss did not improve from 1.02789\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9486 - precision: 0.6120 - val_loss: 1.0382 - val_precision: 0.6101\n",
      "Epoch 17/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9464 - precision: 0.6057\n",
      "Epoch 17: val_loss did not improve from 1.02789\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9448 - precision: 0.6059 - val_loss: 1.0456 - val_precision: 0.6086\n",
      "Epoch 18/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9313 - precision: 0.6114\n",
      "Epoch 18: val_loss improved from 1.02789 to 1.02675, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9304 - precision: 0.6118 - val_loss: 1.0268 - val_precision: 0.6219\n",
      "Epoch 19/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9327 - precision: 0.6138\n",
      "Epoch 19: val_loss did not improve from 1.02675\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9327 - precision: 0.6138 - val_loss: 1.0426 - val_precision: 0.6138\n",
      "Epoch 20/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9231 - precision: 0.6116\n",
      "Epoch 20: val_loss did not improve from 1.02675\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9265 - precision: 0.6119 - val_loss: 1.0352 - val_precision: 0.6109\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9272 - precision: 0.6135\n",
      "Epoch 21: val_loss did not improve from 1.02675\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9264 - precision: 0.6118 - val_loss: 1.0270 - val_precision: 0.6211\n",
      "Epoch 22/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9247 - precision: 0.6157\n",
      "Epoch 22: val_loss did not improve from 1.02675\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9255 - precision: 0.6150 - val_loss: 1.0386 - val_precision: 0.6187\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9128 - precision: 0.6185\n",
      "Epoch 23: val_loss did not improve from 1.02675\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9108 - precision: 0.6184 - val_loss: 1.0481 - val_precision: 0.6001\n",
      "Epoch 24/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9139 - precision: 0.6135\n",
      "Epoch 24: val_loss did not improve from 1.02675\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9133 - precision: 0.6124 - val_loss: 1.0285 - val_precision: 0.6170\n",
      "Epoch 25/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9094 - precision: 0.6224\n",
      "Epoch 25: val_loss improved from 1.02675 to 1.02142, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9121 - precision: 0.6195 - val_loss: 1.0214 - val_precision: 0.6151\n",
      "Epoch 26/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9139 - precision: 0.6206\n",
      "Epoch 26: val_loss did not improve from 1.02142\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9127 - precision: 0.6208 - val_loss: 1.0258 - val_precision: 0.6161\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8996 - precision: 0.6172\n",
      "Epoch 27: val_loss did not improve from 1.02142\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8992 - precision: 0.6172 - val_loss: 1.0426 - val_precision: 0.6083\n",
      "Epoch 28/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8940 - precision: 0.6196\n",
      "Epoch 28: val_loss did not improve from 1.02142\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8972 - precision: 0.6193 - val_loss: 1.0246 - val_precision: 0.6181\n",
      "Epoch 29/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8985 - precision: 0.6193\n",
      "Epoch 29: val_loss did not improve from 1.02142\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8976 - precision: 0.6185 - val_loss: 1.0366 - val_precision: 0.6038\n",
      "Epoch 30/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8911 - precision: 0.6191\n",
      "Epoch 30: val_loss did not improve from 1.02142\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8909 - precision: 0.6183 - val_loss: 1.0380 - val_precision: 0.6098\n",
      "Epoch 31/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8885 - precision: 0.6200\n",
      "Epoch 31: val_loss improved from 1.02142 to 1.00680, saving model to model_ent23.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8885 - precision: 0.6200 - val_loss: 1.0068 - val_precision: 0.6261\n",
      "Epoch 32/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8804 - precision: 0.6258\n",
      "Epoch 32: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8803 - precision: 0.6250 - val_loss: 1.0255 - val_precision: 0.6126\n",
      "Epoch 33/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8755 - precision: 0.6281\n",
      "Epoch 33: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8772 - precision: 0.6273 - val_loss: 1.0322 - val_precision: 0.6062\n",
      "Epoch 34/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8756 - precision: 0.6258\n",
      "Epoch 34: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8756 - precision: 0.6258 - val_loss: 1.0256 - val_precision: 0.6100\n",
      "Epoch 35/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8750 - precision: 0.6237\n",
      "Epoch 35: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8788 - precision: 0.6214 - val_loss: 1.0501 - val_precision: 0.5961\n",
      "Epoch 36/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8750 - precision: 0.6270\n",
      "Epoch 36: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8736 - precision: 0.6274 - val_loss: 1.0210 - val_precision: 0.6169\n",
      "Epoch 37/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8693 - precision: 0.6279\n",
      "Epoch 37: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8707 - precision: 0.6270 - val_loss: 1.0253 - val_precision: 0.6078\n",
      "Epoch 38/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8638 - precision: 0.6282\n",
      "Epoch 38: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8637 - precision: 0.6278 - val_loss: 1.0489 - val_precision: 0.5961\n",
      "Epoch 39/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8603 - precision: 0.6274\n",
      "Epoch 39: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8606 - precision: 0.6272 - val_loss: 1.0219 - val_precision: 0.6098\n",
      "Epoch 40/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8557 - precision: 0.6268\n",
      "Epoch 40: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8557 - precision: 0.6268 - val_loss: 1.0268 - val_precision: 0.6097\n",
      "Epoch 41/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8514 - precision: 0.6317\n",
      "Epoch 41: val_loss did not improve from 1.00680\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8518 - precision: 0.6319 - val_loss: 1.0280 - val_precision: 0.6153\n",
      "Epoch 41: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9357 - precision: 0.6385\n",
      "Combinación 22 = (True, True, False, 32, 0.25) \n",
      " precision train: [0.9357371926307678, 0.6384727358818054]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 24: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.4941 - precision: 0.5345\n",
      "Epoch 1: val_loss improved from inf to 1.28757, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 8s 9ms/step - loss: 1.4858 - precision: 0.5360 - val_loss: 1.2876 - val_precision: 0.6068\n",
      "Epoch 2/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2170 - precision: 0.5956\n",
      "Epoch 2: val_loss improved from 1.28757 to 1.16599, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2149 - precision: 0.5978 - val_loss: 1.1660 - val_precision: 0.6500\n",
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1457 - precision: 0.6208\n",
      "Epoch 3: val_loss improved from 1.16599 to 1.12873, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1472 - precision: 0.6195 - val_loss: 1.1287 - val_precision: 0.6515\n",
      "Epoch 4/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1222 - precision: 0.6216\n",
      "Epoch 4: val_loss improved from 1.12873 to 1.12395, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1204 - precision: 0.6214 - val_loss: 1.1240 - val_precision: 0.6275\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1019 - precision: 0.6126\n",
      "Epoch 5: val_loss improved from 1.12395 to 1.10396, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1019 - precision: 0.6126 - val_loss: 1.1040 - val_precision: 0.6247\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0930 - precision: 0.6077\n",
      "Epoch 6: val_loss improved from 1.10396 to 1.08906, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0930 - precision: 0.6077 - val_loss: 1.0891 - val_precision: 0.6295\n",
      "Epoch 7/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0791 - precision: 0.5937\n",
      "Epoch 7: val_loss improved from 1.08906 to 1.08903, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0791 - precision: 0.5937 - val_loss: 1.0890 - val_precision: 0.6141\n",
      "Epoch 8/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0757 - precision: 0.5858\n",
      "Epoch 8: val_loss improved from 1.08903 to 1.08674, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0775 - precision: 0.5855 - val_loss: 1.0867 - val_precision: 0.6145\n",
      "Epoch 9/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0580 - precision: 0.5980\n",
      "Epoch 9: val_loss improved from 1.08674 to 1.07732, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0583 - precision: 0.6002 - val_loss: 1.0773 - val_precision: 0.6167\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0547 - precision: 0.6023\n",
      "Epoch 10: val_loss did not improve from 1.07732\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0547 - precision: 0.6023 - val_loss: 1.0850 - val_precision: 0.6046\n",
      "Epoch 11/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0528 - precision: 0.5924\n",
      "Epoch 11: val_loss improved from 1.07732 to 1.07675, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0565 - precision: 0.5918 - val_loss: 1.0768 - val_precision: 0.6143\n",
      "Epoch 12/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0470 - precision: 0.6024\n",
      "Epoch 12: val_loss did not improve from 1.07675\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0508 - precision: 0.6011 - val_loss: 1.0774 - val_precision: 0.6093\n",
      "Epoch 13/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0469 - precision: 0.5889\n",
      "Epoch 13: val_loss improved from 1.07675 to 1.07524, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0492 - precision: 0.5907 - val_loss: 1.0752 - val_precision: 0.6170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0475 - precision: 0.6043\n",
      "Epoch 14: val_loss did not improve from 1.07524\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0474 - precision: 0.6037 - val_loss: 1.0830 - val_precision: 0.6115\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0412 - precision: 0.5958\n",
      "Epoch 15: val_loss did not improve from 1.07524\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0412 - precision: 0.5958 - val_loss: 1.0830 - val_precision: 0.6029\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0366 - precision: 0.5992\n",
      "Epoch 16: val_loss did not improve from 1.07524\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0356 - precision: 0.5998 - val_loss: 1.0852 - val_precision: 0.6019\n",
      "Epoch 17/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0210 - precision: 0.5979\n",
      "Epoch 17: val_loss did not improve from 1.07524\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0219 - precision: 0.5985 - val_loss: 1.0766 - val_precision: 0.6001\n",
      "Epoch 18/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0232 - precision: 0.6005\n",
      "Epoch 18: val_loss improved from 1.07524 to 1.06829, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0230 - precision: 0.6014 - val_loss: 1.0683 - val_precision: 0.6225\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0213 - precision: 0.6049\n",
      "Epoch 19: val_loss did not improve from 1.06829\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0207 - precision: 0.6054 - val_loss: 1.0841 - val_precision: 0.6068\n",
      "Epoch 20/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0221 - precision: 0.6011\n",
      "Epoch 20: val_loss improved from 1.06829 to 1.06568, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0230 - precision: 0.6002 - val_loss: 1.0657 - val_precision: 0.6214\n",
      "Epoch 21/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0186 - precision: 0.6082\n",
      "Epoch 21: val_loss did not improve from 1.06568\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0159 - precision: 0.6081 - val_loss: 1.0749 - val_precision: 0.6092\n",
      "Epoch 22/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0082 - precision: 0.6072\n",
      "Epoch 22: val_loss did not improve from 1.06568\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0094 - precision: 0.6060 - val_loss: 1.0897 - val_precision: 0.6018\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0080 - precision: 0.6081\n",
      "Epoch 23: val_loss did not improve from 1.06568\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0071 - precision: 0.6074 - val_loss: 1.0784 - val_precision: 0.6070\n",
      "Epoch 24/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0188 - precision: 0.5994\n",
      "Epoch 24: val_loss did not improve from 1.06568\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0188 - precision: 0.5994 - val_loss: 1.0704 - val_precision: 0.6164\n",
      "Epoch 25/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0113 - precision: 0.5983\n",
      "Epoch 25: val_loss improved from 1.06568 to 1.06451, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0101 - precision: 0.5985 - val_loss: 1.0645 - val_precision: 0.6183\n",
      "Epoch 26/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0105 - precision: 0.6015\n",
      "Epoch 26: val_loss improved from 1.06451 to 1.06059, saving model to model_ent24.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0080 - precision: 0.6021 - val_loss: 1.0606 - val_precision: 0.6168\n",
      "Epoch 27/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9995 - precision: 0.6080\n",
      "Epoch 27: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0012 - precision: 0.6073 - val_loss: 1.0737 - val_precision: 0.6049\n",
      "Epoch 28/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9976 - precision: 0.6043\n",
      "Epoch 28: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9958 - precision: 0.6053 - val_loss: 1.0709 - val_precision: 0.6066\n",
      "Epoch 29/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9969 - precision: 0.6086\n",
      "Epoch 29: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9969 - precision: 0.6086 - val_loss: 1.0737 - val_precision: 0.6070\n",
      "Epoch 30/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0178 - precision: 0.5986\n",
      "Epoch 30: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0172 - precision: 0.6015 - val_loss: 1.0662 - val_precision: 0.6069\n",
      "Epoch 31/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0028 - precision: 0.6060\n",
      "Epoch 31: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0028 - precision: 0.6060 - val_loss: 1.0767 - val_precision: 0.6008\n",
      "Epoch 32/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0035 - precision: 0.6038\n",
      "Epoch 32: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9990 - precision: 0.6052 - val_loss: 1.0622 - val_precision: 0.6068\n",
      "Epoch 33/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0043 - precision: 0.6088\n",
      "Epoch 33: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0070 - precision: 0.6075 - val_loss: 1.0651 - val_precision: 0.6038\n",
      "Epoch 34/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9956 - precision: 0.6141\n",
      "Epoch 34: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9956 - precision: 0.6141 - val_loss: 1.0681 - val_precision: 0.6062\n",
      "Epoch 35/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9856 - precision: 0.6125\n",
      "Epoch 35: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9863 - precision: 0.6111 - val_loss: 1.0624 - val_precision: 0.6047\n",
      "Epoch 36/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9864 - precision: 0.6127\n",
      "Epoch 36: val_loss did not improve from 1.06059\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9895 - precision: 0.6098 - val_loss: 1.0673 - val_precision: 0.6012\n",
      "Epoch 36: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0273 - precision: 0.6130\n",
      "Combinación 23 = (True, True, False, 32, 0.5) \n",
      " precision train: [1.0273038148880005, 0.6130186915397644]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 25: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2676 - precision: 0.6044\n",
      "Epoch 1: val_loss improved from inf to 1.11394, saving model to model_ent25.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.2598 - precision: 0.6030 - val_loss: 1.1139 - val_precision: 0.6116\n",
      "Epoch 2/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0126 - precision: 0.5873\n",
      "Epoch 2: val_loss improved from 1.11394 to 1.06378, saving model to model_ent25.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0142 - precision: 0.5864 - val_loss: 1.0638 - val_precision: 0.6169\n",
      "Epoch 3/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9861 - precision: 0.5988\n",
      "Epoch 3: val_loss did not improve from 1.06378\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9859 - precision: 0.5986 - val_loss: 1.0745 - val_precision: 0.5987\n",
      "Epoch 4/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9594 - precision: 0.5998\n",
      "Epoch 4: val_loss improved from 1.06378 to 1.05347, saving model to model_ent25.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9671 - precision: 0.5961 - val_loss: 1.0535 - val_precision: 0.6097\n",
      "Epoch 5/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9541 - precision: 0.6048\n",
      "Epoch 5: val_loss did not improve from 1.05347\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9536 - precision: 0.6044 - val_loss: 1.0611 - val_precision: 0.6040\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9393 - precision: 0.6022\n",
      "Epoch 6: val_loss improved from 1.05347 to 1.02908, saving model to model_ent25.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9399 - precision: 0.6012 - val_loss: 1.0291 - val_precision: 0.6265\n",
      "Epoch 7/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9290 - precision: 0.6059\n",
      "Epoch 7: val_loss did not improve from 1.02908\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9296 - precision: 0.6060 - val_loss: 1.0343 - val_precision: 0.6162\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9296 - precision: 0.6028\n",
      "Epoch 8: val_loss did not improve from 1.02908\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9278 - precision: 0.6050 - val_loss: 1.0293 - val_precision: 0.6207\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9114 - precision: 0.6087\n",
      "Epoch 9: val_loss improved from 1.02908 to 1.02605, saving model to model_ent25.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9106 - precision: 0.6090 - val_loss: 1.0261 - val_precision: 0.6155\n",
      "Epoch 10/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9057 - precision: 0.6124\n",
      "Epoch 10: val_loss improved from 1.02605 to 1.01070, saving model to model_ent25.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9054 - precision: 0.6130 - val_loss: 1.0107 - val_precision: 0.6285\n",
      "Epoch 11/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8899 - precision: 0.6189\n",
      "Epoch 11: val_loss improved from 1.01070 to 1.00365, saving model to model_ent25.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8916 - precision: 0.6186 - val_loss: 1.0036 - val_precision: 0.6288\n",
      "Epoch 12/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8836 - precision: 0.6198\n",
      "Epoch 12: val_loss did not improve from 1.00365\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8870 - precision: 0.6202 - val_loss: 1.0244 - val_precision: 0.6203\n",
      "Epoch 13/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8795 - precision: 0.6218\n",
      "Epoch 13: val_loss did not improve from 1.00365\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8793 - precision: 0.6220 - val_loss: 1.0388 - val_precision: 0.6097\n",
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8692 - precision: 0.6203\n",
      "Epoch 14: val_loss did not improve from 1.00365\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8696 - precision: 0.6205 - val_loss: 1.0240 - val_precision: 0.6135\n",
      "Epoch 15/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8607 - precision: 0.6229\n",
      "Epoch 15: val_loss did not improve from 1.00365\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8606 - precision: 0.6229 - val_loss: 1.0135 - val_precision: 0.6179\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8531 - precision: 0.6268\n",
      "Epoch 16: val_loss did not improve from 1.00365\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8544 - precision: 0.6262 - val_loss: 1.0350 - val_precision: 0.6011\n",
      "Epoch 17/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8518 - precision: 0.6251\n",
      "Epoch 17: val_loss improved from 1.00365 to 0.99747, saving model to model_ent25.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8518 - precision: 0.6251 - val_loss: 0.9975 - val_precision: 0.6291\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8441 - precision: 0.6257\n",
      "Epoch 18: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8440 - precision: 0.6259 - val_loss: 1.0242 - val_precision: 0.6204\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8371 - precision: 0.6292\n",
      "Epoch 19: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8378 - precision: 0.6294 - val_loss: 1.0405 - val_precision: 0.5951\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8266 - precision: 0.6365\n",
      "Epoch 20: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8270 - precision: 0.6360 - val_loss: 1.0126 - val_precision: 0.6164\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8261 - precision: 0.6339\n",
      "Epoch 21: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8263 - precision: 0.6340 - val_loss: 1.0122 - val_precision: 0.6196\n",
      "Epoch 22/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8113 - precision: 0.6387\n",
      "Epoch 22: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8136 - precision: 0.6374 - val_loss: 1.0310 - val_precision: 0.6088\n",
      "Epoch 23/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8098 - precision: 0.6339\n",
      "Epoch 23: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8092 - precision: 0.6340 - val_loss: 1.0136 - val_precision: 0.6165\n",
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8064 - precision: 0.6390\n",
      "Epoch 24: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8091 - precision: 0.6395 - val_loss: 1.0271 - val_precision: 0.6079\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7944 - precision: 0.6377\n",
      "Epoch 25: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7966 - precision: 0.6365 - val_loss: 1.0294 - val_precision: 0.6138\n",
      "Epoch 26/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.7812 - precision: 0.6462\n",
      "Epoch 26: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7828 - precision: 0.6461 - val_loss: 1.0461 - val_precision: 0.5929\n",
      "Epoch 27/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7881 - precision: 0.6360\n",
      "Epoch 27: val_loss did not improve from 0.99747\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7900 - precision: 0.6365 - val_loss: 1.0059 - val_precision: 0.6314\n",
      "Epoch 27: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 0.8668 - precision: 0.6612\n",
      "Combinación 24 = (True, True, False, 64, 0.1) \n",
      " precision train: [0.8667892217636108, 0.6612138152122498]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 26: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.3352 - precision: 0.6206\n",
      "Epoch 1: val_loss improved from inf to 1.14193, saving model to model_ent26.h5\n",
      "236/236 [==============================] - 9s 11ms/step - loss: 1.3261 - precision: 0.6216 - val_loss: 1.1419 - val_precision: 0.6492\n",
      "Epoch 2/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0468 - precision: 0.5942\n",
      "Epoch 2: val_loss improved from 1.14193 to 1.10290, saving model to model_ent26.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0455 - precision: 0.5938 - val_loss: 1.1029 - val_precision: 0.6028\n",
      "Epoch 3/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0157 - precision: 0.5956\n",
      "Epoch 3: val_loss improved from 1.10290 to 1.07701, saving model to model_ent26.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0162 - precision: 0.5948 - val_loss: 1.0770 - val_precision: 0.6161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9980 - precision: 0.5973\n",
      "Epoch 4: val_loss improved from 1.07701 to 1.06729, saving model to model_ent26.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0009 - precision: 0.5962 - val_loss: 1.0673 - val_precision: 0.6043\n",
      "Epoch 5/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9861 - precision: 0.5995\n",
      "Epoch 5: val_loss improved from 1.06729 to 1.04578, saving model to model_ent26.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9850 - precision: 0.5994 - val_loss: 1.0458 - val_precision: 0.6203\n",
      "Epoch 6/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9704 - precision: 0.6044\n",
      "Epoch 6: val_loss improved from 1.04578 to 1.02477, saving model to model_ent26.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9703 - precision: 0.6040 - val_loss: 1.0248 - val_precision: 0.6317\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9596 - precision: 0.6068\n",
      "Epoch 7: val_loss did not improve from 1.02477\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9603 - precision: 0.6066 - val_loss: 1.0555 - val_precision: 0.6097\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9539 - precision: 0.6054\n",
      "Epoch 8: val_loss did not improve from 1.02477\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9547 - precision: 0.6057 - val_loss: 1.0442 - val_precision: 0.6131\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9436 - precision: 0.6121\n",
      "Epoch 9: val_loss improved from 1.02477 to 1.02207, saving model to model_ent26.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9432 - precision: 0.6126 - val_loss: 1.0221 - val_precision: 0.6267\n",
      "Epoch 10/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9371 - precision: 0.6131\n",
      "Epoch 10: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9363 - precision: 0.6132 - val_loss: 1.0300 - val_precision: 0.6229\n",
      "Epoch 11/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9325 - precision: 0.6121\n",
      "Epoch 11: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9326 - precision: 0.6103 - val_loss: 1.0328 - val_precision: 0.6155\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9261 - precision: 0.6141\n",
      "Epoch 12: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9261 - precision: 0.6141 - val_loss: 1.0338 - val_precision: 0.6150\n",
      "Epoch 13/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9258 - precision: 0.6110\n",
      "Epoch 13: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9250 - precision: 0.6112 - val_loss: 1.0237 - val_precision: 0.6277\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9226 - precision: 0.6129\n",
      "Epoch 14: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9224 - precision: 0.6129 - val_loss: 1.0379 - val_precision: 0.6213\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9048 - precision: 0.6165\n",
      "Epoch 15: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9048 - precision: 0.6165 - val_loss: 1.0259 - val_precision: 0.6224\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9069 - precision: 0.6128\n",
      "Epoch 16: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9066 - precision: 0.6125 - val_loss: 1.0289 - val_precision: 0.6197\n",
      "Epoch 17/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9022 - precision: 0.6153\n",
      "Epoch 17: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9004 - precision: 0.6148 - val_loss: 1.0231 - val_precision: 0.6237\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8933 - precision: 0.6136\n",
      "Epoch 18: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8935 - precision: 0.6136 - val_loss: 1.0353 - val_precision: 0.6034\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8858 - precision: 0.6143\n",
      "Epoch 19: val_loss did not improve from 1.02207\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8856 - precision: 0.6153 - val_loss: 1.0232 - val_precision: 0.6202\n",
      "Epoch 19: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9659 - precision: 0.6296\n",
      "Combinación 25 = (True, True, False, 64, 0.25) \n",
      " precision train: [0.9659119248390198, 0.6296144723892212]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 27: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.4020 - precision: 0.6161\n",
      "Epoch 1: val_loss improved from inf to 1.18419, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 11s 15ms/step - loss: 1.3949 - precision: 0.6167 - val_loss: 1.1842 - val_precision: 0.6618\n",
      "Epoch 2/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1273 - precision: 0.6214\n",
      "Epoch 2: val_loss improved from 1.18419 to 1.09853, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.1273 - precision: 0.6214 - val_loss: 1.0985 - val_precision: 0.6381\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0611 - precision: 0.6095\n",
      "Epoch 3: val_loss improved from 1.09853 to 1.09276, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 1.0648 - precision: 0.6063 - val_loss: 1.0928 - val_precision: 0.6161\n",
      "Epoch 4/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0463 - precision: 0.6025\n",
      "Epoch 4: val_loss improved from 1.09276 to 1.08095, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 1.0473 - precision: 0.6019 - val_loss: 1.0809 - val_precision: 0.6079\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0360 - precision: 0.6011\n",
      "Epoch 5: val_loss improved from 1.08095 to 1.05678, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0360 - precision: 0.6011 - val_loss: 1.0568 - val_precision: 0.6246\n",
      "Epoch 6/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0130 - precision: 0.6001\n",
      "Epoch 6: val_loss improved from 1.05678 to 1.05199, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0158 - precision: 0.6000 - val_loss: 1.0520 - val_precision: 0.6250\n",
      "Epoch 7/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0094 - precision: 0.6019\n",
      "Epoch 7: val_loss did not improve from 1.05199\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0088 - precision: 0.6021 - val_loss: 1.0581 - val_precision: 0.6143\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0101 - precision: 0.6063\n",
      "Epoch 8: val_loss improved from 1.05199 to 1.04462, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0070 - precision: 0.6084 - val_loss: 1.0446 - val_precision: 0.6156\n",
      "Epoch 9/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9980 - precision: 0.6091\n",
      "Epoch 9: val_loss did not improve from 1.04462\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9947 - precision: 0.6106 - val_loss: 1.0713 - val_precision: 0.5977\n",
      "Epoch 10/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9997 - precision: 0.6037\n",
      "Epoch 10: val_loss did not improve from 1.04462\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9975 - precision: 0.6056 - val_loss: 1.0643 - val_precision: 0.5955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9835 - precision: 0.6036\n",
      "Epoch 11: val_loss improved from 1.04462 to 1.04347, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9851 - precision: 0.6029 - val_loss: 1.0435 - val_precision: 0.6199\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9800 - precision: 0.6083\n",
      "Epoch 12: val_loss improved from 1.04347 to 1.03534, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9832 - precision: 0.6073 - val_loss: 1.0353 - val_precision: 0.6237\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9823 - precision: 0.6064\n",
      "Epoch 13: val_loss did not improve from 1.03534\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9802 - precision: 0.6077 - val_loss: 1.0376 - val_precision: 0.6159\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9755 - precision: 0.6098\n",
      "Epoch 14: val_loss did not improve from 1.03534\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9755 - precision: 0.6098 - val_loss: 1.0375 - val_precision: 0.6169\n",
      "Epoch 15/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9731 - precision: 0.6084\n",
      "Epoch 15: val_loss improved from 1.03534 to 1.03225, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9721 - precision: 0.6086 - val_loss: 1.0323 - val_precision: 0.6154\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9712 - precision: 0.6068\n",
      "Epoch 16: val_loss improved from 1.03225 to 1.02428, saving model to model_ent27.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9721 - precision: 0.6066 - val_loss: 1.0243 - val_precision: 0.6304\n",
      "Epoch 17/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9622 - precision: 0.6087\n",
      "Epoch 17: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9633 - precision: 0.6089 - val_loss: 1.0439 - val_precision: 0.6146\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9595 - precision: 0.6075\n",
      "Epoch 18: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9585 - precision: 0.6082 - val_loss: 1.0367 - val_precision: 0.6143\n",
      "Epoch 19/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9623 - precision: 0.6077\n",
      "Epoch 19: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9628 - precision: 0.6078 - val_loss: 1.0425 - val_precision: 0.6113\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9475 - precision: 0.6131\n",
      "Epoch 20: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9482 - precision: 0.6127 - val_loss: 1.0294 - val_precision: 0.6219\n",
      "Epoch 21/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9450 - precision: 0.6118\n",
      "Epoch 21: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9409 - precision: 0.6150 - val_loss: 1.0376 - val_precision: 0.6130\n",
      "Epoch 22/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9485 - precision: 0.6063\n",
      "Epoch 22: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9447 - precision: 0.6095 - val_loss: 1.0351 - val_precision: 0.6174\n",
      "Epoch 23/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9480 - precision: 0.6100\n",
      "Epoch 23: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.9479 - precision: 0.6103 - val_loss: 1.0401 - val_precision: 0.6068\n",
      "Epoch 24/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9406 - precision: 0.6112\n",
      "Epoch 24: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9407 - precision: 0.6097 - val_loss: 1.0374 - val_precision: 0.6117\n",
      "Epoch 25/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9415 - precision: 0.6110\n",
      "Epoch 25: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.9414 - precision: 0.6114 - val_loss: 1.0346 - val_precision: 0.6197\n",
      "Epoch 26/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9365 - precision: 0.6099\n",
      "Epoch 26: val_loss did not improve from 1.02428\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9371 - precision: 0.6109 - val_loss: 1.0339 - val_precision: 0.6268\n",
      "Epoch 26: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9989 - precision: 0.6257\n",
      "Combinación 26 = (True, True, False, 64, 0.5) \n",
      " precision train: [0.9988537430763245, 0.6257044672966003]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 28: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2223 - precision: 0.6302\n",
      "Epoch 1: val_loss improved from inf to 1.16503, saving model to model_ent28.h5\n",
      "236/236 [==============================] - 14s 15ms/step - loss: 1.2187 - precision: 0.6314 - val_loss: 1.1650 - val_precision: 0.6026\n",
      "Epoch 2/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0029 - precision: 0.5978\n",
      "Epoch 2: val_loss improved from 1.16503 to 1.08200, saving model to model_ent28.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 1.0029 - precision: 0.5973 - val_loss: 1.0820 - val_precision: 0.5990\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9676 - precision: 0.6042\n",
      "Epoch 3: val_loss improved from 1.08200 to 1.03352, saving model to model_ent28.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9683 - precision: 0.6034 - val_loss: 1.0335 - val_precision: 0.6280\n",
      "Epoch 4/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9474 - precision: 0.6000\n",
      "Epoch 4: val_loss did not improve from 1.03352\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.9474 - precision: 0.6000 - val_loss: 1.0687 - val_precision: 0.6040\n",
      "Epoch 5/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9440 - precision: 0.6034\n",
      "Epoch 5: val_loss did not improve from 1.03352\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9441 - precision: 0.6036 - val_loss: 1.0407 - val_precision: 0.6219\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9214 - precision: 0.6099\n",
      "Epoch 6: val_loss improved from 1.03352 to 1.03212, saving model to model_ent28.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9227 - precision: 0.6095 - val_loss: 1.0321 - val_precision: 0.6117\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9142 - precision: 0.6132\n",
      "Epoch 7: val_loss did not improve from 1.03212\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9155 - precision: 0.6134 - val_loss: 1.0383 - val_precision: 0.6102\n",
      "Epoch 8/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8960 - precision: 0.6161\n",
      "Epoch 8: val_loss did not improve from 1.03212\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8970 - precision: 0.6163 - val_loss: 1.0343 - val_precision: 0.6053\n",
      "Epoch 9/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8862 - precision: 0.6179\n",
      "Epoch 9: val_loss improved from 1.03212 to 1.01081, saving model to model_ent28.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8853 - precision: 0.6197 - val_loss: 1.0108 - val_precision: 0.6202\n",
      "Epoch 10/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8796 - precision: 0.6207\n",
      "Epoch 10: val_loss did not improve from 1.01081\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8772 - precision: 0.6214 - val_loss: 1.0174 - val_precision: 0.6179\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8733 - precision: 0.6170\n",
      "Epoch 11: val_loss did not improve from 1.01081\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8715 - precision: 0.6171 - val_loss: 1.0198 - val_precision: 0.6274\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8589 - precision: 0.6248\n",
      "Epoch 12: val_loss improved from 1.01081 to 1.00687, saving model to model_ent28.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8579 - precision: 0.6258 - val_loss: 1.0069 - val_precision: 0.6280\n",
      "Epoch 13/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8454 - precision: 0.6297\n",
      "Epoch 13: val_loss did not improve from 1.00687\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8452 - precision: 0.6290 - val_loss: 1.0119 - val_precision: 0.6242\n",
      "Epoch 14/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8395 - precision: 0.6328\n",
      "Epoch 14: val_loss did not improve from 1.00687\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8410 - precision: 0.6313 - val_loss: 1.0103 - val_precision: 0.6242\n",
      "Epoch 15/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8289 - precision: 0.6295\n",
      "Epoch 15: val_loss did not improve from 1.00687\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8302 - precision: 0.6282 - val_loss: 1.0253 - val_precision: 0.6083\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8172 - precision: 0.6318\n",
      "Epoch 16: val_loss did not improve from 1.00687\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8169 - precision: 0.6320 - val_loss: 1.0102 - val_precision: 0.6248\n",
      "Epoch 17/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8160 - precision: 0.6324\n",
      "Epoch 17: val_loss did not improve from 1.00687\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8142 - precision: 0.6343 - val_loss: 1.0157 - val_precision: 0.6218\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8063 - precision: 0.6333\n",
      "Epoch 18: val_loss did not improve from 1.00687\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8039 - precision: 0.6342 - val_loss: 1.0163 - val_precision: 0.6197\n",
      "Epoch 19/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.7924 - precision: 0.6398\n",
      "Epoch 19: val_loss did not improve from 1.00687\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7945 - precision: 0.6386 - val_loss: 1.0401 - val_precision: 0.6041\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.7839 - precision: 0.6441\n",
      "Epoch 20: val_loss improved from 1.00687 to 1.00665, saving model to model_ent28.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7838 - precision: 0.6444 - val_loss: 1.0066 - val_precision: 0.6205\n",
      "Epoch 21/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7741 - precision: 0.6458\n",
      "Epoch 21: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7742 - precision: 0.6457 - val_loss: 1.0447 - val_precision: 0.6127\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7667 - precision: 0.6475\n",
      "Epoch 22: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7675 - precision: 0.6466 - val_loss: 1.0318 - val_precision: 0.6220\n",
      "Epoch 23/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.7584 - precision: 0.6485\n",
      "Epoch 23: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7574 - precision: 0.6489 - val_loss: 1.0762 - val_precision: 0.5980\n",
      "Epoch 24/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.7488 - precision: 0.6540\n",
      "Epoch 24: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7481 - precision: 0.6553 - val_loss: 1.0761 - val_precision: 0.5987\n",
      "Epoch 25/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.7461 - precision: 0.6564\n",
      "Epoch 25: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7454 - precision: 0.6554 - val_loss: 1.0305 - val_precision: 0.6162\n",
      "Epoch 26/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.7296 - precision: 0.6596\n",
      "Epoch 26: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7299 - precision: 0.6596 - val_loss: 1.0596 - val_precision: 0.6201\n",
      "Epoch 27/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7180 - precision: 0.6659\n",
      "Epoch 27: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7192 - precision: 0.6645 - val_loss: 1.0953 - val_precision: 0.5965\n",
      "Epoch 28/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.7258 - precision: 0.6584\n",
      "Epoch 28: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7263 - precision: 0.6591 - val_loss: 1.0821 - val_precision: 0.6019\n",
      "Epoch 29/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.7149 - precision: 0.6610\n",
      "Epoch 29: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7142 - precision: 0.6618 - val_loss: 1.0892 - val_precision: 0.6081\n",
      "Epoch 30/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.7029 - precision: 0.6708\n",
      "Epoch 30: val_loss did not improve from 1.00665\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7058 - precision: 0.6704 - val_loss: 1.0768 - val_precision: 0.6004\n",
      "Epoch 30: early stopping\n",
      "295/295 [==============================] - 1s 3ms/step - loss: 0.8492 - precision: 0.6613\n",
      "Combinación 27 = (True, True, False, 128, 0.1) \n",
      " precision train: [0.8492178320884705, 0.6613441109657288]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 29: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2575 - precision: 0.6283\n",
      "Epoch 1: val_loss improved from inf to 1.11768, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 10s 15ms/step - loss: 1.2513 - precision: 0.6312 - val_loss: 1.1177 - val_precision: 0.6161\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0068 - precision: 0.6013\n",
      "Epoch 2: val_loss improved from 1.11768 to 1.05999, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 1.0054 - precision: 0.6002 - val_loss: 1.0600 - val_precision: 0.6094\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9811 - precision: 0.5967\n",
      "Epoch 3: val_loss improved from 1.05999 to 1.03927, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9812 - precision: 0.5971 - val_loss: 1.0393 - val_precision: 0.6215\n",
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9620 - precision: 0.6000\n",
      "Epoch 4: val_loss improved from 1.03927 to 1.03470, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9642 - precision: 0.5994 - val_loss: 1.0347 - val_precision: 0.6113\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9516 - precision: 0.6060\n",
      "Epoch 5: val_loss did not improve from 1.03470\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9516 - precision: 0.6056 - val_loss: 1.0576 - val_precision: 0.5996\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9420 - precision: 0.6038\n",
      "Epoch 6: val_loss did not improve from 1.03470\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9412 - precision: 0.6043 - val_loss: 1.0643 - val_precision: 0.6012\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9324 - precision: 0.6054\n",
      "Epoch 7: val_loss improved from 1.03470 to 1.03198, saving model to model_ent29.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9329 - precision: 0.6042 - val_loss: 1.0320 - val_precision: 0.6195\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9253 - precision: 0.6062\n",
      "Epoch 8: val_loss improved from 1.03198 to 1.02527, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9247 - precision: 0.6066 - val_loss: 1.0253 - val_precision: 0.6270\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9179 - precision: 0.6091\n",
      "Epoch 9: val_loss did not improve from 1.02527\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9176 - precision: 0.6095 - val_loss: 1.0269 - val_precision: 0.6290\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9095 - precision: 0.6103\n",
      "Epoch 10: val_loss improved from 1.02527 to 1.02411, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9086 - precision: 0.6118 - val_loss: 1.0241 - val_precision: 0.6176\n",
      "Epoch 11/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8884 - precision: 0.6149\n",
      "Epoch 11: val_loss improved from 1.02411 to 1.01841, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8875 - precision: 0.6155 - val_loss: 1.0184 - val_precision: 0.6275\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8911 - precision: 0.6150\n",
      "Epoch 12: val_loss did not improve from 1.01841\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.8910 - precision: 0.6159 - val_loss: 1.0372 - val_precision: 0.6301\n",
      "Epoch 13/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8794 - precision: 0.6251\n",
      "Epoch 13: val_loss improved from 1.01841 to 1.01002, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8802 - precision: 0.6234 - val_loss: 1.0100 - val_precision: 0.6236\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8742 - precision: 0.6251\n",
      "Epoch 14: val_loss did not improve from 1.01002\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8741 - precision: 0.6251 - val_loss: 1.0194 - val_precision: 0.6272\n",
      "Epoch 15/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8629 - precision: 0.6176\n",
      "Epoch 15: val_loss improved from 1.01002 to 1.00923, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8618 - precision: 0.6187 - val_loss: 1.0092 - val_precision: 0.6252\n",
      "Epoch 16/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8570 - precision: 0.6213\n",
      "Epoch 16: val_loss did not improve from 1.00923\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8566 - precision: 0.6215 - val_loss: 1.0389 - val_precision: 0.6087\n",
      "Epoch 17/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8492 - precision: 0.6268\n",
      "Epoch 17: val_loss did not improve from 1.00923\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8501 - precision: 0.6262 - val_loss: 1.0211 - val_precision: 0.6181\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8362 - precision: 0.6274\n",
      "Epoch 18: val_loss did not improve from 1.00923\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8365 - precision: 0.6273 - val_loss: 1.0149 - val_precision: 0.6218\n",
      "Epoch 19/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8407 - precision: 0.6313\n",
      "Epoch 19: val_loss improved from 1.00923 to 1.00181, saving model to model_ent29.h5\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8417 - precision: 0.6307 - val_loss: 1.0018 - val_precision: 0.6248\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8306 - precision: 0.6319\n",
      "Epoch 20: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8316 - precision: 0.6319 - val_loss: 1.0287 - val_precision: 0.6113\n",
      "Epoch 21/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8193 - precision: 0.6332\n",
      "Epoch 21: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8218 - precision: 0.6348 - val_loss: 1.0359 - val_precision: 0.6140\n",
      "Epoch 22/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8141 - precision: 0.6361\n",
      "Epoch 22: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8159 - precision: 0.6350 - val_loss: 1.0247 - val_precision: 0.6126\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8077 - precision: 0.6394\n",
      "Epoch 23: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8082 - precision: 0.6386 - val_loss: 1.0251 - val_precision: 0.6161\n",
      "Epoch 24/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8082 - precision: 0.6352\n",
      "Epoch 24: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8082 - precision: 0.6352 - val_loss: 1.0092 - val_precision: 0.6217\n",
      "Epoch 25/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.7940 - precision: 0.6404\n",
      "Epoch 25: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7940 - precision: 0.6404 - val_loss: 1.0312 - val_precision: 0.6088\n",
      "Epoch 26/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7871 - precision: 0.6419\n",
      "Epoch 26: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7881 - precision: 0.6416 - val_loss: 1.0333 - val_precision: 0.6042\n",
      "Epoch 27/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.7813 - precision: 0.6446\n",
      "Epoch 27: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7807 - precision: 0.6444 - val_loss: 1.0174 - val_precision: 0.6205\n",
      "Epoch 28/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.7760 - precision: 0.6445\n",
      "Epoch 28: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.7776 - precision: 0.6435 - val_loss: 1.0430 - val_precision: 0.6019\n",
      "Epoch 29/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7662 - precision: 0.6504\n",
      "Epoch 29: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7686 - precision: 0.6498 - val_loss: 1.0503 - val_precision: 0.6050\n",
      "Epoch 29: early stopping\n",
      "295/295 [==============================] - 1s 3ms/step - loss: 0.8980 - precision: 0.6381\n",
      "Combinación 28 = (True, True, False, 128, 0.25) \n",
      " precision train: [0.8980076313018799, 0.6381054520606995]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 30: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3180 - precision: 0.6325\n",
      "Epoch 1: val_loss improved from inf to 1.13329, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 11s 14ms/step - loss: 1.3141 - precision: 0.6339 - val_loss: 1.1333 - val_precision: 0.6602\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0626 - precision: 0.6032\n",
      "Epoch 2: val_loss improved from 1.13329 to 1.09981, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 1.0622 - precision: 0.6029 - val_loss: 1.0998 - val_precision: 0.6088\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0330 - precision: 0.6040\n",
      "Epoch 3: val_loss improved from 1.09981 to 1.07483, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0300 - precision: 0.6059 - val_loss: 1.0748 - val_precision: 0.6170\n",
      "Epoch 4/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0077 - precision: 0.6067\n",
      "Epoch 4: val_loss improved from 1.07483 to 1.05362, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 1.0077 - precision: 0.6067 - val_loss: 1.0536 - val_precision: 0.6166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0105 - precision: 0.6027\n",
      "Epoch 5: val_loss did not improve from 1.05362\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 1.0104 - precision: 0.6020 - val_loss: 1.0710 - val_precision: 0.6151\n",
      "Epoch 6/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9876 - precision: 0.5994\n",
      "Epoch 6: val_loss improved from 1.05362 to 1.04257, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9864 - precision: 0.5999 - val_loss: 1.0426 - val_precision: 0.6064\n",
      "Epoch 7/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9861 - precision: 0.5969\n",
      "Epoch 7: val_loss did not improve from 1.04257\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9879 - precision: 0.5974 - val_loss: 1.0471 - val_precision: 0.6030\n",
      "Epoch 8/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9608 - precision: 0.6086\n",
      "Epoch 8: val_loss improved from 1.04257 to 1.02931, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9648 - precision: 0.6089 - val_loss: 1.0293 - val_precision: 0.6167\n",
      "Epoch 9/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9668 - precision: 0.6056\n",
      "Epoch 9: val_loss did not improve from 1.02931\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9658 - precision: 0.6067 - val_loss: 1.0356 - val_precision: 0.6201\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9595 - precision: 0.6036\n",
      "Epoch 10: val_loss did not improve from 1.02931\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9602 - precision: 0.6029 - val_loss: 1.0373 - val_precision: 0.6085\n",
      "Epoch 11/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9556 - precision: 0.5967\n",
      "Epoch 11: val_loss improved from 1.02931 to 1.02276, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9547 - precision: 0.5974 - val_loss: 1.0228 - val_precision: 0.6276\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9479 - precision: 0.6128\n",
      "Epoch 12: val_loss did not improve from 1.02276\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9479 - precision: 0.6128 - val_loss: 1.0378 - val_precision: 0.6144\n",
      "Epoch 13/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9435 - precision: 0.6066\n",
      "Epoch 13: val_loss did not improve from 1.02276\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9437 - precision: 0.6063 - val_loss: 1.0317 - val_precision: 0.6130\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9357 - precision: 0.6129\n",
      "Epoch 14: val_loss did not improve from 1.02276\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9356 - precision: 0.6134 - val_loss: 1.0235 - val_precision: 0.6202\n",
      "Epoch 15/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9329 - precision: 0.6068\n",
      "Epoch 15: val_loss improved from 1.02276 to 1.01624, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9324 - precision: 0.6061 - val_loss: 1.0162 - val_precision: 0.6283\n",
      "Epoch 16/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9263 - precision: 0.6100\n",
      "Epoch 16: val_loss did not improve from 1.01624\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9257 - precision: 0.6117 - val_loss: 1.0206 - val_precision: 0.6111\n",
      "Epoch 17/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9257 - precision: 0.6103\n",
      "Epoch 17: val_loss did not improve from 1.01624\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9266 - precision: 0.6099 - val_loss: 1.0425 - val_precision: 0.6096\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9134 - precision: 0.6130\n",
      "Epoch 18: val_loss did not improve from 1.01624\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9124 - precision: 0.6135 - val_loss: 1.0174 - val_precision: 0.6142\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9076 - precision: 0.6182\n",
      "Epoch 19: val_loss did not improve from 1.01624\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9066 - precision: 0.6183 - val_loss: 1.0168 - val_precision: 0.6112\n",
      "Epoch 20/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9051 - precision: 0.6176\n",
      "Epoch 20: val_loss improved from 1.01624 to 0.99988, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9049 - precision: 0.6178 - val_loss: 0.9999 - val_precision: 0.6262\n",
      "Epoch 21/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8972 - precision: 0.6207\n",
      "Epoch 21: val_loss did not improve from 0.99988\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8964 - precision: 0.6200 - val_loss: 1.0063 - val_precision: 0.6106\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8926 - precision: 0.6222\n",
      "Epoch 22: val_loss did not improve from 0.99988\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8910 - precision: 0.6235 - val_loss: 1.0062 - val_precision: 0.6189\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8913 - precision: 0.6195\n",
      "Epoch 23: val_loss did not improve from 0.99988\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8880 - precision: 0.6202 - val_loss: 1.0112 - val_precision: 0.6184\n",
      "Epoch 24/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8802 - precision: 0.6223\n",
      "Epoch 24: val_loss did not improve from 0.99988\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8802 - precision: 0.6223 - val_loss: 1.0321 - val_precision: 0.6037\n",
      "Epoch 25/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8781 - precision: 0.6202\n",
      "Epoch 25: val_loss improved from 0.99988 to 0.99682, saving model to model_ent30.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8774 - precision: 0.6195 - val_loss: 0.9968 - val_precision: 0.6146\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8666 - precision: 0.6223\n",
      "Epoch 26: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8666 - precision: 0.6223 - val_loss: 1.0366 - val_precision: 0.6023\n",
      "Epoch 27/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8694 - precision: 0.6200\n",
      "Epoch 27: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8711 - precision: 0.6178 - val_loss: 1.0200 - val_precision: 0.6117\n",
      "Epoch 28/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8722 - precision: 0.6221\n",
      "Epoch 28: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8708 - precision: 0.6221 - val_loss: 1.0232 - val_precision: 0.6117\n",
      "Epoch 29/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8623 - precision: 0.6337\n",
      "Epoch 29: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8618 - precision: 0.6338 - val_loss: 1.0537 - val_precision: 0.5925\n",
      "Epoch 30/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8588 - precision: 0.6266\n",
      "Epoch 30: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8582 - precision: 0.6270 - val_loss: 1.0071 - val_precision: 0.6221\n",
      "Epoch 31/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8507 - precision: 0.6280\n",
      "Epoch 31: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8500 - precision: 0.6285 - val_loss: 1.0332 - val_precision: 0.6090\n",
      "Epoch 32/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8434 - precision: 0.6294\n",
      "Epoch 32: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8456 - precision: 0.6290 - val_loss: 1.0609 - val_precision: 0.5874\n",
      "Epoch 33/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8463 - precision: 0.6265\n",
      "Epoch 33: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8463 - precision: 0.6265 - val_loss: 1.0351 - val_precision: 0.6102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8435 - precision: 0.6275\n",
      "Epoch 34: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.8435 - precision: 0.6275 - val_loss: 1.0312 - val_precision: 0.6084\n",
      "Epoch 35/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8432 - precision: 0.6301\n",
      "Epoch 35: val_loss did not improve from 0.99682\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.8429 - precision: 0.6305 - val_loss: 1.0296 - val_precision: 0.6037\n",
      "Epoch 35: early stopping\n",
      "295/295 [==============================] - 1s 4ms/step - loss: 0.9112 - precision: 0.6354\n",
      "Combinación 29 = (True, True, False, 128, 0.5) \n",
      " precision train: [0.9111753106117249, 0.6353851556777954]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 31: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.5405 - precision: 0.5000    \n",
      "Epoch 1: val_loss improved from inf to 1.42772, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 11s 16ms/step - loss: 1.5395 - precision: 0.5000 - val_loss: 1.4277 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3483 - precision: 0.5763\n",
      "Epoch 2: val_loss improved from 1.42772 to 1.34371, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.3474 - precision: 0.5763 - val_loss: 1.3437 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.3062 - precision: 0.4889\n",
      "Epoch 3: val_loss improved from 1.34371 to 1.32087, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.3069 - precision: 0.4894 - val_loss: 1.3209 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2928 - precision: 0.6216\n",
      "Epoch 4: val_loss improved from 1.32087 to 1.29805, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2923 - precision: 0.6216 - val_loss: 1.2980 - val_precision: 0.0000e+00\n",
      "Epoch 5/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2733 - precision: 0.6368\n",
      "Epoch 5: val_loss improved from 1.29805 to 1.27367, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.2739 - precision: 0.6341 - val_loss: 1.2737 - val_precision: 0.6862\n",
      "Epoch 6/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2497 - precision: 0.6444\n",
      "Epoch 6: val_loss improved from 1.27367 to 1.25565, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.2500 - precision: 0.6413 - val_loss: 1.2557 - val_precision: 0.6574\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2331 - precision: 0.6330\n",
      "Epoch 7: val_loss improved from 1.25565 to 1.23584, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 1.2302 - precision: 0.6335 - val_loss: 1.2358 - val_precision: 0.6850\n",
      "Epoch 8/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1916 - precision: 0.6698\n",
      "Epoch 8: val_loss improved from 1.23584 to 1.19105, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1883 - precision: 0.6733 - val_loss: 1.1911 - val_precision: 0.6912\n",
      "Epoch 9/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1269 - precision: 0.6517\n",
      "Epoch 9: val_loss improved from 1.19105 to 1.13722, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1282 - precision: 0.6507 - val_loss: 1.1372 - val_precision: 0.6673\n",
      "Epoch 10/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0764 - precision: 0.6162\n",
      "Epoch 10: val_loss improved from 1.13722 to 1.11525, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0763 - precision: 0.6156 - val_loss: 1.1152 - val_precision: 0.6247\n",
      "Epoch 11/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0501 - precision: 0.5969\n",
      "Epoch 11: val_loss improved from 1.11525 to 1.09982, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0516 - precision: 0.5991 - val_loss: 1.0998 - val_precision: 0.6220\n",
      "Epoch 12/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0324 - precision: 0.5973\n",
      "Epoch 12: val_loss improved from 1.09982 to 1.09199, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0323 - precision: 0.5975 - val_loss: 1.0920 - val_precision: 0.6081\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0253 - precision: 0.5956\n",
      "Epoch 13: val_loss improved from 1.09199 to 1.09017, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0251 - precision: 0.5961 - val_loss: 1.0902 - val_precision: 0.6034\n",
      "Epoch 14/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0149 - precision: 0.5973\n",
      "Epoch 14: val_loss improved from 1.09017 to 1.08227, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0193 - precision: 0.5943 - val_loss: 1.0823 - val_precision: 0.6070\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0143 - precision: 0.5922\n",
      "Epoch 15: val_loss improved from 1.08227 to 1.07469, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0144 - precision: 0.5922 - val_loss: 1.0747 - val_precision: 0.6059\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0106 - precision: 0.5964\n",
      "Epoch 16: val_loss did not improve from 1.07469\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0103 - precision: 0.5978 - val_loss: 1.0754 - val_precision: 0.6053\n",
      "Epoch 17/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0062 - precision: 0.5964\n",
      "Epoch 17: val_loss did not improve from 1.07469\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0062 - precision: 0.5964 - val_loss: 1.0775 - val_precision: 0.5961\n",
      "Epoch 18/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9974 - precision: 0.5992\n",
      "Epoch 18: val_loss improved from 1.07469 to 1.07411, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9952 - precision: 0.5992 - val_loss: 1.0741 - val_precision: 0.6008\n",
      "Epoch 19/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9955 - precision: 0.5935\n",
      "Epoch 19: val_loss improved from 1.07411 to 1.06416, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9961 - precision: 0.5933 - val_loss: 1.0642 - val_precision: 0.6069\n",
      "Epoch 20/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9947 - precision: 0.5998\n",
      "Epoch 20: val_loss did not improve from 1.06416\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9945 - precision: 0.5993 - val_loss: 1.0645 - val_precision: 0.6041\n",
      "Epoch 21/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9898 - precision: 0.5956\n",
      "Epoch 21: val_loss improved from 1.06416 to 1.06157, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9905 - precision: 0.5957 - val_loss: 1.0616 - val_precision: 0.6026\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9804 - precision: 0.5975\n",
      "Epoch 22: val_loss improved from 1.06157 to 1.06078, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9791 - precision: 0.5980 - val_loss: 1.0608 - val_precision: 0.6078\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9781 - precision: 0.6060\n",
      "Epoch 23: val_loss did not improve from 1.06078\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9787 - precision: 0.6054 - val_loss: 1.0747 - val_precision: 0.5960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9839 - precision: 0.5949\n",
      "Epoch 24: val_loss did not improve from 1.06078\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9813 - precision: 0.5956 - val_loss: 1.0644 - val_precision: 0.5987\n",
      "Epoch 25/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9780 - precision: 0.6010\n",
      "Epoch 25: val_loss improved from 1.06078 to 1.05368, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9782 - precision: 0.6003 - val_loss: 1.0537 - val_precision: 0.6082\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9762 - precision: 0.6086\n",
      "Epoch 26: val_loss did not improve from 1.05368\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9762 - precision: 0.6086 - val_loss: 1.0599 - val_precision: 0.6088\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9805 - precision: 0.6007\n",
      "Epoch 27: val_loss did not improve from 1.05368\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9793 - precision: 0.6007 - val_loss: 1.0595 - val_precision: 0.6005\n",
      "Epoch 28/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9716 - precision: 0.6037\n",
      "Epoch 28: val_loss did not improve from 1.05368\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9725 - precision: 0.6018 - val_loss: 1.0567 - val_precision: 0.6102\n",
      "Epoch 29/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9705 - precision: 0.6032\n",
      "Epoch 29: val_loss improved from 1.05368 to 1.05274, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9705 - precision: 0.6032 - val_loss: 1.0527 - val_precision: 0.6088\n",
      "Epoch 30/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9761 - precision: 0.6059\n",
      "Epoch 30: val_loss did not improve from 1.05274\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9735 - precision: 0.6062 - val_loss: 1.0586 - val_precision: 0.6054\n",
      "Epoch 31/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9614 - precision: 0.6057\n",
      "Epoch 31: val_loss did not improve from 1.05274\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9615 - precision: 0.6058 - val_loss: 1.0545 - val_precision: 0.6053\n",
      "Epoch 32/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9688 - precision: 0.6065\n",
      "Epoch 32: val_loss did not improve from 1.05274\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9703 - precision: 0.6053 - val_loss: 1.0626 - val_precision: 0.6031\n",
      "Epoch 33/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9593 - precision: 0.6060\n",
      "Epoch 33: val_loss did not improve from 1.05274\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9600 - precision: 0.6049 - val_loss: 1.0563 - val_precision: 0.6088\n",
      "Epoch 34/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9508 - precision: 0.6122\n",
      "Epoch 34: val_loss did not improve from 1.05274\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9541 - precision: 0.6104 - val_loss: 1.0597 - val_precision: 0.6070\n",
      "Epoch 35/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9570 - precision: 0.6095\n",
      "Epoch 35: val_loss did not improve from 1.05274\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9560 - precision: 0.6100 - val_loss: 1.0588 - val_precision: 0.6087\n",
      "Epoch 36/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9572 - precision: 0.6063\n",
      "Epoch 36: val_loss did not improve from 1.05274\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9564 - precision: 0.6049 - val_loss: 1.0600 - val_precision: 0.6058\n",
      "Epoch 37/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9483 - precision: 0.6171\n",
      "Epoch 37: val_loss improved from 1.05274 to 1.04969, saving model to model_ent31.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9469 - precision: 0.6176 - val_loss: 1.0497 - val_precision: 0.6145\n",
      "Epoch 38/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9483 - precision: 0.6121\n",
      "Epoch 38: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9473 - precision: 0.6121 - val_loss: 1.0539 - val_precision: 0.6095\n",
      "Epoch 39/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9381 - precision: 0.6154\n",
      "Epoch 39: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9399 - precision: 0.6146 - val_loss: 1.0614 - val_precision: 0.6077\n",
      "Epoch 40/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9451 - precision: 0.6089\n",
      "Epoch 40: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9433 - precision: 0.6092 - val_loss: 1.0605 - val_precision: 0.6057\n",
      "Epoch 41/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9402 - precision: 0.6112\n",
      "Epoch 41: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9384 - precision: 0.6119 - val_loss: 1.0555 - val_precision: 0.6094\n",
      "Epoch 42/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9409 - precision: 0.6137\n",
      "Epoch 42: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9425 - precision: 0.6135 - val_loss: 1.0548 - val_precision: 0.6101\n",
      "Epoch 43/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9373 - precision: 0.6122\n",
      "Epoch 43: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9383 - precision: 0.6114 - val_loss: 1.0618 - val_precision: 0.6083\n",
      "Epoch 44/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9420 - precision: 0.6128\n",
      "Epoch 44: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9410 - precision: 0.6132 - val_loss: 1.0616 - val_precision: 0.6045\n",
      "Epoch 45/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9346 - precision: 0.6159\n",
      "Epoch 45: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9356 - precision: 0.6156 - val_loss: 1.0646 - val_precision: 0.6087\n",
      "Epoch 46/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9295 - precision: 0.6096\n",
      "Epoch 46: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9311 - precision: 0.6094 - val_loss: 1.0608 - val_precision: 0.6024\n",
      "Epoch 47/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9365 - precision: 0.6119\n",
      "Epoch 47: val_loss did not improve from 1.04969\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9377 - precision: 0.6118 - val_loss: 1.0644 - val_precision: 0.6051\n",
      "Epoch 47: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 1.0026 - precision: 0.6173\n",
      "Combinación 30 = (True, False, True, 8, 0.1) \n",
      " precision train: [1.0026097297668457, 0.6173290014266968]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 32: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.5458 - precision: 1.0000    \n",
      "Epoch 1: val_loss improved from inf to 1.38942, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.5405 - precision: 1.0000 - val_loss: 1.3894 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3387 - precision: 0.5292\n",
      "Epoch 2: val_loss improved from 1.38942 to 1.32695, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3417 - precision: 0.5279 - val_loss: 1.3269 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3081 - precision: 0.5875\n",
      "Epoch 3: val_loss improved from 1.32695 to 1.29851, saving model to model_ent32.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3086 - precision: 0.5856 - val_loss: 1.2985 - val_precision: 0.7045\n",
      "Epoch 4/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2852 - precision: 0.5917\n",
      "Epoch 4: val_loss improved from 1.29851 to 1.27619, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2835 - precision: 0.5932 - val_loss: 1.2762 - val_precision: 0.6823\n",
      "Epoch 5/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2604 - precision: 0.6161\n",
      "Epoch 5: val_loss improved from 1.27619 to 1.26205, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2620 - precision: 0.6204 - val_loss: 1.2621 - val_precision: 0.6604\n",
      "Epoch 6/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2604 - precision: 0.6369\n",
      "Epoch 6: val_loss improved from 1.26205 to 1.25792, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2575 - precision: 0.6405 - val_loss: 1.2579 - val_precision: 0.6659\n",
      "Epoch 7/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2491 - precision: 0.6383\n",
      "Epoch 7: val_loss improved from 1.25792 to 1.24766, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2512 - precision: 0.6366 - val_loss: 1.2477 - val_precision: 0.6682\n",
      "Epoch 8/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2383 - precision: 0.6392\n",
      "Epoch 8: val_loss did not improve from 1.24766\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2383 - precision: 0.6392 - val_loss: 1.2546 - val_precision: 0.6852\n",
      "Epoch 9/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2330 - precision: 0.6607\n",
      "Epoch 9: val_loss improved from 1.24766 to 1.23828, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2301 - precision: 0.6590 - val_loss: 1.2383 - val_precision: 0.6764\n",
      "Epoch 10/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2209 - precision: 0.6498\n",
      "Epoch 10: val_loss improved from 1.23828 to 1.23319, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2241 - precision: 0.6491 - val_loss: 1.2332 - val_precision: 0.6835\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2158 - precision: 0.6530\n",
      "Epoch 11: val_loss improved from 1.23319 to 1.23027, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2167 - precision: 0.6523 - val_loss: 1.2303 - val_precision: 0.6644\n",
      "Epoch 12/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2209 - precision: 0.6442\n",
      "Epoch 12: val_loss improved from 1.23027 to 1.22862, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2220 - precision: 0.6435 - val_loss: 1.2286 - val_precision: 0.6888\n",
      "Epoch 13/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2123 - precision: 0.6519\n",
      "Epoch 13: val_loss did not improve from 1.22862\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2116 - precision: 0.6529 - val_loss: 1.2308 - val_precision: 0.6782\n",
      "Epoch 14/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2070 - precision: 0.6365\n",
      "Epoch 14: val_loss improved from 1.22862 to 1.22700, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2048 - precision: 0.6352 - val_loss: 1.2270 - val_precision: 0.6770\n",
      "Epoch 15/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2003 - precision: 0.6184\n",
      "Epoch 15: val_loss did not improve from 1.22700\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2054 - precision: 0.6172 - val_loss: 1.2277 - val_precision: 0.6651\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2172 - precision: 0.5903\n",
      "Epoch 16: val_loss did not improve from 1.22700\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2164 - precision: 0.5883 - val_loss: 1.2325 - val_precision: 0.6873\n",
      "Epoch 17/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2014 - precision: 0.6025\n",
      "Epoch 17: val_loss improved from 1.22700 to 1.22140, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1995 - precision: 0.6031 - val_loss: 1.2214 - val_precision: 0.6652\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1959 - precision: 0.6022\n",
      "Epoch 18: val_loss did not improve from 1.22140\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1959 - precision: 0.6025 - val_loss: 1.2231 - val_precision: 0.6697\n",
      "Epoch 19/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2004 - precision: 0.5806\n",
      "Epoch 19: val_loss did not improve from 1.22140\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2002 - precision: 0.5803 - val_loss: 1.2250 - val_precision: 0.6872\n",
      "Epoch 20/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1972 - precision: 0.5868\n",
      "Epoch 20: val_loss improved from 1.22140 to 1.22075, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1986 - precision: 0.5872 - val_loss: 1.2208 - val_precision: 0.6751\n",
      "Epoch 21/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1963 - precision: 0.5782\n",
      "Epoch 21: val_loss improved from 1.22075 to 1.22062, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1967 - precision: 0.5785 - val_loss: 1.2206 - val_precision: 0.6567\n",
      "Epoch 22/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1965 - precision: 0.5829\n",
      "Epoch 22: val_loss did not improve from 1.22062\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1987 - precision: 0.5805 - val_loss: 1.2225 - val_precision: 0.6652\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1828 - precision: 0.5736\n",
      "Epoch 23: val_loss did not improve from 1.22062\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1840 - precision: 0.5750 - val_loss: 1.2247 - val_precision: 0.6761\n",
      "Epoch 24/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1938 - precision: 0.5729\n",
      "Epoch 24: val_loss improved from 1.22062 to 1.21719, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1936 - precision: 0.5724 - val_loss: 1.2172 - val_precision: 0.6502\n",
      "Epoch 25/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1889 - precision: 0.5765\n",
      "Epoch 25: val_loss did not improve from 1.21719\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1881 - precision: 0.5764 - val_loss: 1.2186 - val_precision: 0.6266\n",
      "Epoch 26/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1867 - precision: 0.5752\n",
      "Epoch 26: val_loss did not improve from 1.21719\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1866 - precision: 0.5752 - val_loss: 1.2192 - val_precision: 0.6217\n",
      "Epoch 27/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1889 - precision: 0.5736\n",
      "Epoch 27: val_loss did not improve from 1.21719\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1899 - precision: 0.5712 - val_loss: 1.2196 - val_precision: 0.6125\n",
      "Epoch 28/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1777 - precision: 0.5538\n",
      "Epoch 28: val_loss did not improve from 1.21719\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1808 - precision: 0.5553 - val_loss: 1.2178 - val_precision: 0.6062\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1797 - precision: 0.5713\n",
      "Epoch 29: val_loss did not improve from 1.21719\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1807 - precision: 0.5715 - val_loss: 1.2201 - val_precision: 0.5982\n",
      "Epoch 30/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1810 - precision: 0.5589\n",
      "Epoch 30: val_loss did not improve from 1.21719\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.1804 - precision: 0.5591 - val_loss: 1.2196 - val_precision: 0.5897\n",
      "Epoch 31/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1780 - precision: 0.5562\n",
      "Epoch 31: val_loss improved from 1.21719 to 1.21514, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1780 - precision: 0.5568 - val_loss: 1.2151 - val_precision: 0.5963\n",
      "Epoch 32/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1729 - precision: 0.5659\n",
      "Epoch 32: val_loss improved from 1.21514 to 1.21427, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1730 - precision: 0.5664 - val_loss: 1.2143 - val_precision: 0.5798\n",
      "Epoch 33/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1775 - precision: 0.5540\n",
      "Epoch 33: val_loss did not improve from 1.21427\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1797 - precision: 0.5563 - val_loss: 1.2189 - val_precision: 0.5852\n",
      "Epoch 34/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1768 - precision: 0.5640\n",
      "Epoch 34: val_loss did not improve from 1.21427\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1770 - precision: 0.5642 - val_loss: 1.2213 - val_precision: 0.5615\n",
      "Epoch 35/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1688 - precision: 0.5708\n",
      "Epoch 35: val_loss improved from 1.21427 to 1.21347, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1698 - precision: 0.5708 - val_loss: 1.2135 - val_precision: 0.5664\n",
      "Epoch 36/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1717 - precision: 0.5604\n",
      "Epoch 36: val_loss did not improve from 1.21347\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1714 - precision: 0.5606 - val_loss: 1.2181 - val_precision: 0.5669\n",
      "Epoch 37/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1610 - precision: 0.5611\n",
      "Epoch 37: val_loss did not improve from 1.21347\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1596 - precision: 0.5628 - val_loss: 1.2256 - val_precision: 0.5749\n",
      "Epoch 38/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1657 - precision: 0.5589\n",
      "Epoch 38: val_loss did not improve from 1.21347\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1657 - precision: 0.5589 - val_loss: 1.2261 - val_precision: 0.5693\n",
      "Epoch 39/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1622 - precision: 0.5621\n",
      "Epoch 39: val_loss did not improve from 1.21347\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1623 - precision: 0.5627 - val_loss: 1.2142 - val_precision: 0.5721\n",
      "Epoch 40/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1609 - precision: 0.5712\n",
      "Epoch 40: val_loss did not improve from 1.21347\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1621 - precision: 0.5683 - val_loss: 1.2155 - val_precision: 0.5679\n",
      "Epoch 41/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1728 - precision: 0.5562\n",
      "Epoch 41: val_loss improved from 1.21347 to 1.20635, saving model to model_ent32.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1736 - precision: 0.5586 - val_loss: 1.2064 - val_precision: 0.5827\n",
      "Epoch 42/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1593 - precision: 0.5634\n",
      "Epoch 42: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1603 - precision: 0.5612 - val_loss: 1.2189 - val_precision: 0.5595\n",
      "Epoch 43/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1619 - precision: 0.5677\n",
      "Epoch 43: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1578 - precision: 0.5669 - val_loss: 1.2185 - val_precision: 0.5508\n",
      "Epoch 44/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1512 - precision: 0.5631\n",
      "Epoch 44: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1524 - precision: 0.5630 - val_loss: 1.2157 - val_precision: 0.5748\n",
      "Epoch 45/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1585 - precision: 0.5377\n",
      "Epoch 45: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1589 - precision: 0.5401 - val_loss: 1.2112 - val_precision: 0.5691\n",
      "Epoch 46/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1537 - precision: 0.5423\n",
      "Epoch 46: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1517 - precision: 0.5476 - val_loss: 1.2189 - val_precision: 0.5806\n",
      "Epoch 47/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1535 - precision: 0.5557\n",
      "Epoch 47: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1526 - precision: 0.5565 - val_loss: 1.2113 - val_precision: 0.5747\n",
      "Epoch 48/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1437 - precision: 0.5633\n",
      "Epoch 48: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1478 - precision: 0.5589 - val_loss: 1.2106 - val_precision: 0.5565\n",
      "Epoch 49/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1535 - precision: 0.5625\n",
      "Epoch 49: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1520 - precision: 0.5625 - val_loss: 1.2123 - val_precision: 0.5484\n",
      "Epoch 50/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1468 - precision: 0.5612\n",
      "Epoch 50: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1473 - precision: 0.5623 - val_loss: 1.2133 - val_precision: 0.5559\n",
      "Epoch 51/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1398 - precision: 0.5548\n",
      "Epoch 51: val_loss did not improve from 1.20635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1432 - precision: 0.5518 - val_loss: 1.2155 - val_precision: 0.5670\n",
      "Epoch 51: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.1742 - precision: 0.5813\n",
      "Combinación 31 = (True, False, True, 8, 0.25) \n",
      " precision train: [1.1742417812347412, 0.5813379287719727]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 33: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.6017 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.57103, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 7s 10ms/step - loss: 1.6011 - precision: 0.0000e+00 - val_loss: 1.5710 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.4714 - precision: 0.5461\n",
      "Epoch 2: val_loss improved from 1.57103 to 1.36407, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.4706 - precision: 0.5457 - val_loss: 1.3641 - val_precision: 0.6719\n",
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.4055 - precision: 0.5325\n",
      "Epoch 3: val_loss improved from 1.36407 to 1.32170, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.4050 - precision: 0.5338 - val_loss: 1.3217 - val_precision: 0.6658\n",
      "Epoch 4/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.3777 - precision: 0.5275\n",
      "Epoch 4: val_loss improved from 1.32170 to 1.30334, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3767 - precision: 0.5330 - val_loss: 1.3033 - val_precision: 0.6562\n",
      "Epoch 5/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.3547 - precision: 0.5536\n",
      "Epoch 5: val_loss improved from 1.30334 to 1.28572, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3530 - precision: 0.5504 - val_loss: 1.2857 - val_precision: 0.6574\n",
      "Epoch 6/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/236 [===========================>..] - ETA: 0s - loss: 1.3372 - precision: 0.5714\n",
      "Epoch 6: val_loss improved from 1.28572 to 1.28020, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3366 - precision: 0.5715 - val_loss: 1.2802 - val_precision: 0.6642\n",
      "Epoch 7/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3265 - precision: 0.5720\n",
      "Epoch 7: val_loss improved from 1.28020 to 1.27020, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3234 - precision: 0.5773 - val_loss: 1.2702 - val_precision: 0.6699\n",
      "Epoch 8/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3144 - precision: 0.5949\n",
      "Epoch 8: val_loss improved from 1.27020 to 1.26385, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3158 - precision: 0.5950 - val_loss: 1.2638 - val_precision: 0.6698\n",
      "Epoch 9/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3103 - precision: 0.5990\n",
      "Epoch 9: val_loss did not improve from 1.26385\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3082 - precision: 0.6042 - val_loss: 1.2938 - val_precision: 0.6726\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3045 - precision: 0.5807\n",
      "Epoch 10: val_loss improved from 1.26385 to 1.26167, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3036 - precision: 0.5821 - val_loss: 1.2617 - val_precision: 0.6667\n",
      "Epoch 11/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2925 - precision: 0.5924\n",
      "Epoch 11: val_loss improved from 1.26167 to 1.25658, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2912 - precision: 0.5912 - val_loss: 1.2566 - val_precision: 0.6581\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2970 - precision: 0.6114\n",
      "Epoch 12: val_loss improved from 1.25658 to 1.25554, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2962 - precision: 0.6117 - val_loss: 1.2555 - val_precision: 0.6643\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3054 - precision: 0.5951\n",
      "Epoch 13: val_loss improved from 1.25554 to 1.25348, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3031 - precision: 0.6009 - val_loss: 1.2535 - val_precision: 0.6659\n",
      "Epoch 14/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2989 - precision: 0.6033\n",
      "Epoch 14: val_loss did not improve from 1.25348\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2975 - precision: 0.6031 - val_loss: 1.2570 - val_precision: 0.6682\n",
      "Epoch 15/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2915 - precision: 0.6019\n",
      "Epoch 15: val_loss improved from 1.25348 to 1.25255, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.2920 - precision: 0.5991 - val_loss: 1.2525 - val_precision: 0.6674\n",
      "Epoch 16/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2819 - precision: 0.6216\n",
      "Epoch 16: val_loss did not improve from 1.25255\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2821 - precision: 0.6234 - val_loss: 1.2599 - val_precision: 0.6713\n",
      "Epoch 17/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2843 - precision: 0.6068\n",
      "Epoch 17: val_loss improved from 1.25255 to 1.25231, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2841 - precision: 0.6090 - val_loss: 1.2523 - val_precision: 0.6706\n",
      "Epoch 18/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2820 - precision: 0.6325\n",
      "Epoch 18: val_loss did not improve from 1.25231\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2834 - precision: 0.6325 - val_loss: 1.2541 - val_precision: 0.6667\n",
      "Epoch 19/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2787 - precision: 0.6399\n",
      "Epoch 19: val_loss improved from 1.25231 to 1.24802, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.2780 - precision: 0.6395 - val_loss: 1.2480 - val_precision: 0.6682\n",
      "Epoch 20/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2815 - precision: 0.6140\n",
      "Epoch 20: val_loss did not improve from 1.24802\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.2815 - precision: 0.6146 - val_loss: 1.2523 - val_precision: 0.6643\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2820 - precision: 0.6434\n",
      "Epoch 21: val_loss did not improve from 1.24802\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2817 - precision: 0.6423 - val_loss: 1.2497 - val_precision: 0.6690\n",
      "Epoch 22/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2653 - precision: 0.6352\n",
      "Epoch 22: val_loss did not improve from 1.24802\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2672 - precision: 0.6368 - val_loss: 1.2504 - val_precision: 0.6715\n",
      "Epoch 23/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2771 - precision: 0.6152\n",
      "Epoch 23: val_loss improved from 1.24802 to 1.24717, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2768 - precision: 0.6161 - val_loss: 1.2472 - val_precision: 0.6667\n",
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2690 - precision: 0.6485\n",
      "Epoch 24: val_loss improved from 1.24717 to 1.24379, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.2702 - precision: 0.6478 - val_loss: 1.2438 - val_precision: 0.6594\n",
      "Epoch 25/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2729 - precision: 0.6349\n",
      "Epoch 25: val_loss did not improve from 1.24379\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.2718 - precision: 0.6347 - val_loss: 1.2500 - val_precision: 0.6706\n",
      "Epoch 26/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2789 - precision: 0.6400\n",
      "Epoch 26: val_loss improved from 1.24379 to 1.24138, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2797 - precision: 0.6392 - val_loss: 1.2414 - val_precision: 0.6637\n",
      "Epoch 27/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2731 - precision: 0.6307\n",
      "Epoch 27: val_loss did not improve from 1.24138\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2753 - precision: 0.6228 - val_loss: 1.2453 - val_precision: 0.6644\n",
      "Epoch 28/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2720 - precision: 0.6196\n",
      "Epoch 28: val_loss did not improve from 1.24138\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2734 - precision: 0.6183 - val_loss: 1.2538 - val_precision: 0.6699\n",
      "Epoch 29/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2721 - precision: 0.6257\n",
      "Epoch 29: val_loss did not improve from 1.24138\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2751 - precision: 0.6240 - val_loss: 1.2455 - val_precision: 0.6629\n",
      "Epoch 30/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2617 - precision: 0.6404\n",
      "Epoch 30: val_loss did not improve from 1.24138\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2615 - precision: 0.6424 - val_loss: 1.2463 - val_precision: 0.6674\n",
      "Epoch 31/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2791 - precision: 0.6277\n",
      "Epoch 31: val_loss did not improve from 1.24138\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2773 - precision: 0.6269 - val_loss: 1.2419 - val_precision: 0.6644\n",
      "Epoch 32/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2647 - precision: 0.6471\n",
      "Epoch 32: val_loss improved from 1.24138 to 1.23775, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2647 - precision: 0.6471 - val_loss: 1.2378 - val_precision: 0.6652\n",
      "Epoch 33/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2679 - precision: 0.6165\n",
      "Epoch 33: val_loss did not improve from 1.23775\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2679 - precision: 0.6165 - val_loss: 1.2433 - val_precision: 0.6732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2673 - precision: 0.6244\n",
      "Epoch 34: val_loss did not improve from 1.23775\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2673 - precision: 0.6244 - val_loss: 1.2468 - val_precision: 0.6690\n",
      "Epoch 35/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2708 - precision: 0.5955\n",
      "Epoch 35: val_loss did not improve from 1.23775\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2705 - precision: 0.5954 - val_loss: 1.2382 - val_precision: 0.6630\n",
      "Epoch 36/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2624 - precision: 0.6150\n",
      "Epoch 36: val_loss did not improve from 1.23775\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2644 - precision: 0.6207 - val_loss: 1.2446 - val_precision: 0.6652\n",
      "Epoch 37/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2625 - precision: 0.6296\n",
      "Epoch 37: val_loss did not improve from 1.23775\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2623 - precision: 0.6279 - val_loss: 1.2395 - val_precision: 0.6667\n",
      "Epoch 38/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2719 - precision: 0.6194\n",
      "Epoch 38: val_loss did not improve from 1.23775\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2716 - precision: 0.6193 - val_loss: 1.2401 - val_precision: 0.6682\n",
      "Epoch 39/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2642 - precision: 0.5943\n",
      "Epoch 39: val_loss did not improve from 1.23775\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2642 - precision: 0.5942 - val_loss: 1.2401 - val_precision: 0.6689\n",
      "Epoch 40/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2652 - precision: 0.6168\n",
      "Epoch 40: val_loss did not improve from 1.23775\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2613 - precision: 0.6187 - val_loss: 1.2386 - val_precision: 0.6674\n",
      "Epoch 41/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2600 - precision: 0.6296\n",
      "Epoch 41: val_loss improved from 1.23775 to 1.23769, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2581 - precision: 0.6293 - val_loss: 1.2377 - val_precision: 0.6637\n",
      "Epoch 42/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2643 - precision: 0.5992\n",
      "Epoch 42: val_loss did not improve from 1.23769\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2639 - precision: 0.5997 - val_loss: 1.2387 - val_precision: 0.6713\n",
      "Epoch 43/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2628 - precision: 0.6026\n",
      "Epoch 43: val_loss did not improve from 1.23769\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2628 - precision: 0.6026 - val_loss: 1.2417 - val_precision: 0.6682\n",
      "Epoch 44/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2596 - precision: 0.6279\n",
      "Epoch 44: val_loss improved from 1.23769 to 1.23549, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.2596 - precision: 0.6279 - val_loss: 1.2355 - val_precision: 0.6667\n",
      "Epoch 45/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2616 - precision: 0.5914\n",
      "Epoch 45: val_loss improved from 1.23549 to 1.23266, saving model to model_ent33.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2617 - precision: 0.5926 - val_loss: 1.2327 - val_precision: 0.6712\n",
      "Epoch 46/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2595 - precision: 0.5984\n",
      "Epoch 46: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2595 - precision: 0.5984 - val_loss: 1.2403 - val_precision: 0.6730\n",
      "Epoch 47/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2652 - precision: 0.5882\n",
      "Epoch 47: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2646 - precision: 0.5883 - val_loss: 1.2382 - val_precision: 0.6659\n",
      "Epoch 48/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2651 - precision: 0.5980\n",
      "Epoch 48: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2647 - precision: 0.5976 - val_loss: 1.2344 - val_precision: 0.6719\n",
      "Epoch 49/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2492 - precision: 0.6052\n",
      "Epoch 49: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2492 - precision: 0.6033 - val_loss: 1.2390 - val_precision: 0.6594\n",
      "Epoch 50/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2591 - precision: 0.5833\n",
      "Epoch 50: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2592 - precision: 0.5832 - val_loss: 1.2369 - val_precision: 0.6674\n",
      "Epoch 51/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2536 - precision: 0.5831\n",
      "Epoch 51: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2534 - precision: 0.5839 - val_loss: 1.2343 - val_precision: 0.6674\n",
      "Epoch 52/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2476 - precision: 0.6025\n",
      "Epoch 52: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.2472 - precision: 0.5997 - val_loss: 1.2352 - val_precision: 0.6689\n",
      "Epoch 53/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2494 - precision: 0.5674\n",
      "Epoch 53: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2482 - precision: 0.5680 - val_loss: 1.2362 - val_precision: 0.6682\n",
      "Epoch 54/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2607 - precision: 0.5849\n",
      "Epoch 54: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2610 - precision: 0.5832 - val_loss: 1.2367 - val_precision: 0.6713\n",
      "Epoch 55/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2476 - precision: 0.5856\n",
      "Epoch 55: val_loss did not improve from 1.23266\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2474 - precision: 0.5861 - val_loss: 1.2362 - val_precision: 0.6744\n",
      "Epoch 55: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.2197 - precision: 0.6712\n",
      "Combinación 32 = (True, False, True, 8, 0.5) \n",
      " precision train: [1.2197177410125732, 0.6712141633033752]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 34: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.4777 - precision: 0.6855\n",
      "Epoch 1: val_loss improved from inf to 1.28524, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.4671 - precision: 0.6901 - val_loss: 1.2852 - val_precision: 0.7018\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2243 - precision: 0.6607\n",
      "Epoch 2: val_loss improved from 1.28524 to 1.17936, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2215 - precision: 0.6607 - val_loss: 1.1794 - val_precision: 0.6670\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1164 - precision: 0.6353\n",
      "Epoch 3: val_loss improved from 1.17936 to 1.12426, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1143 - precision: 0.6347 - val_loss: 1.1243 - val_precision: 0.6492\n",
      "Epoch 4/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0677 - precision: 0.6318\n",
      "Epoch 4: val_loss improved from 1.12426 to 1.08783, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0692 - precision: 0.6302 - val_loss: 1.0878 - val_precision: 0.6632\n",
      "Epoch 5/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0324 - precision: 0.6146\n",
      "Epoch 5: val_loss improved from 1.08783 to 1.07707, saving model to model_ent34.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0320 - precision: 0.6148 - val_loss: 1.0771 - val_precision: 0.6208\n",
      "Epoch 6/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0131 - precision: 0.5992\n",
      "Epoch 6: val_loss improved from 1.07707 to 1.07514, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0147 - precision: 0.5998 - val_loss: 1.0751 - val_precision: 0.6065\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0000 - precision: 0.5984\n",
      "Epoch 7: val_loss did not improve from 1.07514\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9994 - precision: 0.5985 - val_loss: 1.0753 - val_precision: 0.5985\n",
      "Epoch 8/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9889 - precision: 0.5997\n",
      "Epoch 8: val_loss improved from 1.07514 to 1.06058, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9881 - precision: 0.5983 - val_loss: 1.0606 - val_precision: 0.6085\n",
      "Epoch 9/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9764 - precision: 0.6010\n",
      "Epoch 9: val_loss improved from 1.06058 to 1.05538, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9745 - precision: 0.6009 - val_loss: 1.0554 - val_precision: 0.6102\n",
      "Epoch 10/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9662 - precision: 0.6023\n",
      "Epoch 10: val_loss improved from 1.05538 to 1.05016, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9641 - precision: 0.6041 - val_loss: 1.0502 - val_precision: 0.6117\n",
      "Epoch 11/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9641 - precision: 0.6042\n",
      "Epoch 11: val_loss did not improve from 1.05016\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9641 - precision: 0.6038 - val_loss: 1.0576 - val_precision: 0.5999\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9559 - precision: 0.6093\n",
      "Epoch 12: val_loss did not improve from 1.05016\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9559 - precision: 0.6093 - val_loss: 1.0531 - val_precision: 0.6099\n",
      "Epoch 13/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9464 - precision: 0.6090\n",
      "Epoch 13: val_loss did not improve from 1.05016\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9490 - precision: 0.6081 - val_loss: 1.0528 - val_precision: 0.6117\n",
      "Epoch 14/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9431 - precision: 0.6114\n",
      "Epoch 14: val_loss improved from 1.05016 to 1.03829, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9425 - precision: 0.6114 - val_loss: 1.0383 - val_precision: 0.6129\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9375 - precision: 0.6156\n",
      "Epoch 15: val_loss did not improve from 1.03829\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9375 - precision: 0.6156 - val_loss: 1.0436 - val_precision: 0.6099\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9332 - precision: 0.6119\n",
      "Epoch 16: val_loss did not improve from 1.03829\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9340 - precision: 0.6115 - val_loss: 1.0578 - val_precision: 0.5989\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9288 - precision: 0.6096\n",
      "Epoch 17: val_loss did not improve from 1.03829\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9280 - precision: 0.6096 - val_loss: 1.0480 - val_precision: 0.6044\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9172 - precision: 0.6126\n",
      "Epoch 18: val_loss improved from 1.03829 to 1.03170, saving model to model_ent34.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9167 - precision: 0.6129 - val_loss: 1.0317 - val_precision: 0.6210\n",
      "Epoch 19/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9218 - precision: 0.6143\n",
      "Epoch 19: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9218 - precision: 0.6138 - val_loss: 1.0342 - val_precision: 0.6161\n",
      "Epoch 20/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9104 - precision: 0.6200\n",
      "Epoch 20: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9155 - precision: 0.6178 - val_loss: 1.0443 - val_precision: 0.6048\n",
      "Epoch 21/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9105 - precision: 0.6133\n",
      "Epoch 21: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9079 - precision: 0.6139 - val_loss: 1.0400 - val_precision: 0.6102\n",
      "Epoch 22/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9057 - precision: 0.6200\n",
      "Epoch 22: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9046 - precision: 0.6205 - val_loss: 1.0407 - val_precision: 0.6102\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9032 - precision: 0.6196\n",
      "Epoch 23: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9056 - precision: 0.6188 - val_loss: 1.0421 - val_precision: 0.6096\n",
      "Epoch 24/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8952 - precision: 0.6198\n",
      "Epoch 24: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8953 - precision: 0.6203 - val_loss: 1.0559 - val_precision: 0.5977\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8918 - precision: 0.6228\n",
      "Epoch 25: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8929 - precision: 0.6231 - val_loss: 1.0549 - val_precision: 0.6015\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8908 - precision: 0.6186\n",
      "Epoch 26: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8908 - precision: 0.6186 - val_loss: 1.0459 - val_precision: 0.6128\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8862 - precision: 0.6244\n",
      "Epoch 27: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8841 - precision: 0.6253 - val_loss: 1.0476 - val_precision: 0.6035\n",
      "Epoch 28/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8803 - precision: 0.6239\n",
      "Epoch 28: val_loss did not improve from 1.03170\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8797 - precision: 0.6251 - val_loss: 1.0323 - val_precision: 0.6110\n",
      "Epoch 28: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9620 - precision: 0.6296\n",
      "Combinación 33 = (True, False, True, 16, 0.1) \n",
      " precision train: [0.9620275497436523, 0.6296147108078003]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 35: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.5110 - precision: 0.6871\n",
      "Epoch 1: val_loss improved from inf to 1.35035, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 8s 9ms/step - loss: 1.5076 - precision: 0.6814 - val_loss: 1.3503 - val_precision: 0.7039\n",
      "Epoch 2/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2974 - precision: 0.6771\n",
      "Epoch 2: val_loss improved from 1.35035 to 1.21459, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2944 - precision: 0.6720 - val_loss: 1.2146 - val_precision: 0.6688\n",
      "Epoch 3/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1689 - precision: 0.6255\n",
      "Epoch 3: val_loss improved from 1.21459 to 1.14626, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1693 - precision: 0.6251 - val_loss: 1.1463 - val_precision: 0.6437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1061 - precision: 0.6243\n",
      "Epoch 4: val_loss improved from 1.14626 to 1.11542, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1102 - precision: 0.6219 - val_loss: 1.1154 - val_precision: 0.6592\n",
      "Epoch 5/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0723 - precision: 0.6159\n",
      "Epoch 5: val_loss improved from 1.11542 to 1.09256, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0729 - precision: 0.6163 - val_loss: 1.0926 - val_precision: 0.6324\n",
      "Epoch 6/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0656 - precision: 0.6083\n",
      "Epoch 6: val_loss improved from 1.09256 to 1.08757, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0654 - precision: 0.6086 - val_loss: 1.0876 - val_precision: 0.6182\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0549 - precision: 0.5975\n",
      "Epoch 7: val_loss did not improve from 1.08757\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0526 - precision: 0.5979 - val_loss: 1.0877 - val_precision: 0.6025\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0550 - precision: 0.5884\n",
      "Epoch 8: val_loss improved from 1.08757 to 1.07403, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0553 - precision: 0.5881 - val_loss: 1.0740 - val_precision: 0.6063\n",
      "Epoch 9/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0392 - precision: 0.5924\n",
      "Epoch 9: val_loss did not improve from 1.07403\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0376 - precision: 0.5923 - val_loss: 1.0754 - val_precision: 0.6066\n",
      "Epoch 10/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0257 - precision: 0.5966\n",
      "Epoch 10: val_loss did not improve from 1.07403\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0257 - precision: 0.5956 - val_loss: 1.0753 - val_precision: 0.6017\n",
      "Epoch 11/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0240 - precision: 0.5951\n",
      "Epoch 11: val_loss improved from 1.07403 to 1.06768, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0228 - precision: 0.5947 - val_loss: 1.0677 - val_precision: 0.6107\n",
      "Epoch 12/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0185 - precision: 0.5954\n",
      "Epoch 12: val_loss did not improve from 1.06768\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0239 - precision: 0.5948 - val_loss: 1.0728 - val_precision: 0.6042\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0143 - precision: 0.5985\n",
      "Epoch 13: val_loss did not improve from 1.06768\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0128 - precision: 0.5983 - val_loss: 1.0688 - val_precision: 0.5989\n",
      "Epoch 14/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0131 - precision: 0.5967\n",
      "Epoch 14: val_loss did not improve from 1.06768\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0105 - precision: 0.5971 - val_loss: 1.0814 - val_precision: 0.5996\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0066 - precision: 0.6030\n",
      "Epoch 15: val_loss improved from 1.06768 to 1.06708, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0066 - precision: 0.6030 - val_loss: 1.0671 - val_precision: 0.6095\n",
      "Epoch 16/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0126 - precision: 0.5948\n",
      "Epoch 16: val_loss improved from 1.06708 to 1.06637, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0049 - precision: 0.5972 - val_loss: 1.0664 - val_precision: 0.6013\n",
      "Epoch 17/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0021 - precision: 0.5998\n",
      "Epoch 17: val_loss improved from 1.06637 to 1.06326, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0021 - precision: 0.5998 - val_loss: 1.0633 - val_precision: 0.6077\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9888 - precision: 0.6056\n",
      "Epoch 18: val_loss did not improve from 1.06326\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9902 - precision: 0.6055 - val_loss: 1.0644 - val_precision: 0.6079\n",
      "Epoch 19/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9856 - precision: 0.6087\n",
      "Epoch 19: val_loss did not improve from 1.06326\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9859 - precision: 0.6082 - val_loss: 1.0661 - val_precision: 0.6007\n",
      "Epoch 20/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9890 - precision: 0.6026\n",
      "Epoch 20: val_loss did not improve from 1.06326\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9855 - precision: 0.6034 - val_loss: 1.0726 - val_precision: 0.6004\n",
      "Epoch 21/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9834 - precision: 0.6081\n",
      "Epoch 21: val_loss improved from 1.06326 to 1.05601, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9877 - precision: 0.6059 - val_loss: 1.0560 - val_precision: 0.6139\n",
      "Epoch 22/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9763 - precision: 0.6107\n",
      "Epoch 22: val_loss improved from 1.05601 to 1.05546, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9824 - precision: 0.6102 - val_loss: 1.0555 - val_precision: 0.6090\n",
      "Epoch 23/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9809 - precision: 0.6084\n",
      "Epoch 23: val_loss did not improve from 1.05546\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9826 - precision: 0.6074 - val_loss: 1.0626 - val_precision: 0.6027\n",
      "Epoch 24/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9793 - precision: 0.6105\n",
      "Epoch 24: val_loss did not improve from 1.05546\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9793 - precision: 0.6105 - val_loss: 1.0644 - val_precision: 0.6044\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9734 - precision: 0.6082\n",
      "Epoch 25: val_loss did not improve from 1.05546\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9747 - precision: 0.6063 - val_loss: 1.0657 - val_precision: 0.6057\n",
      "Epoch 26/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9623 - precision: 0.6086\n",
      "Epoch 26: val_loss did not improve from 1.05546\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9714 - precision: 0.6058 - val_loss: 1.0568 - val_precision: 0.6022\n",
      "Epoch 27/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9698 - precision: 0.6081\n",
      "Epoch 27: val_loss did not improve from 1.05546\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9700 - precision: 0.6076 - val_loss: 1.0625 - val_precision: 0.6056\n",
      "Epoch 28/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9619 - precision: 0.6083\n",
      "Epoch 28: val_loss improved from 1.05546 to 1.05433, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9637 - precision: 0.6088 - val_loss: 1.0543 - val_precision: 0.6142\n",
      "Epoch 29/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9650 - precision: 0.6097\n",
      "Epoch 29: val_loss improved from 1.05433 to 1.05363, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9630 - precision: 0.6113 - val_loss: 1.0536 - val_precision: 0.6087\n",
      "Epoch 30/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9541 - precision: 0.6135\n",
      "Epoch 30: val_loss did not improve from 1.05363\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9588 - precision: 0.6124 - val_loss: 1.0662 - val_precision: 0.5985\n",
      "Epoch 31/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9653 - precision: 0.6132\n",
      "Epoch 31: val_loss did not improve from 1.05363\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9644 - precision: 0.6106 - val_loss: 1.0665 - val_precision: 0.6036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9636 - precision: 0.6116\n",
      "Epoch 32: val_loss improved from 1.05363 to 1.05085, saving model to model_ent35.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9621 - precision: 0.6116 - val_loss: 1.0508 - val_precision: 0.6088\n",
      "Epoch 33/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9605 - precision: 0.6179\n",
      "Epoch 33: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9594 - precision: 0.6169 - val_loss: 1.0599 - val_precision: 0.6069\n",
      "Epoch 34/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9524 - precision: 0.6091\n",
      "Epoch 34: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9516 - precision: 0.6089 - val_loss: 1.0685 - val_precision: 0.6004\n",
      "Epoch 35/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9548 - precision: 0.6141\n",
      "Epoch 35: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9527 - precision: 0.6145 - val_loss: 1.0520 - val_precision: 0.6068\n",
      "Epoch 36/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9479 - precision: 0.6136\n",
      "Epoch 36: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9498 - precision: 0.6135 - val_loss: 1.0611 - val_precision: 0.6045\n",
      "Epoch 37/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9511 - precision: 0.6101\n",
      "Epoch 37: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9495 - precision: 0.6111 - val_loss: 1.0553 - val_precision: 0.6048\n",
      "Epoch 38/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9533 - precision: 0.6092\n",
      "Epoch 38: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9553 - precision: 0.6099 - val_loss: 1.0644 - val_precision: 0.5962\n",
      "Epoch 39/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9477 - precision: 0.6116\n",
      "Epoch 39: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9481 - precision: 0.6109 - val_loss: 1.0589 - val_precision: 0.6019\n",
      "Epoch 40/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9419 - precision: 0.6132\n",
      "Epoch 40: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9419 - precision: 0.6130 - val_loss: 1.0569 - val_precision: 0.6069\n",
      "Epoch 41/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9388 - precision: 0.6182\n",
      "Epoch 41: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9420 - precision: 0.6167 - val_loss: 1.0582 - val_precision: 0.5982\n",
      "Epoch 42/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9409 - precision: 0.6182\n",
      "Epoch 42: val_loss did not improve from 1.05085\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9421 - precision: 0.6179 - val_loss: 1.0596 - val_precision: 0.5983\n",
      "Epoch 42: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9958 - precision: 0.6232\n",
      "Combinación 34 = (True, False, True, 16, 0.25) \n",
      " precision train: [0.9957789182662964, 0.6232283711433411]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 36: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.5679 - precision: 0.6379  \n",
      "Epoch 1: val_loss improved from inf to 1.36780, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 13s 9ms/step - loss: 1.5679 - precision: 0.6379 - val_loss: 1.3678 - val_precision: 0.6860\n",
      "Epoch 2/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.3568 - precision: 0.5969\n",
      "Epoch 2: val_loss improved from 1.36780 to 1.27043, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3571 - precision: 0.5913 - val_loss: 1.2704 - val_precision: 0.6358\n",
      "Epoch 3/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2910 - precision: 0.5750\n",
      "Epoch 3: val_loss improved from 1.27043 to 1.21348, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2939 - precision: 0.5690 - val_loss: 1.2135 - val_precision: 0.6548\n",
      "Epoch 4/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2530 - precision: 0.5825\n",
      "Epoch 4: val_loss improved from 1.21348 to 1.16392, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2502 - precision: 0.5802 - val_loss: 1.1639 - val_precision: 0.6638\n",
      "Epoch 5/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2071 - precision: 0.5687\n",
      "Epoch 5: val_loss improved from 1.16392 to 1.12954, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2048 - precision: 0.5736 - val_loss: 1.1295 - val_precision: 0.6403\n",
      "Epoch 6/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1696 - precision: 0.5867\n",
      "Epoch 6: val_loss improved from 1.12954 to 1.11800, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1675 - precision: 0.5876 - val_loss: 1.1180 - val_precision: 0.6268\n",
      "Epoch 7/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1681 - precision: 0.5728\n",
      "Epoch 7: val_loss improved from 1.11800 to 1.10696, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1692 - precision: 0.5729 - val_loss: 1.1070 - val_precision: 0.6216\n",
      "Epoch 8/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1536 - precision: 0.5836\n",
      "Epoch 8: val_loss improved from 1.10696 to 1.10414, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1523 - precision: 0.5845 - val_loss: 1.1041 - val_precision: 0.6172\n",
      "Epoch 9/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1450 - precision: 0.5885\n",
      "Epoch 9: val_loss did not improve from 1.10414\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1419 - precision: 0.5860 - val_loss: 1.1059 - val_precision: 0.6086\n",
      "Epoch 10/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1470 - precision: 0.5860\n",
      "Epoch 10: val_loss did not improve from 1.10414\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1450 - precision: 0.5860 - val_loss: 1.1042 - val_precision: 0.6096\n",
      "Epoch 11/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1293 - precision: 0.5916\n",
      "Epoch 11: val_loss improved from 1.10414 to 1.09401, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1275 - precision: 0.5927 - val_loss: 1.0940 - val_precision: 0.6167\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1350 - precision: 0.5822\n",
      "Epoch 12: val_loss did not improve from 1.09401\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1353 - precision: 0.5833 - val_loss: 1.0965 - val_precision: 0.6058\n",
      "Epoch 13/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1300 - precision: 0.5931\n",
      "Epoch 13: val_loss did not improve from 1.09401\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1282 - precision: 0.5939 - val_loss: 1.0993 - val_precision: 0.6076\n",
      "Epoch 14/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1211 - precision: 0.5989\n",
      "Epoch 14: val_loss did not improve from 1.09401\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1203 - precision: 0.5969 - val_loss: 1.0950 - val_precision: 0.6118\n",
      "Epoch 15/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1240 - precision: 0.5871\n",
      "Epoch 15: val_loss improved from 1.09401 to 1.09087, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1227 - precision: 0.5878 - val_loss: 1.0909 - val_precision: 0.6125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1126 - precision: 0.5995\n",
      "Epoch 16: val_loss did not improve from 1.09087\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1136 - precision: 0.5996 - val_loss: 1.0986 - val_precision: 0.6143\n",
      "Epoch 17/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1021 - precision: 0.6044\n",
      "Epoch 17: val_loss did not improve from 1.09087\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1043 - precision: 0.6024 - val_loss: 1.0983 - val_precision: 0.6008\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1081 - precision: 0.5947\n",
      "Epoch 18: val_loss did not improve from 1.09087\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1094 - precision: 0.5932 - val_loss: 1.0921 - val_precision: 0.6084\n",
      "Epoch 19/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1016 - precision: 0.5943\n",
      "Epoch 19: val_loss did not improve from 1.09087\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1015 - precision: 0.5934 - val_loss: 1.0915 - val_precision: 0.6042\n",
      "Epoch 20/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1115 - precision: 0.5856\n",
      "Epoch 20: val_loss improved from 1.09087 to 1.08811, saving model to model_ent36.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1115 - precision: 0.5870 - val_loss: 1.0881 - val_precision: 0.6094\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0977 - precision: 0.6000\n",
      "Epoch 21: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0974 - precision: 0.6008 - val_loss: 1.0957 - val_precision: 0.6092\n",
      "Epoch 22/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1012 - precision: 0.5899\n",
      "Epoch 22: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1017 - precision: 0.5905 - val_loss: 1.0945 - val_precision: 0.6069\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0918 - precision: 0.5986\n",
      "Epoch 23: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0924 - precision: 0.5975 - val_loss: 1.0999 - val_precision: 0.5983\n",
      "Epoch 24/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0997 - precision: 0.6011\n",
      "Epoch 24: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0952 - precision: 0.6021 - val_loss: 1.0965 - val_precision: 0.6043\n",
      "Epoch 25/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0901 - precision: 0.6005\n",
      "Epoch 25: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0901 - precision: 0.6005 - val_loss: 1.0993 - val_precision: 0.5983\n",
      "Epoch 26/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0895 - precision: 0.5997\n",
      "Epoch 26: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0877 - precision: 0.6011 - val_loss: 1.0943 - val_precision: 0.6052\n",
      "Epoch 27/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0892 - precision: 0.6028\n",
      "Epoch 27: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0882 - precision: 0.6052 - val_loss: 1.0971 - val_precision: 0.6041\n",
      "Epoch 28/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0813 - precision: 0.6073\n",
      "Epoch 28: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0840 - precision: 0.6061 - val_loss: 1.0980 - val_precision: 0.6035\n",
      "Epoch 29/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0751 - precision: 0.6062\n",
      "Epoch 29: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0788 - precision: 0.6052 - val_loss: 1.0968 - val_precision: 0.6029\n",
      "Epoch 30/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0829 - precision: 0.6023\n",
      "Epoch 30: val_loss did not improve from 1.08811\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0835 - precision: 0.6017 - val_loss: 1.0948 - val_precision: 0.6095\n",
      "Epoch 30: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0733 - precision: 0.6082\n",
      "Combinación 35 = (True, False, True, 16, 0.5) \n",
      " precision train: [1.073285460472107, 0.6081839799880981]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 37: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.3421 - precision: 0.6380\n",
      "Epoch 1: val_loss improved from inf to 1.16301, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.3401 - precision: 0.6384 - val_loss: 1.1630 - val_precision: 0.6388\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0523 - precision: 0.5995\n",
      "Epoch 2: val_loss improved from 1.16301 to 1.10035, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0539 - precision: 0.5989 - val_loss: 1.1003 - val_precision: 0.5987\n",
      "Epoch 3/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0214 - precision: 0.5871\n",
      "Epoch 3: val_loss improved from 1.10035 to 1.07624, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0218 - precision: 0.5875 - val_loss: 1.0762 - val_precision: 0.6133\n",
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9956 - precision: 0.5997\n",
      "Epoch 4: val_loss improved from 1.07624 to 1.06672, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9951 - precision: 0.5998 - val_loss: 1.0667 - val_precision: 0.6115\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9856 - precision: 0.5961\n",
      "Epoch 5: val_loss improved from 1.06672 to 1.06584, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9856 - precision: 0.5961 - val_loss: 1.0658 - val_precision: 0.6043\n",
      "Epoch 6/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9844 - precision: 0.5970\n",
      "Epoch 6: val_loss improved from 1.06584 to 1.06085, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9783 - precision: 0.6008 - val_loss: 1.0609 - val_precision: 0.6091\n",
      "Epoch 7/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9702 - precision: 0.6018\n",
      "Epoch 7: val_loss improved from 1.06085 to 1.04544, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9672 - precision: 0.6033 - val_loss: 1.0454 - val_precision: 0.6122\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9567 - precision: 0.6060\n",
      "Epoch 8: val_loss did not improve from 1.04544\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9563 - precision: 0.6050 - val_loss: 1.0583 - val_precision: 0.6122\n",
      "Epoch 9/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9492 - precision: 0.6086\n",
      "Epoch 9: val_loss improved from 1.04544 to 1.04039, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9506 - precision: 0.6070 - val_loss: 1.0404 - val_precision: 0.6216\n",
      "Epoch 10/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9435 - precision: 0.6094\n",
      "Epoch 10: val_loss did not improve from 1.04039\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9431 - precision: 0.6097 - val_loss: 1.0500 - val_precision: 0.6036\n",
      "Epoch 11/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9330 - precision: 0.6089\n",
      "Epoch 11: val_loss improved from 1.04039 to 1.03096, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9362 - precision: 0.6076 - val_loss: 1.0310 - val_precision: 0.6169\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9319 - precision: 0.6097\n",
      "Epoch 12: val_loss did not improve from 1.03096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9319 - precision: 0.6097 - val_loss: 1.0428 - val_precision: 0.6244\n",
      "Epoch 13/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9177 - precision: 0.6160\n",
      "Epoch 13: val_loss did not improve from 1.03096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9185 - precision: 0.6139 - val_loss: 1.0338 - val_precision: 0.6242\n",
      "Epoch 14/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9201 - precision: 0.6136\n",
      "Epoch 14: val_loss did not improve from 1.03096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9205 - precision: 0.6121 - val_loss: 1.0348 - val_precision: 0.6220\n",
      "Epoch 15/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9102 - precision: 0.6089\n",
      "Epoch 15: val_loss improved from 1.03096 to 1.01841, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9085 - precision: 0.6099 - val_loss: 1.0184 - val_precision: 0.6263\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9024 - precision: 0.6134\n",
      "Epoch 16: val_loss did not improve from 1.01841\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9028 - precision: 0.6135 - val_loss: 1.0289 - val_precision: 0.6185\n",
      "Epoch 17/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8958 - precision: 0.6178\n",
      "Epoch 17: val_loss did not improve from 1.01841\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8955 - precision: 0.6176 - val_loss: 1.0214 - val_precision: 0.6171\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8969 - precision: 0.6198\n",
      "Epoch 18: val_loss improved from 1.01841 to 1.01392, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8978 - precision: 0.6203 - val_loss: 1.0139 - val_precision: 0.6250\n",
      "Epoch 19/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8847 - precision: 0.6167\n",
      "Epoch 19: val_loss did not improve from 1.01392\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8856 - precision: 0.6170 - val_loss: 1.0338 - val_precision: 0.6111\n",
      "Epoch 20/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8826 - precision: 0.6209\n",
      "Epoch 20: val_loss did not improve from 1.01392\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8814 - precision: 0.6205 - val_loss: 1.0258 - val_precision: 0.6195\n",
      "Epoch 21/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8765 - precision: 0.6192\n",
      "Epoch 21: val_loss did not improve from 1.01392\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8783 - precision: 0.6180 - val_loss: 1.0186 - val_precision: 0.6263\n",
      "Epoch 22/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8681 - precision: 0.6206\n",
      "Epoch 22: val_loss did not improve from 1.01392\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8678 - precision: 0.6232 - val_loss: 1.0377 - val_precision: 0.6110\n",
      "Epoch 23/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8640 - precision: 0.6227\n",
      "Epoch 23: val_loss did not improve from 1.01392\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8646 - precision: 0.6229 - val_loss: 1.0256 - val_precision: 0.6151\n",
      "Epoch 24/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8681 - precision: 0.6224\n",
      "Epoch 24: val_loss improved from 1.01392 to 1.01096, saving model to model_ent37.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8661 - precision: 0.6218 - val_loss: 1.0110 - val_precision: 0.6238\n",
      "Epoch 25/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8530 - precision: 0.6267\n",
      "Epoch 25: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8538 - precision: 0.6265 - val_loss: 1.0205 - val_precision: 0.6143\n",
      "Epoch 26/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8575 - precision: 0.6282\n",
      "Epoch 26: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8557 - precision: 0.6281 - val_loss: 1.0204 - val_precision: 0.6170\n",
      "Epoch 27/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8421 - precision: 0.6263\n",
      "Epoch 27: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8451 - precision: 0.6275 - val_loss: 1.0193 - val_precision: 0.6160\n",
      "Epoch 28/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8366 - precision: 0.6332\n",
      "Epoch 28: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8363 - precision: 0.6336 - val_loss: 1.0351 - val_precision: 0.6108\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8406 - precision: 0.6300\n",
      "Epoch 29: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8433 - precision: 0.6293 - val_loss: 1.0353 - val_precision: 0.5970\n",
      "Epoch 30/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8281 - precision: 0.6371\n",
      "Epoch 30: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8277 - precision: 0.6381 - val_loss: 1.0403 - val_precision: 0.6076\n",
      "Epoch 31/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8278 - precision: 0.6345\n",
      "Epoch 31: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8256 - precision: 0.6359 - val_loss: 1.0231 - val_precision: 0.6113\n",
      "Epoch 32/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8196 - precision: 0.6402\n",
      "Epoch 32: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8198 - precision: 0.6399 - val_loss: 1.0336 - val_precision: 0.6029\n",
      "Epoch 33/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8184 - precision: 0.6416\n",
      "Epoch 33: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8154 - precision: 0.6436 - val_loss: 1.0428 - val_precision: 0.6036\n",
      "Epoch 34/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8116 - precision: 0.6436\n",
      "Epoch 34: val_loss did not improve from 1.01096\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8117 - precision: 0.6431 - val_loss: 1.0373 - val_precision: 0.6045\n",
      "Epoch 34: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9109 - precision: 0.6447\n",
      "Combinación 36 = (True, False, True, 32, 0.1) \n",
      " precision train: [0.9108579158782959, 0.6447480916976929]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 38: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.4166 - precision: 0.6173\n",
      "Epoch 1: val_loss improved from inf to 1.23994, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.4108 - precision: 0.6159 - val_loss: 1.2399 - val_precision: 0.6899\n",
      "Epoch 2/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1545 - precision: 0.6377\n",
      "Epoch 2: val_loss improved from 1.23994 to 1.14084, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1577 - precision: 0.6354 - val_loss: 1.1408 - val_precision: 0.6502\n",
      "Epoch 3/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0762 - precision: 0.6218\n",
      "Epoch 3: val_loss improved from 1.14084 to 1.10790, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0766 - precision: 0.6173 - val_loss: 1.1079 - val_precision: 0.6109\n",
      "Epoch 4/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0344 - precision: 0.6008\n",
      "Epoch 4: val_loss improved from 1.10790 to 1.09111, saving model to model_ent38.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0373 - precision: 0.5982 - val_loss: 1.0911 - val_precision: 0.6079\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0210 - precision: 0.5950\n",
      "Epoch 5: val_loss improved from 1.09111 to 1.08645, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0210 - precision: 0.5950 - val_loss: 1.0864 - val_precision: 0.6056\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0137 - precision: 0.5987\n",
      "Epoch 6: val_loss improved from 1.08645 to 1.08162, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0137 - precision: 0.5987 - val_loss: 1.0816 - val_precision: 0.6108\n",
      "Epoch 7/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9997 - precision: 0.6039\n",
      "Epoch 7: val_loss did not improve from 1.08162\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0013 - precision: 0.6012 - val_loss: 1.0919 - val_precision: 0.5978\n",
      "Epoch 8/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9948 - precision: 0.6008\n",
      "Epoch 8: val_loss improved from 1.08162 to 1.06213, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9976 - precision: 0.6002 - val_loss: 1.0621 - val_precision: 0.6155\n",
      "Epoch 9/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9875 - precision: 0.6017\n",
      "Epoch 9: val_loss did not improve from 1.06213\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9897 - precision: 0.6014 - val_loss: 1.0628 - val_precision: 0.6094\n",
      "Epoch 10/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9786 - precision: 0.6021\n",
      "Epoch 10: val_loss did not improve from 1.06213\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9793 - precision: 0.6022 - val_loss: 1.0627 - val_precision: 0.6204\n",
      "Epoch 11/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9825 - precision: 0.6074\n",
      "Epoch 11: val_loss improved from 1.06213 to 1.05709, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9843 - precision: 0.6082 - val_loss: 1.0571 - val_precision: 0.6106\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9729 - precision: 0.6012\n",
      "Epoch 12: val_loss improved from 1.05709 to 1.05610, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9729 - precision: 0.6012 - val_loss: 1.0561 - val_precision: 0.6106\n",
      "Epoch 13/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9659 - precision: 0.6094\n",
      "Epoch 13: val_loss improved from 1.05610 to 1.05342, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9659 - precision: 0.6096 - val_loss: 1.0534 - val_precision: 0.6200\n",
      "Epoch 14/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9613 - precision: 0.6046\n",
      "Epoch 14: val_loss did not improve from 1.05342\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9626 - precision: 0.6056 - val_loss: 1.0585 - val_precision: 0.6135\n",
      "Epoch 15/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9558 - precision: 0.6086\n",
      "Epoch 15: val_loss improved from 1.05342 to 1.03371, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9571 - precision: 0.6076 - val_loss: 1.0337 - val_precision: 0.6258\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9605 - precision: 0.6118\n",
      "Epoch 16: val_loss did not improve from 1.03371\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9583 - precision: 0.6114 - val_loss: 1.0601 - val_precision: 0.6052\n",
      "Epoch 17/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9488 - precision: 0.6107\n",
      "Epoch 17: val_loss did not improve from 1.03371\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9467 - precision: 0.6112 - val_loss: 1.0465 - val_precision: 0.6175\n",
      "Epoch 18/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9491 - precision: 0.6103\n",
      "Epoch 18: val_loss did not improve from 1.03371\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9466 - precision: 0.6125 - val_loss: 1.0402 - val_precision: 0.6137\n",
      "Epoch 19/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9474 - precision: 0.6108\n",
      "Epoch 19: val_loss did not improve from 1.03371\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9465 - precision: 0.6115 - val_loss: 1.0475 - val_precision: 0.6176\n",
      "Epoch 20/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9358 - precision: 0.6096\n",
      "Epoch 20: val_loss did not improve from 1.03371\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9376 - precision: 0.6094 - val_loss: 1.0432 - val_precision: 0.6129\n",
      "Epoch 21/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9385 - precision: 0.6100\n",
      "Epoch 21: val_loss did not improve from 1.03371\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9343 - precision: 0.6125 - val_loss: 1.0463 - val_precision: 0.6144\n",
      "Epoch 22/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9311 - precision: 0.6130\n",
      "Epoch 22: val_loss improved from 1.03371 to 1.02951, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9281 - precision: 0.6137 - val_loss: 1.0295 - val_precision: 0.6146\n",
      "Epoch 23/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9264 - precision: 0.6153\n",
      "Epoch 23: val_loss did not improve from 1.02951\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9271 - precision: 0.6154 - val_loss: 1.0352 - val_precision: 0.6188\n",
      "Epoch 24/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9173 - precision: 0.6140\n",
      "Epoch 24: val_loss did not improve from 1.02951\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9175 - precision: 0.6138 - val_loss: 1.0418 - val_precision: 0.6128\n",
      "Epoch 25/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9137 - precision: 0.6143\n",
      "Epoch 25: val_loss did not improve from 1.02951\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9132 - precision: 0.6144 - val_loss: 1.0399 - val_precision: 0.6183\n",
      "Epoch 26/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9112 - precision: 0.6144\n",
      "Epoch 26: val_loss did not improve from 1.02951\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9095 - precision: 0.6152 - val_loss: 1.0409 - val_precision: 0.6106\n",
      "Epoch 27/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9112 - precision: 0.6096\n",
      "Epoch 27: val_loss improved from 1.02951 to 1.02183, saving model to model_ent38.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9124 - precision: 0.6109 - val_loss: 1.0218 - val_precision: 0.6244\n",
      "Epoch 28/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8978 - precision: 0.6206\n",
      "Epoch 28: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9005 - precision: 0.6207 - val_loss: 1.0318 - val_precision: 0.6206\n",
      "Epoch 29/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9053 - precision: 0.6218\n",
      "Epoch 29: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9048 - precision: 0.6216 - val_loss: 1.0285 - val_precision: 0.6165\n",
      "Epoch 30/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8992 - precision: 0.6218\n",
      "Epoch 30: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8991 - precision: 0.6217 - val_loss: 1.0469 - val_precision: 0.6114\n",
      "Epoch 31/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8985 - precision: 0.6201\n",
      "Epoch 31: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8950 - precision: 0.6209 - val_loss: 1.0411 - val_precision: 0.6083\n",
      "Epoch 32/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8940 - precision: 0.6184\n",
      "Epoch 32: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8917 - precision: 0.6205 - val_loss: 1.0471 - val_precision: 0.6031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8879 - precision: 0.6213\n",
      "Epoch 33: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8879 - precision: 0.6213 - val_loss: 1.0494 - val_precision: 0.6008\n",
      "Epoch 34/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8898 - precision: 0.6130\n",
      "Epoch 34: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8907 - precision: 0.6134 - val_loss: 1.0435 - val_precision: 0.6061\n",
      "Epoch 35/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8829 - precision: 0.6195\n",
      "Epoch 35: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8817 - precision: 0.6206 - val_loss: 1.0438 - val_precision: 0.5987\n",
      "Epoch 36/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8780 - precision: 0.6254\n",
      "Epoch 36: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8769 - precision: 0.6266 - val_loss: 1.0548 - val_precision: 0.5990\n",
      "Epoch 37/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8742 - precision: 0.6191\n",
      "Epoch 37: val_loss did not improve from 1.02183\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8735 - precision: 0.6181 - val_loss: 1.0324 - val_precision: 0.6156\n",
      "Epoch 37: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9470 - precision: 0.6354\n",
      "Combinación 37 = (True, False, True, 32, 0.25) \n",
      " precision train: [0.9469572305679321, 0.6353539228439331]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 39: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.5102 - precision: 0.5662\n",
      "Epoch 1: val_loss improved from inf to 1.31242, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 9s 12ms/step - loss: 1.5063 - precision: 0.5586 - val_loss: 1.3124 - val_precision: 0.6835\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2447 - precision: 0.5807\n",
      "Epoch 2: val_loss improved from 1.31242 to 1.14637, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2427 - precision: 0.5818 - val_loss: 1.1464 - val_precision: 0.6439\n",
      "Epoch 3/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1342 - precision: 0.5853\n",
      "Epoch 3: val_loss improved from 1.14637 to 1.10417, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1335 - precision: 0.5858 - val_loss: 1.1042 - val_precision: 0.6175\n",
      "Epoch 4/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1022 - precision: 0.5956\n",
      "Epoch 4: val_loss improved from 1.10417 to 1.10104, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1033 - precision: 0.5933 - val_loss: 1.1010 - val_precision: 0.6090\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0783 - precision: 0.5949\n",
      "Epoch 5: val_loss improved from 1.10104 to 1.08350, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0783 - precision: 0.5949 - val_loss: 1.0835 - val_precision: 0.6213\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0723 - precision: 0.6044\n",
      "Epoch 6: val_loss did not improve from 1.08350\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0718 - precision: 0.6043 - val_loss: 1.0869 - val_precision: 0.6055\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0735 - precision: 0.6009\n",
      "Epoch 7: val_loss did not improve from 1.08350\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0741 - precision: 0.6005 - val_loss: 1.0880 - val_precision: 0.6027\n",
      "Epoch 8/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0666 - precision: 0.5964\n",
      "Epoch 8: val_loss improved from 1.08350 to 1.08173, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0664 - precision: 0.5940 - val_loss: 1.0817 - val_precision: 0.6137\n",
      "Epoch 9/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0607 - precision: 0.6059\n",
      "Epoch 9: val_loss did not improve from 1.08173\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0619 - precision: 0.6059 - val_loss: 1.0869 - val_precision: 0.6083\n",
      "Epoch 10/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0561 - precision: 0.6007\n",
      "Epoch 10: val_loss improved from 1.08173 to 1.08170, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0526 - precision: 0.6010 - val_loss: 1.0817 - val_precision: 0.6077\n",
      "Epoch 11/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0468 - precision: 0.6026\n",
      "Epoch 11: val_loss improved from 1.08170 to 1.07509, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0519 - precision: 0.6001 - val_loss: 1.0751 - val_precision: 0.6168\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0513 - precision: 0.6013\n",
      "Epoch 12: val_loss did not improve from 1.07509\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0521 - precision: 0.6011 - val_loss: 1.0753 - val_precision: 0.6206\n",
      "Epoch 13/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0445 - precision: 0.6039\n",
      "Epoch 13: val_loss did not improve from 1.07509\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0410 - precision: 0.6046 - val_loss: 1.0799 - val_precision: 0.6131\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0451 - precision: 0.6097\n",
      "Epoch 14: val_loss did not improve from 1.07509\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0451 - precision: 0.6097 - val_loss: 1.0795 - val_precision: 0.6236\n",
      "Epoch 15/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0354 - precision: 0.6116\n",
      "Epoch 15: val_loss did not improve from 1.07509\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0359 - precision: 0.6112 - val_loss: 1.0753 - val_precision: 0.6159\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0453 - precision: 0.6031\n",
      "Epoch 16: val_loss did not improve from 1.07509\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0449 - precision: 0.6036 - val_loss: 1.0774 - val_precision: 0.6130\n",
      "Epoch 17/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0347 - precision: 0.6138\n",
      "Epoch 17: val_loss did not improve from 1.07509\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0326 - precision: 0.6154 - val_loss: 1.0863 - val_precision: 0.6115\n",
      "Epoch 18/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0207 - precision: 0.6183\n",
      "Epoch 18: val_loss did not improve from 1.07509\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0237 - precision: 0.6176 - val_loss: 1.0784 - val_precision: 0.6075\n",
      "Epoch 19/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0186 - precision: 0.6107\n",
      "Epoch 19: val_loss did not improve from 1.07509\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0149 - precision: 0.6125 - val_loss: 1.0766 - val_precision: 0.6081\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0205 - precision: 0.6113\n",
      "Epoch 20: val_loss improved from 1.07509 to 1.06764, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0193 - precision: 0.6119 - val_loss: 1.0676 - val_precision: 0.6270\n",
      "Epoch 21/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0146 - precision: 0.6160\n",
      "Epoch 21: val_loss did not improve from 1.06764\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0146 - precision: 0.6160 - val_loss: 1.0791 - val_precision: 0.6065\n",
      "Epoch 22/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0231 - precision: 0.6104\n",
      "Epoch 22: val_loss improved from 1.06764 to 1.06570, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0248 - precision: 0.6103 - val_loss: 1.0657 - val_precision: 0.6193\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0175 - precision: 0.6098\n",
      "Epoch 23: val_loss did not improve from 1.06570\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0191 - precision: 0.6107 - val_loss: 1.0809 - val_precision: 0.6116\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0173 - precision: 0.6097\n",
      "Epoch 24: val_loss did not improve from 1.06570\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0173 - precision: 0.6099 - val_loss: 1.0693 - val_precision: 0.6192\n",
      "Epoch 25/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0092 - precision: 0.6156\n",
      "Epoch 25: val_loss did not improve from 1.06570\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0064 - precision: 0.6165 - val_loss: 1.0830 - val_precision: 0.6126\n",
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0110 - precision: 0.6103\n",
      "Epoch 26: val_loss did not improve from 1.06570\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0127 - precision: 0.6093 - val_loss: 1.0674 - val_precision: 0.6226\n",
      "Epoch 27/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0112 - precision: 0.6143\n",
      "Epoch 27: val_loss did not improve from 1.06570\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0096 - precision: 0.6131 - val_loss: 1.0773 - val_precision: 0.6139\n",
      "Epoch 28/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0055 - precision: 0.6162\n",
      "Epoch 28: val_loss did not improve from 1.06570\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0081 - precision: 0.6156 - val_loss: 1.0770 - val_precision: 0.6158\n",
      "Epoch 29/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0001 - precision: 0.6161\n",
      "Epoch 29: val_loss did not improve from 1.06570\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9999 - precision: 0.6162 - val_loss: 1.0730 - val_precision: 0.6116\n",
      "Epoch 30/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9914 - precision: 0.6216\n",
      "Epoch 30: val_loss did not improve from 1.06570\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9914 - precision: 0.6216 - val_loss: 1.0733 - val_precision: 0.6177\n",
      "Epoch 31/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0011 - precision: 0.6166\n",
      "Epoch 31: val_loss did not improve from 1.06570\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0019 - precision: 0.6159 - val_loss: 1.0721 - val_precision: 0.6115\n",
      "Epoch 32/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0007 - precision: 0.6143\n",
      "Epoch 32: val_loss improved from 1.06570 to 1.06219, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9997 - precision: 0.6146 - val_loss: 1.0622 - val_precision: 0.6167\n",
      "Epoch 33/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9888 - precision: 0.6240\n",
      "Epoch 33: val_loss did not improve from 1.06219\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9890 - precision: 0.6236 - val_loss: 1.0756 - val_precision: 0.6127\n",
      "Epoch 34/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9892 - precision: 0.6202\n",
      "Epoch 34: val_loss did not improve from 1.06219\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9885 - precision: 0.6207 - val_loss: 1.0650 - val_precision: 0.6214\n",
      "Epoch 35/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9953 - precision: 0.6182\n",
      "Epoch 35: val_loss did not improve from 1.06219\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9964 - precision: 0.6177 - val_loss: 1.0730 - val_precision: 0.6074\n",
      "Epoch 36/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9967 - precision: 0.6156\n",
      "Epoch 36: val_loss did not improve from 1.06219\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9922 - precision: 0.6166 - val_loss: 1.0780 - val_precision: 0.6046\n",
      "Epoch 37/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9863 - precision: 0.6121\n",
      "Epoch 37: val_loss did not improve from 1.06219\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9854 - precision: 0.6124 - val_loss: 1.0699 - val_precision: 0.6139\n",
      "Epoch 38/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9820 - precision: 0.6222\n",
      "Epoch 38: val_loss improved from 1.06219 to 1.05956, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9816 - precision: 0.6223 - val_loss: 1.0596 - val_precision: 0.6207\n",
      "Epoch 39/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9825 - precision: 0.6213\n",
      "Epoch 39: val_loss did not improve from 1.05956\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9836 - precision: 0.6202 - val_loss: 1.0621 - val_precision: 0.6184\n",
      "Epoch 40/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9731 - precision: 0.6213\n",
      "Epoch 40: val_loss did not improve from 1.05956\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9724 - precision: 0.6213 - val_loss: 1.0672 - val_precision: 0.6083\n",
      "Epoch 41/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9760 - precision: 0.6125\n",
      "Epoch 41: val_loss improved from 1.05956 to 1.05755, saving model to model_ent39.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9753 - precision: 0.6133 - val_loss: 1.0575 - val_precision: 0.6179\n",
      "Epoch 42/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9749 - precision: 0.6192\n",
      "Epoch 42: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9750 - precision: 0.6192 - val_loss: 1.0755 - val_precision: 0.6064\n",
      "Epoch 43/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9797 - precision: 0.6172\n",
      "Epoch 43: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9785 - precision: 0.6172 - val_loss: 1.0688 - val_precision: 0.6133\n",
      "Epoch 44/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9644 - precision: 0.6267\n",
      "Epoch 44: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9651 - precision: 0.6267 - val_loss: 1.0707 - val_precision: 0.6113\n",
      "Epoch 45/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9737 - precision: 0.6203\n",
      "Epoch 45: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9737 - precision: 0.6208 - val_loss: 1.0726 - val_precision: 0.6122\n",
      "Epoch 46/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9758 - precision: 0.6201\n",
      "Epoch 46: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9754 - precision: 0.6197 - val_loss: 1.0724 - val_precision: 0.6054\n",
      "Epoch 47/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9681 - precision: 0.6205\n",
      "Epoch 47: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9681 - precision: 0.6205 - val_loss: 1.0662 - val_precision: 0.6147\n",
      "Epoch 48/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9634 - precision: 0.6273\n",
      "Epoch 48: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9638 - precision: 0.6255 - val_loss: 1.0688 - val_precision: 0.6061\n",
      "Epoch 49/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9680 - precision: 0.6187\n",
      "Epoch 49: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9678 - precision: 0.6188 - val_loss: 1.0691 - val_precision: 0.6137\n",
      "Epoch 50/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9573 - precision: 0.6248\n",
      "Epoch 50: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9568 - precision: 0.6266 - val_loss: 1.0781 - val_precision: 0.6030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9543 - precision: 0.6207\n",
      "Epoch 51: val_loss did not improve from 1.05755\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9535 - precision: 0.6218 - val_loss: 1.0723 - val_precision: 0.6060\n",
      "Epoch 51: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 1.0099 - precision: 0.6238\n",
      "Combinación 38 = (True, False, True, 32, 0.5) \n",
      " precision train: [1.0099122524261475, 0.6238057613372803]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 40: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2837 - precision: 0.6104\n",
      "Epoch 1: val_loss improved from inf to 1.10998, saving model to model_ent40.h5\n",
      "236/236 [==============================] - 8s 11ms/step - loss: 1.2773 - precision: 0.6104 - val_loss: 1.1100 - val_precision: 0.6130\n",
      "Epoch 2/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0302 - precision: 0.5919\n",
      "Epoch 2: val_loss improved from 1.10998 to 1.09585, saving model to model_ent40.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0303 - precision: 0.5916 - val_loss: 1.0958 - val_precision: 0.6030\n",
      "Epoch 3/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9963 - precision: 0.6024\n",
      "Epoch 3: val_loss improved from 1.09585 to 1.07960, saving model to model_ent40.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9963 - precision: 0.6024 - val_loss: 1.0796 - val_precision: 0.5974\n",
      "Epoch 4/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9780 - precision: 0.6029\n",
      "Epoch 4: val_loss improved from 1.07960 to 1.05816, saving model to model_ent40.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9778 - precision: 0.6033 - val_loss: 1.0582 - val_precision: 0.6212\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9630 - precision: 0.6067\n",
      "Epoch 5: val_loss did not improve from 1.05816\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9628 - precision: 0.6065 - val_loss: 1.0600 - val_precision: 0.6165\n",
      "Epoch 6/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9520 - precision: 0.6071\n",
      "Epoch 6: val_loss improved from 1.05816 to 1.05359, saving model to model_ent40.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9537 - precision: 0.6071 - val_loss: 1.0536 - val_precision: 0.6111\n",
      "Epoch 7/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9303 - precision: 0.6097\n",
      "Epoch 7: val_loss improved from 1.05359 to 1.02795, saving model to model_ent40.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9353 - precision: 0.6099 - val_loss: 1.0279 - val_precision: 0.6238\n",
      "Epoch 8/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9247 - precision: 0.6067\n",
      "Epoch 8: val_loss improved from 1.02795 to 1.02419, saving model to model_ent40.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9267 - precision: 0.6065 - val_loss: 1.0242 - val_precision: 0.6311\n",
      "Epoch 9/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9187 - precision: 0.6153\n",
      "Epoch 9: val_loss did not improve from 1.02419\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9186 - precision: 0.6144 - val_loss: 1.0383 - val_precision: 0.6100\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9083 - precision: 0.6126\n",
      "Epoch 10: val_loss did not improve from 1.02419\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9063 - precision: 0.6136 - val_loss: 1.0440 - val_precision: 0.6201\n",
      "Epoch 11/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8972 - precision: 0.6165\n",
      "Epoch 11: val_loss did not improve from 1.02419\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8972 - precision: 0.6165 - val_loss: 1.0318 - val_precision: 0.6105\n",
      "Epoch 12/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8890 - precision: 0.6217\n",
      "Epoch 12: val_loss improved from 1.02419 to 1.00778, saving model to model_ent40.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8899 - precision: 0.6213 - val_loss: 1.0078 - val_precision: 0.6254\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8832 - precision: 0.6196\n",
      "Epoch 13: val_loss did not improve from 1.00778\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8854 - precision: 0.6200 - val_loss: 1.0134 - val_precision: 0.6264\n",
      "Epoch 14/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8719 - precision: 0.6243\n",
      "Epoch 14: val_loss did not improve from 1.00778\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8732 - precision: 0.6241 - val_loss: 1.0275 - val_precision: 0.6074\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8670 - precision: 0.6218\n",
      "Epoch 15: val_loss improved from 1.00778 to 0.99818, saving model to model_ent40.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8669 - precision: 0.6221 - val_loss: 0.9982 - val_precision: 0.6299\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8528 - precision: 0.6292\n",
      "Epoch 16: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8522 - precision: 0.6293 - val_loss: 1.0358 - val_precision: 0.6017\n",
      "Epoch 17/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8509 - precision: 0.6268\n",
      "Epoch 17: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8509 - precision: 0.6266 - val_loss: 1.0290 - val_precision: 0.6121\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8376 - precision: 0.6296\n",
      "Epoch 18: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8383 - precision: 0.6302 - val_loss: 1.0135 - val_precision: 0.6200\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8295 - precision: 0.6324\n",
      "Epoch 19: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8292 - precision: 0.6327 - val_loss: 1.0409 - val_precision: 0.6077\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8274 - precision: 0.6375\n",
      "Epoch 20: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8278 - precision: 0.6375 - val_loss: 1.0352 - val_precision: 0.6005\n",
      "Epoch 21/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8138 - precision: 0.6343\n",
      "Epoch 21: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8158 - precision: 0.6353 - val_loss: 1.0192 - val_precision: 0.6203\n",
      "Epoch 22/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8111 - precision: 0.6401\n",
      "Epoch 22: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8110 - precision: 0.6399 - val_loss: 1.0227 - val_precision: 0.6153\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8001 - precision: 0.6377\n",
      "Epoch 23: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8016 - precision: 0.6365 - val_loss: 1.0180 - val_precision: 0.6151\n",
      "Epoch 24/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.7973 - precision: 0.6423\n",
      "Epoch 24: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7991 - precision: 0.6434 - val_loss: 1.0370 - val_precision: 0.6037\n",
      "Epoch 25/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.7921 - precision: 0.6411\n",
      "Epoch 25: val_loss did not improve from 0.99818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7909 - precision: 0.6414 - val_loss: 1.0134 - val_precision: 0.6175\n",
      "Epoch 25: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.8839 - precision: 0.6552\n",
      "Combinación 39 = (True, False, True, 64, 0.1) \n",
      " precision train: [0.8838821649551392, 0.6552407145500183]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 41: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.3423 - precision: 0.6246\n",
      "Epoch 1: val_loss improved from inf to 1.14278, saving model to model_ent41.h5\n",
      "236/236 [==============================] - 8s 11ms/step - loss: 1.3418 - precision: 0.6235 - val_loss: 1.1428 - val_precision: 0.6438\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0475 - precision: 0.5885\n",
      "Epoch 2: val_loss improved from 1.14278 to 1.08531, saving model to model_ent41.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0476 - precision: 0.5880 - val_loss: 1.0853 - val_precision: 0.6074\n",
      "Epoch 3/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0123 - precision: 0.5981\n",
      "Epoch 3: val_loss improved from 1.08531 to 1.06967, saving model to model_ent41.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0131 - precision: 0.5980 - val_loss: 1.0697 - val_precision: 0.6132\n",
      "Epoch 4/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0091 - precision: 0.6024\n",
      "Epoch 4: val_loss improved from 1.06967 to 1.06032, saving model to model_ent41.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0077 - precision: 0.6040 - val_loss: 1.0603 - val_precision: 0.6192\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9861 - precision: 0.6004\n",
      "Epoch 5: val_loss improved from 1.06032 to 1.03867, saving model to model_ent41.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9865 - precision: 0.6003 - val_loss: 1.0387 - val_precision: 0.6263\n",
      "Epoch 6/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9699 - precision: 0.6056\n",
      "Epoch 6: val_loss did not improve from 1.03867\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9713 - precision: 0.6051 - val_loss: 1.0454 - val_precision: 0.6141\n",
      "Epoch 7/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9553 - precision: 0.6104\n",
      "Epoch 7: val_loss did not improve from 1.03867\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9596 - precision: 0.6104 - val_loss: 1.0416 - val_precision: 0.6114\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9494 - precision: 0.6106\n",
      "Epoch 8: val_loss improved from 1.03867 to 1.03611, saving model to model_ent41.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9514 - precision: 0.6094 - val_loss: 1.0361 - val_precision: 0.6152\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9549 - precision: 0.6027\n",
      "Epoch 9: val_loss improved from 1.03611 to 1.02788, saving model to model_ent41.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9545 - precision: 0.6032 - val_loss: 1.0279 - val_precision: 0.6197\n",
      "Epoch 10/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9388 - precision: 0.6128\n",
      "Epoch 10: val_loss did not improve from 1.02788\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9393 - precision: 0.6125 - val_loss: 1.0354 - val_precision: 0.6217\n",
      "Epoch 11/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9360 - precision: 0.6127\n",
      "Epoch 11: val_loss improved from 1.02788 to 1.01399, saving model to model_ent41.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9361 - precision: 0.6129 - val_loss: 1.0140 - val_precision: 0.6309\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9231 - precision: 0.6097\n",
      "Epoch 12: val_loss did not improve from 1.01399\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9229 - precision: 0.6102 - val_loss: 1.0559 - val_precision: 0.6092\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9154 - precision: 0.6097\n",
      "Epoch 13: val_loss did not improve from 1.01399\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9148 - precision: 0.6107 - val_loss: 1.0350 - val_precision: 0.6245\n",
      "Epoch 14/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9199 - precision: 0.6121\n",
      "Epoch 14: val_loss did not improve from 1.01399\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9192 - precision: 0.6099 - val_loss: 1.0378 - val_precision: 0.6117\n",
      "Epoch 15/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9150 - precision: 0.6158\n",
      "Epoch 15: val_loss did not improve from 1.01399\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9143 - precision: 0.6164 - val_loss: 1.0302 - val_precision: 0.6141\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8992 - precision: 0.6139\n",
      "Epoch 16: val_loss did not improve from 1.01399\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8992 - precision: 0.6142 - val_loss: 1.0268 - val_precision: 0.6181\n",
      "Epoch 17/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9005 - precision: 0.6199\n",
      "Epoch 17: val_loss did not improve from 1.01399\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9030 - precision: 0.6189 - val_loss: 1.0262 - val_precision: 0.6184\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8949 - precision: 0.6153\n",
      "Epoch 18: val_loss improved from 1.01399 to 1.00627, saving model to model_ent41.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8952 - precision: 0.6150 - val_loss: 1.0063 - val_precision: 0.6325\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8873 - precision: 0.6204\n",
      "Epoch 19: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8870 - precision: 0.6202 - val_loss: 1.0148 - val_precision: 0.6217\n",
      "Epoch 20/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8819 - precision: 0.6194\n",
      "Epoch 20: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8806 - precision: 0.6201 - val_loss: 1.0425 - val_precision: 0.6092\n",
      "Epoch 21/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8755 - precision: 0.6215\n",
      "Epoch 21: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8758 - precision: 0.6215 - val_loss: 1.0141 - val_precision: 0.6148\n",
      "Epoch 22/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8708 - precision: 0.6282\n",
      "Epoch 22: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8707 - precision: 0.6271 - val_loss: 1.0180 - val_precision: 0.6238\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8591 - precision: 0.6285\n",
      "Epoch 23: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8589 - precision: 0.6270 - val_loss: 1.0115 - val_precision: 0.6135\n",
      "Epoch 24/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8609 - precision: 0.6235\n",
      "Epoch 24: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8581 - precision: 0.6259 - val_loss: 1.0175 - val_precision: 0.6198\n",
      "Epoch 25/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8435 - precision: 0.6291\n",
      "Epoch 25: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8493 - precision: 0.6276 - val_loss: 1.0371 - val_precision: 0.6026\n",
      "Epoch 26/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8399 - precision: 0.6374\n",
      "Epoch 26: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8416 - precision: 0.6365 - val_loss: 1.0374 - val_precision: 0.6110\n",
      "Epoch 27/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/236 [============================>.] - ETA: 0s - loss: 0.8392 - precision: 0.6347\n",
      "Epoch 27: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8393 - precision: 0.6357 - val_loss: 1.0099 - val_precision: 0.6105\n",
      "Epoch 28/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8341 - precision: 0.6328\n",
      "Epoch 28: val_loss did not improve from 1.00627\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8341 - precision: 0.6328 - val_loss: 1.0100 - val_precision: 0.6163\n",
      "Epoch 28: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9066 - precision: 0.6474\n",
      "Combinación 40 = (True, False, True, 64, 0.25) \n",
      " precision train: [0.9066234827041626, 0.6473596692085266]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 42: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.4057 - precision: 0.6452\n",
      "Epoch 1: val_loss improved from inf to 1.18968, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.3975 - precision: 0.6443 - val_loss: 1.1897 - val_precision: 0.6484\n",
      "Epoch 2/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1407 - precision: 0.6309\n",
      "Epoch 2: val_loss improved from 1.18968 to 1.12159, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1420 - precision: 0.6300 - val_loss: 1.1216 - val_precision: 0.6568\n",
      "Epoch 3/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0781 - precision: 0.6136\n",
      "Epoch 3: val_loss improved from 1.12159 to 1.09252, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0771 - precision: 0.6132 - val_loss: 1.0925 - val_precision: 0.6134\n",
      "Epoch 4/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0396 - precision: 0.6052\n",
      "Epoch 4: val_loss improved from 1.09252 to 1.07235, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0399 - precision: 0.6046 - val_loss: 1.0724 - val_precision: 0.6060\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0284 - precision: 0.5967\n",
      "Epoch 5: val_loss improved from 1.07235 to 1.06167, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0284 - precision: 0.5967 - val_loss: 1.0617 - val_precision: 0.6036\n",
      "Epoch 6/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0213 - precision: 0.6024\n",
      "Epoch 6: val_loss improved from 1.06167 to 1.05270, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0212 - precision: 0.6030 - val_loss: 1.0527 - val_precision: 0.6005\n",
      "Epoch 7/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0197 - precision: 0.6004\n",
      "Epoch 7: val_loss did not improve from 1.05270\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0187 - precision: 0.5998 - val_loss: 1.0608 - val_precision: 0.6013\n",
      "Epoch 8/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0024 - precision: 0.6007\n",
      "Epoch 8: val_loss did not improve from 1.05270\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0024 - precision: 0.6007 - val_loss: 1.0569 - val_precision: 0.6018\n",
      "Epoch 9/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9960 - precision: 0.6016\n",
      "Epoch 9: val_loss did not improve from 1.05270\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9984 - precision: 0.6015 - val_loss: 1.0529 - val_precision: 0.6025\n",
      "Epoch 10/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9903 - precision: 0.6046\n",
      "Epoch 10: val_loss did not improve from 1.05270\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9895 - precision: 0.6033 - val_loss: 1.0540 - val_precision: 0.6008\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9968 - precision: 0.5987\n",
      "Epoch 11: val_loss improved from 1.05270 to 1.05031, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9956 - precision: 0.5990 - val_loss: 1.0503 - val_precision: 0.6054\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9795 - precision: 0.6034\n",
      "Epoch 12: val_loss did not improve from 1.05031\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9782 - precision: 0.6048 - val_loss: 1.0518 - val_precision: 0.6052\n",
      "Epoch 13/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9680 - precision: 0.6087\n",
      "Epoch 13: val_loss improved from 1.05031 to 1.04113, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9688 - precision: 0.6090 - val_loss: 1.0411 - val_precision: 0.6117\n",
      "Epoch 14/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9760 - precision: 0.6067\n",
      "Epoch 14: val_loss did not improve from 1.04113\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9762 - precision: 0.6062 - val_loss: 1.0516 - val_precision: 0.6110\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9675 - precision: 0.6058\n",
      "Epoch 15: val_loss improved from 1.04113 to 1.03818, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9642 - precision: 0.6066 - val_loss: 1.0382 - val_precision: 0.6131\n",
      "Epoch 16/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9601 - precision: 0.6054\n",
      "Epoch 16: val_loss did not improve from 1.03818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9597 - precision: 0.6067 - val_loss: 1.0489 - val_precision: 0.5992\n",
      "Epoch 17/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9460 - precision: 0.6104\n",
      "Epoch 17: val_loss did not improve from 1.03818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9483 - precision: 0.6091 - val_loss: 1.0418 - val_precision: 0.6092\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9542 - precision: 0.6122\n",
      "Epoch 18: val_loss did not improve from 1.03818\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9529 - precision: 0.6127 - val_loss: 1.0389 - val_precision: 0.6151\n",
      "Epoch 19/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9515 - precision: 0.6069\n",
      "Epoch 19: val_loss improved from 1.03818 to 1.02971, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9528 - precision: 0.6065 - val_loss: 1.0297 - val_precision: 0.6196\n",
      "Epoch 20/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9410 - precision: 0.6161\n",
      "Epoch 20: val_loss did not improve from 1.02971\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9423 - precision: 0.6146 - val_loss: 1.0330 - val_precision: 0.6155\n",
      "Epoch 21/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9409 - precision: 0.6036\n",
      "Epoch 21: val_loss did not improve from 1.02971\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9395 - precision: 0.6045 - val_loss: 1.0428 - val_precision: 0.6105\n",
      "Epoch 22/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9372 - precision: 0.6104\n",
      "Epoch 22: val_loss did not improve from 1.02971\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9389 - precision: 0.6107 - val_loss: 1.0382 - val_precision: 0.6153\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9393 - precision: 0.6114\n",
      "Epoch 23: val_loss improved from 1.02971 to 1.02646, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9390 - precision: 0.6121 - val_loss: 1.0265 - val_precision: 0.6183\n",
      "Epoch 24/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9330 - precision: 0.6129\n",
      "Epoch 24: val_loss did not improve from 1.02646\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9361 - precision: 0.6108 - val_loss: 1.0558 - val_precision: 0.6047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9335 - precision: 0.6109\n",
      "Epoch 25: val_loss did not improve from 1.02646\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9340 - precision: 0.6104 - val_loss: 1.0296 - val_precision: 0.6167\n",
      "Epoch 26/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9371 - precision: 0.6092\n",
      "Epoch 26: val_loss did not improve from 1.02646\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9347 - precision: 0.6106 - val_loss: 1.0297 - val_precision: 0.6158\n",
      "Epoch 27/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9206 - precision: 0.6141\n",
      "Epoch 27: val_loss did not improve from 1.02646\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9243 - precision: 0.6138 - val_loss: 1.0462 - val_precision: 0.6036\n",
      "Epoch 28/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9236 - precision: 0.6147\n",
      "Epoch 28: val_loss improved from 1.02646 to 1.02137, saving model to model_ent42.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9238 - precision: 0.6140 - val_loss: 1.0214 - val_precision: 0.6209\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9220 - precision: 0.6171\n",
      "Epoch 29: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9217 - precision: 0.6176 - val_loss: 1.0321 - val_precision: 0.6155\n",
      "Epoch 30/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9205 - precision: 0.6128\n",
      "Epoch 30: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9207 - precision: 0.6127 - val_loss: 1.0386 - val_precision: 0.6078\n",
      "Epoch 31/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9141 - precision: 0.6196\n",
      "Epoch 31: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9151 - precision: 0.6190 - val_loss: 1.0296 - val_precision: 0.6121\n",
      "Epoch 32/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9105 - precision: 0.6145\n",
      "Epoch 32: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9080 - precision: 0.6161 - val_loss: 1.0389 - val_precision: 0.6117\n",
      "Epoch 33/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9050 - precision: 0.6152\n",
      "Epoch 33: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9038 - precision: 0.6173 - val_loss: 1.0230 - val_precision: 0.6163\n",
      "Epoch 34/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9099 - precision: 0.6124\n",
      "Epoch 34: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9106 - precision: 0.6123 - val_loss: 1.0298 - val_precision: 0.6154\n",
      "Epoch 35/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9084 - precision: 0.6171\n",
      "Epoch 35: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9079 - precision: 0.6169 - val_loss: 1.0314 - val_precision: 0.6093\n",
      "Epoch 36/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9041 - precision: 0.6150\n",
      "Epoch 36: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9045 - precision: 0.6150 - val_loss: 1.0413 - val_precision: 0.6031\n",
      "Epoch 37/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9024 - precision: 0.6096\n",
      "Epoch 37: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9019 - precision: 0.6106 - val_loss: 1.0218 - val_precision: 0.6144\n",
      "Epoch 38/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8994 - precision: 0.6141\n",
      "Epoch 38: val_loss did not improve from 1.02137\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8994 - precision: 0.6141 - val_loss: 1.0351 - val_precision: 0.6119\n",
      "Epoch 38: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9686 - precision: 0.6254\n",
      "Combinación 41 = (True, False, True, 64, 0.5) \n",
      " precision train: [0.9685826897621155, 0.6254355311393738]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 43: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1937 - precision: 0.6137\n",
      "Epoch 1: val_loss improved from inf to 1.09358, saving model to model_ent43.h5\n",
      "236/236 [==============================] - 8s 12ms/step - loss: 1.1940 - precision: 0.6133 - val_loss: 1.0936 - val_precision: 0.6386\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0018 - precision: 0.6056\n",
      "Epoch 2: val_loss improved from 1.09358 to 1.07759, saving model to model_ent43.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0036 - precision: 0.6049 - val_loss: 1.0776 - val_precision: 0.6165\n",
      "Epoch 3/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9757 - precision: 0.6055\n",
      "Epoch 3: val_loss improved from 1.07759 to 1.05709, saving model to model_ent43.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9751 - precision: 0.6059 - val_loss: 1.0571 - val_precision: 0.6124\n",
      "Epoch 4/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9453 - precision: 0.6075\n",
      "Epoch 4: val_loss improved from 1.05709 to 1.02354, saving model to model_ent43.h5\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.9480 - precision: 0.6052 - val_loss: 1.0235 - val_precision: 0.6247\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9403 - precision: 0.6010\n",
      "Epoch 5: val_loss did not improve from 1.02354\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9403 - precision: 0.6010 - val_loss: 1.0450 - val_precision: 0.6127\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9252 - precision: 0.6082\n",
      "Epoch 6: val_loss improved from 1.02354 to 1.01643, saving model to model_ent43.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9257 - precision: 0.6088 - val_loss: 1.0164 - val_precision: 0.6280\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9189 - precision: 0.6089\n",
      "Epoch 7: val_loss did not improve from 1.01643\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9220 - precision: 0.6080 - val_loss: 1.0409 - val_precision: 0.6208\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9083 - precision: 0.6130\n",
      "Epoch 8: val_loss did not improve from 1.01643\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9066 - precision: 0.6138 - val_loss: 1.0243 - val_precision: 0.6188\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8935 - precision: 0.6141\n",
      "Epoch 9: val_loss improved from 1.01643 to 0.99841, saving model to model_ent43.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8931 - precision: 0.6147 - val_loss: 0.9984 - val_precision: 0.6346\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8837 - precision: 0.6231\n",
      "Epoch 10: val_loss improved from 0.99841 to 0.99794, saving model to model_ent43.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8846 - precision: 0.6225 - val_loss: 0.9979 - val_precision: 0.6319\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8686 - precision: 0.6279\n",
      "Epoch 11: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8684 - precision: 0.6279 - val_loss: 1.0126 - val_precision: 0.6221\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8613 - precision: 0.6276\n",
      "Epoch 12: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8602 - precision: 0.6273 - val_loss: 1.0012 - val_precision: 0.6299\n",
      "Epoch 13/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8536 - precision: 0.6251\n",
      "Epoch 13: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8540 - precision: 0.6251 - val_loss: 1.0325 - val_precision: 0.6097\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8391 - precision: 0.6308\n",
      "Epoch 14: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8394 - precision: 0.6311 - val_loss: 1.0246 - val_precision: 0.6105\n",
      "Epoch 15/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8319 - precision: 0.6318\n",
      "Epoch 15: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8310 - precision: 0.6324 - val_loss: 1.0255 - val_precision: 0.6234\n",
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8197 - precision: 0.6371\n",
      "Epoch 16: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8204 - precision: 0.6362 - val_loss: 1.0235 - val_precision: 0.6128\n",
      "Epoch 17/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8109 - precision: 0.6392\n",
      "Epoch 17: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8129 - precision: 0.6374 - val_loss: 1.0356 - val_precision: 0.6084\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8007 - precision: 0.6396\n",
      "Epoch 18: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8010 - precision: 0.6394 - val_loss: 1.0531 - val_precision: 0.6037\n",
      "Epoch 19/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8005 - precision: 0.6421\n",
      "Epoch 19: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7995 - precision: 0.6433 - val_loss: 1.0119 - val_precision: 0.6214\n",
      "Epoch 20/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.7894 - precision: 0.6454\n",
      "Epoch 20: val_loss did not improve from 0.99794\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7894 - precision: 0.6452 - val_loss: 1.0145 - val_precision: 0.6183\n",
      "Epoch 20: early stopping\n",
      "295/295 [==============================] - 1s 3ms/step - loss: 0.8890 - precision: 0.6534\n",
      "Combinación 42 = (True, False, True, 128, 0.1) \n",
      " precision train: [0.8890494108200073, 0.6534013152122498]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 44: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2672 - precision: 0.6288\n",
      "Epoch 1: val_loss improved from inf to 1.10401, saving model to model_ent44.h5\n",
      "236/236 [==============================] - 9s 13ms/step - loss: 1.2597 - precision: 0.6284 - val_loss: 1.1040 - val_precision: 0.6452\n",
      "Epoch 2/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0197 - precision: 0.6049\n",
      "Epoch 2: val_loss improved from 1.10401 to 1.05503, saving model to model_ent44.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0187 - precision: 0.6045 - val_loss: 1.0550 - val_precision: 0.6166\n",
      "Epoch 3/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9849 - precision: 0.6025\n",
      "Epoch 3: val_loss did not improve from 1.05503\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9858 - precision: 0.6016 - val_loss: 1.0707 - val_precision: 0.5986\n",
      "Epoch 4/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9637 - precision: 0.5991\n",
      "Epoch 4: val_loss improved from 1.05503 to 1.03543, saving model to model_ent44.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9633 - precision: 0.6008 - val_loss: 1.0354 - val_precision: 0.6212\n",
      "Epoch 5/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9485 - precision: 0.6038\n",
      "Epoch 5: val_loss improved from 1.03543 to 1.03260, saving model to model_ent44.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9468 - precision: 0.6034 - val_loss: 1.0326 - val_precision: 0.6132\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9358 - precision: 0.6088\n",
      "Epoch 6: val_loss did not improve from 1.03260\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9359 - precision: 0.6085 - val_loss: 1.0346 - val_precision: 0.6151\n",
      "Epoch 7/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9330 - precision: 0.6102\n",
      "Epoch 7: val_loss did not improve from 1.03260\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9330 - precision: 0.6102 - val_loss: 1.0526 - val_precision: 0.5983\n",
      "Epoch 8/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9213 - precision: 0.6150\n",
      "Epoch 8: val_loss improved from 1.03260 to 1.02754, saving model to model_ent44.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9215 - precision: 0.6134 - val_loss: 1.0275 - val_precision: 0.6142\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9159 - precision: 0.6139\n",
      "Epoch 9: val_loss improved from 1.02754 to 1.02281, saving model to model_ent44.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9162 - precision: 0.6134 - val_loss: 1.0228 - val_precision: 0.6092\n",
      "Epoch 10/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9073 - precision: 0.6141\n",
      "Epoch 10: val_loss improved from 1.02281 to 1.01597, saving model to model_ent44.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9070 - precision: 0.6140 - val_loss: 1.0160 - val_precision: 0.6297\n",
      "Epoch 11/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8877 - precision: 0.6187\n",
      "Epoch 11: val_loss improved from 1.01597 to 1.01475, saving model to model_ent44.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8870 - precision: 0.6182 - val_loss: 1.0147 - val_precision: 0.6254\n",
      "Epoch 12/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8848 - precision: 0.6224\n",
      "Epoch 12: val_loss did not improve from 1.01475\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8847 - precision: 0.6229 - val_loss: 1.0283 - val_precision: 0.6182\n",
      "Epoch 13/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8743 - precision: 0.6194\n",
      "Epoch 13: val_loss improved from 1.01475 to 1.00013, saving model to model_ent44.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8745 - precision: 0.6198 - val_loss: 1.0001 - val_precision: 0.6345\n",
      "Epoch 14/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8637 - precision: 0.6246\n",
      "Epoch 14: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8641 - precision: 0.6243 - val_loss: 1.0436 - val_precision: 0.5991\n",
      "Epoch 15/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8589 - precision: 0.6226\n",
      "Epoch 15: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8583 - precision: 0.6233 - val_loss: 1.0448 - val_precision: 0.6115\n",
      "Epoch 16/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8545 - precision: 0.6299\n",
      "Epoch 16: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8540 - precision: 0.6298 - val_loss: 1.0062 - val_precision: 0.6374\n",
      "Epoch 17/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8556 - precision: 0.6278\n",
      "Epoch 17: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.8543 - precision: 0.6280 - val_loss: 1.0142 - val_precision: 0.6182\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8377 - precision: 0.6277\n",
      "Epoch 18: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8380 - precision: 0.6282 - val_loss: 1.0128 - val_precision: 0.6293\n",
      "Epoch 19/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/236 [============================>.] - ETA: 0s - loss: 0.8341 - precision: 0.6297\n",
      "Epoch 19: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8340 - precision: 0.6294 - val_loss: 1.0147 - val_precision: 0.6107\n",
      "Epoch 20/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8201 - precision: 0.6313\n",
      "Epoch 20: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.8211 - precision: 0.6312 - val_loss: 1.0325 - val_precision: 0.6085\n",
      "Epoch 21/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8165 - precision: 0.6308\n",
      "Epoch 21: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8171 - precision: 0.6306 - val_loss: 1.0242 - val_precision: 0.6169\n",
      "Epoch 22/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8149 - precision: 0.6324\n",
      "Epoch 22: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8142 - precision: 0.6329 - val_loss: 1.0146 - val_precision: 0.6262\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8072 - precision: 0.6349\n",
      "Epoch 23: val_loss did not improve from 1.00013\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8060 - precision: 0.6341 - val_loss: 1.0216 - val_precision: 0.6160\n",
      "Epoch 23: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.8849 - precision: 0.6459\n",
      "Combinación 43 = (True, False, True, 128, 0.25) \n",
      " precision train: [0.8848968744277954, 0.6459224820137024]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 45: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3208 - precision: 0.6284\n",
      "Epoch 1: val_loss improved from inf to 1.08986, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 9s 13ms/step - loss: 1.3173 - precision: 0.6255 - val_loss: 1.0899 - val_precision: 0.6476\n",
      "Epoch 2/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0355 - precision: 0.6033\n",
      "Epoch 2: val_loss improved from 1.08986 to 1.06955, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0368 - precision: 0.6020 - val_loss: 1.0695 - val_precision: 0.6221\n",
      "Epoch 3/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0189 - precision: 0.5987\n",
      "Epoch 3: val_loss improved from 1.06955 to 1.05947, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 1.0157 - precision: 0.6013 - val_loss: 1.0595 - val_precision: 0.6215\n",
      "Epoch 4/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0010 - precision: 0.5970\n",
      "Epoch 4: val_loss improved from 1.05947 to 1.04333, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.0010 - precision: 0.5970 - val_loss: 1.0433 - val_precision: 0.6162\n",
      "Epoch 5/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9872 - precision: 0.6000\n",
      "Epoch 5: val_loss improved from 1.04333 to 1.04235, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9868 - precision: 0.5996 - val_loss: 1.0423 - val_precision: 0.6116\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9713 - precision: 0.6031\n",
      "Epoch 6: val_loss improved from 1.04235 to 1.03963, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9713 - precision: 0.6018 - val_loss: 1.0396 - val_precision: 0.6141\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9691 - precision: 0.5982\n",
      "Epoch 7: val_loss improved from 1.03963 to 1.02854, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9692 - precision: 0.5984 - val_loss: 1.0285 - val_precision: 0.6152\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9631 - precision: 0.6020\n",
      "Epoch 8: val_loss did not improve from 1.02854\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9617 - precision: 0.6026 - val_loss: 1.0397 - val_precision: 0.6102\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9591 - precision: 0.6000\n",
      "Epoch 9: val_loss did not improve from 1.02854\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.9584 - precision: 0.6000 - val_loss: 1.0286 - val_precision: 0.6210\n",
      "Epoch 10/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9514 - precision: 0.6039\n",
      "Epoch 10: val_loss did not improve from 1.02854\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.9510 - precision: 0.6039 - val_loss: 1.0342 - val_precision: 0.6116\n",
      "Epoch 11/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9467 - precision: 0.6042\n",
      "Epoch 11: val_loss did not improve from 1.02854\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9471 - precision: 0.6039 - val_loss: 1.0446 - val_precision: 0.6098\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9418 - precision: 0.6046\n",
      "Epoch 12: val_loss improved from 1.02854 to 1.02190, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9416 - precision: 0.6057 - val_loss: 1.0219 - val_precision: 0.6164\n",
      "Epoch 13/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9311 - precision: 0.6082\n",
      "Epoch 13: val_loss did not improve from 1.02190\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9308 - precision: 0.6092 - val_loss: 1.0236 - val_precision: 0.6189\n",
      "Epoch 14/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9384 - precision: 0.6025\n",
      "Epoch 14: val_loss improved from 1.02190 to 1.01735, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9373 - precision: 0.6028 - val_loss: 1.0174 - val_precision: 0.6248\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9318 - precision: 0.6058\n",
      "Epoch 15: val_loss did not improve from 1.01735\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9318 - precision: 0.6058 - val_loss: 1.0212 - val_precision: 0.6141\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9281 - precision: 0.6057\n",
      "Epoch 16: val_loss did not improve from 1.01735\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9286 - precision: 0.6048 - val_loss: 1.0209 - val_precision: 0.6135\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9255 - precision: 0.6129\n",
      "Epoch 17: val_loss did not improve from 1.01735\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.9237 - precision: 0.6134 - val_loss: 1.0305 - val_precision: 0.6106\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9110 - precision: 0.6057\n",
      "Epoch 18: val_loss did not improve from 1.01735\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9114 - precision: 0.6058 - val_loss: 1.0275 - val_precision: 0.6177\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9118 - precision: 0.6102\n",
      "Epoch 19: val_loss did not improve from 1.01735\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9118 - precision: 0.6101 - val_loss: 1.0174 - val_precision: 0.6096\n",
      "Epoch 20/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9005 - precision: 0.6182\n",
      "Epoch 20: val_loss did not improve from 1.01735\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9038 - precision: 0.6167 - val_loss: 1.0246 - val_precision: 0.6133\n",
      "Epoch 21/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8986 - precision: 0.6119\n",
      "Epoch 21: val_loss did not improve from 1.01735\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8986 - precision: 0.6119 - val_loss: 1.0267 - val_precision: 0.6130\n",
      "Epoch 22/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8887 - precision: 0.6179\n",
      "Epoch 22: val_loss improved from 1.01735 to 1.00720, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8903 - precision: 0.6176 - val_loss: 1.0072 - val_precision: 0.6206\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8912 - precision: 0.6164\n",
      "Epoch 23: val_loss did not improve from 1.00720\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8913 - precision: 0.6174 - val_loss: 1.0111 - val_precision: 0.6101\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8840 - precision: 0.6196\n",
      "Epoch 24: val_loss did not improve from 1.00720\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8838 - precision: 0.6196 - val_loss: 1.0189 - val_precision: 0.6135\n",
      "Epoch 25/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8763 - precision: 0.6184\n",
      "Epoch 25: val_loss improved from 1.00720 to 1.00430, saving model to model_ent45.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8807 - precision: 0.6172 - val_loss: 1.0043 - val_precision: 0.6190\n",
      "Epoch 26/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8809 - precision: 0.6242\n",
      "Epoch 26: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8822 - precision: 0.6231 - val_loss: 1.0198 - val_precision: 0.6158\n",
      "Epoch 27/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8566 - precision: 0.6253\n",
      "Epoch 27: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8591 - precision: 0.6256 - val_loss: 1.0270 - val_precision: 0.6076\n",
      "Epoch 28/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8703 - precision: 0.6259\n",
      "Epoch 28: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8697 - precision: 0.6260 - val_loss: 1.0313 - val_precision: 0.6068\n",
      "Epoch 29/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8628 - precision: 0.6257\n",
      "Epoch 29: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8621 - precision: 0.6260 - val_loss: 1.0319 - val_precision: 0.6015\n",
      "Epoch 30/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8592 - precision: 0.6216\n",
      "Epoch 30: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8598 - precision: 0.6214 - val_loss: 1.0281 - val_precision: 0.6009\n",
      "Epoch 31/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8527 - precision: 0.6314\n",
      "Epoch 31: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8537 - precision: 0.6310 - val_loss: 1.0442 - val_precision: 0.5902\n",
      "Epoch 32/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8523 - precision: 0.6259\n",
      "Epoch 32: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8518 - precision: 0.6259 - val_loss: 1.0048 - val_precision: 0.6184\n",
      "Epoch 33/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8514 - precision: 0.6324\n",
      "Epoch 33: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8515 - precision: 0.6321 - val_loss: 1.0133 - val_precision: 0.6212\n",
      "Epoch 34/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8425 - precision: 0.6298\n",
      "Epoch 34: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8420 - precision: 0.6302 - val_loss: 1.0256 - val_precision: 0.6043\n",
      "Epoch 35/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8361 - precision: 0.6286\n",
      "Epoch 35: val_loss did not improve from 1.00430\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8358 - precision: 0.6302 - val_loss: 1.0069 - val_precision: 0.6110\n",
      "Epoch 35: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9121 - precision: 0.6393\n",
      "Combinación 44 = (True, False, True, 128, 0.5) \n",
      " precision train: [0.9120780825614929, 0.6393194794654846]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 46: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.4825 - precision: 0.5882  \n",
      "Epoch 1: val_loss improved from inf to 1.33635, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.4739 - precision: 0.5455 - val_loss: 1.3363 - val_precision: 0.6667\n",
      "Epoch 2/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.2993 - precision: 0.5914\n",
      "Epoch 2: val_loss improved from 1.33635 to 1.30058, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3035 - precision: 0.5956 - val_loss: 1.3006 - val_precision: 0.6906\n",
      "Epoch 3/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2718 - precision: 0.6414\n",
      "Epoch 3: val_loss improved from 1.30058 to 1.27594, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2704 - precision: 0.6423 - val_loss: 1.2759 - val_precision: 0.6731\n",
      "Epoch 4/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2513 - precision: 0.6486\n",
      "Epoch 4: val_loss improved from 1.27594 to 1.25897, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2490 - precision: 0.6515 - val_loss: 1.2590 - val_precision: 0.6800\n",
      "Epoch 5/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2311 - precision: 0.6684\n",
      "Epoch 5: val_loss improved from 1.25897 to 1.23385, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2318 - precision: 0.6672 - val_loss: 1.2338 - val_precision: 0.6723\n",
      "Epoch 6/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2138 - precision: 0.6680\n",
      "Epoch 6: val_loss improved from 1.23385 to 1.21418, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2125 - precision: 0.6702 - val_loss: 1.2142 - val_precision: 0.7044\n",
      "Epoch 7/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.1915 - precision: 0.6782\n",
      "Epoch 7: val_loss improved from 1.21418 to 1.19275, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1896 - precision: 0.6788 - val_loss: 1.1927 - val_precision: 0.7071\n",
      "Epoch 8/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1533 - precision: 0.6884\n",
      "Epoch 8: val_loss improved from 1.19275 to 1.17606, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1571 - precision: 0.6877 - val_loss: 1.1761 - val_precision: 0.7063\n",
      "Epoch 9/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1209 - precision: 0.6565\n",
      "Epoch 9: val_loss improved from 1.17606 to 1.15645, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1233 - precision: 0.6555 - val_loss: 1.1564 - val_precision: 0.6615\n",
      "Epoch 10/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0849 - precision: 0.6304\n",
      "Epoch 10: val_loss improved from 1.15645 to 1.12888, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0847 - precision: 0.6268 - val_loss: 1.1289 - val_precision: 0.6243\n",
      "Epoch 11/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0609 - precision: 0.6086\n",
      "Epoch 11: val_loss improved from 1.12888 to 1.10392, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0575 - precision: 0.6059 - val_loss: 1.1039 - val_precision: 0.6159\n",
      "Epoch 12/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0341 - precision: 0.6033\n",
      "Epoch 12: val_loss improved from 1.10392 to 1.08688, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0338 - precision: 0.6031 - val_loss: 1.0869 - val_precision: 0.6158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0145 - precision: 0.6031\n",
      "Epoch 13: val_loss improved from 1.08688 to 1.07659, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0124 - precision: 0.6046 - val_loss: 1.0766 - val_precision: 0.6123\n",
      "Epoch 14/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0027 - precision: 0.6059\n",
      "Epoch 14: val_loss improved from 1.07659 to 1.06036, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0011 - precision: 0.6066 - val_loss: 1.0604 - val_precision: 0.6182\n",
      "Epoch 15/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9929 - precision: 0.6066\n",
      "Epoch 15: val_loss improved from 1.06036 to 1.05912, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9964 - precision: 0.6050 - val_loss: 1.0591 - val_precision: 0.6161\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9902 - precision: 0.6048\n",
      "Epoch 16: val_loss did not improve from 1.05912\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9888 - precision: 0.6045 - val_loss: 1.0657 - val_precision: 0.6098\n",
      "Epoch 17/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9847 - precision: 0.6070\n",
      "Epoch 17: val_loss improved from 1.05912 to 1.05417, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9847 - precision: 0.6058 - val_loss: 1.0542 - val_precision: 0.6130\n",
      "Epoch 18/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9873 - precision: 0.6035\n",
      "Epoch 18: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9856 - precision: 0.6029 - val_loss: 1.0568 - val_precision: 0.6128\n",
      "Epoch 19/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9779 - precision: 0.6007\n",
      "Epoch 19: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9767 - precision: 0.6012 - val_loss: 1.0570 - val_precision: 0.6146\n",
      "Epoch 20/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9719 - precision: 0.6028\n",
      "Epoch 20: val_loss improved from 1.05417 to 1.04031, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9739 - precision: 0.6005 - val_loss: 1.0403 - val_precision: 0.6212\n",
      "Epoch 21/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9756 - precision: 0.6058\n",
      "Epoch 21: val_loss did not improve from 1.04031\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9761 - precision: 0.6061 - val_loss: 1.0578 - val_precision: 0.6107\n",
      "Epoch 22/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.9651 - precision: 0.6119\n",
      "Epoch 22: val_loss did not improve from 1.04031\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9627 - precision: 0.6121 - val_loss: 1.0439 - val_precision: 0.6188\n",
      "Epoch 23/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9593 - precision: 0.6182\n",
      "Epoch 23: val_loss did not improve from 1.04031\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9624 - precision: 0.6157 - val_loss: 1.0448 - val_precision: 0.6235\n",
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9639 - precision: 0.6123\n",
      "Epoch 24: val_loss did not improve from 1.04031\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9618 - precision: 0.6130 - val_loss: 1.0565 - val_precision: 0.6132\n",
      "Epoch 25/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9564 - precision: 0.6117\n",
      "Epoch 25: val_loss did not improve from 1.04031\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9570 - precision: 0.6105 - val_loss: 1.0496 - val_precision: 0.6130\n",
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9505 - precision: 0.6154\n",
      "Epoch 26: val_loss did not improve from 1.04031\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9517 - precision: 0.6152 - val_loss: 1.0514 - val_precision: 0.6146\n",
      "Epoch 27/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9607 - precision: 0.6109\n",
      "Epoch 27: val_loss did not improve from 1.04031\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9599 - precision: 0.6105 - val_loss: 1.0480 - val_precision: 0.6158\n",
      "Epoch 28/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9431 - precision: 0.6197\n",
      "Epoch 28: val_loss improved from 1.04031 to 1.03985, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9472 - precision: 0.6183 - val_loss: 1.0398 - val_precision: 0.6224\n",
      "Epoch 29/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9444 - precision: 0.6194\n",
      "Epoch 29: val_loss did not improve from 1.03985\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9429 - precision: 0.6193 - val_loss: 1.0456 - val_precision: 0.6185\n",
      "Epoch 30/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9383 - precision: 0.6190\n",
      "Epoch 30: val_loss did not improve from 1.03985\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9424 - precision: 0.6174 - val_loss: 1.0548 - val_precision: 0.6107\n",
      "Epoch 31/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9383 - precision: 0.6189\n",
      "Epoch 31: val_loss did not improve from 1.03985\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9401 - precision: 0.6184 - val_loss: 1.0538 - val_precision: 0.6116\n",
      "Epoch 32/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9350 - precision: 0.6204\n",
      "Epoch 32: val_loss did not improve from 1.03985\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9348 - precision: 0.6209 - val_loss: 1.0418 - val_precision: 0.6150\n",
      "Epoch 33/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9424 - precision: 0.6147\n",
      "Epoch 33: val_loss improved from 1.03985 to 1.03445, saving model to model_ent46.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9415 - precision: 0.6145 - val_loss: 1.0344 - val_precision: 0.6227\n",
      "Epoch 34/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9356 - precision: 0.6200\n",
      "Epoch 34: val_loss did not improve from 1.03445\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9329 - precision: 0.6209 - val_loss: 1.0436 - val_precision: 0.6185\n",
      "Epoch 35/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9347 - precision: 0.6147\n",
      "Epoch 35: val_loss did not improve from 1.03445\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9356 - precision: 0.6157 - val_loss: 1.0370 - val_precision: 0.6198\n",
      "Epoch 36/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9326 - precision: 0.6199\n",
      "Epoch 36: val_loss did not improve from 1.03445\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9335 - precision: 0.6187 - val_loss: 1.0460 - val_precision: 0.6091\n",
      "Epoch 37/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9226 - precision: 0.6199\n",
      "Epoch 37: val_loss did not improve from 1.03445\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9230 - precision: 0.6208 - val_loss: 1.0438 - val_precision: 0.6181\n",
      "Epoch 38/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9196 - precision: 0.6207\n",
      "Epoch 38: val_loss did not improve from 1.03445\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9194 - precision: 0.6213 - val_loss: 1.0567 - val_precision: 0.6062\n",
      "Epoch 39/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.9237 - precision: 0.6232\n",
      "Epoch 39: val_loss did not improve from 1.03445\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9225 - precision: 0.6235 - val_loss: 1.0435 - val_precision: 0.6083\n",
      "Epoch 40/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.9131 - precision: 0.6230\n",
      "Epoch 40: val_loss did not improve from 1.03445\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9162 - precision: 0.6210 - val_loss: 1.0545 - val_precision: 0.6106\n",
      "Epoch 41/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9085 - precision: 0.6303\n",
      "Epoch 41: val_loss did not improve from 1.03445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9117 - precision: 0.6284 - val_loss: 1.0466 - val_precision: 0.6107\n",
      "Epoch 42/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9102 - precision: 0.6260\n",
      "Epoch 42: val_loss did not improve from 1.03445\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9111 - precision: 0.6264 - val_loss: 1.0418 - val_precision: 0.6124\n",
      "Epoch 43/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9066 - precision: 0.6275\n",
      "Epoch 43: val_loss did not improve from 1.03445\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9017 - precision: 0.6287 - val_loss: 1.0424 - val_precision: 0.6130\n",
      "Epoch 43: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9771 - precision: 0.6301\n",
      "Combinación 45 = (True, False, False, 8, 0.1) \n",
      " precision train: [0.9770582914352417, 0.6300845146179199]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 47: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.5614 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.42011, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.5534 - precision: 0.0000e+00 - val_loss: 1.4201 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.3028 - precision: 0.6068\n",
      "Epoch 2: val_loss improved from 1.42011 to 1.23036, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2981 - precision: 0.6052 - val_loss: 1.2304 - val_precision: 0.6713\n",
      "Epoch 3/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2064 - precision: 0.5667\n",
      "Epoch 3: val_loss improved from 1.23036 to 1.16813, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2045 - precision: 0.5714 - val_loss: 1.1681 - val_precision: 0.6294\n",
      "Epoch 4/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.1778 - precision: 0.5810\n",
      "Epoch 4: val_loss improved from 1.16813 to 1.14839, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1774 - precision: 0.5792 - val_loss: 1.1484 - val_precision: 0.6170\n",
      "Epoch 5/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.1564 - precision: 0.5779\n",
      "Epoch 5: val_loss improved from 1.14839 to 1.13370, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1559 - precision: 0.5784 - val_loss: 1.1337 - val_precision: 0.6159\n",
      "Epoch 6/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1338 - precision: 0.6024\n",
      "Epoch 6: val_loss did not improve from 1.13370\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1345 - precision: 0.6012 - val_loss: 1.1387 - val_precision: 0.6048\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1261 - precision: 0.5922\n",
      "Epoch 7: val_loss improved from 1.13370 to 1.11729, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1260 - precision: 0.5923 - val_loss: 1.1173 - val_precision: 0.6238\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1177 - precision: 0.6041\n",
      "Epoch 8: val_loss improved from 1.11729 to 1.09728, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1175 - precision: 0.6044 - val_loss: 1.0973 - val_precision: 0.6382\n",
      "Epoch 9/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1094 - precision: 0.6010\n",
      "Epoch 9: val_loss did not improve from 1.09728\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1079 - precision: 0.6014 - val_loss: 1.1105 - val_precision: 0.6230\n",
      "Epoch 10/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1106 - precision: 0.6110\n",
      "Epoch 10: val_loss improved from 1.09728 to 1.09696, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1082 - precision: 0.6105 - val_loss: 1.0970 - val_precision: 0.6254\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0935 - precision: 0.6115\n",
      "Epoch 11: val_loss improved from 1.09696 to 1.08963, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0911 - precision: 0.6124 - val_loss: 1.0896 - val_precision: 0.6324\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0964 - precision: 0.6105\n",
      "Epoch 12: val_loss did not improve from 1.08963\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0964 - precision: 0.6105 - val_loss: 1.1104 - val_precision: 0.6178\n",
      "Epoch 13/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0914 - precision: 0.6041\n",
      "Epoch 13: val_loss improved from 1.08963 to 1.08447, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0902 - precision: 0.6049 - val_loss: 1.0845 - val_precision: 0.6317\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0879 - precision: 0.6137\n",
      "Epoch 14: val_loss did not improve from 1.08447\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0896 - precision: 0.6132 - val_loss: 1.0863 - val_precision: 0.6197\n",
      "Epoch 15/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0849 - precision: 0.6098\n",
      "Epoch 15: val_loss did not improve from 1.08447\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0835 - precision: 0.6108 - val_loss: 1.0870 - val_precision: 0.6261\n",
      "Epoch 16/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0760 - precision: 0.6137\n",
      "Epoch 16: val_loss improved from 1.08447 to 1.07255, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0782 - precision: 0.6117 - val_loss: 1.0725 - val_precision: 0.6376\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0771 - precision: 0.6133\n",
      "Epoch 17: val_loss did not improve from 1.07255\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0774 - precision: 0.6136 - val_loss: 1.0836 - val_precision: 0.6246\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0719 - precision: 0.6241\n",
      "Epoch 18: val_loss did not improve from 1.07255\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0701 - precision: 0.6245 - val_loss: 1.0730 - val_precision: 0.6216\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0610 - precision: 0.6172\n",
      "Epoch 19: val_loss did not improve from 1.07255\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0620 - precision: 0.6157 - val_loss: 1.0728 - val_precision: 0.6317\n",
      "Epoch 20/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0695 - precision: 0.6155\n",
      "Epoch 20: val_loss improved from 1.07255 to 1.06216, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0703 - precision: 0.6152 - val_loss: 1.0622 - val_precision: 0.6327\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0693 - precision: 0.6126\n",
      "Epoch 21: val_loss did not improve from 1.06216\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0688 - precision: 0.6130 - val_loss: 1.0700 - val_precision: 0.6201\n",
      "Epoch 22/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0595 - precision: 0.6150\n",
      "Epoch 22: val_loss did not improve from 1.06216\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0590 - precision: 0.6167 - val_loss: 1.0657 - val_precision: 0.6237\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0573 - precision: 0.6164\n",
      "Epoch 23: val_loss did not improve from 1.06216\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0543 - precision: 0.6191 - val_loss: 1.0642 - val_precision: 0.6254\n",
      "Epoch 24/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0534 - precision: 0.6145\n",
      "Epoch 24: val_loss improved from 1.06216 to 1.05284, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0552 - precision: 0.6151 - val_loss: 1.0528 - val_precision: 0.6351\n",
      "Epoch 25/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0434 - precision: 0.6148\n",
      "Epoch 25: val_loss did not improve from 1.05284\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0412 - precision: 0.6147 - val_loss: 1.0562 - val_precision: 0.6265\n",
      "Epoch 26/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0393 - precision: 0.6175\n",
      "Epoch 26: val_loss did not improve from 1.05284\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0427 - precision: 0.6157 - val_loss: 1.0569 - val_precision: 0.6350\n",
      "Epoch 27/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0476 - precision: 0.6175\n",
      "Epoch 27: val_loss did not improve from 1.05284\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0433 - precision: 0.6173 - val_loss: 1.0585 - val_precision: 0.6306\n",
      "Epoch 28/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0501 - precision: 0.6108\n",
      "Epoch 28: val_loss did not improve from 1.05284\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0480 - precision: 0.6108 - val_loss: 1.0557 - val_precision: 0.6246\n",
      "Epoch 29/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0365 - precision: 0.6212\n",
      "Epoch 29: val_loss did not improve from 1.05284\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0370 - precision: 0.6223 - val_loss: 1.0725 - val_precision: 0.6098\n",
      "Epoch 30/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0282 - precision: 0.6124\n",
      "Epoch 30: val_loss did not improve from 1.05284\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0307 - precision: 0.6112 - val_loss: 1.0612 - val_precision: 0.6245\n",
      "Epoch 31/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0289 - precision: 0.6212\n",
      "Epoch 31: val_loss did not improve from 1.05284\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0339 - precision: 0.6200 - val_loss: 1.0636 - val_precision: 0.6167\n",
      "Epoch 32/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0367 - precision: 0.6159\n",
      "Epoch 32: val_loss improved from 1.05284 to 1.04858, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0333 - precision: 0.6168 - val_loss: 1.0486 - val_precision: 0.6350\n",
      "Epoch 33/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0436 - precision: 0.6146\n",
      "Epoch 33: val_loss did not improve from 1.04858\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0421 - precision: 0.6154 - val_loss: 1.0591 - val_precision: 0.6245\n",
      "Epoch 34/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0383 - precision: 0.6158\n",
      "Epoch 34: val_loss did not improve from 1.04858\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0419 - precision: 0.6156 - val_loss: 1.0598 - val_precision: 0.6236\n",
      "Epoch 35/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0352 - precision: 0.6089\n",
      "Epoch 35: val_loss did not improve from 1.04858\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0355 - precision: 0.6081 - val_loss: 1.0499 - val_precision: 0.6224\n",
      "Epoch 36/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0266 - precision: 0.6173\n",
      "Epoch 36: val_loss did not improve from 1.04858\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0280 - precision: 0.6174 - val_loss: 1.0558 - val_precision: 0.6277\n",
      "Epoch 37/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0199 - precision: 0.6162\n",
      "Epoch 37: val_loss improved from 1.04858 to 1.04150, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0201 - precision: 0.6175 - val_loss: 1.0415 - val_precision: 0.6226\n",
      "Epoch 38/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0179 - precision: 0.6182\n",
      "Epoch 38: val_loss did not improve from 1.04150\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0177 - precision: 0.6169 - val_loss: 1.0634 - val_precision: 0.6222\n",
      "Epoch 39/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0245 - precision: 0.6156\n",
      "Epoch 39: val_loss improved from 1.04150 to 1.03972, saving model to model_ent47.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0231 - precision: 0.6164 - val_loss: 1.0397 - val_precision: 0.6308\n",
      "Epoch 40/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0146 - precision: 0.6211\n",
      "Epoch 40: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0139 - precision: 0.6215 - val_loss: 1.0457 - val_precision: 0.6214\n",
      "Epoch 41/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0124 - precision: 0.6167\n",
      "Epoch 41: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0117 - precision: 0.6168 - val_loss: 1.0494 - val_precision: 0.6241\n",
      "Epoch 42/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0069 - precision: 0.6234\n",
      "Epoch 42: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0131 - precision: 0.6205 - val_loss: 1.0576 - val_precision: 0.6156\n",
      "Epoch 43/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0074 - precision: 0.6167\n",
      "Epoch 43: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0074 - precision: 0.6179 - val_loss: 1.0545 - val_precision: 0.6169\n",
      "Epoch 44/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0055 - precision: 0.6206\n",
      "Epoch 44: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0053 - precision: 0.6197 - val_loss: 1.0521 - val_precision: 0.6205\n",
      "Epoch 45/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0114 - precision: 0.6088\n",
      "Epoch 45: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0149 - precision: 0.6078 - val_loss: 1.0494 - val_precision: 0.6180\n",
      "Epoch 46/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0067 - precision: 0.6163\n",
      "Epoch 46: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0099 - precision: 0.6148 - val_loss: 1.0485 - val_precision: 0.6222\n",
      "Epoch 47/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0147 - precision: 0.6180\n",
      "Epoch 47: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0156 - precision: 0.6192 - val_loss: 1.0496 - val_precision: 0.6240\n",
      "Epoch 48/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0054 - precision: 0.6136\n",
      "Epoch 48: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0068 - precision: 0.6131 - val_loss: 1.0469 - val_precision: 0.6185\n",
      "Epoch 49/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9988 - precision: 0.6217\n",
      "Epoch 49: val_loss did not improve from 1.03972\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0003 - precision: 0.6184 - val_loss: 1.0474 - val_precision: 0.6218\n",
      "Epoch 49: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0134 - precision: 0.6273\n",
      "Combinación 46 = (True, False, False, 8, 0.25) \n",
      " precision train: [1.0134007930755615, 0.6272727251052856]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 48: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.5782 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.46244, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.5751 - precision: 0.0000e+00 - val_loss: 1.4624 - val_precision: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.4261 - precision: 0.5036\n",
      "Epoch 2: val_loss improved from 1.46244 to 1.34397, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.4260 - precision: 0.4856 - val_loss: 1.3440 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3630 - precision: 0.4942\n",
      "Epoch 3: val_loss improved from 1.34397 to 1.31095, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3652 - precision: 0.4913 - val_loss: 1.3110 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3416 - precision: 0.5225\n",
      "Epoch 4: val_loss improved from 1.31095 to 1.28390, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3412 - precision: 0.5228 - val_loss: 1.2839 - val_precision: 0.6741\n",
      "Epoch 5/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3268 - precision: 0.5138\n",
      "Epoch 5: val_loss improved from 1.28390 to 1.26171, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3271 - precision: 0.5141 - val_loss: 1.2617 - val_precision: 0.6808\n",
      "Epoch 6/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.3176 - precision: 0.5533\n",
      "Epoch 6: val_loss improved from 1.26171 to 1.24757, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3180 - precision: 0.5511 - val_loss: 1.2476 - val_precision: 0.6834\n",
      "Epoch 7/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.3049 - precision: 0.5645\n",
      "Epoch 7: val_loss improved from 1.24757 to 1.23328, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3081 - precision: 0.5555 - val_loss: 1.2333 - val_precision: 0.6856\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3010 - precision: 0.5608\n",
      "Epoch 8: val_loss improved from 1.23328 to 1.21286, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2996 - precision: 0.5606 - val_loss: 1.2129 - val_precision: 0.6579\n",
      "Epoch 9/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2774 - precision: 0.5684\n",
      "Epoch 9: val_loss improved from 1.21286 to 1.19690, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2798 - precision: 0.5641 - val_loss: 1.1969 - val_precision: 0.6593\n",
      "Epoch 10/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2761 - precision: 0.5561\n",
      "Epoch 10: val_loss improved from 1.19690 to 1.18366, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2749 - precision: 0.5574 - val_loss: 1.1837 - val_precision: 0.6633\n",
      "Epoch 11/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2637 - precision: 0.5550\n",
      "Epoch 11: val_loss improved from 1.18366 to 1.16488, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2640 - precision: 0.5541 - val_loss: 1.1649 - val_precision: 0.6733\n",
      "Epoch 12/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2568 - precision: 0.5718\n",
      "Epoch 12: val_loss improved from 1.16488 to 1.15517, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2544 - precision: 0.5737 - val_loss: 1.1552 - val_precision: 0.6736\n",
      "Epoch 13/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2570 - precision: 0.5514\n",
      "Epoch 13: val_loss improved from 1.15517 to 1.14169, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2556 - precision: 0.5533 - val_loss: 1.1417 - val_precision: 0.6817\n",
      "Epoch 14/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2555 - precision: 0.5739\n",
      "Epoch 14: val_loss improved from 1.14169 to 1.13564, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2521 - precision: 0.5725 - val_loss: 1.1356 - val_precision: 0.6767\n",
      "Epoch 15/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2398 - precision: 0.5738\n",
      "Epoch 15: val_loss improved from 1.13564 to 1.13053, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2369 - precision: 0.5719 - val_loss: 1.1305 - val_precision: 0.6688\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2298 - precision: 0.5732\n",
      "Epoch 16: val_loss improved from 1.13053 to 1.12596, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2304 - precision: 0.5726 - val_loss: 1.1260 - val_precision: 0.6682\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2306 - precision: 0.5868\n",
      "Epoch 17: val_loss improved from 1.12596 to 1.11861, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2293 - precision: 0.5889 - val_loss: 1.1186 - val_precision: 0.6667\n",
      "Epoch 18/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2118 - precision: 0.5967\n",
      "Epoch 18: val_loss improved from 1.11861 to 1.11124, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2109 - precision: 0.5976 - val_loss: 1.1112 - val_precision: 0.6655\n",
      "Epoch 19/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.2016 - precision: 0.6008\n",
      "Epoch 19: val_loss did not improve from 1.11124\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2049 - precision: 0.5985 - val_loss: 1.1147 - val_precision: 0.6500\n",
      "Epoch 20/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2133 - precision: 0.5966\n",
      "Epoch 20: val_loss improved from 1.11124 to 1.10549, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2124 - precision: 0.6021 - val_loss: 1.1055 - val_precision: 0.6640\n",
      "Epoch 21/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2025 - precision: 0.6118\n",
      "Epoch 21: val_loss improved from 1.10549 to 1.10129, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2000 - precision: 0.6089 - val_loss: 1.1013 - val_precision: 0.6551\n",
      "Epoch 22/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.2122 - precision: 0.5901\n",
      "Epoch 22: val_loss improved from 1.10129 to 1.10047, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2093 - precision: 0.5940 - val_loss: 1.1005 - val_precision: 0.6596\n",
      "Epoch 23/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2212 - precision: 0.5829\n",
      "Epoch 23: val_loss did not improve from 1.10047\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2176 - precision: 0.5830 - val_loss: 1.1008 - val_precision: 0.6612\n",
      "Epoch 24/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.1881 - precision: 0.6146\n",
      "Epoch 24: val_loss did not improve from 1.10047\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1860 - precision: 0.6128 - val_loss: 1.1071 - val_precision: 0.6519\n",
      "Epoch 25/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2040 - precision: 0.5866\n",
      "Epoch 25: val_loss improved from 1.10047 to 1.09751, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2009 - precision: 0.5910 - val_loss: 1.0975 - val_precision: 0.6557\n",
      "Epoch 26/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2080 - precision: 0.5954\n",
      "Epoch 26: val_loss improved from 1.09751 to 1.09574, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2012 - precision: 0.6017 - val_loss: 1.0957 - val_precision: 0.6560\n",
      "Epoch 27/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.2025 - precision: 0.5989\n",
      "Epoch 27: val_loss did not improve from 1.09574\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2043 - precision: 0.5973 - val_loss: 1.0963 - val_precision: 0.6582\n",
      "Epoch 28/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.1971 - precision: 0.5866\n",
      "Epoch 28: val_loss did not improve from 1.09574\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2023 - precision: 0.5851 - val_loss: 1.0998 - val_precision: 0.6525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.2020 - precision: 0.5940\n",
      "Epoch 29: val_loss did not improve from 1.09574\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1987 - precision: 0.5965 - val_loss: 1.0987 - val_precision: 0.6549\n",
      "Epoch 30/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.1779 - precision: 0.6118\n",
      "Epoch 30: val_loss did not improve from 1.09574\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1775 - precision: 0.6093 - val_loss: 1.0997 - val_precision: 0.6463\n",
      "Epoch 31/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.1903 - precision: 0.6087\n",
      "Epoch 31: val_loss did not improve from 1.09574\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1859 - precision: 0.6086 - val_loss: 1.0970 - val_precision: 0.6456\n",
      "Epoch 32/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.1891 - precision: 0.6127\n",
      "Epoch 32: val_loss improved from 1.09574 to 1.09362, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1903 - precision: 0.6106 - val_loss: 1.0936 - val_precision: 0.6541\n",
      "Epoch 33/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1770 - precision: 0.6037\n",
      "Epoch 33: val_loss improved from 1.09362 to 1.08991, saving model to model_ent48.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1757 - precision: 0.6062 - val_loss: 1.0899 - val_precision: 0.6512\n",
      "Epoch 34/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.1871 - precision: 0.5970\n",
      "Epoch 34: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1857 - precision: 0.5986 - val_loss: 1.0973 - val_precision: 0.6516\n",
      "Epoch 35/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1779 - precision: 0.6259\n",
      "Epoch 35: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1790 - precision: 0.6250 - val_loss: 1.1036 - val_precision: 0.6403\n",
      "Epoch 36/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1866 - precision: 0.6001\n",
      "Epoch 36: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1854 - precision: 0.6003 - val_loss: 1.1022 - val_precision: 0.6403\n",
      "Epoch 37/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1813 - precision: 0.6116\n",
      "Epoch 37: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1815 - precision: 0.6118 - val_loss: 1.0954 - val_precision: 0.6458\n",
      "Epoch 38/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1874 - precision: 0.5999\n",
      "Epoch 38: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1870 - precision: 0.6013 - val_loss: 1.0997 - val_precision: 0.6428\n",
      "Epoch 39/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1962 - precision: 0.5997\n",
      "Epoch 39: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1979 - precision: 0.5966 - val_loss: 1.0977 - val_precision: 0.6442\n",
      "Epoch 40/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1886 - precision: 0.5992\n",
      "Epoch 40: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1896 - precision: 0.5998 - val_loss: 1.0928 - val_precision: 0.6543\n",
      "Epoch 41/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1797 - precision: 0.6012\n",
      "Epoch 41: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1798 - precision: 0.6006 - val_loss: 1.0984 - val_precision: 0.6473\n",
      "Epoch 42/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1910 - precision: 0.6076\n",
      "Epoch 42: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1921 - precision: 0.6087 - val_loss: 1.0958 - val_precision: 0.6498\n",
      "Epoch 43/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1860 - precision: 0.6003\n",
      "Epoch 43: val_loss did not improve from 1.08991\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1884 - precision: 0.5999 - val_loss: 1.0970 - val_precision: 0.6418\n",
      "Epoch 43: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0809 - precision: 0.6428\n",
      "Combinación 47 = (True, False, False, 8, 0.5) \n",
      " precision train: [1.0809128284454346, 0.642812967300415]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 49: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.4092 - precision: 0.6647\n",
      "Epoch 1: val_loss improved from inf to 1.20496, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.4094 - precision: 0.6657 - val_loss: 1.2050 - val_precision: 0.6671\n",
      "Epoch 2/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1046 - precision: 0.6243\n",
      "Epoch 2: val_loss improved from 1.20496 to 1.12102, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1000 - precision: 0.6265 - val_loss: 1.1210 - val_precision: 0.6298\n",
      "Epoch 3/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0279 - precision: 0.6049\n",
      "Epoch 3: val_loss improved from 1.12102 to 1.08063, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0288 - precision: 0.6049 - val_loss: 1.0806 - val_precision: 0.6137\n",
      "Epoch 4/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0104 - precision: 0.6012\n",
      "Epoch 4: val_loss improved from 1.08063 to 1.07400, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0134 - precision: 0.6015 - val_loss: 1.0740 - val_precision: 0.6155\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9949 - precision: 0.6019\n",
      "Epoch 5: val_loss improved from 1.07400 to 1.06030, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9985 - precision: 0.6006 - val_loss: 1.0603 - val_precision: 0.6198\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9837 - precision: 0.6034\n",
      "Epoch 6: val_loss improved from 1.06030 to 1.04891, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9830 - precision: 0.6040 - val_loss: 1.0489 - val_precision: 0.6171\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9753 - precision: 0.6039\n",
      "Epoch 7: val_loss did not improve from 1.04891\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9742 - precision: 0.6041 - val_loss: 1.0525 - val_precision: 0.6153\n",
      "Epoch 8/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9669 - precision: 0.6076\n",
      "Epoch 8: val_loss improved from 1.04891 to 1.04405, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9681 - precision: 0.6070 - val_loss: 1.0440 - val_precision: 0.6219\n",
      "Epoch 9/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9582 - precision: 0.6090\n",
      "Epoch 9: val_loss improved from 1.04405 to 1.04339, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9622 - precision: 0.6074 - val_loss: 1.0434 - val_precision: 0.6143\n",
      "Epoch 10/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9552 - precision: 0.6064\n",
      "Epoch 10: val_loss did not improve from 1.04339\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9542 - precision: 0.6066 - val_loss: 1.0489 - val_precision: 0.6090\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9539 - precision: 0.6098\n",
      "Epoch 11: val_loss did not improve from 1.04339\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9538 - precision: 0.6088 - val_loss: 1.0532 - val_precision: 0.6103\n",
      "Epoch 12/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9419 - precision: 0.6116\n",
      "Epoch 12: val_loss improved from 1.04339 to 1.03417, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9438 - precision: 0.6106 - val_loss: 1.0342 - val_precision: 0.6261\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9424 - precision: 0.6145\n",
      "Epoch 13: val_loss improved from 1.03417 to 1.03101, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9392 - precision: 0.6163 - val_loss: 1.0310 - val_precision: 0.6273\n",
      "Epoch 14/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9405 - precision: 0.6070\n",
      "Epoch 14: val_loss improved from 1.03101 to 1.02843, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9358 - precision: 0.6084 - val_loss: 1.0284 - val_precision: 0.6297\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9278 - precision: 0.6169\n",
      "Epoch 15: val_loss did not improve from 1.02843\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9287 - precision: 0.6166 - val_loss: 1.0290 - val_precision: 0.6210\n",
      "Epoch 16/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9223 - precision: 0.6161\n",
      "Epoch 16: val_loss did not improve from 1.02843\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9230 - precision: 0.6177 - val_loss: 1.0295 - val_precision: 0.6298\n",
      "Epoch 17/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9220 - precision: 0.6182\n",
      "Epoch 17: val_loss did not improve from 1.02843\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9246 - precision: 0.6195 - val_loss: 1.0323 - val_precision: 0.6260\n",
      "Epoch 18/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9123 - precision: 0.6179\n",
      "Epoch 18: val_loss did not improve from 1.02843\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9135 - precision: 0.6185 - val_loss: 1.0295 - val_precision: 0.6249\n",
      "Epoch 19/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9048 - precision: 0.6230\n",
      "Epoch 19: val_loss did not improve from 1.02843\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9074 - precision: 0.6207 - val_loss: 1.0284 - val_precision: 0.6229\n",
      "Epoch 20/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9099 - precision: 0.6234\n",
      "Epoch 20: val_loss improved from 1.02843 to 1.01913, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9078 - precision: 0.6238 - val_loss: 1.0191 - val_precision: 0.6227\n",
      "Epoch 21/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9016 - precision: 0.6273\n",
      "Epoch 21: val_loss did not improve from 1.01913\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9014 - precision: 0.6255 - val_loss: 1.0194 - val_precision: 0.6310\n",
      "Epoch 22/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.8926 - precision: 0.6306\n",
      "Epoch 22: val_loss did not improve from 1.01913\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8944 - precision: 0.6287 - val_loss: 1.0386 - val_precision: 0.6140\n",
      "Epoch 23/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8920 - precision: 0.6258\n",
      "Epoch 23: val_loss did not improve from 1.01913\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8924 - precision: 0.6258 - val_loss: 1.0291 - val_precision: 0.6210\n",
      "Epoch 24/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8843 - precision: 0.6285\n",
      "Epoch 24: val_loss did not improve from 1.01913\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8843 - precision: 0.6285 - val_loss: 1.0212 - val_precision: 0.6248\n",
      "Epoch 25/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8860 - precision: 0.6281\n",
      "Epoch 25: val_loss did not improve from 1.01913\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8856 - precision: 0.6294 - val_loss: 1.0249 - val_precision: 0.6251\n",
      "Epoch 26/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.8821 - precision: 0.6283\n",
      "Epoch 26: val_loss did not improve from 1.01913\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8802 - precision: 0.6304 - val_loss: 1.0364 - val_precision: 0.6067\n",
      "Epoch 27/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8830 - precision: 0.6247\n",
      "Epoch 27: val_loss improved from 1.01913 to 1.01040, saving model to model_ent49.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8822 - precision: 0.6249 - val_loss: 1.0104 - val_precision: 0.6290\n",
      "Epoch 28/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8726 - precision: 0.6318\n",
      "Epoch 28: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8722 - precision: 0.6327 - val_loss: 1.0248 - val_precision: 0.6206\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8620 - precision: 0.6350\n",
      "Epoch 29: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8632 - precision: 0.6347 - val_loss: 1.0113 - val_precision: 0.6233\n",
      "Epoch 30/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8702 - precision: 0.6333\n",
      "Epoch 30: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8697 - precision: 0.6347 - val_loss: 1.0225 - val_precision: 0.6220\n",
      "Epoch 31/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8649 - precision: 0.6334\n",
      "Epoch 31: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8659 - precision: 0.6336 - val_loss: 1.0209 - val_precision: 0.6140\n",
      "Epoch 32/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8614 - precision: 0.6330\n",
      "Epoch 32: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8600 - precision: 0.6333 - val_loss: 1.0120 - val_precision: 0.6223\n",
      "Epoch 33/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8580 - precision: 0.6363\n",
      "Epoch 33: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8597 - precision: 0.6340 - val_loss: 1.0255 - val_precision: 0.6143\n",
      "Epoch 34/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8558 - precision: 0.6319\n",
      "Epoch 34: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8538 - precision: 0.6341 - val_loss: 1.0185 - val_precision: 0.6148\n",
      "Epoch 35/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8547 - precision: 0.6359\n",
      "Epoch 35: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8536 - precision: 0.6370 - val_loss: 1.0192 - val_precision: 0.6147\n",
      "Epoch 36/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8537 - precision: 0.6377\n",
      "Epoch 36: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8522 - precision: 0.6383 - val_loss: 1.0173 - val_precision: 0.6215\n",
      "Epoch 37/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8494 - precision: 0.6399\n",
      "Epoch 37: val_loss did not improve from 1.01040\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8489 - precision: 0.6389 - val_loss: 1.0253 - val_precision: 0.6110\n",
      "Epoch 37: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9349 - precision: 0.6420\n",
      "Combinación 48 = (True, False, False, 16, 0.1) \n",
      " precision train: [0.9348883628845215, 0.6420184969902039]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 50: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.4779 - precision: 0.6148 \n",
      "Epoch 1: val_loss improved from inf to 1.26556, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.4655 - precision: 0.6025 - val_loss: 1.2656 - val_precision: 0.6993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.1597 - precision: 0.6328\n",
      "Epoch 2: val_loss improved from 1.26556 to 1.11887, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1575 - precision: 0.6292 - val_loss: 1.1189 - val_precision: 0.6363\n",
      "Epoch 3/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0737 - precision: 0.6089\n",
      "Epoch 3: val_loss improved from 1.11887 to 1.09256, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0773 - precision: 0.6060 - val_loss: 1.0926 - val_precision: 0.6151\n",
      "Epoch 4/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0545 - precision: 0.6024\n",
      "Epoch 4: val_loss improved from 1.09256 to 1.07094, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0505 - precision: 0.6041 - val_loss: 1.0709 - val_precision: 0.6260\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0385 - precision: 0.6047\n",
      "Epoch 5: val_loss improved from 1.07094 to 1.06332, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0349 - precision: 0.6053 - val_loss: 1.0633 - val_precision: 0.6187\n",
      "Epoch 6/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0209 - precision: 0.6024\n",
      "Epoch 6: val_loss improved from 1.06332 to 1.05521, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0222 - precision: 0.6024 - val_loss: 1.0552 - val_precision: 0.6161\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0205 - precision: 0.6040\n",
      "Epoch 7: val_loss improved from 1.05521 to 1.04484, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0208 - precision: 0.6044 - val_loss: 1.0448 - val_precision: 0.6209\n",
      "Epoch 8/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0060 - precision: 0.6105\n",
      "Epoch 8: val_loss did not improve from 1.04484\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0060 - precision: 0.6105 - val_loss: 1.0457 - val_precision: 0.6246\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9936 - precision: 0.6124\n",
      "Epoch 9: val_loss did not improve from 1.04484\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9932 - precision: 0.6120 - val_loss: 1.0449 - val_precision: 0.6237\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9951 - precision: 0.6067\n",
      "Epoch 10: val_loss improved from 1.04484 to 1.04480, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9951 - precision: 0.6067 - val_loss: 1.0448 - val_precision: 0.6223\n",
      "Epoch 11/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9916 - precision: 0.6087\n",
      "Epoch 11: val_loss improved from 1.04480 to 1.03918, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9916 - precision: 0.6087 - val_loss: 1.0392 - val_precision: 0.6168\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9848 - precision: 0.6103\n",
      "Epoch 12: val_loss improved from 1.03918 to 1.03904, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9859 - precision: 0.6088 - val_loss: 1.0390 - val_precision: 0.6206\n",
      "Epoch 13/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9972 - precision: 0.6055\n",
      "Epoch 13: val_loss did not improve from 1.03904\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9932 - precision: 0.6057 - val_loss: 1.0477 - val_precision: 0.6140\n",
      "Epoch 14/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9689 - precision: 0.6069\n",
      "Epoch 14: val_loss did not improve from 1.03904\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9721 - precision: 0.6075 - val_loss: 1.0468 - val_precision: 0.6151\n",
      "Epoch 15/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9780 - precision: 0.6114\n",
      "Epoch 15: val_loss did not improve from 1.03904\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9748 - precision: 0.6106 - val_loss: 1.0470 - val_precision: 0.6122\n",
      "Epoch 16/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9722 - precision: 0.6101\n",
      "Epoch 16: val_loss improved from 1.03904 to 1.03677, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9770 - precision: 0.6092 - val_loss: 1.0368 - val_precision: 0.6245\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9704 - precision: 0.6121\n",
      "Epoch 17: val_loss did not improve from 1.03677\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9696 - precision: 0.6129 - val_loss: 1.0414 - val_precision: 0.6193\n",
      "Epoch 18/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9653 - precision: 0.6122\n",
      "Epoch 18: val_loss did not improve from 1.03677\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9686 - precision: 0.6154 - val_loss: 1.0381 - val_precision: 0.6180\n",
      "Epoch 19/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9682 - precision: 0.6165\n",
      "Epoch 19: val_loss improved from 1.03677 to 1.02996, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9685 - precision: 0.6151 - val_loss: 1.0300 - val_precision: 0.6254\n",
      "Epoch 20/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9637 - precision: 0.6126\n",
      "Epoch 20: val_loss did not improve from 1.02996\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9604 - precision: 0.6146 - val_loss: 1.0302 - val_precision: 0.6282\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9610 - precision: 0.6105\n",
      "Epoch 21: val_loss did not improve from 1.02996\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9620 - precision: 0.6102 - val_loss: 1.0426 - val_precision: 0.6147\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9593 - precision: 0.6071\n",
      "Epoch 22: val_loss did not improve from 1.02996\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9592 - precision: 0.6072 - val_loss: 1.0305 - val_precision: 0.6254\n",
      "Epoch 23/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9458 - precision: 0.6155\n",
      "Epoch 23: val_loss did not improve from 1.02996\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9471 - precision: 0.6166 - val_loss: 1.0388 - val_precision: 0.6128\n",
      "Epoch 24/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9504 - precision: 0.6121\n",
      "Epoch 24: val_loss did not improve from 1.02996\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9504 - precision: 0.6121 - val_loss: 1.0329 - val_precision: 0.6246\n",
      "Epoch 25/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9461 - precision: 0.6176\n",
      "Epoch 25: val_loss improved from 1.02996 to 1.02874, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9471 - precision: 0.6147 - val_loss: 1.0287 - val_precision: 0.6215\n",
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9417 - precision: 0.6157\n",
      "Epoch 26: val_loss did not improve from 1.02874\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9419 - precision: 0.6147 - val_loss: 1.0361 - val_precision: 0.6184\n",
      "Epoch 27/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9465 - precision: 0.6167\n",
      "Epoch 27: val_loss improved from 1.02874 to 1.01542, saving model to model_ent50.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9465 - precision: 0.6167 - val_loss: 1.0154 - val_precision: 0.6299\n",
      "Epoch 28/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9325 - precision: 0.6197\n",
      "Epoch 28: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9322 - precision: 0.6201 - val_loss: 1.0492 - val_precision: 0.6061\n",
      "Epoch 29/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9361 - precision: 0.6160\n",
      "Epoch 29: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9364 - precision: 0.6155 - val_loss: 1.0289 - val_precision: 0.6196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9426 - precision: 0.6148\n",
      "Epoch 30: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9405 - precision: 0.6142 - val_loss: 1.0273 - val_precision: 0.6182\n",
      "Epoch 31/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9195 - precision: 0.6181\n",
      "Epoch 31: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9250 - precision: 0.6165 - val_loss: 1.0318 - val_precision: 0.6127\n",
      "Epoch 32/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9222 - precision: 0.6211\n",
      "Epoch 32: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9231 - precision: 0.6190 - val_loss: 1.0308 - val_precision: 0.6191\n",
      "Epoch 33/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9302 - precision: 0.6211\n",
      "Epoch 33: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9275 - precision: 0.6213 - val_loss: 1.0266 - val_precision: 0.6204\n",
      "Epoch 34/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9212 - precision: 0.6231\n",
      "Epoch 34: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9211 - precision: 0.6229 - val_loss: 1.0350 - val_precision: 0.6196\n",
      "Epoch 35/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9191 - precision: 0.6183\n",
      "Epoch 35: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9140 - precision: 0.6211 - val_loss: 1.0366 - val_precision: 0.6083\n",
      "Epoch 36/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9176 - precision: 0.6184\n",
      "Epoch 36: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9199 - precision: 0.6177 - val_loss: 1.0399 - val_precision: 0.6109\n",
      "Epoch 37/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9139 - precision: 0.6183\n",
      "Epoch 37: val_loss did not improve from 1.01542\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9138 - precision: 0.6181 - val_loss: 1.0380 - val_precision: 0.6100\n",
      "Epoch 37: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9802 - precision: 0.6204\n",
      "Combinación 49 = (True, False, False, 16, 0.25) \n",
      " precision train: [0.9802178144454956, 0.6204205751419067]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 51: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.5367 - precision: 0.6341 \n",
      "Epoch 1: val_loss improved from inf to 1.28873, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.5272 - precision: 0.6598 - val_loss: 1.2887 - val_precision: 0.7104\n",
      "Epoch 2/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2629 - precision: 0.6278\n",
      "Epoch 2: val_loss improved from 1.28873 to 1.15640, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2656 - precision: 0.6240 - val_loss: 1.1564 - val_precision: 0.6667\n",
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2015 - precision: 0.6075\n",
      "Epoch 3: val_loss improved from 1.15640 to 1.12085, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1998 - precision: 0.6074 - val_loss: 1.1208 - val_precision: 0.6584\n",
      "Epoch 4/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1817 - precision: 0.6091\n",
      "Epoch 4: val_loss improved from 1.12085 to 1.10568, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1797 - precision: 0.6099 - val_loss: 1.1057 - val_precision: 0.6568\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1433 - precision: 0.6030\n",
      "Epoch 5: val_loss improved from 1.10568 to 1.10422, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1432 - precision: 0.6030 - val_loss: 1.1042 - val_precision: 0.6376\n",
      "Epoch 6/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.1327 - precision: 0.6019\n",
      "Epoch 6: val_loss improved from 1.10422 to 1.08635, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1391 - precision: 0.5981 - val_loss: 1.0863 - val_precision: 0.6357\n",
      "Epoch 7/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1318 - precision: 0.6003\n",
      "Epoch 7: val_loss did not improve from 1.08635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1315 - precision: 0.5990 - val_loss: 1.0892 - val_precision: 0.6311\n",
      "Epoch 8/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.1244 - precision: 0.5947\n",
      "Epoch 8: val_loss improved from 1.08635 to 1.07938, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1186 - precision: 0.5984 - val_loss: 1.0794 - val_precision: 0.6241\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1099 - precision: 0.5936\n",
      "Epoch 9: val_loss improved from 1.07938 to 1.07581, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1092 - precision: 0.5936 - val_loss: 1.0758 - val_precision: 0.6195\n",
      "Epoch 10/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0979 - precision: 0.5962\n",
      "Epoch 10: val_loss improved from 1.07581 to 1.07498, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1056 - precision: 0.5933 - val_loss: 1.0750 - val_precision: 0.6281\n",
      "Epoch 11/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.1019 - precision: 0.5915\n",
      "Epoch 11: val_loss improved from 1.07498 to 1.06699, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1007 - precision: 0.5937 - val_loss: 1.0670 - val_precision: 0.6219\n",
      "Epoch 12/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0920 - precision: 0.6020\n",
      "Epoch 12: val_loss did not improve from 1.06699\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0914 - precision: 0.6010 - val_loss: 1.0721 - val_precision: 0.6139\n",
      "Epoch 13/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0960 - precision: 0.6085\n",
      "Epoch 13: val_loss did not improve from 1.06699\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0969 - precision: 0.6067 - val_loss: 1.0790 - val_precision: 0.6085\n",
      "Epoch 14/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0981 - precision: 0.5941\n",
      "Epoch 14: val_loss did not improve from 1.06699\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0943 - precision: 0.5984 - val_loss: 1.0805 - val_precision: 0.6106\n",
      "Epoch 15/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0877 - precision: 0.5965\n",
      "Epoch 15: val_loss did not improve from 1.06699\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0883 - precision: 0.5986 - val_loss: 1.0731 - val_precision: 0.6074\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0884 - precision: 0.6012\n",
      "Epoch 16: val_loss did not improve from 1.06699\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0861 - precision: 0.6066 - val_loss: 1.0784 - val_precision: 0.6129\n",
      "Epoch 17/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0841 - precision: 0.6011\n",
      "Epoch 17: val_loss improved from 1.06699 to 1.06393, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0766 - precision: 0.6039 - val_loss: 1.0639 - val_precision: 0.6147\n",
      "Epoch 18/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0803 - precision: 0.6021\n",
      "Epoch 18: val_loss improved from 1.06393 to 1.06363, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0803 - precision: 0.6021 - val_loss: 1.0636 - val_precision: 0.6171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0792 - precision: 0.6017\n",
      "Epoch 19: val_loss did not improve from 1.06363\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0772 - precision: 0.6046 - val_loss: 1.0637 - val_precision: 0.6189\n",
      "Epoch 20/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0859 - precision: 0.5939\n",
      "Epoch 20: val_loss did not improve from 1.06363\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0829 - precision: 0.5953 - val_loss: 1.0656 - val_precision: 0.6184\n",
      "Epoch 21/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0727 - precision: 0.6070\n",
      "Epoch 21: val_loss did not improve from 1.06363\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0724 - precision: 0.6065 - val_loss: 1.0656 - val_precision: 0.6156\n",
      "Epoch 22/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0550 - precision: 0.6147\n",
      "Epoch 22: val_loss improved from 1.06363 to 1.06305, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0636 - precision: 0.6097 - val_loss: 1.0631 - val_precision: 0.6186\n",
      "Epoch 23/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0765 - precision: 0.6023\n",
      "Epoch 23: val_loss did not improve from 1.06305\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0755 - precision: 0.6019 - val_loss: 1.0636 - val_precision: 0.6165\n",
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0756 - precision: 0.6002\n",
      "Epoch 24: val_loss did not improve from 1.06305\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0763 - precision: 0.6016 - val_loss: 1.0671 - val_precision: 0.6172\n",
      "Epoch 25/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0757 - precision: 0.6085\n",
      "Epoch 25: val_loss did not improve from 1.06305\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0759 - precision: 0.6082 - val_loss: 1.0655 - val_precision: 0.6140\n",
      "Epoch 26/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0686 - precision: 0.6090\n",
      "Epoch 26: val_loss improved from 1.06305 to 1.05804, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0644 - precision: 0.6061 - val_loss: 1.0580 - val_precision: 0.6192\n",
      "Epoch 27/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0636 - precision: 0.6063\n",
      "Epoch 27: val_loss improved from 1.05804 to 1.05724, saving model to model_ent51.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0614 - precision: 0.6051 - val_loss: 1.0572 - val_precision: 0.6197\n",
      "Epoch 28/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0571 - precision: 0.6106\n",
      "Epoch 28: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0571 - precision: 0.6106 - val_loss: 1.0639 - val_precision: 0.6163\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0520 - precision: 0.6122\n",
      "Epoch 29: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0530 - precision: 0.6108 - val_loss: 1.0714 - val_precision: 0.6098\n",
      "Epoch 30/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0599 - precision: 0.6062\n",
      "Epoch 30: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0574 - precision: 0.6057 - val_loss: 1.0612 - val_precision: 0.6206\n",
      "Epoch 31/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0564 - precision: 0.6055\n",
      "Epoch 31: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0561 - precision: 0.6073 - val_loss: 1.0638 - val_precision: 0.6186\n",
      "Epoch 32/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0514 - precision: 0.6138\n",
      "Epoch 32: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0510 - precision: 0.6128 - val_loss: 1.0643 - val_precision: 0.6127\n",
      "Epoch 33/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0530 - precision: 0.6133\n",
      "Epoch 33: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0555 - precision: 0.6120 - val_loss: 1.0606 - val_precision: 0.6205\n",
      "Epoch 34/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0493 - precision: 0.6147\n",
      "Epoch 34: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0493 - precision: 0.6147 - val_loss: 1.0605 - val_precision: 0.6176\n",
      "Epoch 35/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0426 - precision: 0.6098\n",
      "Epoch 35: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0455 - precision: 0.6104 - val_loss: 1.0671 - val_precision: 0.6152\n",
      "Epoch 36/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0360 - precision: 0.6077\n",
      "Epoch 36: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0387 - precision: 0.6082 - val_loss: 1.0657 - val_precision: 0.6110\n",
      "Epoch 37/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0454 - precision: 0.6116\n",
      "Epoch 37: val_loss did not improve from 1.05724\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0466 - precision: 0.6110 - val_loss: 1.0651 - val_precision: 0.6193\n",
      "Epoch 37: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0454 - precision: 0.6168\n",
      "Combinación 50 = (True, False, False, 16, 0.5) \n",
      " precision train: [1.0454175472259521, 0.6168123483657837]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 52: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.3169 - precision: 0.6211\n",
      "Epoch 1: val_loss improved from inf to 1.13174, saving model to model_ent52.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.3068 - precision: 0.6146 - val_loss: 1.1317 - val_precision: 0.6421\n",
      "Epoch 2/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0262 - precision: 0.6039\n",
      "Epoch 2: val_loss improved from 1.13174 to 1.06770, saving model to model_ent52.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0226 - precision: 0.6027 - val_loss: 1.0677 - val_precision: 0.6103\n",
      "Epoch 3/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9902 - precision: 0.6018\n",
      "Epoch 3: val_loss improved from 1.06770 to 1.05018, saving model to model_ent52.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9908 - precision: 0.6029 - val_loss: 1.0502 - val_precision: 0.6216\n",
      "Epoch 4/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9719 - precision: 0.6039\n",
      "Epoch 4: val_loss improved from 1.05018 to 1.04571, saving model to model_ent52.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9720 - precision: 0.6040 - val_loss: 1.0457 - val_precision: 0.6231\n",
      "Epoch 5/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9587 - precision: 0.6095\n",
      "Epoch 5: val_loss improved from 1.04571 to 1.04353, saving model to model_ent52.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9585 - precision: 0.6091 - val_loss: 1.0435 - val_precision: 0.6065\n",
      "Epoch 6/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9472 - precision: 0.6103\n",
      "Epoch 6: val_loss improved from 1.04353 to 1.03477, saving model to model_ent52.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9518 - precision: 0.6083 - val_loss: 1.0348 - val_precision: 0.6154\n",
      "Epoch 7/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9343 - precision: 0.6160\n",
      "Epoch 7: val_loss did not improve from 1.03477\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9370 - precision: 0.6155 - val_loss: 1.0356 - val_precision: 0.6151\n",
      "Epoch 8/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9333 - precision: 0.6151\n",
      "Epoch 8: val_loss improved from 1.03477 to 1.02114, saving model to model_ent52.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9336 - precision: 0.6146 - val_loss: 1.0211 - val_precision: 0.6243\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9211 - precision: 0.6199\n",
      "Epoch 9: val_loss improved from 1.02114 to 1.01907, saving model to model_ent52.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9189 - precision: 0.6213 - val_loss: 1.0191 - val_precision: 0.6245\n",
      "Epoch 10/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9128 - precision: 0.6133\n",
      "Epoch 10: val_loss improved from 1.01907 to 1.01158, saving model to model_ent52.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9153 - precision: 0.6132 - val_loss: 1.0116 - val_precision: 0.6319\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9088 - precision: 0.6205\n",
      "Epoch 11: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9100 - precision: 0.6203 - val_loss: 1.0285 - val_precision: 0.6169\n",
      "Epoch 12/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9077 - precision: 0.6214\n",
      "Epoch 12: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9065 - precision: 0.6205 - val_loss: 1.0237 - val_precision: 0.6259\n",
      "Epoch 13/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8948 - precision: 0.6232\n",
      "Epoch 13: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8945 - precision: 0.6234 - val_loss: 1.0202 - val_precision: 0.6271\n",
      "Epoch 14/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8905 - precision: 0.6262\n",
      "Epoch 14: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8919 - precision: 0.6258 - val_loss: 1.0263 - val_precision: 0.6127\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8869 - precision: 0.6281\n",
      "Epoch 15: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8851 - precision: 0.6275 - val_loss: 1.0162 - val_precision: 0.6273\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8779 - precision: 0.6303\n",
      "Epoch 16: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8778 - precision: 0.6281 - val_loss: 1.0174 - val_precision: 0.6167\n",
      "Epoch 17/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8732 - precision: 0.6299\n",
      "Epoch 17: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8758 - precision: 0.6287 - val_loss: 1.0249 - val_precision: 0.6214\n",
      "Epoch 18/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8716 - precision: 0.6260\n",
      "Epoch 18: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8718 - precision: 0.6266 - val_loss: 1.0178 - val_precision: 0.6225\n",
      "Epoch 19/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8611 - precision: 0.6334\n",
      "Epoch 19: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8630 - precision: 0.6319 - val_loss: 1.0145 - val_precision: 0.6244\n",
      "Epoch 20/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8560 - precision: 0.6356\n",
      "Epoch 20: val_loss did not improve from 1.01158\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8564 - precision: 0.6341 - val_loss: 1.0184 - val_precision: 0.6262\n",
      "Epoch 20: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9527 - precision: 0.6375\n",
      "Combinación 51 = (True, False, False, 32, 0.1) \n",
      " precision train: [0.9526523351669312, 0.6374543309211731]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 53: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3469 - precision: 0.6267\n",
      "Epoch 1: val_loss improved from inf to 1.15073, saving model to model_ent53.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.3368 - precision: 0.6285 - val_loss: 1.1507 - val_precision: 0.6341\n",
      "Epoch 2/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0493 - precision: 0.6037\n",
      "Epoch 2: val_loss improved from 1.15073 to 1.07361, saving model to model_ent53.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0458 - precision: 0.6067 - val_loss: 1.0736 - val_precision: 0.6124\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0110 - precision: 0.6007\n",
      "Epoch 3: val_loss improved from 1.07361 to 1.03898, saving model to model_ent53.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0122 - precision: 0.5993 - val_loss: 1.0390 - val_precision: 0.6236\n",
      "Epoch 4/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9874 - precision: 0.6005\n",
      "Epoch 4: val_loss did not improve from 1.03898\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9877 - precision: 0.6013 - val_loss: 1.0410 - val_precision: 0.6192\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9796 - precision: 0.6043\n",
      "Epoch 5: val_loss improved from 1.03898 to 1.02733, saving model to model_ent53.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9796 - precision: 0.6043 - val_loss: 1.0273 - val_precision: 0.6227\n",
      "Epoch 6/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9663 - precision: 0.6050\n",
      "Epoch 6: val_loss did not improve from 1.02733\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9673 - precision: 0.6043 - val_loss: 1.0372 - val_precision: 0.6106\n",
      "Epoch 7/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9653 - precision: 0.6021\n",
      "Epoch 7: val_loss did not improve from 1.02733\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9662 - precision: 0.6021 - val_loss: 1.0294 - val_precision: 0.6214\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9544 - precision: 0.6050\n",
      "Epoch 8: val_loss improved from 1.02733 to 1.02511, saving model to model_ent53.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9580 - precision: 0.6024 - val_loss: 1.0251 - val_precision: 0.6215\n",
      "Epoch 9/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9527 - precision: 0.6094\n",
      "Epoch 9: val_loss improved from 1.02511 to 1.01719, saving model to model_ent53.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9517 - precision: 0.6092 - val_loss: 1.0172 - val_precision: 0.6257\n",
      "Epoch 10/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9575 - precision: 0.5967\n",
      "Epoch 10: val_loss improved from 1.01719 to 1.01678, saving model to model_ent53.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9494 - precision: 0.5993 - val_loss: 1.0168 - val_precision: 0.6181\n",
      "Epoch 11/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9422 - precision: 0.6083\n",
      "Epoch 11: val_loss did not improve from 1.01678\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9401 - precision: 0.6068 - val_loss: 1.0342 - val_precision: 0.6098\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9404 - precision: 0.6064\n",
      "Epoch 12: val_loss did not improve from 1.01678\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9404 - precision: 0.6064 - val_loss: 1.0285 - val_precision: 0.6069\n",
      "Epoch 13/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9263 - precision: 0.6168\n",
      "Epoch 13: val_loss did not improve from 1.01678\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9271 - precision: 0.6163 - val_loss: 1.0342 - val_precision: 0.6132\n",
      "Epoch 14/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/236 [============================>.] - ETA: 0s - loss: 0.9297 - precision: 0.6128\n",
      "Epoch 14: val_loss did not improve from 1.01678\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9304 - precision: 0.6133 - val_loss: 1.0207 - val_precision: 0.6212\n",
      "Epoch 15/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9233 - precision: 0.6140\n",
      "Epoch 15: val_loss did not improve from 1.01678\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9237 - precision: 0.6141 - val_loss: 1.0216 - val_precision: 0.6196\n",
      "Epoch 16/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9222 - precision: 0.6201\n",
      "Epoch 16: val_loss improved from 1.01678 to 1.00635, saving model to model_ent53.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9209 - precision: 0.6216 - val_loss: 1.0063 - val_precision: 0.6306\n",
      "Epoch 17/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9102 - precision: 0.6176\n",
      "Epoch 17: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9113 - precision: 0.6174 - val_loss: 1.0161 - val_precision: 0.6188\n",
      "Epoch 18/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9101 - precision: 0.6211\n",
      "Epoch 18: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9113 - precision: 0.6183 - val_loss: 1.0185 - val_precision: 0.6194\n",
      "Epoch 19/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9053 - precision: 0.6215\n",
      "Epoch 19: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9014 - precision: 0.6242 - val_loss: 1.0308 - val_precision: 0.6117\n",
      "Epoch 20/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8958 - precision: 0.6217\n",
      "Epoch 20: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8987 - precision: 0.6202 - val_loss: 1.0192 - val_precision: 0.6223\n",
      "Epoch 21/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8955 - precision: 0.6260\n",
      "Epoch 21: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8997 - precision: 0.6228 - val_loss: 1.0186 - val_precision: 0.6299\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9003 - precision: 0.6237\n",
      "Epoch 22: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9003 - precision: 0.6234 - val_loss: 1.0312 - val_precision: 0.6135\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8886 - precision: 0.6258\n",
      "Epoch 23: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8866 - precision: 0.6250 - val_loss: 1.0095 - val_precision: 0.6250\n",
      "Epoch 24/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8872 - precision: 0.6203\n",
      "Epoch 24: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8884 - precision: 0.6218 - val_loss: 1.0121 - val_precision: 0.6179\n",
      "Epoch 25/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8891 - precision: 0.6230\n",
      "Epoch 25: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8826 - precision: 0.6248 - val_loss: 1.0262 - val_precision: 0.6140\n",
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8824 - precision: 0.6329\n",
      "Epoch 26: val_loss did not improve from 1.00635\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8849 - precision: 0.6307 - val_loss: 1.0206 - val_precision: 0.6130\n",
      "Epoch 26: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9517 - precision: 0.6273\n",
      "Combinación 52 = (True, False, False, 32, 0.25) \n",
      " precision train: [0.9516645669937134, 0.6272634267807007]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 54: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.4529 - precision: 0.6220\n",
      "Epoch 1: val_loss improved from inf to 1.19815, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.4492 - precision: 0.6233 - val_loss: 1.1981 - val_precision: 0.6630\n",
      "Epoch 2/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1777 - precision: 0.6389\n",
      "Epoch 2: val_loss improved from 1.19815 to 1.11828, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1732 - precision: 0.6398 - val_loss: 1.1183 - val_precision: 0.6557\n",
      "Epoch 3/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1099 - precision: 0.6190\n",
      "Epoch 3: val_loss improved from 1.11828 to 1.09078, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1099 - precision: 0.6190 - val_loss: 1.0908 - val_precision: 0.6286\n",
      "Epoch 4/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0711 - precision: 0.6049\n",
      "Epoch 4: val_loss improved from 1.09078 to 1.06198, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0711 - precision: 0.6049 - val_loss: 1.0620 - val_precision: 0.6259\n",
      "Epoch 5/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0575 - precision: 0.6165\n",
      "Epoch 5: val_loss did not improve from 1.06198\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0568 - precision: 0.6161 - val_loss: 1.0696 - val_precision: 0.6179\n",
      "Epoch 6/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0406 - precision: 0.6067\n",
      "Epoch 6: val_loss did not improve from 1.06198\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0454 - precision: 0.6075 - val_loss: 1.0622 - val_precision: 0.6187\n",
      "Epoch 7/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0454 - precision: 0.6066\n",
      "Epoch 7: val_loss improved from 1.06198 to 1.05335, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0401 - precision: 0.6048 - val_loss: 1.0533 - val_precision: 0.6138\n",
      "Epoch 8/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0330 - precision: 0.6076\n",
      "Epoch 8: val_loss improved from 1.05335 to 1.05097, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0329 - precision: 0.6080 - val_loss: 1.0510 - val_precision: 0.6136\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0210 - precision: 0.5980\n",
      "Epoch 9: val_loss improved from 1.05097 to 1.04143, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0224 - precision: 0.5980 - val_loss: 1.0414 - val_precision: 0.6234\n",
      "Epoch 10/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0238 - precision: 0.6065\n",
      "Epoch 10: val_loss did not improve from 1.04143\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0255 - precision: 0.6058 - val_loss: 1.0545 - val_precision: 0.6083\n",
      "Epoch 11/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0196 - precision: 0.5959\n",
      "Epoch 11: val_loss did not improve from 1.04143\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0197 - precision: 0.5975 - val_loss: 1.0489 - val_precision: 0.6108\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0113 - precision: 0.6043\n",
      "Epoch 12: val_loss did not improve from 1.04143\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0113 - precision: 0.6043 - val_loss: 1.0448 - val_precision: 0.6172\n",
      "Epoch 13/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0043 - precision: 0.6084\n",
      "Epoch 13: val_loss did not improve from 1.04143\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0055 - precision: 0.6089 - val_loss: 1.0479 - val_precision: 0.6085\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0042 - precision: 0.6050\n",
      "Epoch 14: val_loss improved from 1.04143 to 1.03217, saving model to model_ent54.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0032 - precision: 0.6057 - val_loss: 1.0322 - val_precision: 0.6185\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0105 - precision: 0.5978\n",
      "Epoch 15: val_loss did not improve from 1.03217\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0071 - precision: 0.6003 - val_loss: 1.0470 - val_precision: 0.6081\n",
      "Epoch 16/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0072 - precision: 0.6056\n",
      "Epoch 16: val_loss did not improve from 1.03217\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0046 - precision: 0.6045 - val_loss: 1.0416 - val_precision: 0.6138\n",
      "Epoch 17/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9940 - precision: 0.6012\n",
      "Epoch 17: val_loss did not improve from 1.03217\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9972 - precision: 0.6011 - val_loss: 1.0323 - val_precision: 0.6255\n",
      "Epoch 18/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9874 - precision: 0.6103\n",
      "Epoch 18: val_loss improved from 1.03217 to 1.03198, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9879 - precision: 0.6111 - val_loss: 1.0320 - val_precision: 0.6142\n",
      "Epoch 19/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0052 - precision: 0.6130\n",
      "Epoch 19: val_loss did not improve from 1.03198\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0014 - precision: 0.6123 - val_loss: 1.0467 - val_precision: 0.6100\n",
      "Epoch 20/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9836 - precision: 0.6084\n",
      "Epoch 20: val_loss did not improve from 1.03198\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9833 - precision: 0.6075 - val_loss: 1.0475 - val_precision: 0.6122\n",
      "Epoch 21/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9819 - precision: 0.6097\n",
      "Epoch 21: val_loss did not improve from 1.03198\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9793 - precision: 0.6108 - val_loss: 1.0361 - val_precision: 0.6196\n",
      "Epoch 22/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9828 - precision: 0.6115\n",
      "Epoch 22: val_loss did not improve from 1.03198\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9861 - precision: 0.6101 - val_loss: 1.0322 - val_precision: 0.6163\n",
      "Epoch 23/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9823 - precision: 0.6103\n",
      "Epoch 23: val_loss improved from 1.03198 to 1.02971, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9867 - precision: 0.6080 - val_loss: 1.0297 - val_precision: 0.6242\n",
      "Epoch 24/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9772 - precision: 0.6129\n",
      "Epoch 24: val_loss did not improve from 1.02971\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9784 - precision: 0.6138 - val_loss: 1.0579 - val_precision: 0.5984\n",
      "Epoch 25/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9795 - precision: 0.6082\n",
      "Epoch 25: val_loss did not improve from 1.02971\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9795 - precision: 0.6079 - val_loss: 1.0344 - val_precision: 0.6110\n",
      "Epoch 26/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9756 - precision: 0.6057\n",
      "Epoch 26: val_loss did not improve from 1.02971\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9793 - precision: 0.6047 - val_loss: 1.0553 - val_precision: 0.6049\n",
      "Epoch 27/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9718 - precision: 0.6117\n",
      "Epoch 27: val_loss improved from 1.02971 to 1.02947, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9688 - precision: 0.6136 - val_loss: 1.0295 - val_precision: 0.6158\n",
      "Epoch 28/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9734 - precision: 0.6095\n",
      "Epoch 28: val_loss did not improve from 1.02947\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9719 - precision: 0.6086 - val_loss: 1.0299 - val_precision: 0.6174\n",
      "Epoch 29/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9689 - precision: 0.6142\n",
      "Epoch 29: val_loss did not improve from 1.02947\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9716 - precision: 0.6113 - val_loss: 1.0344 - val_precision: 0.6131\n",
      "Epoch 30/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9576 - precision: 0.6129\n",
      "Epoch 30: val_loss did not improve from 1.02947\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9587 - precision: 0.6131 - val_loss: 1.0392 - val_precision: 0.6099\n",
      "Epoch 31/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9641 - precision: 0.6151\n",
      "Epoch 31: val_loss did not improve from 1.02947\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9641 - precision: 0.6148 - val_loss: 1.0301 - val_precision: 0.6190\n",
      "Epoch 32/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9571 - precision: 0.6187\n",
      "Epoch 32: val_loss did not improve from 1.02947\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9578 - precision: 0.6177 - val_loss: 1.0358 - val_precision: 0.6094\n",
      "Epoch 33/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9543 - precision: 0.6153\n",
      "Epoch 33: val_loss improved from 1.02947 to 1.02530, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9567 - precision: 0.6150 - val_loss: 1.0253 - val_precision: 0.6217\n",
      "Epoch 34/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9534 - precision: 0.6130\n",
      "Epoch 34: val_loss did not improve from 1.02530\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9544 - precision: 0.6135 - val_loss: 1.0323 - val_precision: 0.6154\n",
      "Epoch 35/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9560 - precision: 0.6154\n",
      "Epoch 35: val_loss did not improve from 1.02530\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9557 - precision: 0.6147 - val_loss: 1.0385 - val_precision: 0.6120\n",
      "Epoch 36/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9489 - precision: 0.6141\n",
      "Epoch 36: val_loss improved from 1.02530 to 1.02276, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9486 - precision: 0.6163 - val_loss: 1.0228 - val_precision: 0.6189\n",
      "Epoch 37/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9558 - precision: 0.6153\n",
      "Epoch 37: val_loss did not improve from 1.02276\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9517 - precision: 0.6166 - val_loss: 1.0325 - val_precision: 0.6090\n",
      "Epoch 38/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9401 - precision: 0.6196\n",
      "Epoch 38: val_loss did not improve from 1.02276\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9402 - precision: 0.6220 - val_loss: 1.0396 - val_precision: 0.6116\n",
      "Epoch 39/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9529 - precision: 0.6157\n",
      "Epoch 39: val_loss did not improve from 1.02276\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9523 - precision: 0.6160 - val_loss: 1.0375 - val_precision: 0.6135\n",
      "Epoch 40/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9367 - precision: 0.6194\n",
      "Epoch 40: val_loss improved from 1.02276 to 1.01775, saving model to model_ent54.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9367 - precision: 0.6194 - val_loss: 1.0178 - val_precision: 0.6168\n",
      "Epoch 41/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9400 - precision: 0.6213\n",
      "Epoch 41: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9400 - precision: 0.6213 - val_loss: 1.0403 - val_precision: 0.6015\n",
      "Epoch 42/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9453 - precision: 0.6090\n",
      "Epoch 42: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9479 - precision: 0.6087 - val_loss: 1.0274 - val_precision: 0.6120\n",
      "Epoch 43/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9339 - precision: 0.6158\n",
      "Epoch 43: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9343 - precision: 0.6160 - val_loss: 1.0351 - val_precision: 0.6139\n",
      "Epoch 44/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9337 - precision: 0.6198\n",
      "Epoch 44: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9334 - precision: 0.6196 - val_loss: 1.0350 - val_precision: 0.6070\n",
      "Epoch 45/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9444 - precision: 0.6189\n",
      "Epoch 45: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9458 - precision: 0.6182 - val_loss: 1.0263 - val_precision: 0.6128\n",
      "Epoch 46/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9353 - precision: 0.6217\n",
      "Epoch 46: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9344 - precision: 0.6221 - val_loss: 1.0300 - val_precision: 0.6058\n",
      "Epoch 47/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9425 - precision: 0.6147\n",
      "Epoch 47: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9424 - precision: 0.6148 - val_loss: 1.0247 - val_precision: 0.6144\n",
      "Epoch 48/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9373 - precision: 0.6180\n",
      "Epoch 48: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9373 - precision: 0.6180 - val_loss: 1.0278 - val_precision: 0.6114\n",
      "Epoch 49/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9328 - precision: 0.6204\n",
      "Epoch 49: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9319 - precision: 0.6205 - val_loss: 1.0249 - val_precision: 0.6100\n",
      "Epoch 50/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9266 - precision: 0.6158\n",
      "Epoch 50: val_loss did not improve from 1.01775\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9269 - precision: 0.6159 - val_loss: 1.0285 - val_precision: 0.6081\n",
      "Epoch 50: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9677 - precision: 0.6243\n",
      "Combinación 53 = (True, False, False, 32, 0.5) \n",
      " precision train: [0.9677473306655884, 0.6242751479148865]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 55: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2225 - precision: 0.6245\n",
      "Epoch 1: val_loss improved from inf to 1.14419, saving model to model_ent55.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.2172 - precision: 0.6252 - val_loss: 1.1442 - val_precision: 0.5764\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9897 - precision: 0.6043\n",
      "Epoch 2: val_loss improved from 1.14419 to 1.05677, saving model to model_ent55.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9903 - precision: 0.6043 - val_loss: 1.0568 - val_precision: 0.6152\n",
      "Epoch 3/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9632 - precision: 0.6100\n",
      "Epoch 3: val_loss improved from 1.05677 to 1.02592, saving model to model_ent55.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9623 - precision: 0.6103 - val_loss: 1.0259 - val_precision: 0.6274\n",
      "Epoch 4/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9495 - precision: 0.6128\n",
      "Epoch 4: val_loss did not improve from 1.02592\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9471 - precision: 0.6151 - val_loss: 1.0370 - val_precision: 0.6124\n",
      "Epoch 5/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9300 - precision: 0.6121\n",
      "Epoch 5: val_loss did not improve from 1.02592\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9297 - precision: 0.6125 - val_loss: 1.0465 - val_precision: 0.6086\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9251 - precision: 0.6125\n",
      "Epoch 6: val_loss did not improve from 1.02592\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9251 - precision: 0.6125 - val_loss: 1.0291 - val_precision: 0.6148\n",
      "Epoch 7/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9090 - precision: 0.6142\n",
      "Epoch 7: val_loss improved from 1.02592 to 1.01338, saving model to model_ent55.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9101 - precision: 0.6153 - val_loss: 1.0134 - val_precision: 0.6179\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9040 - precision: 0.6185\n",
      "Epoch 8: val_loss improved from 1.01338 to 0.99656, saving model to model_ent55.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9026 - precision: 0.6185 - val_loss: 0.9966 - val_precision: 0.6372\n",
      "Epoch 9/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8880 - precision: 0.6207\n",
      "Epoch 9: val_loss did not improve from 0.99656\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8921 - precision: 0.6208 - val_loss: 1.0567 - val_precision: 0.6067\n",
      "Epoch 10/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8865 - precision: 0.6266\n",
      "Epoch 10: val_loss did not improve from 0.99656\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8852 - precision: 0.6268 - val_loss: 1.0227 - val_precision: 0.6163\n",
      "Epoch 11/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8752 - precision: 0.6255\n",
      "Epoch 11: val_loss did not improve from 0.99656\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8752 - precision: 0.6255 - val_loss: 0.9986 - val_precision: 0.6226\n",
      "Epoch 12/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8678 - precision: 0.6270\n",
      "Epoch 12: val_loss did not improve from 0.99656\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8690 - precision: 0.6269 - val_loss: 1.0297 - val_precision: 0.6187\n",
      "Epoch 13/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.8588 - precision: 0.6284\n",
      "Epoch 13: val_loss did not improve from 0.99656\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8608 - precision: 0.6290 - val_loss: 1.0329 - val_precision: 0.6179\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8559 - precision: 0.6254\n",
      "Epoch 14: val_loss did not improve from 0.99656\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8559 - precision: 0.6254 - val_loss: 1.0668 - val_precision: 0.6045\n",
      "Epoch 15/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8497 - precision: 0.6318\n",
      "Epoch 15: val_loss did not improve from 0.99656\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8492 - precision: 0.6329 - val_loss: 1.0254 - val_precision: 0.6154\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8438 - precision: 0.6323\n",
      "Epoch 16: val_loss did not improve from 0.99656\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8435 - precision: 0.6322 - val_loss: 1.0227 - val_precision: 0.6171\n",
      "Epoch 17/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.8355 - precision: 0.6340\n",
      "Epoch 17: val_loss did not improve from 0.99656\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8375 - precision: 0.6326 - val_loss: 1.0379 - val_precision: 0.6035\n",
      "Epoch 18/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.8251 - precision: 0.6361\n",
      "Epoch 18: val_loss improved from 0.99656 to 0.99334, saving model to model_ent55.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8309 - precision: 0.6329 - val_loss: 0.9933 - val_precision: 0.6296\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8254 - precision: 0.6368\n",
      "Epoch 19: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8247 - precision: 0.6372 - val_loss: 1.0455 - val_precision: 0.6008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.8209 - precision: 0.6381\n",
      "Epoch 20: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8223 - precision: 0.6377 - val_loss: 1.0247 - val_precision: 0.6192\n",
      "Epoch 21/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8102 - precision: 0.6383\n",
      "Epoch 21: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8105 - precision: 0.6377 - val_loss: 1.0343 - val_precision: 0.6069\n",
      "Epoch 22/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8121 - precision: 0.6351\n",
      "Epoch 22: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8128 - precision: 0.6368 - val_loss: 1.0107 - val_precision: 0.6229\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7955 - precision: 0.6395\n",
      "Epoch 23: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7986 - precision: 0.6384 - val_loss: 1.0033 - val_precision: 0.6254\n",
      "Epoch 24/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.7916 - precision: 0.6462\n",
      "Epoch 24: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7919 - precision: 0.6464 - val_loss: 1.0376 - val_precision: 0.6097\n",
      "Epoch 25/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.7860 - precision: 0.6454\n",
      "Epoch 25: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7868 - precision: 0.6467 - val_loss: 1.0290 - val_precision: 0.6180\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.7797 - precision: 0.6479\n",
      "Epoch 26: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7797 - precision: 0.6479 - val_loss: 1.0567 - val_precision: 0.5972\n",
      "Epoch 27/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.7722 - precision: 0.6462\n",
      "Epoch 27: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7742 - precision: 0.6435 - val_loss: 1.0450 - val_precision: 0.6051\n",
      "Epoch 28/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.7665 - precision: 0.6519\n",
      "Epoch 28: val_loss did not improve from 0.99334\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7665 - precision: 0.6519 - val_loss: 1.0385 - val_precision: 0.6192\n",
      "Epoch 28: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.8696 - precision: 0.6585\n",
      "Combinación 54 = (True, False, False, 64, 0.1) \n",
      " precision train: [0.8695966005325317, 0.6584781408309937]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 56: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2484 - precision: 0.6262\n",
      "Epoch 1: val_loss improved from inf to 1.08767, saving model to model_ent56.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.2413 - precision: 0.6234 - val_loss: 1.0877 - val_precision: 0.6218\n",
      "Epoch 2/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0093 - precision: 0.6074\n",
      "Epoch 2: val_loss improved from 1.08767 to 1.06941, saving model to model_ent56.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0100 - precision: 0.6060 - val_loss: 1.0694 - val_precision: 0.6028\n",
      "Epoch 3/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9842 - precision: 0.6049\n",
      "Epoch 3: val_loss improved from 1.06941 to 1.03814, saving model to model_ent56.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9848 - precision: 0.6044 - val_loss: 1.0381 - val_precision: 0.6233\n",
      "Epoch 4/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9646 - precision: 0.6051\n",
      "Epoch 4: val_loss improved from 1.03814 to 1.02572, saving model to model_ent56.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9646 - precision: 0.6052 - val_loss: 1.0257 - val_precision: 0.6145\n",
      "Epoch 5/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9488 - precision: 0.6114\n",
      "Epoch 5: val_loss did not improve from 1.02572\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9499 - precision: 0.6103 - val_loss: 1.0417 - val_precision: 0.6095\n",
      "Epoch 6/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9448 - precision: 0.6120\n",
      "Epoch 6: val_loss improved from 1.02572 to 1.02038, saving model to model_ent56.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9444 - precision: 0.6126 - val_loss: 1.0204 - val_precision: 0.6237\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9337 - precision: 0.6199\n",
      "Epoch 7: val_loss improved from 1.02038 to 1.01556, saving model to model_ent56.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9335 - precision: 0.6193 - val_loss: 1.0156 - val_precision: 0.6263\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9291 - precision: 0.6154\n",
      "Epoch 8: val_loss did not improve from 1.01556\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9265 - precision: 0.6166 - val_loss: 1.0335 - val_precision: 0.6156\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9124 - precision: 0.6190\n",
      "Epoch 9: val_loss improved from 1.01556 to 0.98981, saving model to model_ent56.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9132 - precision: 0.6190 - val_loss: 0.9898 - val_precision: 0.6297\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9074 - precision: 0.6233\n",
      "Epoch 10: val_loss did not improve from 0.98981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9085 - precision: 0.6227 - val_loss: 1.0253 - val_precision: 0.6111\n",
      "Epoch 11/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9065 - precision: 0.6202\n",
      "Epoch 11: val_loss did not improve from 0.98981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9052 - precision: 0.6180 - val_loss: 1.0071 - val_precision: 0.6298\n",
      "Epoch 12/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8887 - precision: 0.6240\n",
      "Epoch 12: val_loss did not improve from 0.98981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8960 - precision: 0.6195 - val_loss: 1.0087 - val_precision: 0.6340\n",
      "Epoch 13/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8863 - precision: 0.6231\n",
      "Epoch 13: val_loss did not improve from 0.98981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8911 - precision: 0.6210 - val_loss: 1.0134 - val_precision: 0.6340\n",
      "Epoch 14/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.8903 - precision: 0.6247\n",
      "Epoch 14: val_loss did not improve from 0.98981\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8914 - precision: 0.6231 - val_loss: 1.0137 - val_precision: 0.6301\n",
      "Epoch 15/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8771 - precision: 0.6274\n",
      "Epoch 15: val_loss did not improve from 0.98981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8764 - precision: 0.6286 - val_loss: 1.0623 - val_precision: 0.5983\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8787 - precision: 0.6264\n",
      "Epoch 16: val_loss did not improve from 0.98981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8777 - precision: 0.6269 - val_loss: 1.0087 - val_precision: 0.6303\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8682 - precision: 0.6296\n",
      "Epoch 17: val_loss did not improve from 0.98981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8709 - precision: 0.6286 - val_loss: 0.9982 - val_precision: 0.6351\n",
      "Epoch 18/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8663 - precision: 0.6326\n",
      "Epoch 18: val_loss did not improve from 0.98981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8640 - precision: 0.6328 - val_loss: 0.9985 - val_precision: 0.6270\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8622 - precision: 0.6325\n",
      "Epoch 19: val_loss did not improve from 0.98981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8632 - precision: 0.6325 - val_loss: 1.0042 - val_precision: 0.6245\n",
      "Epoch 19: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9281 - precision: 0.6365\n",
      "Combinación 55 = (True, False, False, 64, 0.25) \n",
      " precision train: [0.9281447529792786, 0.6365474462509155]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 57: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3570 - precision: 0.6524\n",
      "Epoch 1: val_loss improved from inf to 1.15178, saving model to model_ent57.h5\n",
      "236/236 [==============================] - 6s 8ms/step - loss: 1.3505 - precision: 0.6517 - val_loss: 1.1518 - val_precision: 0.6681\n",
      "Epoch 2/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0952 - precision: 0.6205\n",
      "Epoch 2: val_loss improved from 1.15178 to 1.07847, saving model to model_ent57.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0906 - precision: 0.6220 - val_loss: 1.0785 - val_precision: 0.6277\n",
      "Epoch 3/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0267 - precision: 0.6049\n",
      "Epoch 3: val_loss improved from 1.07847 to 1.06090, saving model to model_ent57.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0288 - precision: 0.6041 - val_loss: 1.0609 - val_precision: 0.6241\n",
      "Epoch 4/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0135 - precision: 0.6073\n",
      "Epoch 4: val_loss improved from 1.06090 to 1.03618, saving model to model_ent57.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0120 - precision: 0.6072 - val_loss: 1.0362 - val_precision: 0.6275\n",
      "Epoch 5/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0060 - precision: 0.6023\n",
      "Epoch 5: val_loss did not improve from 1.03618\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0052 - precision: 0.6031 - val_loss: 1.0403 - val_precision: 0.6115\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9960 - precision: 0.6067\n",
      "Epoch 6: val_loss did not improve from 1.03618\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9949 - precision: 0.6068 - val_loss: 1.0483 - val_precision: 0.6013\n",
      "Epoch 7/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9889 - precision: 0.6042\n",
      "Epoch 7: val_loss did not improve from 1.03618\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9911 - precision: 0.6041 - val_loss: 1.0388 - val_precision: 0.6070\n",
      "Epoch 8/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9799 - precision: 0.6034\n",
      "Epoch 8: val_loss improved from 1.03618 to 1.03145, saving model to model_ent57.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9791 - precision: 0.6050 - val_loss: 1.0315 - val_precision: 0.6066\n",
      "Epoch 9/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9724 - precision: 0.6051\n",
      "Epoch 9: val_loss improved from 1.03145 to 1.02198, saving model to model_ent57.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9723 - precision: 0.6042 - val_loss: 1.0220 - val_precision: 0.6154\n",
      "Epoch 10/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9699 - precision: 0.6088\n",
      "Epoch 10: val_loss did not improve from 1.02198\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9674 - precision: 0.6088 - val_loss: 1.0290 - val_precision: 0.6132\n",
      "Epoch 11/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9677 - precision: 0.5993\n",
      "Epoch 11: val_loss improved from 1.02198 to 1.02145, saving model to model_ent57.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9634 - precision: 0.6027 - val_loss: 1.0214 - val_precision: 0.6118\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9543 - precision: 0.6066\n",
      "Epoch 12: val_loss did not improve from 1.02145\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9543 - precision: 0.6066 - val_loss: 1.0231 - val_precision: 0.6200\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9531 - precision: 0.6074\n",
      "Epoch 13: val_loss improved from 1.02145 to 1.01335, saving model to model_ent57.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9529 - precision: 0.6074 - val_loss: 1.0134 - val_precision: 0.6186\n",
      "Epoch 14/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9422 - precision: 0.6123\n",
      "Epoch 14: val_loss did not improve from 1.01335\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9449 - precision: 0.6124 - val_loss: 1.0218 - val_precision: 0.6137\n",
      "Epoch 15/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9454 - precision: 0.6124\n",
      "Epoch 15: val_loss did not improve from 1.01335\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9441 - precision: 0.6142 - val_loss: 1.0156 - val_precision: 0.6171\n",
      "Epoch 16/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9442 - precision: 0.6179\n",
      "Epoch 16: val_loss improved from 1.01335 to 1.01324, saving model to model_ent57.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9428 - precision: 0.6176 - val_loss: 1.0132 - val_precision: 0.6225\n",
      "Epoch 17/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9360 - precision: 0.6179\n",
      "Epoch 17: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9356 - precision: 0.6176 - val_loss: 1.0243 - val_precision: 0.6108\n",
      "Epoch 18/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9329 - precision: 0.6162\n",
      "Epoch 18: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9340 - precision: 0.6155 - val_loss: 1.0216 - val_precision: 0.6182\n",
      "Epoch 19/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9237 - precision: 0.6205\n",
      "Epoch 19: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9272 - precision: 0.6189 - val_loss: 1.0147 - val_precision: 0.6204\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9243 - precision: 0.6176\n",
      "Epoch 20: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9213 - precision: 0.6185 - val_loss: 1.0161 - val_precision: 0.6189\n",
      "Epoch 21/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9238 - precision: 0.6152\n",
      "Epoch 21: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9205 - precision: 0.6162 - val_loss: 1.0155 - val_precision: 0.6218\n",
      "Epoch 22/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9153 - precision: 0.6179\n",
      "Epoch 22: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9153 - precision: 0.6179 - val_loss: 1.0210 - val_precision: 0.6146\n",
      "Epoch 23/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9105 - precision: 0.6181\n",
      "Epoch 23: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9101 - precision: 0.6172 - val_loss: 1.0213 - val_precision: 0.6198\n",
      "Epoch 24/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9134 - precision: 0.6183\n",
      "Epoch 24: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9157 - precision: 0.6181 - val_loss: 1.0170 - val_precision: 0.6154\n",
      "Epoch 25/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9047 - precision: 0.6249\n",
      "Epoch 25: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9034 - precision: 0.6252 - val_loss: 1.0393 - val_precision: 0.6040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9079 - precision: 0.6160\n",
      "Epoch 26: val_loss did not improve from 1.01324\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9066 - precision: 0.6174 - val_loss: 1.0204 - val_precision: 0.6184\n",
      "Epoch 26: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9588 - precision: 0.6279\n",
      "Combinación 56 = (True, False, False, 64, 0.5) \n",
      " precision train: [0.9587733149528503, 0.627895176410675]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 58: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1757 - precision: 0.6079\n",
      "Epoch 1: val_loss improved from inf to 1.07175, saving model to model_ent58.h5\n",
      "236/236 [==============================] - 7s 12ms/step - loss: 1.1749 - precision: 0.6064 - val_loss: 1.0718 - val_precision: 0.6241\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9802 - precision: 0.6075\n",
      "Epoch 2: val_loss did not improve from 1.07175\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9804 - precision: 0.6075 - val_loss: 1.0739 - val_precision: 0.6020\n",
      "Epoch 3/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9444 - precision: 0.6112\n",
      "Epoch 3: val_loss improved from 1.07175 to 1.02065, saving model to model_ent58.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9463 - precision: 0.6101 - val_loss: 1.0206 - val_precision: 0.6316\n",
      "Epoch 4/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9268 - precision: 0.6115\n",
      "Epoch 4: val_loss did not improve from 1.02065\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9292 - precision: 0.6104 - val_loss: 1.0885 - val_precision: 0.5868\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9133 - precision: 0.6183\n",
      "Epoch 5: val_loss did not improve from 1.02065\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9151 - precision: 0.6162 - val_loss: 1.0250 - val_precision: 0.6200\n",
      "Epoch 6/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8945 - precision: 0.6177\n",
      "Epoch 6: val_loss did not improve from 1.02065\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9006 - precision: 0.6156 - val_loss: 1.0235 - val_precision: 0.6201\n",
      "Epoch 7/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8986 - precision: 0.6191\n",
      "Epoch 7: val_loss improved from 1.02065 to 1.01902, saving model to model_ent58.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8986 - precision: 0.6191 - val_loss: 1.0190 - val_precision: 0.6167\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8852 - precision: 0.6269\n",
      "Epoch 8: val_loss improved from 1.01902 to 1.01316, saving model to model_ent58.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8868 - precision: 0.6236 - val_loss: 1.0132 - val_precision: 0.6278\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8739 - precision: 0.6286\n",
      "Epoch 9: val_loss did not improve from 1.01316\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8741 - precision: 0.6286 - val_loss: 1.0165 - val_precision: 0.6288\n",
      "Epoch 10/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8684 - precision: 0.6257\n",
      "Epoch 10: val_loss did not improve from 1.01316\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8659 - precision: 0.6269 - val_loss: 1.0271 - val_precision: 0.6078\n",
      "Epoch 11/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8515 - precision: 0.6307\n",
      "Epoch 11: val_loss did not improve from 1.01316\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8553 - precision: 0.6283 - val_loss: 1.0314 - val_precision: 0.6115\n",
      "Epoch 12/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8474 - precision: 0.6275\n",
      "Epoch 12: val_loss improved from 1.01316 to 1.00482, saving model to model_ent58.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8463 - precision: 0.6275 - val_loss: 1.0048 - val_precision: 0.6235\n",
      "Epoch 13/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8373 - precision: 0.6314\n",
      "Epoch 13: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8375 - precision: 0.6319 - val_loss: 1.0054 - val_precision: 0.6306\n",
      "Epoch 14/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8286 - precision: 0.6374\n",
      "Epoch 14: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8277 - precision: 0.6378 - val_loss: 1.0384 - val_precision: 0.6115\n",
      "Epoch 15/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8218 - precision: 0.6319\n",
      "Epoch 15: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8210 - precision: 0.6320 - val_loss: 1.0205 - val_precision: 0.6102\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8155 - precision: 0.6364\n",
      "Epoch 16: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8164 - precision: 0.6361 - val_loss: 1.0517 - val_precision: 0.6094\n",
      "Epoch 17/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8042 - precision: 0.6417\n",
      "Epoch 17: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8049 - precision: 0.6420 - val_loss: 1.0233 - val_precision: 0.6187\n",
      "Epoch 18/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.7949 - precision: 0.6417\n",
      "Epoch 18: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7973 - precision: 0.6396 - val_loss: 1.0087 - val_precision: 0.6311\n",
      "Epoch 19/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.7911 - precision: 0.6424\n",
      "Epoch 19: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7908 - precision: 0.6423 - val_loss: 1.0139 - val_precision: 0.6227\n",
      "Epoch 20/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.7800 - precision: 0.6533\n",
      "Epoch 20: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7812 - precision: 0.6520 - val_loss: 1.0652 - val_precision: 0.5970\n",
      "Epoch 21/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.7710 - precision: 0.6461\n",
      "Epoch 21: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7728 - precision: 0.6450 - val_loss: 1.0794 - val_precision: 0.5987\n",
      "Epoch 22/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.7597 - precision: 0.6562\n",
      "Epoch 22: val_loss did not improve from 1.00482\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7631 - precision: 0.6553 - val_loss: 1.0504 - val_precision: 0.6029\n",
      "Epoch 22: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 0.8847 - precision: 0.6493\n",
      "Combinación 57 = (True, False, False, 128, 0.1) \n",
      " precision train: [0.8846508860588074, 0.6492627263069153]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 59: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1674 - precision: 0.6296\n",
      "Epoch 1: val_loss improved from inf to 1.07497, saving model to model_ent59.h5\n",
      "236/236 [==============================] - 6s 9ms/step - loss: 1.1669 - precision: 0.6259 - val_loss: 1.0750 - val_precision: 0.6367\n",
      "Epoch 2/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9894 - precision: 0.6095\n",
      "Epoch 2: val_loss improved from 1.07497 to 1.05642, saving model to model_ent59.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9870 - precision: 0.6107 - val_loss: 1.0564 - val_precision: 0.6218\n",
      "Epoch 3/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9582 - precision: 0.6091\n",
      "Epoch 3: val_loss improved from 1.05642 to 1.02492, saving model to model_ent59.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9599 - precision: 0.6090 - val_loss: 1.0249 - val_precision: 0.6217\n",
      "Epoch 4/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9395 - precision: 0.6079\n",
      "Epoch 4: val_loss improved from 1.02492 to 0.98838, saving model to model_ent59.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9386 - precision: 0.6077 - val_loss: 0.9884 - val_precision: 0.6348\n",
      "Epoch 5/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9221 - precision: 0.6176\n",
      "Epoch 5: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9236 - precision: 0.6171 - val_loss: 1.0048 - val_precision: 0.6248\n",
      "Epoch 6/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9184 - precision: 0.6167\n",
      "Epoch 6: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9190 - precision: 0.6150 - val_loss: 1.0097 - val_precision: 0.6238\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9117 - precision: 0.6163\n",
      "Epoch 7: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9136 - precision: 0.6152 - val_loss: 1.0138 - val_precision: 0.6222\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8989 - precision: 0.6196\n",
      "Epoch 8: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8985 - precision: 0.6199 - val_loss: 1.0208 - val_precision: 0.6170\n",
      "Epoch 9/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8920 - precision: 0.6238\n",
      "Epoch 9: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8917 - precision: 0.6249 - val_loss: 1.0105 - val_precision: 0.6282\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8794 - precision: 0.6207\n",
      "Epoch 10: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8789 - precision: 0.6216 - val_loss: 1.0267 - val_precision: 0.6201\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8746 - precision: 0.6253\n",
      "Epoch 11: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8764 - precision: 0.6248 - val_loss: 1.0215 - val_precision: 0.6188\n",
      "Epoch 12/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8630 - precision: 0.6213\n",
      "Epoch 12: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8634 - precision: 0.6231 - val_loss: 1.0279 - val_precision: 0.6180\n",
      "Epoch 13/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8593 - precision: 0.6226\n",
      "Epoch 13: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8584 - precision: 0.6226 - val_loss: 1.0077 - val_precision: 0.6309\n",
      "Epoch 14/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8601 - precision: 0.6258\n",
      "Epoch 14: val_loss did not improve from 0.98838\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8605 - precision: 0.6256 - val_loss: 1.0250 - val_precision: 0.6262\n",
      "Epoch 14: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 0.9484 - precision: 0.6350\n",
      "Combinación 58 = (True, False, False, 128, 0.25) \n",
      " precision train: [0.948394775390625, 0.6350411176681519]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 60: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2396 - precision: 0.6230\n",
      "Epoch 1: val_loss improved from inf to 1.09971, saving model to model_ent60.h5\n",
      "236/236 [==============================] - 6s 9ms/step - loss: 1.2340 - precision: 0.6209 - val_loss: 1.0997 - val_precision: 0.6189\n",
      "Epoch 2/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0257 - precision: 0.6089\n",
      "Epoch 2: val_loss improved from 1.09971 to 1.06178, saving model to model_ent60.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0270 - precision: 0.6083 - val_loss: 1.0618 - val_precision: 0.6202\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9977 - precision: 0.6062\n",
      "Epoch 3: val_loss improved from 1.06178 to 1.02774, saving model to model_ent60.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9989 - precision: 0.6052 - val_loss: 1.0277 - val_precision: 0.6344\n",
      "Epoch 4/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9783 - precision: 0.6050\n",
      "Epoch 4: val_loss did not improve from 1.02774\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9799 - precision: 0.6059 - val_loss: 1.0299 - val_precision: 0.6214\n",
      "Epoch 5/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9632 - precision: 0.6080\n",
      "Epoch 5: val_loss did not improve from 1.02774\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9633 - precision: 0.6098 - val_loss: 1.0364 - val_precision: 0.6014\n",
      "Epoch 6/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9481 - precision: 0.6098\n",
      "Epoch 6: val_loss improved from 1.02774 to 1.00271, saving model to model_ent60.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9504 - precision: 0.6104 - val_loss: 1.0027 - val_precision: 0.6280\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9519 - precision: 0.6102\n",
      "Epoch 7: val_loss did not improve from 1.00271\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9510 - precision: 0.6109 - val_loss: 1.0068 - val_precision: 0.6251\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9491 - precision: 0.6151\n",
      "Epoch 8: val_loss did not improve from 1.00271\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9488 - precision: 0.6149 - val_loss: 1.0535 - val_precision: 0.6079\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9315 - precision: 0.6134\n",
      "Epoch 9: val_loss did not improve from 1.00271\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9314 - precision: 0.6130 - val_loss: 1.0096 - val_precision: 0.6167\n",
      "Epoch 10/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9223 - precision: 0.6240\n",
      "Epoch 10: val_loss did not improve from 1.00271\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9210 - precision: 0.6251 - val_loss: 1.0462 - val_precision: 0.6057\n",
      "Epoch 11/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9139 - precision: 0.6251\n",
      "Epoch 11: val_loss did not improve from 1.00271\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9143 - precision: 0.6245 - val_loss: 1.0141 - val_precision: 0.6177\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9148 - precision: 0.6163\n",
      "Epoch 12: val_loss improved from 1.00271 to 0.99974, saving model to model_ent60.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9173 - precision: 0.6148 - val_loss: 0.9997 - val_precision: 0.6265\n",
      "Epoch 13/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9095 - precision: 0.6189\n",
      "Epoch 13: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9092 - precision: 0.6185 - val_loss: 1.0130 - val_precision: 0.6302\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9058 - precision: 0.6177\n",
      "Epoch 14: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9058 - precision: 0.6177 - val_loss: 1.0105 - val_precision: 0.6231\n",
      "Epoch 15/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/236 [============================>.] - ETA: 0s - loss: 0.9031 - precision: 0.6219\n",
      "Epoch 15: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9014 - precision: 0.6226 - val_loss: 1.0155 - val_precision: 0.6206\n",
      "Epoch 16/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8992 - precision: 0.6234\n",
      "Epoch 16: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8967 - precision: 0.6243 - val_loss: 1.0225 - val_precision: 0.6159\n",
      "Epoch 17/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8891 - precision: 0.6241\n",
      "Epoch 17: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8876 - precision: 0.6243 - val_loss: 1.0266 - val_precision: 0.6165\n",
      "Epoch 18/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8899 - precision: 0.6227\n",
      "Epoch 18: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8901 - precision: 0.6219 - val_loss: 1.0048 - val_precision: 0.6275\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8790 - precision: 0.6237\n",
      "Epoch 19: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8833 - precision: 0.6237 - val_loss: 1.0767 - val_precision: 0.5949\n",
      "Epoch 20/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8797 - precision: 0.6245\n",
      "Epoch 20: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8784 - precision: 0.6242 - val_loss: 1.0145 - val_precision: 0.6151\n",
      "Epoch 21/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8630 - precision: 0.6273\n",
      "Epoch 21: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8661 - precision: 0.6269 - val_loss: 1.0082 - val_precision: 0.6277\n",
      "Epoch 22/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8676 - precision: 0.6276\n",
      "Epoch 22: val_loss did not improve from 0.99974\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8695 - precision: 0.6257 - val_loss: 1.0059 - val_precision: 0.6307\n",
      "Epoch 22: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 0.9251 - precision: 0.6408\n",
      "Combinación 59 = (True, False, False, 128, 0.5) \n",
      " precision train: [0.9250839352607727, 0.6408184170722961]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 61: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.5393 - precision: 0.6490  \n",
      "Epoch 1: val_loss improved from inf to 1.37224, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 10s 8ms/step - loss: 1.5392 - precision: 0.6445 - val_loss: 1.3722 - val_precision: 0.6304\n",
      "Epoch 2/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.3119 - precision: 0.6269\n",
      "Epoch 2: val_loss improved from 1.37224 to 1.23854, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3093 - precision: 0.6280 - val_loss: 1.2385 - val_precision: 0.6534\n",
      "Epoch 3/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2241 - precision: 0.6427\n",
      "Epoch 3: val_loss improved from 1.23854 to 1.20494, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2241 - precision: 0.6427 - val_loss: 1.2049 - val_precision: 0.6946\n",
      "Epoch 4/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1737 - precision: 0.6260\n",
      "Epoch 4: val_loss improved from 1.20494 to 1.16999, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1744 - precision: 0.6250 - val_loss: 1.1700 - val_precision: 0.6638\n",
      "Epoch 5/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.1401 - precision: 0.6198\n",
      "Epoch 5: val_loss improved from 1.16999 to 1.14483, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1380 - precision: 0.6169 - val_loss: 1.1448 - val_precision: 0.6406\n",
      "Epoch 6/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1143 - precision: 0.6074\n",
      "Epoch 6: val_loss improved from 1.14483 to 1.13488, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1097 - precision: 0.6092 - val_loss: 1.1349 - val_precision: 0.6232\n",
      "Epoch 7/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0850 - precision: 0.6008\n",
      "Epoch 7: val_loss improved from 1.13488 to 1.10877, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0870 - precision: 0.6000 - val_loss: 1.1088 - val_precision: 0.6276\n",
      "Epoch 8/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0746 - precision: 0.5998\n",
      "Epoch 8: val_loss improved from 1.10877 to 1.10798, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0737 - precision: 0.6002 - val_loss: 1.1080 - val_precision: 0.6302\n",
      "Epoch 9/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0583 - precision: 0.5999\n",
      "Epoch 9: val_loss improved from 1.10798 to 1.10437, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0613 - precision: 0.5986 - val_loss: 1.1044 - val_precision: 0.6188\n",
      "Epoch 10/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0512 - precision: 0.6057\n",
      "Epoch 10: val_loss did not improve from 1.10437\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0526 - precision: 0.6068 - val_loss: 1.1071 - val_precision: 0.6095\n",
      "Epoch 11/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0391 - precision: 0.6043\n",
      "Epoch 11: val_loss improved from 1.10437 to 1.08718, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0422 - precision: 0.6029 - val_loss: 1.0872 - val_precision: 0.6265\n",
      "Epoch 12/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0428 - precision: 0.6014\n",
      "Epoch 12: val_loss did not improve from 1.08718\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0413 - precision: 0.6033 - val_loss: 1.0973 - val_precision: 0.6129\n",
      "Epoch 13/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0328 - precision: 0.6094\n",
      "Epoch 13: val_loss did not improve from 1.08718\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0307 - precision: 0.6100 - val_loss: 1.0880 - val_precision: 0.6200\n",
      "Epoch 14/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0355 - precision: 0.6075\n",
      "Epoch 14: val_loss did not improve from 1.08718\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0369 - precision: 0.6063 - val_loss: 1.0914 - val_precision: 0.6210\n",
      "Epoch 15/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0169 - precision: 0.6114\n",
      "Epoch 15: val_loss improved from 1.08718 to 1.08341, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0226 - precision: 0.6097 - val_loss: 1.0834 - val_precision: 0.6255\n",
      "Epoch 16/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0266 - precision: 0.6094\n",
      "Epoch 16: val_loss did not improve from 1.08341\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0268 - precision: 0.6084 - val_loss: 1.0835 - val_precision: 0.6231\n",
      "Epoch 17/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0209 - precision: 0.6086\n",
      "Epoch 17: val_loss did not improve from 1.08341\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0199 - precision: 0.6110 - val_loss: 1.0975 - val_precision: 0.6084\n",
      "Epoch 18/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0113 - precision: 0.6120\n",
      "Epoch 18: val_loss did not improve from 1.08341\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0113 - precision: 0.6120 - val_loss: 1.0867 - val_precision: 0.6212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0114 - precision: 0.6125\n",
      "Epoch 19: val_loss did not improve from 1.08341\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0148 - precision: 0.6110 - val_loss: 1.0846 - val_precision: 0.6192\n",
      "Epoch 20/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0101 - precision: 0.6133\n",
      "Epoch 20: val_loss improved from 1.08341 to 1.08110, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0101 - precision: 0.6133 - val_loss: 1.0811 - val_precision: 0.6218\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0040 - precision: 0.6100\n",
      "Epoch 21: val_loss improved from 1.08110 to 1.07705, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0046 - precision: 0.6098 - val_loss: 1.0770 - val_precision: 0.6215\n",
      "Epoch 22/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9991 - precision: 0.6121\n",
      "Epoch 22: val_loss improved from 1.07705 to 1.07008, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0009 - precision: 0.6121 - val_loss: 1.0701 - val_precision: 0.6236\n",
      "Epoch 23/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0037 - precision: 0.6112\n",
      "Epoch 23: val_loss improved from 1.07008 to 1.06322, saving model to model_ent61.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0007 - precision: 0.6125 - val_loss: 1.0632 - val_precision: 0.6338\n",
      "Epoch 24/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9938 - precision: 0.6169\n",
      "Epoch 24: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9912 - precision: 0.6162 - val_loss: 1.0721 - val_precision: 0.6192\n",
      "Epoch 25/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9974 - precision: 0.6113\n",
      "Epoch 25: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9961 - precision: 0.6118 - val_loss: 1.0709 - val_precision: 0.6245\n",
      "Epoch 26/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9883 - precision: 0.6146\n",
      "Epoch 26: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9917 - precision: 0.6143 - val_loss: 1.0732 - val_precision: 0.6219\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9896 - precision: 0.6153\n",
      "Epoch 27: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9904 - precision: 0.6144 - val_loss: 1.0800 - val_precision: 0.6167\n",
      "Epoch 28/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9855 - precision: 0.6202\n",
      "Epoch 28: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9884 - precision: 0.6194 - val_loss: 1.0875 - val_precision: 0.6165\n",
      "Epoch 29/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9842 - precision: 0.6170\n",
      "Epoch 29: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9818 - precision: 0.6180 - val_loss: 1.0836 - val_precision: 0.6155\n",
      "Epoch 30/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9847 - precision: 0.6228\n",
      "Epoch 30: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9842 - precision: 0.6207 - val_loss: 1.0916 - val_precision: 0.6036\n",
      "Epoch 31/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9809 - precision: 0.6092\n",
      "Epoch 31: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9809 - precision: 0.6092 - val_loss: 1.0840 - val_precision: 0.6141\n",
      "Epoch 32/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9736 - precision: 0.6178\n",
      "Epoch 32: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9731 - precision: 0.6169 - val_loss: 1.0770 - val_precision: 0.6222\n",
      "Epoch 33/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9707 - precision: 0.6135\n",
      "Epoch 33: val_loss did not improve from 1.06322\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9653 - precision: 0.6154 - val_loss: 1.0787 - val_precision: 0.6152\n",
      "Epoch 33: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0357 - precision: 0.6230\n",
      "Combinación 60 = (False, True, True, 8, 0.1) \n",
      " precision train: [1.035747766494751, 0.6229641437530518]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 62: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.5630 - precision: 1.0000    \n",
      "Epoch 1: val_loss improved from inf to 1.40259, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 7s 8ms/step - loss: 1.5611 - precision: 1.0000 - val_loss: 1.4026 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3932 - precision: 0.6165\n",
      "Epoch 2: val_loss improved from 1.40259 to 1.29804, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3934 - precision: 0.6200 - val_loss: 1.2980 - val_precision: 0.7079\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3176 - precision: 0.6591\n",
      "Epoch 3: val_loss improved from 1.29804 to 1.24228, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3185 - precision: 0.6582 - val_loss: 1.2423 - val_precision: 0.6773\n",
      "Epoch 4/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2829 - precision: 0.6677\n",
      "Epoch 4: val_loss improved from 1.24228 to 1.22091, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2785 - precision: 0.6677 - val_loss: 1.2209 - val_precision: 0.6874\n",
      "Epoch 5/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2523 - precision: 0.6709\n",
      "Epoch 5: val_loss improved from 1.22091 to 1.19844, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2493 - precision: 0.6687 - val_loss: 1.1984 - val_precision: 0.6868\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2168 - precision: 0.6612\n",
      "Epoch 6: val_loss improved from 1.19844 to 1.16791, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2160 - precision: 0.6615 - val_loss: 1.1679 - val_precision: 0.6765\n",
      "Epoch 7/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1809 - precision: 0.6613\n",
      "Epoch 7: val_loss improved from 1.16791 to 1.14068, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1785 - precision: 0.6576 - val_loss: 1.1407 - val_precision: 0.6533\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1626 - precision: 0.6315\n",
      "Epoch 8: val_loss improved from 1.14068 to 1.12401, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1622 - precision: 0.6319 - val_loss: 1.1240 - val_precision: 0.6503\n",
      "Epoch 9/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1290 - precision: 0.6315\n",
      "Epoch 9: val_loss improved from 1.12401 to 1.11193, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1325 - precision: 0.6341 - val_loss: 1.1119 - val_precision: 0.6526\n",
      "Epoch 10/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1326 - precision: 0.6224\n",
      "Epoch 10: val_loss did not improve from 1.11193\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1319 - precision: 0.6232 - val_loss: 1.1142 - val_precision: 0.6377\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1235 - precision: 0.6292\n",
      "Epoch 11: val_loss improved from 1.11193 to 1.10096, saving model to model_ent62.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1234 - precision: 0.6293 - val_loss: 1.1010 - val_precision: 0.6383\n",
      "Epoch 12/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1171 - precision: 0.6214\n",
      "Epoch 12: val_loss improved from 1.10096 to 1.09363, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1175 - precision: 0.6205 - val_loss: 1.0936 - val_precision: 0.6384\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1034 - precision: 0.6087\n",
      "Epoch 13: val_loss did not improve from 1.09363\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1009 - precision: 0.6099 - val_loss: 1.0946 - val_precision: 0.6347\n",
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0910 - precision: 0.6097\n",
      "Epoch 14: val_loss improved from 1.09363 to 1.08738, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0911 - precision: 0.6096 - val_loss: 1.0874 - val_precision: 0.6255\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0836 - precision: 0.6046\n",
      "Epoch 15: val_loss improved from 1.08738 to 1.08287, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0836 - precision: 0.6046 - val_loss: 1.0829 - val_precision: 0.6239\n",
      "Epoch 16/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0799 - precision: 0.6073\n",
      "Epoch 16: val_loss did not improve from 1.08287\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0812 - precision: 0.6061 - val_loss: 1.0830 - val_precision: 0.6215\n",
      "Epoch 17/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0774 - precision: 0.6003\n",
      "Epoch 17: val_loss improved from 1.08287 to 1.07976, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0770 - precision: 0.6007 - val_loss: 1.0798 - val_precision: 0.6147\n",
      "Epoch 18/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0729 - precision: 0.6127\n",
      "Epoch 18: val_loss did not improve from 1.07976\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0712 - precision: 0.6101 - val_loss: 1.0925 - val_precision: 0.6063\n",
      "Epoch 19/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0779 - precision: 0.6026\n",
      "Epoch 19: val_loss did not improve from 1.07976\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0770 - precision: 0.6028 - val_loss: 1.0830 - val_precision: 0.6123\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0642 - precision: 0.6053\n",
      "Epoch 20: val_loss did not improve from 1.07976\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0649 - precision: 0.6050 - val_loss: 1.0872 - val_precision: 0.5978\n",
      "Epoch 21/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0652 - precision: 0.6010\n",
      "Epoch 21: val_loss did not improve from 1.07976\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0676 - precision: 0.5977 - val_loss: 1.0881 - val_precision: 0.6052\n",
      "Epoch 22/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0526 - precision: 0.6035\n",
      "Epoch 22: val_loss did not improve from 1.07976\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0531 - precision: 0.6007 - val_loss: 1.0915 - val_precision: 0.5961\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0544 - precision: 0.5981\n",
      "Epoch 23: val_loss improved from 1.07976 to 1.07954, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0530 - precision: 0.6008 - val_loss: 1.0795 - val_precision: 0.6092\n",
      "Epoch 24/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0537 - precision: 0.6003\n",
      "Epoch 24: val_loss did not improve from 1.07954\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0557 - precision: 0.5995 - val_loss: 1.0798 - val_precision: 0.6120\n",
      "Epoch 25/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0449 - precision: 0.6050\n",
      "Epoch 25: val_loss did not improve from 1.07954\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0489 - precision: 0.6039 - val_loss: 1.0818 - val_precision: 0.6092\n",
      "Epoch 26/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0605 - precision: 0.5995\n",
      "Epoch 26: val_loss improved from 1.07954 to 1.07857, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0586 - precision: 0.6002 - val_loss: 1.0786 - val_precision: 0.6139\n",
      "Epoch 27/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0493 - precision: 0.5985\n",
      "Epoch 27: val_loss did not improve from 1.07857\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0485 - precision: 0.6005 - val_loss: 1.0857 - val_precision: 0.6061\n",
      "Epoch 28/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0572 - precision: 0.5949\n",
      "Epoch 28: val_loss improved from 1.07857 to 1.07290, saving model to model_ent62.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0536 - precision: 0.5985 - val_loss: 1.0729 - val_precision: 0.6154\n",
      "Epoch 29/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0495 - precision: 0.6022\n",
      "Epoch 29: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0478 - precision: 0.6012 - val_loss: 1.0904 - val_precision: 0.5999\n",
      "Epoch 30/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0487 - precision: 0.6035\n",
      "Epoch 30: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0473 - precision: 0.6045 - val_loss: 1.0828 - val_precision: 0.6004\n",
      "Epoch 31/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0216 - precision: 0.6111\n",
      "Epoch 31: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0279 - precision: 0.6085 - val_loss: 1.0797 - val_precision: 0.6012\n",
      "Epoch 32/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0446 - precision: 0.5950\n",
      "Epoch 32: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0446 - precision: 0.5950 - val_loss: 1.0809 - val_precision: 0.6038\n",
      "Epoch 33/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0379 - precision: 0.6070\n",
      "Epoch 33: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0398 - precision: 0.6068 - val_loss: 1.0889 - val_precision: 0.5987\n",
      "Epoch 34/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0390 - precision: 0.5906\n",
      "Epoch 34: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0371 - precision: 0.5923 - val_loss: 1.0798 - val_precision: 0.6000\n",
      "Epoch 35/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0350 - precision: 0.6058\n",
      "Epoch 35: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0375 - precision: 0.6070 - val_loss: 1.0793 - val_precision: 0.6045\n",
      "Epoch 36/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0353 - precision: 0.6019\n",
      "Epoch 36: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0324 - precision: 0.6022 - val_loss: 1.0880 - val_precision: 0.5953\n",
      "Epoch 37/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0331 - precision: 0.6041\n",
      "Epoch 37: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0331 - precision: 0.6041 - val_loss: 1.0927 - val_precision: 0.5949\n",
      "Epoch 38/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0227 - precision: 0.5996\n",
      "Epoch 38: val_loss did not improve from 1.07290\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0253 - precision: 0.6018 - val_loss: 1.0879 - val_precision: 0.5968\n",
      "Epoch 38: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0518 - precision: 0.6062\n",
      "Combinación 61 = (False, True, True, 8, 0.25) \n",
      " precision train: [1.051838994026184, 0.60622638463974]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 63: \n",
      "\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.5840 - precision: 0.7500  \n",
      "Epoch 1: val_loss improved from inf to 1.47609, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 7s 8ms/step - loss: 1.5840 - precision: 0.7500 - val_loss: 1.4761 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.4242 - precision: 0.4803\n",
      "Epoch 2: val_loss improved from 1.47609 to 1.35220, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.4205 - precision: 0.4856 - val_loss: 1.3522 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.3755 - precision: 0.4446\n",
      "Epoch 3: val_loss improved from 1.35220 to 1.33762, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3742 - precision: 0.4456 - val_loss: 1.3376 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3600 - precision: 0.4527\n",
      "Epoch 4: val_loss improved from 1.33762 to 1.31951, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3604 - precision: 0.4517 - val_loss: 1.3195 - val_precision: 0.0000e+00\n",
      "Epoch 5/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.3568 - precision: 0.4599\n",
      "Epoch 5: val_loss improved from 1.31951 to 1.31729, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3561 - precision: 0.4528 - val_loss: 1.3173 - val_precision: 0.0000e+00\n",
      "Epoch 6/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.3423 - precision: 0.4826\n",
      "Epoch 6: val_loss improved from 1.31729 to 1.30959, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3386 - precision: 0.4915 - val_loss: 1.3096 - val_precision: 0.0000e+00\n",
      "Epoch 7/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.3310 - precision: 0.5273\n",
      "Epoch 7: val_loss improved from 1.30959 to 1.29985, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3321 - precision: 0.5296 - val_loss: 1.2999 - val_precision: 0.6916\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.3211 - precision: 0.5557\n",
      "Epoch 8: val_loss improved from 1.29985 to 1.28683, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3205 - precision: 0.5556 - val_loss: 1.2868 - val_precision: 0.7104\n",
      "Epoch 9/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.3211 - precision: 0.5572\n",
      "Epoch 9: val_loss did not improve from 1.28683\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3173 - precision: 0.5605 - val_loss: 1.2871 - val_precision: 0.6630\n",
      "Epoch 10/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.3166 - precision: 0.5742\n",
      "Epoch 10: val_loss improved from 1.28683 to 1.27459, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3156 - precision: 0.5764 - val_loss: 1.2746 - val_precision: 0.6918\n",
      "Epoch 11/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.3145 - precision: 0.5810\n",
      "Epoch 11: val_loss did not improve from 1.27459\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3137 - precision: 0.5832 - val_loss: 1.2755 - val_precision: 0.6906\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.3066 - precision: 0.5958\n",
      "Epoch 12: val_loss improved from 1.27459 to 1.27313, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3066 - precision: 0.5958 - val_loss: 1.2731 - val_precision: 0.6701\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3123 - precision: 0.6054\n",
      "Epoch 13: val_loss did not improve from 1.27313\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3108 - precision: 0.5985 - val_loss: 1.2750 - val_precision: 0.6807\n",
      "Epoch 14/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2973 - precision: 0.6070\n",
      "Epoch 14: val_loss did not improve from 1.27313\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2973 - precision: 0.6086 - val_loss: 1.2739 - val_precision: 0.6635\n",
      "Epoch 15/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2916 - precision: 0.5990\n",
      "Epoch 15: val_loss improved from 1.27313 to 1.26569, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2906 - precision: 0.5990 - val_loss: 1.2657 - val_precision: 0.6725\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2995 - precision: 0.6071\n",
      "Epoch 16: val_loss did not improve from 1.26569\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2974 - precision: 0.6093 - val_loss: 1.2664 - val_precision: 0.6699\n",
      "Epoch 17/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2861 - precision: 0.6105\n",
      "Epoch 17: val_loss did not improve from 1.26569\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2887 - precision: 0.6086 - val_loss: 1.2681 - val_precision: 0.6775\n",
      "Epoch 18/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2966 - precision: 0.6229\n",
      "Epoch 18: val_loss did not improve from 1.26569\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2949 - precision: 0.6251 - val_loss: 1.2672 - val_precision: 0.6651\n",
      "Epoch 19/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2939 - precision: 0.6249\n",
      "Epoch 19: val_loss improved from 1.26569 to 1.26416, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2945 - precision: 0.6244 - val_loss: 1.2642 - val_precision: 0.6748\n",
      "Epoch 20/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2940 - precision: 0.6234\n",
      "Epoch 20: val_loss did not improve from 1.26416\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2918 - precision: 0.6235 - val_loss: 1.2654 - val_precision: 0.6767\n",
      "Epoch 21/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2818 - precision: 0.6538\n",
      "Epoch 21: val_loss improved from 1.26416 to 1.26185, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2840 - precision: 0.6560 - val_loss: 1.2618 - val_precision: 0.6765\n",
      "Epoch 22/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.2879 - precision: 0.6172\n",
      "Epoch 22: val_loss did not improve from 1.26185\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2864 - precision: 0.6225 - val_loss: 1.2623 - val_precision: 0.6659\n",
      "Epoch 23/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2866 - precision: 0.6227\n",
      "Epoch 23: val_loss improved from 1.26185 to 1.25726, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2824 - precision: 0.6209 - val_loss: 1.2573 - val_precision: 0.6732\n",
      "Epoch 24/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2842 - precision: 0.6391\n",
      "Epoch 24: val_loss did not improve from 1.25726\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2803 - precision: 0.6450 - val_loss: 1.2587 - val_precision: 0.6739\n",
      "Epoch 25/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2864 - precision: 0.6150\n",
      "Epoch 25: val_loss did not improve from 1.25726\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2889 - precision: 0.6149 - val_loss: 1.2606 - val_precision: 0.6674\n",
      "Epoch 26/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2853 - precision: 0.6316\n",
      "Epoch 26: val_loss did not improve from 1.25726\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2851 - precision: 0.6304 - val_loss: 1.2593 - val_precision: 0.6675\n",
      "Epoch 27/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2836 - precision: 0.6451\n",
      "Epoch 27: val_loss did not improve from 1.25726\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2823 - precision: 0.6437 - val_loss: 1.2614 - val_precision: 0.6757\n",
      "Epoch 28/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.2824 - precision: 0.6306\n",
      "Epoch 28: val_loss did not improve from 1.25726\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2777 - precision: 0.6331 - val_loss: 1.2669 - val_precision: 0.6831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2721 - precision: 0.6387\n",
      "Epoch 29: val_loss did not improve from 1.25726\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2754 - precision: 0.6349 - val_loss: 1.2622 - val_precision: 0.6755\n",
      "Epoch 30/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2761 - precision: 0.6445\n",
      "Epoch 30: val_loss improved from 1.25726 to 1.25611, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2727 - precision: 0.6461 - val_loss: 1.2561 - val_precision: 0.6690\n",
      "Epoch 31/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2765 - precision: 0.6295\n",
      "Epoch 31: val_loss improved from 1.25611 to 1.25234, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2716 - precision: 0.6349 - val_loss: 1.2523 - val_precision: 0.6630\n",
      "Epoch 32/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2705 - precision: 0.6339\n",
      "Epoch 32: val_loss did not improve from 1.25234\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2706 - precision: 0.6327 - val_loss: 1.2610 - val_precision: 0.6741\n",
      "Epoch 33/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2710 - precision: 0.6422\n",
      "Epoch 33: val_loss did not improve from 1.25234\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2708 - precision: 0.6423 - val_loss: 1.2527 - val_precision: 0.6691\n",
      "Epoch 34/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2694 - precision: 0.6521\n",
      "Epoch 34: val_loss did not improve from 1.25234\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2694 - precision: 0.6521 - val_loss: 1.2539 - val_precision: 0.6732\n",
      "Epoch 35/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2767 - precision: 0.6486\n",
      "Epoch 35: val_loss did not improve from 1.25234\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2749 - precision: 0.6522 - val_loss: 1.2533 - val_precision: 0.6698\n",
      "Epoch 36/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2782 - precision: 0.6302\n",
      "Epoch 36: val_loss did not improve from 1.25234\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2740 - precision: 0.6336 - val_loss: 1.2552 - val_precision: 0.6725\n",
      "Epoch 37/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2640 - precision: 0.6471\n",
      "Epoch 37: val_loss improved from 1.25234 to 1.24885, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2664 - precision: 0.6446 - val_loss: 1.2489 - val_precision: 0.6727\n",
      "Epoch 38/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2695 - precision: 0.6410\n",
      "Epoch 38: val_loss did not improve from 1.24885\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2663 - precision: 0.6428 - val_loss: 1.2537 - val_precision: 0.6713\n",
      "Epoch 39/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2690 - precision: 0.6513\n",
      "Epoch 39: val_loss did not improve from 1.24885\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2690 - precision: 0.6513 - val_loss: 1.2504 - val_precision: 0.6682\n",
      "Epoch 40/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2665 - precision: 0.6447\n",
      "Epoch 40: val_loss did not improve from 1.24885\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2699 - precision: 0.6430 - val_loss: 1.2542 - val_precision: 0.6763\n",
      "Epoch 41/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2625 - precision: 0.6377\n",
      "Epoch 41: val_loss did not improve from 1.24885\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2625 - precision: 0.6377 - val_loss: 1.2519 - val_precision: 0.6699\n",
      "Epoch 42/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2631 - precision: 0.6550\n",
      "Epoch 42: val_loss improved from 1.24885 to 1.24877, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2641 - precision: 0.6524 - val_loss: 1.2488 - val_precision: 0.6716\n",
      "Epoch 43/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2580 - precision: 0.6444\n",
      "Epoch 43: val_loss did not improve from 1.24877\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2580 - precision: 0.6453 - val_loss: 1.2551 - val_precision: 0.6767\n",
      "Epoch 44/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2640 - precision: 0.6419\n",
      "Epoch 44: val_loss did not improve from 1.24877\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2642 - precision: 0.6417 - val_loss: 1.2490 - val_precision: 0.6739\n",
      "Epoch 45/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2647 - precision: 0.6127\n",
      "Epoch 45: val_loss did not improve from 1.24877\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2650 - precision: 0.6133 - val_loss: 1.2507 - val_precision: 0.6773\n",
      "Epoch 46/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2586 - precision: 0.6263\n",
      "Epoch 46: val_loss did not improve from 1.24877\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2590 - precision: 0.6250 - val_loss: 1.2510 - val_precision: 0.6659\n",
      "Epoch 47/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2635 - precision: 0.6162\n",
      "Epoch 47: val_loss did not improve from 1.24877\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2642 - precision: 0.6145 - val_loss: 1.2620 - val_precision: 0.6822\n",
      "Epoch 48/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2549 - precision: 0.6256\n",
      "Epoch 48: val_loss did not improve from 1.24877\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2536 - precision: 0.6268 - val_loss: 1.2545 - val_precision: 0.6714\n",
      "Epoch 49/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2637 - precision: 0.6085\n",
      "Epoch 49: val_loss improved from 1.24877 to 1.24814, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2627 - precision: 0.6056 - val_loss: 1.2481 - val_precision: 0.6628\n",
      "Epoch 50/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2596 - precision: 0.5941\n",
      "Epoch 50: val_loss improved from 1.24814 to 1.24337, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2585 - precision: 0.5965 - val_loss: 1.2434 - val_precision: 0.6614\n",
      "Epoch 51/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2531 - precision: 0.5951\n",
      "Epoch 51: val_loss improved from 1.24337 to 1.23572, saving model to model_ent63.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2562 - precision: 0.5934 - val_loss: 1.2357 - val_precision: 0.6690\n",
      "Epoch 52/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2466 - precision: 0.6135\n",
      "Epoch 52: val_loss did not improve from 1.23572\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2490 - precision: 0.6136 - val_loss: 1.2390 - val_precision: 0.6715\n",
      "Epoch 53/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2573 - precision: 0.5880\n",
      "Epoch 53: val_loss did not improve from 1.23572\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2554 - precision: 0.5858 - val_loss: 1.2425 - val_precision: 0.6651\n",
      "Epoch 54/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2520 - precision: 0.6145\n",
      "Epoch 54: val_loss did not improve from 1.23572\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2546 - precision: 0.6149 - val_loss: 1.2422 - val_precision: 0.6732\n",
      "Epoch 55/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2575 - precision: 0.5777\n",
      "Epoch 55: val_loss did not improve from 1.23572\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2577 - precision: 0.5771 - val_loss: 1.2436 - val_precision: 0.6622\n",
      "Epoch 56/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2467 - precision: 0.5639\n",
      "Epoch 56: val_loss did not improve from 1.23572\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2478 - precision: 0.5649 - val_loss: 1.2431 - val_precision: 0.6644\n",
      "Epoch 57/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2488 - precision: 0.5763\n",
      "Epoch 57: val_loss did not improve from 1.23572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2459 - precision: 0.5782 - val_loss: 1.2472 - val_precision: 0.6714\n",
      "Epoch 58/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2510 - precision: 0.5833\n",
      "Epoch 58: val_loss did not improve from 1.23572\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2531 - precision: 0.5824 - val_loss: 1.2417 - val_precision: 0.6576\n",
      "Epoch 59/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2400 - precision: 0.5543\n",
      "Epoch 59: val_loss did not improve from 1.23572\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2400 - precision: 0.5543 - val_loss: 1.2451 - val_precision: 0.6628\n",
      "Epoch 60/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2610 - precision: 0.5631\n",
      "Epoch 60: val_loss did not improve from 1.23572\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2613 - precision: 0.5627 - val_loss: 1.2401 - val_precision: 0.6605\n",
      "Epoch 61/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2523 - precision: 0.5491\n",
      "Epoch 61: val_loss did not improve from 1.23572\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2536 - precision: 0.5480 - val_loss: 1.2417 - val_precision: 0.6590\n",
      "Epoch 61: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.2230 - precision: 0.6652\n",
      "Combinación 62 = (False, True, True, 8, 0.5) \n",
      " precision train: [1.2229863405227661, 0.6651725769042969]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 64: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.4732 - precision: 0.6035 \n",
      "Epoch 1: val_loss improved from inf to 1.25436, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.4641 - precision: 0.5955 - val_loss: 1.2544 - val_precision: 0.5848\n",
      "Epoch 2/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1158 - precision: 0.5967\n",
      "Epoch 2: val_loss improved from 1.25436 to 1.14072, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1138 - precision: 0.5989 - val_loss: 1.1407 - val_precision: 0.6027\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0528 - precision: 0.5870\n",
      "Epoch 3: val_loss improved from 1.14072 to 1.12457, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0524 - precision: 0.5877 - val_loss: 1.1246 - val_precision: 0.5808\n",
      "Epoch 4/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0253 - precision: 0.5889\n",
      "Epoch 4: val_loss improved from 1.12457 to 1.08986, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0297 - precision: 0.5861 - val_loss: 1.0899 - val_precision: 0.6018\n",
      "Epoch 5/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0156 - precision: 0.5936\n",
      "Epoch 5: val_loss improved from 1.08986 to 1.08562, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0165 - precision: 0.5956 - val_loss: 1.0856 - val_precision: 0.6035\n",
      "Epoch 6/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0082 - precision: 0.5954\n",
      "Epoch 6: val_loss improved from 1.08562 to 1.07911, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0078 - precision: 0.5953 - val_loss: 1.0791 - val_precision: 0.6039\n",
      "Epoch 7/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0031 - precision: 0.5972\n",
      "Epoch 7: val_loss improved from 1.07911 to 1.06944, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0062 - precision: 0.5965 - val_loss: 1.0694 - val_precision: 0.6150\n",
      "Epoch 8/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9896 - precision: 0.6065\n",
      "Epoch 8: val_loss did not improve from 1.06944\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9889 - precision: 0.6066 - val_loss: 1.0765 - val_precision: 0.6094\n",
      "Epoch 9/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9890 - precision: 0.6040\n",
      "Epoch 9: val_loss improved from 1.06944 to 1.06731, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9895 - precision: 0.6041 - val_loss: 1.0673 - val_precision: 0.6133\n",
      "Epoch 10/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9730 - precision: 0.6047\n",
      "Epoch 10: val_loss improved from 1.06731 to 1.05681, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9743 - precision: 0.6045 - val_loss: 1.0568 - val_precision: 0.6123\n",
      "Epoch 11/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9705 - precision: 0.6098\n",
      "Epoch 11: val_loss did not improve from 1.05681\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9698 - precision: 0.6103 - val_loss: 1.0632 - val_precision: 0.6193\n",
      "Epoch 12/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9681 - precision: 0.6081\n",
      "Epoch 12: val_loss improved from 1.05681 to 1.04942, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9673 - precision: 0.6088 - val_loss: 1.0494 - val_precision: 0.6239\n",
      "Epoch 13/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9631 - precision: 0.6096\n",
      "Epoch 13: val_loss did not improve from 1.04942\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9605 - precision: 0.6110 - val_loss: 1.0584 - val_precision: 0.6135\n",
      "Epoch 14/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9564 - precision: 0.6215\n",
      "Epoch 14: val_loss improved from 1.04942 to 1.04386, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9553 - precision: 0.6185 - val_loss: 1.0439 - val_precision: 0.6229\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9526 - precision: 0.6095\n",
      "Epoch 15: val_loss did not improve from 1.04386\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9526 - precision: 0.6095 - val_loss: 1.0482 - val_precision: 0.6140\n",
      "Epoch 16/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9449 - precision: 0.6131\n",
      "Epoch 16: val_loss improved from 1.04386 to 1.03968, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9444 - precision: 0.6131 - val_loss: 1.0397 - val_precision: 0.6209\n",
      "Epoch 17/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9413 - precision: 0.6132\n",
      "Epoch 17: val_loss did not improve from 1.03968\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9419 - precision: 0.6131 - val_loss: 1.0421 - val_precision: 0.6190\n",
      "Epoch 18/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9265 - precision: 0.6143\n",
      "Epoch 18: val_loss improved from 1.03968 to 1.03635, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9292 - precision: 0.6134 - val_loss: 1.0363 - val_precision: 0.6225\n",
      "Epoch 19/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9309 - precision: 0.6135\n",
      "Epoch 19: val_loss did not improve from 1.03635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9309 - precision: 0.6135 - val_loss: 1.0389 - val_precision: 0.6204\n",
      "Epoch 20/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9198 - precision: 0.6184\n",
      "Epoch 20: val_loss did not improve from 1.03635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9200 - precision: 0.6168 - val_loss: 1.0429 - val_precision: 0.6152\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9209 - precision: 0.6225\n",
      "Epoch 21: val_loss did not improve from 1.03635\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9208 - precision: 0.6215 - val_loss: 1.0502 - val_precision: 0.6095\n",
      "Epoch 22/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9192 - precision: 0.6127\n",
      "Epoch 22: val_loss improved from 1.03635 to 1.03444, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9206 - precision: 0.6144 - val_loss: 1.0344 - val_precision: 0.6143\n",
      "Epoch 23/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9150 - precision: 0.6204\n",
      "Epoch 23: val_loss did not improve from 1.03444\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9137 - precision: 0.6204 - val_loss: 1.0525 - val_precision: 0.6058\n",
      "Epoch 24/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9011 - precision: 0.6180\n",
      "Epoch 24: val_loss did not improve from 1.03444\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9046 - precision: 0.6163 - val_loss: 1.0350 - val_precision: 0.6206\n",
      "Epoch 25/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9042 - precision: 0.6168\n",
      "Epoch 25: val_loss did not improve from 1.03444\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9035 - precision: 0.6179 - val_loss: 1.0348 - val_precision: 0.6143\n",
      "Epoch 26/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8972 - precision: 0.6206\n",
      "Epoch 26: val_loss did not improve from 1.03444\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8975 - precision: 0.6209 - val_loss: 1.0499 - val_precision: 0.6076\n",
      "Epoch 27/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9044 - precision: 0.6167\n",
      "Epoch 27: val_loss improved from 1.03444 to 1.02637, saving model to model_ent64.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9036 - precision: 0.6168 - val_loss: 1.0264 - val_precision: 0.6179\n",
      "Epoch 28/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8919 - precision: 0.6262\n",
      "Epoch 28: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8922 - precision: 0.6236 - val_loss: 1.0367 - val_precision: 0.6184\n",
      "Epoch 29/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8996 - precision: 0.6240\n",
      "Epoch 29: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8980 - precision: 0.6254 - val_loss: 1.0347 - val_precision: 0.6174\n",
      "Epoch 30/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8925 - precision: 0.6238\n",
      "Epoch 30: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8933 - precision: 0.6236 - val_loss: 1.0430 - val_precision: 0.6089\n",
      "Epoch 31/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8931 - precision: 0.6207\n",
      "Epoch 31: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8931 - precision: 0.6207 - val_loss: 1.0292 - val_precision: 0.6226\n",
      "Epoch 32/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8788 - precision: 0.6277\n",
      "Epoch 32: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8802 - precision: 0.6268 - val_loss: 1.0528 - val_precision: 0.6071\n",
      "Epoch 33/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8788 - precision: 0.6304\n",
      "Epoch 33: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8801 - precision: 0.6296 - val_loss: 1.0433 - val_precision: 0.6091\n",
      "Epoch 34/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8721 - precision: 0.6261\n",
      "Epoch 34: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8742 - precision: 0.6259 - val_loss: 1.0373 - val_precision: 0.6097\n",
      "Epoch 35/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8723 - precision: 0.6238\n",
      "Epoch 35: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8723 - precision: 0.6238 - val_loss: 1.0389 - val_precision: 0.6096\n",
      "Epoch 36/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8742 - precision: 0.6271\n",
      "Epoch 36: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8747 - precision: 0.6251 - val_loss: 1.0449 - val_precision: 0.6121\n",
      "Epoch 37/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8613 - precision: 0.6331\n",
      "Epoch 37: val_loss did not improve from 1.02637\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8649 - precision: 0.6310 - val_loss: 1.0384 - val_precision: 0.6100\n",
      "Epoch 37: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9529 - precision: 0.6355\n",
      "Combinación 63 = (False, True, True, 16, 0.1) \n",
      " precision train: [0.9529058933258057, 0.6354847550392151]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 65: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.5001 - precision: 0.6415\n",
      "Epoch 1: val_loss improved from inf to 1.27320, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.4980 - precision: 0.6401 - val_loss: 1.2732 - val_precision: 0.6736\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2608 - precision: 0.6671\n",
      "Epoch 2: val_loss improved from 1.27320 to 1.18894, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2592 - precision: 0.6680 - val_loss: 1.1889 - val_precision: 0.6910\n",
      "Epoch 3/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1438 - precision: 0.6376\n",
      "Epoch 3: val_loss improved from 1.18894 to 1.12456, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1480 - precision: 0.6340 - val_loss: 1.1246 - val_precision: 0.6619\n",
      "Epoch 4/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0924 - precision: 0.6309\n",
      "Epoch 4: val_loss improved from 1.12456 to 1.11442, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0935 - precision: 0.6293 - val_loss: 1.1144 - val_precision: 0.6255\n",
      "Epoch 5/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0621 - precision: 0.5989\n",
      "Epoch 5: val_loss improved from 1.11442 to 1.08579, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0619 - precision: 0.5986 - val_loss: 1.0858 - val_precision: 0.6084\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0471 - precision: 0.5954\n",
      "Epoch 6: val_loss improved from 1.08579 to 1.07909, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0468 - precision: 0.5956 - val_loss: 1.0791 - val_precision: 0.6024\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0389 - precision: 0.5957\n",
      "Epoch 7: val_loss did not improve from 1.07909\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0392 - precision: 0.5952 - val_loss: 1.0805 - val_precision: 0.6029\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0263 - precision: 0.5970\n",
      "Epoch 8: val_loss improved from 1.07909 to 1.07276, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0295 - precision: 0.5963 - val_loss: 1.0728 - val_precision: 0.5956\n",
      "Epoch 9/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0260 - precision: 0.5924\n",
      "Epoch 9: val_loss improved from 1.07276 to 1.06507, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0260 - precision: 0.5924 - val_loss: 1.0651 - val_precision: 0.6098\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0135 - precision: 0.6000\n",
      "Epoch 10: val_loss did not improve from 1.06507\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0135 - precision: 0.6000 - val_loss: 1.0658 - val_precision: 0.6061\n",
      "Epoch 11/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/236 [============================>.] - ETA: 0s - loss: 1.0024 - precision: 0.5994\n",
      "Epoch 11: val_loss improved from 1.06507 to 1.05836, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0024 - precision: 0.6000 - val_loss: 1.0584 - val_precision: 0.6045\n",
      "Epoch 12/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0032 - precision: 0.6031\n",
      "Epoch 12: val_loss did not improve from 1.05836\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0049 - precision: 0.6024 - val_loss: 1.0684 - val_precision: 0.6008\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9956 - precision: 0.6000\n",
      "Epoch 13: val_loss improved from 1.05836 to 1.05789, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9961 - precision: 0.5992 - val_loss: 1.0579 - val_precision: 0.6066\n",
      "Epoch 14/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0053 - precision: 0.5983\n",
      "Epoch 14: val_loss improved from 1.05789 to 1.05388, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0008 - precision: 0.5990 - val_loss: 1.0539 - val_precision: 0.6089\n",
      "Epoch 15/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9867 - precision: 0.6115\n",
      "Epoch 15: val_loss improved from 1.05388 to 1.05248, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9888 - precision: 0.6097 - val_loss: 1.0525 - val_precision: 0.6068\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9905 - precision: 0.6006\n",
      "Epoch 16: val_loss improved from 1.05248 to 1.05177, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9918 - precision: 0.5999 - val_loss: 1.0518 - val_precision: 0.6077\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9901 - precision: 0.6032\n",
      "Epoch 17: val_loss improved from 1.05177 to 1.05109, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9899 - precision: 0.6029 - val_loss: 1.0511 - val_precision: 0.6137\n",
      "Epoch 18/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9890 - precision: 0.5991\n",
      "Epoch 18: val_loss did not improve from 1.05109\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9918 - precision: 0.6001 - val_loss: 1.0512 - val_precision: 0.6123\n",
      "Epoch 19/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9798 - precision: 0.6017\n",
      "Epoch 19: val_loss did not improve from 1.05109\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9795 - precision: 0.6035 - val_loss: 1.0555 - val_precision: 0.6051\n",
      "Epoch 20/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9832 - precision: 0.6068\n",
      "Epoch 20: val_loss did not improve from 1.05109\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9826 - precision: 0.6080 - val_loss: 1.0519 - val_precision: 0.6116\n",
      "Epoch 21/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9643 - precision: 0.6157\n",
      "Epoch 21: val_loss did not improve from 1.05109\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9651 - precision: 0.6154 - val_loss: 1.0549 - val_precision: 0.6074\n",
      "Epoch 22/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9644 - precision: 0.6142\n",
      "Epoch 22: val_loss improved from 1.05109 to 1.04920, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9648 - precision: 0.6145 - val_loss: 1.0492 - val_precision: 0.6139\n",
      "Epoch 23/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9691 - precision: 0.6093\n",
      "Epoch 23: val_loss did not improve from 1.04920\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9697 - precision: 0.6088 - val_loss: 1.0545 - val_precision: 0.6107\n",
      "Epoch 24/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9645 - precision: 0.6059\n",
      "Epoch 24: val_loss did not improve from 1.04920\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9655 - precision: 0.6075 - val_loss: 1.0528 - val_precision: 0.6020\n",
      "Epoch 25/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9658 - precision: 0.6071\n",
      "Epoch 25: val_loss did not improve from 1.04920\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9648 - precision: 0.6080 - val_loss: 1.0518 - val_precision: 0.6030\n",
      "Epoch 26/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9600 - precision: 0.6109\n",
      "Epoch 26: val_loss improved from 1.04920 to 1.04295, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9582 - precision: 0.6106 - val_loss: 1.0430 - val_precision: 0.6223\n",
      "Epoch 27/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9490 - precision: 0.6149\n",
      "Epoch 27: val_loss did not improve from 1.04295\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9517 - precision: 0.6140 - val_loss: 1.0592 - val_precision: 0.5983\n",
      "Epoch 28/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9537 - precision: 0.6095\n",
      "Epoch 28: val_loss did not improve from 1.04295\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9530 - precision: 0.6106 - val_loss: 1.0577 - val_precision: 0.6080\n",
      "Epoch 29/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9561 - precision: 0.6151\n",
      "Epoch 29: val_loss did not improve from 1.04295\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9515 - precision: 0.6176 - val_loss: 1.0447 - val_precision: 0.6094\n",
      "Epoch 30/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9412 - precision: 0.6143\n",
      "Epoch 30: val_loss did not improve from 1.04295\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9416 - precision: 0.6147 - val_loss: 1.0523 - val_precision: 0.6061\n",
      "Epoch 31/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9607 - precision: 0.6136\n",
      "Epoch 31: val_loss improved from 1.04295 to 1.04101, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9590 - precision: 0.6149 - val_loss: 1.0410 - val_precision: 0.6121\n",
      "Epoch 32/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9509 - precision: 0.6188\n",
      "Epoch 32: val_loss did not improve from 1.04101\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9500 - precision: 0.6179 - val_loss: 1.0456 - val_precision: 0.6058\n",
      "Epoch 33/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9419 - precision: 0.6163\n",
      "Epoch 33: val_loss did not improve from 1.04101\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9479 - precision: 0.6158 - val_loss: 1.0423 - val_precision: 0.6103\n",
      "Epoch 34/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9429 - precision: 0.6130\n",
      "Epoch 34: val_loss improved from 1.04101 to 1.03704, saving model to model_ent65.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9438 - precision: 0.6134 - val_loss: 1.0370 - val_precision: 0.6138\n",
      "Epoch 35/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9406 - precision: 0.6236\n",
      "Epoch 35: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9431 - precision: 0.6216 - val_loss: 1.0387 - val_precision: 0.6105\n",
      "Epoch 36/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9424 - precision: 0.6186\n",
      "Epoch 36: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9420 - precision: 0.6177 - val_loss: 1.0473 - val_precision: 0.6028\n",
      "Epoch 37/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9320 - precision: 0.6228\n",
      "Epoch 37: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9332 - precision: 0.6230 - val_loss: 1.0382 - val_precision: 0.6120\n",
      "Epoch 38/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9351 - precision: 0.6174\n",
      "Epoch 38: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9355 - precision: 0.6185 - val_loss: 1.0470 - val_precision: 0.6065\n",
      "Epoch 39/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9193 - precision: 0.6177\n",
      "Epoch 39: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9209 - precision: 0.6172 - val_loss: 1.0448 - val_precision: 0.6033\n",
      "Epoch 40/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9273 - precision: 0.6175\n",
      "Epoch 40: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9280 - precision: 0.6163 - val_loss: 1.0517 - val_precision: 0.6068\n",
      "Epoch 41/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9212 - precision: 0.6232\n",
      "Epoch 41: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9229 - precision: 0.6214 - val_loss: 1.0417 - val_precision: 0.6070\n",
      "Epoch 42/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9232 - precision: 0.6216\n",
      "Epoch 42: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9241 - precision: 0.6220 - val_loss: 1.0475 - val_precision: 0.6081\n",
      "Epoch 43/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9227 - precision: 0.6254\n",
      "Epoch 43: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9264 - precision: 0.6224 - val_loss: 1.0487 - val_precision: 0.6056\n",
      "Epoch 44/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9200 - precision: 0.6210\n",
      "Epoch 44: val_loss did not improve from 1.03704\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9256 - precision: 0.6184 - val_loss: 1.0404 - val_precision: 0.6162\n",
      "Epoch 44: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9739 - precision: 0.6276\n",
      "Combinación 64 = (False, True, True, 16, 0.25) \n",
      " precision train: [0.97392338514328, 0.6276066303253174]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 66: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.5736 - precision: 0.4848  \n",
      "Epoch 1: val_loss improved from inf to 1.39435, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.5736 - precision: 0.4848 - val_loss: 1.3944 - val_precision: 0.6753\n",
      "Epoch 2/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.3875 - precision: 0.6151\n",
      "Epoch 2: val_loss improved from 1.39435 to 1.25869, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3843 - precision: 0.6158 - val_loss: 1.2587 - val_precision: 0.6899\n",
      "Epoch 3/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.3200 - precision: 0.6356\n",
      "Epoch 3: val_loss improved from 1.25869 to 1.21499, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3187 - precision: 0.6394 - val_loss: 1.2150 - val_precision: 0.6840\n",
      "Epoch 4/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2798 - precision: 0.6501\n",
      "Epoch 4: val_loss improved from 1.21499 to 1.19484, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2810 - precision: 0.6482 - val_loss: 1.1948 - val_precision: 0.6808\n",
      "Epoch 5/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2477 - precision: 0.6582\n",
      "Epoch 5: val_loss improved from 1.19484 to 1.16415, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2482 - precision: 0.6560 - val_loss: 1.1641 - val_precision: 0.6963\n",
      "Epoch 6/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2155 - precision: 0.6458\n",
      "Epoch 6: val_loss improved from 1.16415 to 1.13739, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2192 - precision: 0.6417 - val_loss: 1.1374 - val_precision: 0.6768\n",
      "Epoch 7/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1978 - precision: 0.6424\n",
      "Epoch 7: val_loss improved from 1.13739 to 1.12984, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1944 - precision: 0.6408 - val_loss: 1.1298 - val_precision: 0.6506\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1763 - precision: 0.6216\n",
      "Epoch 8: val_loss improved from 1.12984 to 1.11462, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1773 - precision: 0.6217 - val_loss: 1.1146 - val_precision: 0.6554\n",
      "Epoch 9/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1591 - precision: 0.6170\n",
      "Epoch 9: val_loss improved from 1.11462 to 1.11072, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1579 - precision: 0.6171 - val_loss: 1.1107 - val_precision: 0.6474\n",
      "Epoch 10/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1556 - precision: 0.6144\n",
      "Epoch 10: val_loss improved from 1.11072 to 1.10142, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1555 - precision: 0.6138 - val_loss: 1.1014 - val_precision: 0.6440\n",
      "Epoch 11/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1467 - precision: 0.6059\n",
      "Epoch 11: val_loss improved from 1.10142 to 1.09885, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1467 - precision: 0.6059 - val_loss: 1.0988 - val_precision: 0.6405\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1425 - precision: 0.6021\n",
      "Epoch 12: val_loss improved from 1.09885 to 1.09247, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1435 - precision: 0.6017 - val_loss: 1.0925 - val_precision: 0.6412\n",
      "Epoch 13/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1409 - precision: 0.6006\n",
      "Epoch 13: val_loss did not improve from 1.09247\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1364 - precision: 0.6027 - val_loss: 1.0951 - val_precision: 0.6263\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1277 - precision: 0.6026\n",
      "Epoch 14: val_loss did not improve from 1.09247\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1281 - precision: 0.6027 - val_loss: 1.1031 - val_precision: 0.6152\n",
      "Epoch 15/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1237 - precision: 0.5958\n",
      "Epoch 15: val_loss did not improve from 1.09247\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1271 - precision: 0.5956 - val_loss: 1.1035 - val_precision: 0.6168\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1221 - precision: 0.5980\n",
      "Epoch 16: val_loss improved from 1.09247 to 1.09170, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1225 - precision: 0.5983 - val_loss: 1.0917 - val_precision: 0.6253\n",
      "Epoch 17/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1126 - precision: 0.6106\n",
      "Epoch 17: val_loss improved from 1.09170 to 1.09097, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1123 - precision: 0.6080 - val_loss: 1.0910 - val_precision: 0.6179\n",
      "Epoch 18/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1217 - precision: 0.5983\n",
      "Epoch 18: val_loss improved from 1.09097 to 1.09062, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1226 - precision: 0.5972 - val_loss: 1.0906 - val_precision: 0.6195\n",
      "Epoch 19/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1113 - precision: 0.6000\n",
      "Epoch 19: val_loss did not improve from 1.09062\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1125 - precision: 0.6014 - val_loss: 1.1093 - val_precision: 0.5997\n",
      "Epoch 20/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1174 - precision: 0.6048\n",
      "Epoch 20: val_loss did not improve from 1.09062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1196 - precision: 0.6021 - val_loss: 1.0916 - val_precision: 0.6140\n",
      "Epoch 21/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1051 - precision: 0.5935\n",
      "Epoch 21: val_loss improved from 1.09062 to 1.08556, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1070 - precision: 0.5937 - val_loss: 1.0856 - val_precision: 0.6164\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1035 - precision: 0.6072\n",
      "Epoch 22: val_loss did not improve from 1.08556\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1032 - precision: 0.6074 - val_loss: 1.0919 - val_precision: 0.6104\n",
      "Epoch 23/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0992 - precision: 0.5988\n",
      "Epoch 23: val_loss did not improve from 1.08556\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0993 - precision: 0.6021 - val_loss: 1.0898 - val_precision: 0.6031\n",
      "Epoch 24/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0990 - precision: 0.5965\n",
      "Epoch 24: val_loss did not improve from 1.08556\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0990 - precision: 0.5965 - val_loss: 1.0899 - val_precision: 0.6059\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0927 - precision: 0.6005\n",
      "Epoch 25: val_loss did not improve from 1.08556\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0956 - precision: 0.6007 - val_loss: 1.0876 - val_precision: 0.6105\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0995 - precision: 0.5913\n",
      "Epoch 26: val_loss improved from 1.08556 to 1.08417, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0995 - precision: 0.5913 - val_loss: 1.0842 - val_precision: 0.6067\n",
      "Epoch 27/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0961 - precision: 0.5967\n",
      "Epoch 27: val_loss did not improve from 1.08417\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0921 - precision: 0.5983 - val_loss: 1.0859 - val_precision: 0.6019\n",
      "Epoch 28/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0940 - precision: 0.5963\n",
      "Epoch 28: val_loss improved from 1.08417 to 1.08055, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0940 - precision: 0.5963 - val_loss: 1.0805 - val_precision: 0.6101\n",
      "Epoch 29/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0785 - precision: 0.6097\n",
      "Epoch 29: val_loss did not improve from 1.08055\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0789 - precision: 0.6065 - val_loss: 1.0876 - val_precision: 0.6060\n",
      "Epoch 30/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0851 - precision: 0.6058\n",
      "Epoch 30: val_loss did not improve from 1.08055\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0836 - precision: 0.6068 - val_loss: 1.0837 - val_precision: 0.6121\n",
      "Epoch 31/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0751 - precision: 0.6047\n",
      "Epoch 31: val_loss did not improve from 1.08055\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0776 - precision: 0.6055 - val_loss: 1.0932 - val_precision: 0.6093\n",
      "Epoch 32/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0749 - precision: 0.6077\n",
      "Epoch 32: val_loss did not improve from 1.08055\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0722 - precision: 0.6080 - val_loss: 1.0925 - val_precision: 0.5979\n",
      "Epoch 33/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0771 - precision: 0.5959\n",
      "Epoch 33: val_loss did not improve from 1.08055\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0782 - precision: 0.5948 - val_loss: 1.0922 - val_precision: 0.6042\n",
      "Epoch 34/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0827 - precision: 0.6005\n",
      "Epoch 34: val_loss did not improve from 1.08055\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0815 - precision: 0.6025 - val_loss: 1.0873 - val_precision: 0.6073\n",
      "Epoch 35/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0762 - precision: 0.6010\n",
      "Epoch 35: val_loss improved from 1.08055 to 1.07999, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0790 - precision: 0.6003 - val_loss: 1.0800 - val_precision: 0.6067\n",
      "Epoch 36/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0799 - precision: 0.6001\n",
      "Epoch 36: val_loss improved from 1.07999 to 1.07948, saving model to model_ent66.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0787 - precision: 0.6004 - val_loss: 1.0795 - val_precision: 0.6130\n",
      "Epoch 37/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0625 - precision: 0.6005\n",
      "Epoch 37: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0635 - precision: 0.5995 - val_loss: 1.0873 - val_precision: 0.6009\n",
      "Epoch 38/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0693 - precision: 0.6076\n",
      "Epoch 38: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0686 - precision: 0.6066 - val_loss: 1.0941 - val_precision: 0.6041\n",
      "Epoch 39/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0728 - precision: 0.5962\n",
      "Epoch 39: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0713 - precision: 0.5975 - val_loss: 1.0963 - val_precision: 0.6039\n",
      "Epoch 40/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0527 - precision: 0.6068\n",
      "Epoch 40: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0543 - precision: 0.6059 - val_loss: 1.0973 - val_precision: 0.6035\n",
      "Epoch 41/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0621 - precision: 0.6045\n",
      "Epoch 41: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0644 - precision: 0.6043 - val_loss: 1.0896 - val_precision: 0.5974\n",
      "Epoch 42/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0689 - precision: 0.6076\n",
      "Epoch 42: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0632 - precision: 0.6094 - val_loss: 1.0903 - val_precision: 0.5995\n",
      "Epoch 43/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0743 - precision: 0.6036\n",
      "Epoch 43: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0716 - precision: 0.6051 - val_loss: 1.0977 - val_precision: 0.5937\n",
      "Epoch 44/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0605 - precision: 0.6000\n",
      "Epoch 44: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0600 - precision: 0.5999 - val_loss: 1.0988 - val_precision: 0.5928\n",
      "Epoch 45/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0640 - precision: 0.6010\n",
      "Epoch 45: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0639 - precision: 0.6031 - val_loss: 1.0915 - val_precision: 0.5978\n",
      "Epoch 46/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0546 - precision: 0.6058\n",
      "Epoch 46: val_loss did not improve from 1.07948\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0541 - precision: 0.6061 - val_loss: 1.0890 - val_precision: 0.5947\n",
      "Epoch 46: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0548 - precision: 0.6021\n",
      "Combinación 65 = (False, True, True, 16, 0.5) \n",
      " precision train: [1.0547720193862915, 0.6020615696907043]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 67: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.3978 - precision: 0.6364\n",
      "Epoch 1: val_loss improved from inf to 1.21983, saving model to model_ent67.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.3857 - precision: 0.6419 - val_loss: 1.2198 - val_precision: 0.6748\n",
      "Epoch 2/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1558 - precision: 0.6398\n",
      "Epoch 2: val_loss improved from 1.21983 to 1.15297, saving model to model_ent67.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1571 - precision: 0.6382 - val_loss: 1.1530 - val_precision: 0.6187\n",
      "Epoch 3/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0459 - precision: 0.5989\n",
      "Epoch 3: val_loss improved from 1.15297 to 1.07747, saving model to model_ent67.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0461 - precision: 0.5984 - val_loss: 1.0775 - val_precision: 0.6168\n",
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0032 - precision: 0.5976\n",
      "Epoch 4: val_loss improved from 1.07747 to 1.05638, saving model to model_ent67.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0032 - precision: 0.5976 - val_loss: 1.0564 - val_precision: 0.6277\n",
      "Epoch 5/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9780 - precision: 0.6010\n",
      "Epoch 5: val_loss did not improve from 1.05638\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9786 - precision: 0.6011 - val_loss: 1.0623 - val_precision: 0.6047\n",
      "Epoch 6/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9707 - precision: 0.6018\n",
      "Epoch 6: val_loss improved from 1.05638 to 1.03836, saving model to model_ent67.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9699 - precision: 0.6037 - val_loss: 1.0384 - val_precision: 0.6213\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9577 - precision: 0.6057\n",
      "Epoch 7: val_loss did not improve from 1.03836\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9574 - precision: 0.6050 - val_loss: 1.0410 - val_precision: 0.6216\n",
      "Epoch 8/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9575 - precision: 0.6049\n",
      "Epoch 8: val_loss improved from 1.03836 to 1.03580, saving model to model_ent67.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9546 - precision: 0.6051 - val_loss: 1.0358 - val_precision: 0.6239\n",
      "Epoch 9/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9416 - precision: 0.6114\n",
      "Epoch 9: val_loss did not improve from 1.03580\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9416 - precision: 0.6114 - val_loss: 1.0455 - val_precision: 0.6206\n",
      "Epoch 10/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9379 - precision: 0.6116\n",
      "Epoch 10: val_loss did not improve from 1.03580\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9384 - precision: 0.6111 - val_loss: 1.0416 - val_precision: 0.6201\n",
      "Epoch 11/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9305 - precision: 0.6063\n",
      "Epoch 11: val_loss did not improve from 1.03580\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9309 - precision: 0.6081 - val_loss: 1.0369 - val_precision: 0.6245\n",
      "Epoch 12/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9186 - precision: 0.6172\n",
      "Epoch 12: val_loss did not improve from 1.03580\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9199 - precision: 0.6158 - val_loss: 1.0362 - val_precision: 0.6171\n",
      "Epoch 13/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9135 - precision: 0.6123\n",
      "Epoch 13: val_loss improved from 1.03580 to 1.03142, saving model to model_ent67.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9152 - precision: 0.6131 - val_loss: 1.0314 - val_precision: 0.6231\n",
      "Epoch 14/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9075 - precision: 0.6149\n",
      "Epoch 14: val_loss improved from 1.03142 to 1.02038, saving model to model_ent67.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9129 - precision: 0.6119 - val_loss: 1.0204 - val_precision: 0.6214\n",
      "Epoch 15/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9057 - precision: 0.6159\n",
      "Epoch 15: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9064 - precision: 0.6162 - val_loss: 1.0290 - val_precision: 0.6225\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9092 - precision: 0.6104\n",
      "Epoch 16: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9089 - precision: 0.6110 - val_loss: 1.0327 - val_precision: 0.6178\n",
      "Epoch 17/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8959 - precision: 0.6198\n",
      "Epoch 17: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8948 - precision: 0.6193 - val_loss: 1.0213 - val_precision: 0.6243\n",
      "Epoch 18/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8879 - precision: 0.6190\n",
      "Epoch 18: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8879 - precision: 0.6190 - val_loss: 1.0234 - val_precision: 0.6260\n",
      "Epoch 19/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8907 - precision: 0.6192\n",
      "Epoch 19: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8900 - precision: 0.6186 - val_loss: 1.0295 - val_precision: 0.6183\n",
      "Epoch 20/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8792 - precision: 0.6210\n",
      "Epoch 20: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8783 - precision: 0.6209 - val_loss: 1.0408 - val_precision: 0.6055\n",
      "Epoch 21/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8786 - precision: 0.6180\n",
      "Epoch 21: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8783 - precision: 0.6183 - val_loss: 1.0261 - val_precision: 0.6182\n",
      "Epoch 22/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8716 - precision: 0.6210\n",
      "Epoch 22: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8714 - precision: 0.6212 - val_loss: 1.0306 - val_precision: 0.6102\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8686 - precision: 0.6196\n",
      "Epoch 23: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8674 - precision: 0.6206 - val_loss: 1.0324 - val_precision: 0.6129\n",
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8598 - precision: 0.6227\n",
      "Epoch 24: val_loss did not improve from 1.02038\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8587 - precision: 0.6232 - val_loss: 1.0324 - val_precision: 0.6103\n",
      "Epoch 24: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9573 - precision: 0.6241\n",
      "Combinación 66 = (False, True, True, 32, 0.1) \n",
      " precision train: [0.9573251008987427, 0.6240847110748291]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 68: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.4318 - precision: 0.6638\n",
      "Epoch 1: val_loss improved from inf to 1.25346, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 8s 9ms/step - loss: 1.4296 - precision: 0.6611 - val_loss: 1.2535 - val_precision: 0.6986\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1751 - precision: 0.6426\n",
      "Epoch 2: val_loss improved from 1.25346 to 1.14325, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1745 - precision: 0.6418 - val_loss: 1.1432 - val_precision: 0.6172\n",
      "Epoch 3/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/236 [============================>.] - ETA: 0s - loss: 1.0520 - precision: 0.6003\n",
      "Epoch 3: val_loss improved from 1.14325 to 1.07782, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0528 - precision: 0.5999 - val_loss: 1.0778 - val_precision: 0.6086\n",
      "Epoch 4/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0275 - precision: 0.5984\n",
      "Epoch 4: val_loss improved from 1.07782 to 1.07109, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0286 - precision: 0.5978 - val_loss: 1.0711 - val_precision: 0.6099\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0166 - precision: 0.6032\n",
      "Epoch 5: val_loss did not improve from 1.07109\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0169 - precision: 0.6023 - val_loss: 1.0740 - val_precision: 0.6029\n",
      "Epoch 6/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0056 - precision: 0.5986\n",
      "Epoch 6: val_loss improved from 1.07109 to 1.05768, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0061 - precision: 0.5979 - val_loss: 1.0577 - val_precision: 0.6073\n",
      "Epoch 7/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9850 - precision: 0.5997\n",
      "Epoch 7: val_loss improved from 1.05768 to 1.05014, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9842 - precision: 0.6021 - val_loss: 1.0501 - val_precision: 0.6109\n",
      "Epoch 8/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9845 - precision: 0.6046\n",
      "Epoch 8: val_loss did not improve from 1.05014\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9855 - precision: 0.6040 - val_loss: 1.0532 - val_precision: 0.6118\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9746 - precision: 0.6091\n",
      "Epoch 9: val_loss improved from 1.05014 to 1.04951, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9749 - precision: 0.6092 - val_loss: 1.0495 - val_precision: 0.6146\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9692 - precision: 0.6099\n",
      "Epoch 10: val_loss did not improve from 1.04951\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9711 - precision: 0.6089 - val_loss: 1.0503 - val_precision: 0.6128\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9675 - precision: 0.6087\n",
      "Epoch 11: val_loss improved from 1.04951 to 1.04726, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9652 - precision: 0.6091 - val_loss: 1.0473 - val_precision: 0.6131\n",
      "Epoch 12/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9625 - precision: 0.6070\n",
      "Epoch 12: val_loss improved from 1.04726 to 1.03564, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9625 - precision: 0.6087 - val_loss: 1.0356 - val_precision: 0.6172\n",
      "Epoch 13/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9491 - precision: 0.6142\n",
      "Epoch 13: val_loss did not improve from 1.03564\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9523 - precision: 0.6124 - val_loss: 1.0412 - val_precision: 0.6171\n",
      "Epoch 14/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9518 - precision: 0.6134\n",
      "Epoch 14: val_loss did not improve from 1.03564\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9518 - precision: 0.6109 - val_loss: 1.0448 - val_precision: 0.6133\n",
      "Epoch 15/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9459 - precision: 0.6134\n",
      "Epoch 15: val_loss did not improve from 1.03564\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9449 - precision: 0.6146 - val_loss: 1.0422 - val_precision: 0.6165\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9401 - precision: 0.6116\n",
      "Epoch 16: val_loss improved from 1.03564 to 1.03299, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9382 - precision: 0.6127 - val_loss: 1.0330 - val_precision: 0.6239\n",
      "Epoch 17/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9391 - precision: 0.6152\n",
      "Epoch 17: val_loss improved from 1.03299 to 1.02648, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9385 - precision: 0.6147 - val_loss: 1.0265 - val_precision: 0.6162\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9323 - precision: 0.6097\n",
      "Epoch 18: val_loss did not improve from 1.02648\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9321 - precision: 0.6101 - val_loss: 1.0374 - val_precision: 0.6085\n",
      "Epoch 19/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9259 - precision: 0.6126\n",
      "Epoch 19: val_loss improved from 1.02648 to 1.02391, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9289 - precision: 0.6120 - val_loss: 1.0239 - val_precision: 0.6189\n",
      "Epoch 20/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9287 - precision: 0.6167\n",
      "Epoch 20: val_loss did not improve from 1.02391\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9279 - precision: 0.6177 - val_loss: 1.0315 - val_precision: 0.6155\n",
      "Epoch 21/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9218 - precision: 0.6156\n",
      "Epoch 21: val_loss did not improve from 1.02391\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9195 - precision: 0.6173 - val_loss: 1.0383 - val_precision: 0.6124\n",
      "Epoch 22/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9164 - precision: 0.6124\n",
      "Epoch 22: val_loss improved from 1.02391 to 1.01658, saving model to model_ent68.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9154 - precision: 0.6132 - val_loss: 1.0166 - val_precision: 0.6235\n",
      "Epoch 23/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9094 - precision: 0.6194\n",
      "Epoch 23: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9094 - precision: 0.6194 - val_loss: 1.0387 - val_precision: 0.6127\n",
      "Epoch 24/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9038 - precision: 0.6127\n",
      "Epoch 24: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9069 - precision: 0.6117 - val_loss: 1.0398 - val_precision: 0.6099\n",
      "Epoch 25/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8980 - precision: 0.6213\n",
      "Epoch 25: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8974 - precision: 0.6204 - val_loss: 1.0357 - val_precision: 0.6101\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8927 - precision: 0.6186\n",
      "Epoch 26: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8927 - precision: 0.6186 - val_loss: 1.0205 - val_precision: 0.6244\n",
      "Epoch 27/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8977 - precision: 0.6192\n",
      "Epoch 27: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8979 - precision: 0.6197 - val_loss: 1.0578 - val_precision: 0.5985\n",
      "Epoch 28/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8881 - precision: 0.6205\n",
      "Epoch 28: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8878 - precision: 0.6206 - val_loss: 1.0248 - val_precision: 0.6202\n",
      "Epoch 29/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8898 - precision: 0.6214\n",
      "Epoch 29: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8920 - precision: 0.6211 - val_loss: 1.0273 - val_precision: 0.6157\n",
      "Epoch 30/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8846 - precision: 0.6184\n",
      "Epoch 30: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8849 - precision: 0.6187 - val_loss: 1.0281 - val_precision: 0.6174\n",
      "Epoch 31/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/236 [============================>.] - ETA: 0s - loss: 0.8858 - precision: 0.6213\n",
      "Epoch 31: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8866 - precision: 0.6208 - val_loss: 1.0323 - val_precision: 0.6111\n",
      "Epoch 32/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8785 - precision: 0.6206\n",
      "Epoch 32: val_loss did not improve from 1.01658\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8780 - precision: 0.6207 - val_loss: 1.0287 - val_precision: 0.6155\n",
      "Epoch 32: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9533 - precision: 0.6321\n",
      "Combinación 67 = (False, True, True, 32, 0.25) \n",
      " precision train: [0.9533178806304932, 0.6321271061897278]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 69: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.4897 - precision: 0.5820\n",
      "Epoch 1: val_loss improved from inf to 1.29426, saving model to model_ent69.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.4797 - precision: 0.5775 - val_loss: 1.2943 - val_precision: 0.5740\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2466 - precision: 0.5924\n",
      "Epoch 2: val_loss improved from 1.29426 to 1.15640, saving model to model_ent69.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2466 - precision: 0.5920 - val_loss: 1.1564 - val_precision: 0.6411\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1568 - precision: 0.5983\n",
      "Epoch 3: val_loss improved from 1.15640 to 1.13846, saving model to model_ent69.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1557 - precision: 0.5997 - val_loss: 1.1385 - val_precision: 0.6314\n",
      "Epoch 4/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1105 - precision: 0.6060\n",
      "Epoch 4: val_loss improved from 1.13846 to 1.11134, saving model to model_ent69.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1045 - precision: 0.6079 - val_loss: 1.1113 - val_precision: 0.6157\n",
      "Epoch 5/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0973 - precision: 0.5924\n",
      "Epoch 5: val_loss improved from 1.11134 to 1.08790, saving model to model_ent69.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0951 - precision: 0.5909 - val_loss: 1.0879 - val_precision: 0.6277\n",
      "Epoch 6/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0874 - precision: 0.5982\n",
      "Epoch 6: val_loss did not improve from 1.08790\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0871 - precision: 0.5969 - val_loss: 1.0982 - val_precision: 0.6201\n",
      "Epoch 7/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0746 - precision: 0.5986\n",
      "Epoch 7: val_loss improved from 1.08790 to 1.07823, saving model to model_ent69.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0777 - precision: 0.5986 - val_loss: 1.0782 - val_precision: 0.6242\n",
      "Epoch 8/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0675 - precision: 0.6007\n",
      "Epoch 8: val_loss did not improve from 1.07823\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0680 - precision: 0.6005 - val_loss: 1.0813 - val_precision: 0.6093\n",
      "Epoch 9/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0531 - precision: 0.6042\n",
      "Epoch 9: val_loss improved from 1.07823 to 1.07798, saving model to model_ent69.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0524 - precision: 0.6046 - val_loss: 1.0780 - val_precision: 0.6032\n",
      "Epoch 10/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0484 - precision: 0.5973\n",
      "Epoch 10: val_loss did not improve from 1.07798\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0519 - precision: 0.5953 - val_loss: 1.0843 - val_precision: 0.5976\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0567 - precision: 0.5982\n",
      "Epoch 11: val_loss improved from 1.07798 to 1.06909, saving model to model_ent69.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0567 - precision: 0.5981 - val_loss: 1.0691 - val_precision: 0.6199\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0416 - precision: 0.6106\n",
      "Epoch 12: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0407 - precision: 0.6110 - val_loss: 1.0799 - val_precision: 0.6135\n",
      "Epoch 13/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0494 - precision: 0.6008\n",
      "Epoch 13: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0495 - precision: 0.6012 - val_loss: 1.0768 - val_precision: 0.6043\n",
      "Epoch 14/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0320 - precision: 0.6072\n",
      "Epoch 14: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0284 - precision: 0.6099 - val_loss: 1.0727 - val_precision: 0.6256\n",
      "Epoch 15/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0382 - precision: 0.6020\n",
      "Epoch 15: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0388 - precision: 0.6018 - val_loss: 1.0696 - val_precision: 0.6102\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0295 - precision: 0.6029\n",
      "Epoch 16: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0314 - precision: 0.6033 - val_loss: 1.0692 - val_precision: 0.6189\n",
      "Epoch 17/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0333 - precision: 0.6033\n",
      "Epoch 17: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0341 - precision: 0.6029 - val_loss: 1.0701 - val_precision: 0.6143\n",
      "Epoch 18/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0169 - precision: 0.6048\n",
      "Epoch 18: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0194 - precision: 0.6058 - val_loss: 1.0763 - val_precision: 0.6098\n",
      "Epoch 19/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0181 - precision: 0.6128\n",
      "Epoch 19: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0234 - precision: 0.6122 - val_loss: 1.0796 - val_precision: 0.6007\n",
      "Epoch 20/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0225 - precision: 0.6034\n",
      "Epoch 20: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0241 - precision: 0.6051 - val_loss: 1.0695 - val_precision: 0.6136\n",
      "Epoch 21/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0205 - precision: 0.6120\n",
      "Epoch 21: val_loss did not improve from 1.06909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0187 - precision: 0.6111 - val_loss: 1.0727 - val_precision: 0.6168\n",
      "Epoch 21: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0523 - precision: 0.6140\n",
      "Combinación 68 = (False, True, True, 32, 0.5) \n",
      " precision train: [1.052322506904602, 0.6139785051345825]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 70: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.3102 - precision: 0.6180\n",
      "Epoch 1: val_loss improved from inf to 1.12604, saving model to model_ent70.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.2980 - precision: 0.6185 - val_loss: 1.1260 - val_precision: 0.6709\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0306 - precision: 0.6006\n",
      "Epoch 2: val_loss improved from 1.12604 to 1.07797, saving model to model_ent70.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0307 - precision: 0.6006 - val_loss: 1.0780 - val_precision: 0.6109\n",
      "Epoch 3/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9905 - precision: 0.5980\n",
      "Epoch 3: val_loss improved from 1.07797 to 1.06442, saving model to model_ent70.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9900 - precision: 0.5984 - val_loss: 1.0644 - val_precision: 0.6149\n",
      "Epoch 4/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9839 - precision: 0.5979\n",
      "Epoch 4: val_loss improved from 1.06442 to 1.06168, saving model to model_ent70.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9831 - precision: 0.5961 - val_loss: 1.0617 - val_precision: 0.5981\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9575 - precision: 0.6002\n",
      "Epoch 5: val_loss improved from 1.06168 to 1.03770, saving model to model_ent70.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9590 - precision: 0.6007 - val_loss: 1.0377 - val_precision: 0.6157\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9462 - precision: 0.6006\n",
      "Epoch 6: val_loss did not improve from 1.03770\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9462 - precision: 0.6006 - val_loss: 1.0379 - val_precision: 0.6161\n",
      "Epoch 7/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9398 - precision: 0.6015\n",
      "Epoch 7: val_loss improved from 1.03770 to 1.02396, saving model to model_ent70.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9384 - precision: 0.6023 - val_loss: 1.0240 - val_precision: 0.6261\n",
      "Epoch 8/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9224 - precision: 0.6083\n",
      "Epoch 8: val_loss did not improve from 1.02396\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9224 - precision: 0.6083 - val_loss: 1.0283 - val_precision: 0.6304\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9195 - precision: 0.6107\n",
      "Epoch 9: val_loss did not improve from 1.02396\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9188 - precision: 0.6107 - val_loss: 1.0413 - val_precision: 0.6082\n",
      "Epoch 10/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9150 - precision: 0.6082\n",
      "Epoch 10: val_loss did not improve from 1.02396\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9143 - precision: 0.6074 - val_loss: 1.0263 - val_precision: 0.6323\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9021 - precision: 0.6137\n",
      "Epoch 11: val_loss did not improve from 1.02396\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9016 - precision: 0.6135 - val_loss: 1.0292 - val_precision: 0.6216\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8933 - precision: 0.6174\n",
      "Epoch 12: val_loss did not improve from 1.02396\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8939 - precision: 0.6174 - val_loss: 1.0516 - val_precision: 0.6027\n",
      "Epoch 13/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8829 - precision: 0.6204\n",
      "Epoch 13: val_loss did not improve from 1.02396\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8847 - precision: 0.6209 - val_loss: 1.0299 - val_precision: 0.6139\n",
      "Epoch 14/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8760 - precision: 0.6201\n",
      "Epoch 14: val_loss did not improve from 1.02396\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8760 - precision: 0.6209 - val_loss: 1.0273 - val_precision: 0.6136\n",
      "Epoch 15/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8644 - precision: 0.6273\n",
      "Epoch 15: val_loss did not improve from 1.02396\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8654 - precision: 0.6264 - val_loss: 1.0404 - val_precision: 0.6040\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8576 - precision: 0.6278\n",
      "Epoch 16: val_loss improved from 1.02396 to 1.01574, saving model to model_ent70.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8578 - precision: 0.6275 - val_loss: 1.0157 - val_precision: 0.6152\n",
      "Epoch 17/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8561 - precision: 0.6258\n",
      "Epoch 17: val_loss did not improve from 1.01574\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8535 - precision: 0.6274 - val_loss: 1.0174 - val_precision: 0.6252\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8368 - precision: 0.6327\n",
      "Epoch 18: val_loss did not improve from 1.01574\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8374 - precision: 0.6337 - val_loss: 1.0423 - val_precision: 0.6055\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8356 - precision: 0.6292\n",
      "Epoch 19: val_loss improved from 1.01574 to 1.01328, saving model to model_ent70.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8356 - precision: 0.6290 - val_loss: 1.0133 - val_precision: 0.6221\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8299 - precision: 0.6296\n",
      "Epoch 20: val_loss improved from 1.01328 to 1.00919, saving model to model_ent70.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8295 - precision: 0.6298 - val_loss: 1.0092 - val_precision: 0.6218\n",
      "Epoch 21/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8218 - precision: 0.6315\n",
      "Epoch 21: val_loss did not improve from 1.00919\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8224 - precision: 0.6313 - val_loss: 1.0301 - val_precision: 0.6182\n",
      "Epoch 22/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8141 - precision: 0.6372\n",
      "Epoch 22: val_loss did not improve from 1.00919\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8139 - precision: 0.6369 - val_loss: 1.0286 - val_precision: 0.6136\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8044 - precision: 0.6410\n",
      "Epoch 23: val_loss did not improve from 1.00919\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8048 - precision: 0.6396 - val_loss: 1.0245 - val_precision: 0.6128\n",
      "Epoch 24/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.7986 - precision: 0.6386\n",
      "Epoch 24: val_loss did not improve from 1.00919\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7994 - precision: 0.6388 - val_loss: 1.0403 - val_precision: 0.6021\n",
      "Epoch 25/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7891 - precision: 0.6442\n",
      "Epoch 25: val_loss did not improve from 1.00919\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7896 - precision: 0.6441 - val_loss: 1.0223 - val_precision: 0.6196\n",
      "Epoch 26/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7847 - precision: 0.6432\n",
      "Epoch 26: val_loss did not improve from 1.00919\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7850 - precision: 0.6432 - val_loss: 1.0261 - val_precision: 0.6134\n",
      "Epoch 27/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7807 - precision: 0.6422\n",
      "Epoch 27: val_loss did not improve from 1.00919\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7805 - precision: 0.6419 - val_loss: 1.0334 - val_precision: 0.6139\n",
      "Epoch 28/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.7670 - precision: 0.6459\n",
      "Epoch 28: val_loss did not improve from 1.00919\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7672 - precision: 0.6454 - val_loss: 1.0431 - val_precision: 0.6034\n",
      "Epoch 29/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7648 - precision: 0.6510\n",
      "Epoch 29: val_loss did not improve from 1.00919\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7645 - precision: 0.6510 - val_loss: 1.0586 - val_precision: 0.6043\n",
      "Epoch 30/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7627 - precision: 0.6471\n",
      "Epoch 30: val_loss did not improve from 1.00919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7626 - precision: 0.6482 - val_loss: 1.0240 - val_precision: 0.6266\n",
      "Epoch 30: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.8515 - precision: 0.6680\n",
      "Combinación 69 = (False, True, True, 64, 0.1) \n",
      " precision train: [0.8515021800994873, 0.6680382490158081]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 71: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3506 - precision: 0.6473\n",
      "Epoch 1: val_loss improved from inf to 1.19548, saving model to model_ent71.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.3440 - precision: 0.6442 - val_loss: 1.1955 - val_precision: 0.6500\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0794 - precision: 0.6182\n",
      "Epoch 2: val_loss improved from 1.19548 to 1.07946, saving model to model_ent71.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0799 - precision: 0.6179 - val_loss: 1.0795 - val_precision: 0.6323\n",
      "Epoch 3/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0165 - precision: 0.6080\n",
      "Epoch 3: val_loss improved from 1.07946 to 1.06512, saving model to model_ent71.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0164 - precision: 0.6082 - val_loss: 1.0651 - val_precision: 0.6158\n",
      "Epoch 4/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9830 - precision: 0.5994\n",
      "Epoch 4: val_loss improved from 1.06512 to 1.05334, saving model to model_ent71.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9855 - precision: 0.5986 - val_loss: 1.0533 - val_precision: 0.6104\n",
      "Epoch 5/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9759 - precision: 0.6018\n",
      "Epoch 5: val_loss improved from 1.05334 to 1.04247, saving model to model_ent71.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9731 - precision: 0.6022 - val_loss: 1.0425 - val_precision: 0.6144\n",
      "Epoch 6/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9630 - precision: 0.6014\n",
      "Epoch 6: val_loss improved from 1.04247 to 1.02323, saving model to model_ent71.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9612 - precision: 0.6007 - val_loss: 1.0232 - val_precision: 0.6193\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9548 - precision: 0.6023\n",
      "Epoch 7: val_loss did not improve from 1.02323\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9554 - precision: 0.6040 - val_loss: 1.0476 - val_precision: 0.6085\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9422 - precision: 0.6076\n",
      "Epoch 8: val_loss did not improve from 1.02323\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9440 - precision: 0.6072 - val_loss: 1.0388 - val_precision: 0.6099\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9411 - precision: 0.6061\n",
      "Epoch 9: val_loss did not improve from 1.02323\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9411 - precision: 0.6061 - val_loss: 1.0373 - val_precision: 0.6201\n",
      "Epoch 10/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9301 - precision: 0.6063\n",
      "Epoch 10: val_loss did not improve from 1.02323\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9318 - precision: 0.6061 - val_loss: 1.0292 - val_precision: 0.6186\n",
      "Epoch 11/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9299 - precision: 0.6064\n",
      "Epoch 11: val_loss improved from 1.02323 to 1.01008, saving model to model_ent71.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9296 - precision: 0.6067 - val_loss: 1.0101 - val_precision: 0.6282\n",
      "Epoch 12/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9092 - precision: 0.6175\n",
      "Epoch 12: val_loss did not improve from 1.01008\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9099 - precision: 0.6184 - val_loss: 1.0408 - val_precision: 0.6128\n",
      "Epoch 13/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9076 - precision: 0.6170\n",
      "Epoch 13: val_loss did not improve from 1.01008\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9111 - precision: 0.6130 - val_loss: 1.0283 - val_precision: 0.6102\n",
      "Epoch 14/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9033 - precision: 0.6195\n",
      "Epoch 14: val_loss improved from 1.01008 to 1.00671, saving model to model_ent71.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9054 - precision: 0.6198 - val_loss: 1.0067 - val_precision: 0.6189\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8965 - precision: 0.6203\n",
      "Epoch 15: val_loss did not improve from 1.00671\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8956 - precision: 0.6208 - val_loss: 1.0254 - val_precision: 0.6185\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8882 - precision: 0.6219\n",
      "Epoch 16: val_loss did not improve from 1.00671\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8894 - precision: 0.6215 - val_loss: 1.0303 - val_precision: 0.6043\n",
      "Epoch 17/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8836 - precision: 0.6252\n",
      "Epoch 17: val_loss did not improve from 1.00671\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8808 - precision: 0.6256 - val_loss: 1.0347 - val_precision: 0.6073\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8805 - precision: 0.6209\n",
      "Epoch 18: val_loss did not improve from 1.00671\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8799 - precision: 0.6223 - val_loss: 1.0228 - val_precision: 0.6214\n",
      "Epoch 19/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8730 - precision: 0.6212\n",
      "Epoch 19: val_loss did not improve from 1.00671\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8740 - precision: 0.6200 - val_loss: 1.0131 - val_precision: 0.6209\n",
      "Epoch 20/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8707 - precision: 0.6224\n",
      "Epoch 20: val_loss did not improve from 1.00671\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8692 - precision: 0.6225 - val_loss: 1.0209 - val_precision: 0.6197\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8597 - precision: 0.6221\n",
      "Epoch 21: val_loss did not improve from 1.00671\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8590 - precision: 0.6217 - val_loss: 1.0458 - val_precision: 0.6053\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8526 - precision: 0.6312\n",
      "Epoch 22: val_loss did not improve from 1.00671\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8524 - precision: 0.6313 - val_loss: 1.0176 - val_precision: 0.6152\n",
      "Epoch 23/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8473 - precision: 0.6318\n",
      "Epoch 23: val_loss did not improve from 1.00671\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8483 - precision: 0.6312 - val_loss: 1.0191 - val_precision: 0.6178\n",
      "Epoch 24/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8419 - precision: 0.6306\n",
      "Epoch 24: val_loss improved from 1.00671 to 1.00123, saving model to model_ent71.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8442 - precision: 0.6299 - val_loss: 1.0012 - val_precision: 0.6229\n",
      "Epoch 25/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8428 - precision: 0.6311\n",
      "Epoch 25: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8407 - precision: 0.6320 - val_loss: 1.0272 - val_precision: 0.6117\n",
      "Epoch 26/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8371 - precision: 0.6337\n",
      "Epoch 26: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8366 - precision: 0.6335 - val_loss: 1.0275 - val_precision: 0.6103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8272 - precision: 0.6341\n",
      "Epoch 27: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8284 - precision: 0.6344 - val_loss: 1.0140 - val_precision: 0.6159\n",
      "Epoch 28/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8264 - precision: 0.6307\n",
      "Epoch 28: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8253 - precision: 0.6315 - val_loss: 1.0061 - val_precision: 0.6227\n",
      "Epoch 29/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8202 - precision: 0.6326\n",
      "Epoch 29: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8201 - precision: 0.6329 - val_loss: 1.0208 - val_precision: 0.6122\n",
      "Epoch 30/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8184 - precision: 0.6313\n",
      "Epoch 30: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8184 - precision: 0.6308 - val_loss: 1.0305 - val_precision: 0.6088\n",
      "Epoch 31/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8074 - precision: 0.6405\n",
      "Epoch 31: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8091 - precision: 0.6403 - val_loss: 1.0222 - val_precision: 0.6223\n",
      "Epoch 32/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8065 - precision: 0.6416\n",
      "Epoch 32: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8059 - precision: 0.6418 - val_loss: 1.0413 - val_precision: 0.6121\n",
      "Epoch 33/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8061 - precision: 0.6351\n",
      "Epoch 33: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8068 - precision: 0.6349 - val_loss: 1.0274 - val_precision: 0.6082\n",
      "Epoch 34/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7933 - precision: 0.6448\n",
      "Epoch 34: val_loss did not improve from 1.00123\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7934 - precision: 0.6451 - val_loss: 1.0279 - val_precision: 0.6071\n",
      "Epoch 34: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 0.8925 - precision: 0.6472\n",
      "Combinación 70 = (False, True, True, 64, 0.25) \n",
      " precision train: [0.8924514651298523, 0.6472437381744385]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 72: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.4296 - precision: 0.6026\n",
      "Epoch 1: val_loss improved from inf to 1.23937, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 8s 10ms/step - loss: 1.4254 - precision: 0.6036 - val_loss: 1.2394 - val_precision: 0.6549\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1489 - precision: 0.6346\n",
      "Epoch 2: val_loss improved from 1.23937 to 1.10767, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1484 - precision: 0.6319 - val_loss: 1.1077 - val_precision: 0.6446\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0749 - precision: 0.6034\n",
      "Epoch 3: val_loss improved from 1.10767 to 1.08282, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0745 - precision: 0.6031 - val_loss: 1.0828 - val_precision: 0.6083\n",
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0391 - precision: 0.6017\n",
      "Epoch 4: val_loss improved from 1.08282 to 1.07365, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0390 - precision: 0.6018 - val_loss: 1.0736 - val_precision: 0.6122\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0282 - precision: 0.6000\n",
      "Epoch 5: val_loss improved from 1.07365 to 1.06008, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0285 - precision: 0.5994 - val_loss: 1.0601 - val_precision: 0.6162\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0249 - precision: 0.6013\n",
      "Epoch 6: val_loss improved from 1.06008 to 1.06002, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0245 - precision: 0.6018 - val_loss: 1.0600 - val_precision: 0.6046\n",
      "Epoch 7/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9952 - precision: 0.6033\n",
      "Epoch 7: val_loss improved from 1.06002 to 1.05461, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9953 - precision: 0.6025 - val_loss: 1.0546 - val_precision: 0.6035\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9904 - precision: 0.6027\n",
      "Epoch 8: val_loss improved from 1.05461 to 1.05148, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9963 - precision: 0.6014 - val_loss: 1.0515 - val_precision: 0.6071\n",
      "Epoch 9/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9934 - precision: 0.6013\n",
      "Epoch 9: val_loss improved from 1.05148 to 1.04359, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9963 - precision: 0.6006 - val_loss: 1.0436 - val_precision: 0.6182\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9848 - precision: 0.6050\n",
      "Epoch 10: val_loss improved from 1.04359 to 1.02629, saving model to model_ent72.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9848 - precision: 0.6050 - val_loss: 1.0263 - val_precision: 0.6157\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9794 - precision: 0.6054\n",
      "Epoch 11: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9778 - precision: 0.6061 - val_loss: 1.0463 - val_precision: 0.6019\n",
      "Epoch 12/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9744 - precision: 0.6045\n",
      "Epoch 12: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9761 - precision: 0.6043 - val_loss: 1.0539 - val_precision: 0.6107\n",
      "Epoch 13/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9749 - precision: 0.6079\n",
      "Epoch 13: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9749 - precision: 0.6079 - val_loss: 1.0379 - val_precision: 0.6146\n",
      "Epoch 14/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9679 - precision: 0.6038\n",
      "Epoch 14: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9687 - precision: 0.6053 - val_loss: 1.0482 - val_precision: 0.6049\n",
      "Epoch 15/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9714 - precision: 0.5986\n",
      "Epoch 15: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9737 - precision: 0.5975 - val_loss: 1.0377 - val_precision: 0.6145\n",
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9596 - precision: 0.6056\n",
      "Epoch 16: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9608 - precision: 0.6059 - val_loss: 1.0410 - val_precision: 0.6096\n",
      "Epoch 17/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9587 - precision: 0.6083\n",
      "Epoch 17: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9587 - precision: 0.6083 - val_loss: 1.0358 - val_precision: 0.6151\n",
      "Epoch 18/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9592 - precision: 0.6070\n",
      "Epoch 18: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9639 - precision: 0.6064 - val_loss: 1.0331 - val_precision: 0.6131\n",
      "Epoch 19/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9611 - precision: 0.6048\n",
      "Epoch 19: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9580 - precision: 0.6067 - val_loss: 1.0347 - val_precision: 0.6220\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9414 - precision: 0.6114\n",
      "Epoch 20: val_loss did not improve from 1.02629\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9400 - precision: 0.6113 - val_loss: 1.0424 - val_precision: 0.6115\n",
      "Epoch 20: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0093 - precision: 0.6157\n",
      "Combinación 71 = (False, True, True, 64, 0.5) \n",
      " precision train: [1.009315848350525, 0.6156646013259888]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 73: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2000 - precision: 0.6172\n",
      "Epoch 1: val_loss improved from inf to 1.09947, saving model to model_ent73.h5\n",
      "236/236 [==============================] - 8s 11ms/step - loss: 1.1990 - precision: 0.6164 - val_loss: 1.0995 - val_precision: 0.6138\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9972 - precision: 0.5981\n",
      "Epoch 2: val_loss improved from 1.09947 to 1.06069, saving model to model_ent73.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9964 - precision: 0.5976 - val_loss: 1.0607 - val_precision: 0.6161\n",
      "Epoch 3/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9647 - precision: 0.5955\n",
      "Epoch 3: val_loss did not improve from 1.06069\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9648 - precision: 0.5951 - val_loss: 1.0792 - val_precision: 0.6081\n",
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9457 - precision: 0.6028\n",
      "Epoch 4: val_loss improved from 1.06069 to 1.05878, saving model to model_ent73.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9451 - precision: 0.6033 - val_loss: 1.0588 - val_precision: 0.6099\n",
      "Epoch 5/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9384 - precision: 0.6062\n",
      "Epoch 5: val_loss improved from 1.05878 to 1.02161, saving model to model_ent73.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9364 - precision: 0.6054 - val_loss: 1.0216 - val_precision: 0.6190\n",
      "Epoch 6/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9268 - precision: 0.6077\n",
      "Epoch 6: val_loss did not improve from 1.02161\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9277 - precision: 0.6054 - val_loss: 1.0233 - val_precision: 0.6196\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9152 - precision: 0.6089\n",
      "Epoch 7: val_loss did not improve from 1.02161\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9136 - precision: 0.6089 - val_loss: 1.0539 - val_precision: 0.6074\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9123 - precision: 0.6154\n",
      "Epoch 8: val_loss did not improve from 1.02161\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9129 - precision: 0.6151 - val_loss: 1.0527 - val_precision: 0.6065\n",
      "Epoch 9/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9059 - precision: 0.6102\n",
      "Epoch 9: val_loss did not improve from 1.02161\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9042 - precision: 0.6119 - val_loss: 1.0320 - val_precision: 0.6231\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8919 - precision: 0.6152\n",
      "Epoch 10: val_loss did not improve from 1.02161\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8919 - precision: 0.6152 - val_loss: 1.0541 - val_precision: 0.6054\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8802 - precision: 0.6141\n",
      "Epoch 11: val_loss improved from 1.02161 to 1.02114, saving model to model_ent73.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8811 - precision: 0.6140 - val_loss: 1.0211 - val_precision: 0.6117\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8741 - precision: 0.6176\n",
      "Epoch 12: val_loss did not improve from 1.02114\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8738 - precision: 0.6177 - val_loss: 1.0584 - val_precision: 0.6048\n",
      "Epoch 13/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8638 - precision: 0.6216\n",
      "Epoch 13: val_loss did not improve from 1.02114\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8625 - precision: 0.6221 - val_loss: 1.0379 - val_precision: 0.6036\n",
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8468 - precision: 0.6231\n",
      "Epoch 14: val_loss did not improve from 1.02114\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8460 - precision: 0.6236 - val_loss: 1.0326 - val_precision: 0.6136\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8356 - precision: 0.6331\n",
      "Epoch 15: val_loss did not improve from 1.02114\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8353 - precision: 0.6331 - val_loss: 1.0326 - val_precision: 0.6095\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8307 - precision: 0.6267\n",
      "Epoch 16: val_loss improved from 1.02114 to 1.01524, saving model to model_ent73.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8303 - precision: 0.6271 - val_loss: 1.0152 - val_precision: 0.6180\n",
      "Epoch 17/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8167 - precision: 0.6361\n",
      "Epoch 17: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8161 - precision: 0.6359 - val_loss: 1.0642 - val_precision: 0.5904\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8102 - precision: 0.6350\n",
      "Epoch 18: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8101 - precision: 0.6348 - val_loss: 1.0268 - val_precision: 0.6251\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8024 - precision: 0.6404\n",
      "Epoch 19: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8021 - precision: 0.6403 - val_loss: 1.0173 - val_precision: 0.6161\n",
      "Epoch 20/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7940 - precision: 0.6380\n",
      "Epoch 20: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7934 - precision: 0.6384 - val_loss: 1.0440 - val_precision: 0.6142\n",
      "Epoch 21/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7778 - precision: 0.6434\n",
      "Epoch 21: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.7780 - precision: 0.6437 - val_loss: 1.0302 - val_precision: 0.6092\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7714 - precision: 0.6443\n",
      "Epoch 22: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.7716 - precision: 0.6443 - val_loss: 1.0499 - val_precision: 0.6015\n",
      "Epoch 23/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.7638 - precision: 0.6510\n",
      "Epoch 23: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.7634 - precision: 0.6506 - val_loss: 1.0509 - val_precision: 0.6071\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7546 - precision: 0.6486\n",
      "Epoch 24: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.7542 - precision: 0.6489 - val_loss: 1.0845 - val_precision: 0.5782\n",
      "Epoch 25/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7544 - precision: 0.6493\n",
      "Epoch 25: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.7544 - precision: 0.6491 - val_loss: 1.0400 - val_precision: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.7414 - precision: 0.6561\n",
      "Epoch 26: val_loss did not improve from 1.01524\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.7422 - precision: 0.6557 - val_loss: 1.0447 - val_precision: 0.6167\n",
      "Epoch 26: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.8397 - precision: 0.6724\n",
      "Combinación 72 = (False, True, True, 128, 0.1) \n",
      " precision train: [0.8396868705749512, 0.6724470257759094]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 74: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2508 - precision: 0.6205\n",
      "Epoch 1: val_loss improved from inf to 1.10792, saving model to model_ent74.h5\n",
      "236/236 [==============================] - 8s 11ms/step - loss: 1.2471 - precision: 0.6215 - val_loss: 1.1079 - val_precision: 0.6361\n",
      "Epoch 2/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0101 - precision: 0.6003\n",
      "Epoch 2: val_loss improved from 1.10792 to 1.06025, saving model to model_ent74.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0090 - precision: 0.6016 - val_loss: 1.0603 - val_precision: 0.6249\n",
      "Epoch 3/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9765 - precision: 0.6027\n",
      "Epoch 3: val_loss improved from 1.06025 to 1.04134, saving model to model_ent74.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9800 - precision: 0.6029 - val_loss: 1.0413 - val_precision: 0.6275\n",
      "Epoch 4/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9644 - precision: 0.6028\n",
      "Epoch 4: val_loss did not improve from 1.04134\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9623 - precision: 0.6039 - val_loss: 1.0718 - val_precision: 0.5986\n",
      "Epoch 5/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9550 - precision: 0.5978\n",
      "Epoch 5: val_loss did not improve from 1.04134\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9573 - precision: 0.5976 - val_loss: 1.0735 - val_precision: 0.5960\n",
      "Epoch 6/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9407 - precision: 0.6069\n",
      "Epoch 6: val_loss improved from 1.04134 to 1.01092, saving model to model_ent74.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9447 - precision: 0.6062 - val_loss: 1.0109 - val_precision: 0.6267\n",
      "Epoch 7/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9289 - precision: 0.6097\n",
      "Epoch 7: val_loss did not improve from 1.01092\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9282 - precision: 0.6100 - val_loss: 1.0331 - val_precision: 0.6161\n",
      "Epoch 8/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9229 - precision: 0.6108\n",
      "Epoch 8: val_loss did not improve from 1.01092\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9205 - precision: 0.6111 - val_loss: 1.0142 - val_precision: 0.6312\n",
      "Epoch 9/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9109 - precision: 0.6205\n",
      "Epoch 9: val_loss did not improve from 1.01092\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9120 - precision: 0.6185 - val_loss: 1.0243 - val_precision: 0.6201\n",
      "Epoch 10/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9058 - precision: 0.6160\n",
      "Epoch 10: val_loss did not improve from 1.01092\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9046 - precision: 0.6163 - val_loss: 1.0137 - val_precision: 0.6246\n",
      "Epoch 11/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8855 - precision: 0.6225\n",
      "Epoch 11: val_loss did not improve from 1.01092\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8865 - precision: 0.6227 - val_loss: 1.0278 - val_precision: 0.6200\n",
      "Epoch 12/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8843 - precision: 0.6219\n",
      "Epoch 12: val_loss did not improve from 1.01092\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8875 - precision: 0.6207 - val_loss: 1.0380 - val_precision: 0.6239\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8828 - precision: 0.6203\n",
      "Epoch 13: val_loss did not improve from 1.01092\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8807 - precision: 0.6209 - val_loss: 1.0189 - val_precision: 0.6073\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8658 - precision: 0.6238\n",
      "Epoch 14: val_loss did not improve from 1.01092\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8679 - precision: 0.6222 - val_loss: 1.0376 - val_precision: 0.6111\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8633 - precision: 0.6242\n",
      "Epoch 15: val_loss improved from 1.01092 to 1.01021, saving model to model_ent74.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8627 - precision: 0.6238 - val_loss: 1.0102 - val_precision: 0.6264\n",
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8502 - precision: 0.6300\n",
      "Epoch 16: val_loss improved from 1.01021 to 1.00421, saving model to model_ent74.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8500 - precision: 0.6308 - val_loss: 1.0042 - val_precision: 0.6275\n",
      "Epoch 17/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8440 - precision: 0.6322\n",
      "Epoch 17: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8440 - precision: 0.6322 - val_loss: 1.0163 - val_precision: 0.6166\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8443 - precision: 0.6239\n",
      "Epoch 18: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8441 - precision: 0.6240 - val_loss: 1.0062 - val_precision: 0.6311\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8317 - precision: 0.6297\n",
      "Epoch 19: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8323 - precision: 0.6296 - val_loss: 1.0283 - val_precision: 0.6122\n",
      "Epoch 20/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8250 - precision: 0.6329\n",
      "Epoch 20: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8251 - precision: 0.6314 - val_loss: 1.0307 - val_precision: 0.6084\n",
      "Epoch 21/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8210 - precision: 0.6364\n",
      "Epoch 21: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8210 - precision: 0.6364 - val_loss: 1.0215 - val_precision: 0.6140\n",
      "Epoch 22/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8136 - precision: 0.6377\n",
      "Epoch 22: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8133 - precision: 0.6377 - val_loss: 1.0595 - val_precision: 0.5930\n",
      "Epoch 23/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8038 - precision: 0.6355\n",
      "Epoch 23: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8038 - precision: 0.6355 - val_loss: 1.0205 - val_precision: 0.6111\n",
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7921 - precision: 0.6386\n",
      "Epoch 24: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.7941 - precision: 0.6384 - val_loss: 1.0422 - val_precision: 0.6075\n",
      "Epoch 25/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.7927 - precision: 0.6396\n",
      "Epoch 25: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.7947 - precision: 0.6387 - val_loss: 1.0389 - val_precision: 0.6142\n",
      "Epoch 26/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.7847 - precision: 0.6446\n",
      "Epoch 26: val_loss did not improve from 1.00421\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.7832 - precision: 0.6457 - val_loss: 1.0579 - val_precision: 0.6021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9175 - precision: 0.6392\n",
      "Combinación 73 = (False, True, True, 128, 0.25) \n",
      " precision train: [0.9174919128417969, 0.639204204082489]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 75: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.3205 - precision: 0.6298\n",
      "Epoch 1: val_loss improved from inf to 1.11866, saving model to model_ent75.h5\n",
      "236/236 [==============================] - 15s 11ms/step - loss: 1.3144 - precision: 0.6284 - val_loss: 1.1187 - val_precision: 0.6552\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0433 - precision: 0.6083\n",
      "Epoch 2: val_loss improved from 1.11866 to 1.04768, saving model to model_ent75.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0424 - precision: 0.6086 - val_loss: 1.0477 - val_precision: 0.6294\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0158 - precision: 0.6016\n",
      "Epoch 3: val_loss did not improve from 1.04768\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0154 - precision: 0.6011 - val_loss: 1.0494 - val_precision: 0.6196\n",
      "Epoch 4/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9906 - precision: 0.6019\n",
      "Epoch 4: val_loss improved from 1.04768 to 1.03534, saving model to model_ent75.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9901 - precision: 0.6021 - val_loss: 1.0353 - val_precision: 0.6197\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9853 - precision: 0.6041\n",
      "Epoch 5: val_loss did not improve from 1.03534\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9861 - precision: 0.6041 - val_loss: 1.0395 - val_precision: 0.6193\n",
      "Epoch 6/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9685 - precision: 0.6005\n",
      "Epoch 6: val_loss did not improve from 1.03534\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9714 - precision: 0.6003 - val_loss: 1.0623 - val_precision: 0.6123\n",
      "Epoch 7/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9671 - precision: 0.5998\n",
      "Epoch 7: val_loss did not improve from 1.03534\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9696 - precision: 0.6000 - val_loss: 1.0402 - val_precision: 0.6088\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9646 - precision: 0.6048\n",
      "Epoch 8: val_loss did not improve from 1.03534\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9645 - precision: 0.6045 - val_loss: 1.0426 - val_precision: 0.6109\n",
      "Epoch 9/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9599 - precision: 0.6042\n",
      "Epoch 9: val_loss improved from 1.03534 to 1.02830, saving model to model_ent75.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9605 - precision: 0.6035 - val_loss: 1.0283 - val_precision: 0.6210\n",
      "Epoch 10/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9585 - precision: 0.6061\n",
      "Epoch 10: val_loss did not improve from 1.02830\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9574 - precision: 0.6076 - val_loss: 1.0386 - val_precision: 0.6066\n",
      "Epoch 11/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9457 - precision: 0.6051\n",
      "Epoch 11: val_loss did not improve from 1.02830\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9485 - precision: 0.6020 - val_loss: 1.0524 - val_precision: 0.6014\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9410 - precision: 0.6096\n",
      "Epoch 12: val_loss did not improve from 1.02830\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9410 - precision: 0.6096 - val_loss: 1.0332 - val_precision: 0.6087\n",
      "Epoch 13/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9391 - precision: 0.6078\n",
      "Epoch 13: val_loss did not improve from 1.02830\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9391 - precision: 0.6075 - val_loss: 1.0469 - val_precision: 0.6102\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9324 - precision: 0.6108\n",
      "Epoch 14: val_loss did not improve from 1.02830\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9324 - precision: 0.6108 - val_loss: 1.0358 - val_precision: 0.6121\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9288 - precision: 0.6111\n",
      "Epoch 15: val_loss did not improve from 1.02830\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9288 - precision: 0.6111 - val_loss: 1.0297 - val_precision: 0.6188\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9302 - precision: 0.6056\n",
      "Epoch 16: val_loss improved from 1.02830 to 1.01470, saving model to model_ent75.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9296 - precision: 0.6059 - val_loss: 1.0147 - val_precision: 0.6226\n",
      "Epoch 17/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9228 - precision: 0.6086\n",
      "Epoch 17: val_loss did not improve from 1.01470\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.9231 - precision: 0.6084 - val_loss: 1.0150 - val_precision: 0.6211\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9198 - precision: 0.6106\n",
      "Epoch 18: val_loss did not improve from 1.01470\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9198 - precision: 0.6102 - val_loss: 1.0254 - val_precision: 0.6154\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9163 - precision: 0.6151\n",
      "Epoch 19: val_loss did not improve from 1.01470\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9160 - precision: 0.6149 - val_loss: 1.0283 - val_precision: 0.6167\n",
      "Epoch 20/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9064 - precision: 0.6123\n",
      "Epoch 20: val_loss did not improve from 1.01470\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9060 - precision: 0.6119 - val_loss: 1.0233 - val_precision: 0.6164\n",
      "Epoch 21/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9047 - precision: 0.6148\n",
      "Epoch 21: val_loss did not improve from 1.01470\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9040 - precision: 0.6152 - val_loss: 1.0209 - val_precision: 0.6164\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8990 - precision: 0.6117\n",
      "Epoch 22: val_loss did not improve from 1.01470\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9007 - precision: 0.6114 - val_loss: 1.0388 - val_precision: 0.6090\n",
      "Epoch 23/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8962 - precision: 0.6162\n",
      "Epoch 23: val_loss did not improve from 1.01470\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8961 - precision: 0.6164 - val_loss: 1.0159 - val_precision: 0.6158\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8843 - precision: 0.6206\n",
      "Epoch 24: val_loss improved from 1.01470 to 1.00882, saving model to model_ent75.h5\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8840 - precision: 0.6204 - val_loss: 1.0088 - val_precision: 0.6204\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8770 - precision: 0.6144\n",
      "Epoch 25: val_loss did not improve from 1.00882\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8786 - precision: 0.6140 - val_loss: 1.0239 - val_precision: 0.6149\n",
      "Epoch 26/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8833 - precision: 0.6202\n",
      "Epoch 26: val_loss did not improve from 1.00882\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8827 - precision: 0.6203 - val_loss: 1.0293 - val_precision: 0.6109\n",
      "Epoch 27/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8823 - precision: 0.6186\n",
      "Epoch 27: val_loss did not improve from 1.00882\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8814 - precision: 0.6189 - val_loss: 1.0153 - val_precision: 0.6196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8734 - precision: 0.6201\n",
      "Epoch 28: val_loss did not improve from 1.00882\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8719 - precision: 0.6198 - val_loss: 1.0347 - val_precision: 0.6086\n",
      "Epoch 29/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8623 - precision: 0.6286\n",
      "Epoch 29: val_loss did not improve from 1.00882\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8627 - precision: 0.6281 - val_loss: 1.0260 - val_precision: 0.6025\n",
      "Epoch 30/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8630 - precision: 0.6203\n",
      "Epoch 30: val_loss improved from 1.00882 to 1.00147, saving model to model_ent75.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8635 - precision: 0.6201 - val_loss: 1.0015 - val_precision: 0.6190\n",
      "Epoch 31/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8584 - precision: 0.6198\n",
      "Epoch 31: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8576 - precision: 0.6200 - val_loss: 1.0046 - val_precision: 0.6176\n",
      "Epoch 32/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8469 - precision: 0.6243\n",
      "Epoch 32: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8473 - precision: 0.6241 - val_loss: 1.0324 - val_precision: 0.6010\n",
      "Epoch 33/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8473 - precision: 0.6285\n",
      "Epoch 33: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8489 - precision: 0.6278 - val_loss: 1.0235 - val_precision: 0.6116\n",
      "Epoch 34/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8514 - precision: 0.6297\n",
      "Epoch 34: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8513 - precision: 0.6294 - val_loss: 1.0126 - val_precision: 0.6147\n",
      "Epoch 35/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8393 - precision: 0.6258\n",
      "Epoch 35: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8397 - precision: 0.6262 - val_loss: 1.0215 - val_precision: 0.6109\n",
      "Epoch 36/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8384 - precision: 0.6332\n",
      "Epoch 36: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8384 - precision: 0.6334 - val_loss: 1.0342 - val_precision: 0.6135\n",
      "Epoch 37/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8332 - precision: 0.6356\n",
      "Epoch 37: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8331 - precision: 0.6356 - val_loss: 1.0224 - val_precision: 0.6211\n",
      "Epoch 38/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8311 - precision: 0.6302\n",
      "Epoch 38: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8303 - precision: 0.6303 - val_loss: 1.0251 - val_precision: 0.6139\n",
      "Epoch 39/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8259 - precision: 0.6390\n",
      "Epoch 39: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8255 - precision: 0.6391 - val_loss: 1.0245 - val_precision: 0.6058\n",
      "Epoch 40/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8167 - precision: 0.6376\n",
      "Epoch 40: val_loss did not improve from 1.00147\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8168 - precision: 0.6372 - val_loss: 1.0227 - val_precision: 0.5998\n",
      "Epoch 40: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.8956 - precision: 0.6388\n",
      "Combinación 74 = (False, True, True, 128, 0.5) \n",
      " precision train: [0.8955883383750916, 0.6387681365013123]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 76: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.5252 - precision: 0.7000   \n",
      "Epoch 1: val_loss improved from inf to 1.34787, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.5206 - precision: 0.6600 - val_loss: 1.3479 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2620 - precision: 0.6789\n",
      "Epoch 2: val_loss improved from 1.34787 to 1.19055, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2546 - precision: 0.6775 - val_loss: 1.1905 - val_precision: 0.6867\n",
      "Epoch 3/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.1046 - precision: 0.6292\n",
      "Epoch 3: val_loss improved from 1.19055 to 1.13843, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1023 - precision: 0.6311 - val_loss: 1.1384 - val_precision: 0.6307\n",
      "Epoch 4/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0574 - precision: 0.6036\n",
      "Epoch 4: val_loss improved from 1.13843 to 1.10604, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0549 - precision: 0.6036 - val_loss: 1.1060 - val_precision: 0.6068\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0363 - precision: 0.6035\n",
      "Epoch 5: val_loss improved from 1.10604 to 1.08462, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0367 - precision: 0.6013 - val_loss: 1.0846 - val_precision: 0.6093\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0246 - precision: 0.6002\n",
      "Epoch 6: val_loss improved from 1.08462 to 1.07765, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0231 - precision: 0.6011 - val_loss: 1.0777 - val_precision: 0.6066\n",
      "Epoch 7/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0100 - precision: 0.5974\n",
      "Epoch 7: val_loss improved from 1.07765 to 1.06431, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0106 - precision: 0.5968 - val_loss: 1.0643 - val_precision: 0.6154\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9973 - precision: 0.6064\n",
      "Epoch 8: val_loss improved from 1.06431 to 1.04738, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9980 - precision: 0.6062 - val_loss: 1.0474 - val_precision: 0.6251\n",
      "Epoch 9/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9920 - precision: 0.6059\n",
      "Epoch 9: val_loss did not improve from 1.04738\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9934 - precision: 0.6044 - val_loss: 1.0529 - val_precision: 0.6129\n",
      "Epoch 10/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9886 - precision: 0.6074\n",
      "Epoch 10: val_loss did not improve from 1.04738\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9851 - precision: 0.6079 - val_loss: 1.0485 - val_precision: 0.6214\n",
      "Epoch 11/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9879 - precision: 0.6088\n",
      "Epoch 11: val_loss did not improve from 1.04738\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9879 - precision: 0.6088 - val_loss: 1.0504 - val_precision: 0.6157\n",
      "Epoch 12/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 0.9708 - precision: 0.6108\n",
      "Epoch 12: val_loss improved from 1.04738 to 1.03974, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9758 - precision: 0.6084 - val_loss: 1.0397 - val_precision: 0.6237\n",
      "Epoch 13/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9781 - precision: 0.6070\n",
      "Epoch 13: val_loss did not improve from 1.03974\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9777 - precision: 0.6074 - val_loss: 1.0440 - val_precision: 0.6222\n",
      "Epoch 14/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/236 [============================>.] - ETA: 0s - loss: 0.9763 - precision: 0.6134\n",
      "Epoch 14: val_loss improved from 1.03974 to 1.03893, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9762 - precision: 0.6131 - val_loss: 1.0389 - val_precision: 0.6211\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9639 - precision: 0.6216\n",
      "Epoch 15: val_loss improved from 1.03893 to 1.03863, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9652 - precision: 0.6213 - val_loss: 1.0386 - val_precision: 0.6235\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9665 - precision: 0.6189\n",
      "Epoch 16: val_loss did not improve from 1.03863\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9670 - precision: 0.6183 - val_loss: 1.0524 - val_precision: 0.6127\n",
      "Epoch 17/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9564 - precision: 0.6176\n",
      "Epoch 17: val_loss improved from 1.03863 to 1.03494, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9564 - precision: 0.6176 - val_loss: 1.0349 - val_precision: 0.6242\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9631 - precision: 0.6106\n",
      "Epoch 18: val_loss did not improve from 1.03494\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9608 - precision: 0.6111 - val_loss: 1.0359 - val_precision: 0.6246\n",
      "Epoch 19/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9565 - precision: 0.6162\n",
      "Epoch 19: val_loss improved from 1.03494 to 1.02981, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9568 - precision: 0.6150 - val_loss: 1.0298 - val_precision: 0.6291\n",
      "Epoch 20/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9555 - precision: 0.6152\n",
      "Epoch 20: val_loss did not improve from 1.02981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9529 - precision: 0.6156 - val_loss: 1.0377 - val_precision: 0.6186\n",
      "Epoch 21/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9441 - precision: 0.6191\n",
      "Epoch 21: val_loss did not improve from 1.02981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9441 - precision: 0.6191 - val_loss: 1.0335 - val_precision: 0.6262\n",
      "Epoch 22/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9484 - precision: 0.6117\n",
      "Epoch 22: val_loss did not improve from 1.02981\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9477 - precision: 0.6115 - val_loss: 1.0313 - val_precision: 0.6225\n",
      "Epoch 23/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9496 - precision: 0.6162\n",
      "Epoch 23: val_loss improved from 1.02981 to 1.02937, saving model to model_ent76.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9475 - precision: 0.6166 - val_loss: 1.0294 - val_precision: 0.6267\n",
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9449 - precision: 0.6180\n",
      "Epoch 24: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9453 - precision: 0.6180 - val_loss: 1.0364 - val_precision: 0.6238\n",
      "Epoch 25/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9456 - precision: 0.6153\n",
      "Epoch 25: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9459 - precision: 0.6140 - val_loss: 1.0400 - val_precision: 0.6167\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9439 - precision: 0.6154\n",
      "Epoch 26: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9439 - precision: 0.6154 - val_loss: 1.0315 - val_precision: 0.6249\n",
      "Epoch 27/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9344 - precision: 0.6223\n",
      "Epoch 27: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9336 - precision: 0.6231 - val_loss: 1.0345 - val_precision: 0.6230\n",
      "Epoch 28/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9240 - precision: 0.6213\n",
      "Epoch 28: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9275 - precision: 0.6208 - val_loss: 1.0334 - val_precision: 0.6246\n",
      "Epoch 29/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9297 - precision: 0.6243\n",
      "Epoch 29: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9284 - precision: 0.6246 - val_loss: 1.0459 - val_precision: 0.6089\n",
      "Epoch 30/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9275 - precision: 0.6194\n",
      "Epoch 30: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9296 - precision: 0.6173 - val_loss: 1.0480 - val_precision: 0.6049\n",
      "Epoch 31/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9326 - precision: 0.6207\n",
      "Epoch 31: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9294 - precision: 0.6199 - val_loss: 1.0404 - val_precision: 0.6179\n",
      "Epoch 32/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9249 - precision: 0.6253\n",
      "Epoch 32: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9250 - precision: 0.6261 - val_loss: 1.0477 - val_precision: 0.6104\n",
      "Epoch 33/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9281 - precision: 0.6222\n",
      "Epoch 33: val_loss did not improve from 1.02937\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9281 - precision: 0.6222 - val_loss: 1.0380 - val_precision: 0.6181\n",
      "Epoch 33: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9941 - precision: 0.6247\n",
      "Combinación 75 = (False, True, False, 8, 0.1) \n",
      " precision train: [0.9941479563713074, 0.6246537566184998]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 77: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.5252 - precision: 0.4854  \n",
      "Epoch 1: val_loss improved from inf to 1.36260, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.5135 - precision: 0.5355 - val_loss: 1.3626 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.3349 - precision: 0.5440\n",
      "Epoch 2: val_loss improved from 1.36260 to 1.31594, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3350 - precision: 0.5426 - val_loss: 1.3159 - val_precision: 0.6859\n",
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.3041 - precision: 0.5359\n",
      "Epoch 3: val_loss improved from 1.31594 to 1.28618, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3044 - precision: 0.5341 - val_loss: 1.2862 - val_precision: 0.6833\n",
      "Epoch 4/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.2768 - precision: 0.6056\n",
      "Epoch 4: val_loss improved from 1.28618 to 1.24755, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2746 - precision: 0.6080 - val_loss: 1.2475 - val_precision: 0.6720\n",
      "Epoch 5/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2196 - precision: 0.6138\n",
      "Epoch 5: val_loss improved from 1.24755 to 1.17972, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2169 - precision: 0.6150 - val_loss: 1.1797 - val_precision: 0.6732\n",
      "Epoch 6/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.1587 - precision: 0.6181\n",
      "Epoch 6: val_loss improved from 1.17972 to 1.13997, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1581 - precision: 0.6199 - val_loss: 1.1400 - val_precision: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1325 - precision: 0.6163\n",
      "Epoch 7: val_loss improved from 1.13997 to 1.11513, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1324 - precision: 0.6160 - val_loss: 1.1151 - val_precision: 0.6526\n",
      "Epoch 8/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1093 - precision: 0.6189\n",
      "Epoch 8: val_loss improved from 1.11513 to 1.09995, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1099 - precision: 0.6176 - val_loss: 1.1000 - val_precision: 0.6487\n",
      "Epoch 9/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1055 - precision: 0.6117\n",
      "Epoch 9: val_loss improved from 1.09995 to 1.08914, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1030 - precision: 0.6127 - val_loss: 1.0891 - val_precision: 0.6412\n",
      "Epoch 10/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0909 - precision: 0.6139\n",
      "Epoch 10: val_loss did not improve from 1.08914\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0941 - precision: 0.6113 - val_loss: 1.0970 - val_precision: 0.6303\n",
      "Epoch 11/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0827 - precision: 0.6084\n",
      "Epoch 11: val_loss improved from 1.08914 to 1.08567, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0816 - precision: 0.6090 - val_loss: 1.0857 - val_precision: 0.6252\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0926 - precision: 0.5996\n",
      "Epoch 12: val_loss improved from 1.08567 to 1.07660, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0913 - precision: 0.5994 - val_loss: 1.0766 - val_precision: 0.6309\n",
      "Epoch 13/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0713 - precision: 0.6018\n",
      "Epoch 13: val_loss did not improve from 1.07660\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0708 - precision: 0.6021 - val_loss: 1.0772 - val_precision: 0.6267\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0690 - precision: 0.6080\n",
      "Epoch 14: val_loss improved from 1.07660 to 1.07634, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0685 - precision: 0.6084 - val_loss: 1.0763 - val_precision: 0.6237\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0562 - precision: 0.6178\n",
      "Epoch 15: val_loss did not improve from 1.07634\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0562 - precision: 0.6175 - val_loss: 1.0809 - val_precision: 0.6167\n",
      "Epoch 16/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0590 - precision: 0.6105\n",
      "Epoch 16: val_loss improved from 1.07634 to 1.06580, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0577 - precision: 0.6103 - val_loss: 1.0658 - val_precision: 0.6324\n",
      "Epoch 17/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0547 - precision: 0.6114\n",
      "Epoch 17: val_loss did not improve from 1.06580\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0549 - precision: 0.6107 - val_loss: 1.0695 - val_precision: 0.6311\n",
      "Epoch 18/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0574 - precision: 0.6086\n",
      "Epoch 18: val_loss did not improve from 1.06580\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0546 - precision: 0.6080 - val_loss: 1.0717 - val_precision: 0.6259\n",
      "Epoch 19/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0453 - precision: 0.6066\n",
      "Epoch 19: val_loss improved from 1.06580 to 1.05809, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0456 - precision: 0.6066 - val_loss: 1.0581 - val_precision: 0.6329\n",
      "Epoch 20/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0535 - precision: 0.6075\n",
      "Epoch 20: val_loss did not improve from 1.05809\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0535 - precision: 0.6075 - val_loss: 1.0656 - val_precision: 0.6239\n",
      "Epoch 21/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0551 - precision: 0.6096\n",
      "Epoch 21: val_loss did not improve from 1.05809\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0551 - precision: 0.6096 - val_loss: 1.0667 - val_precision: 0.6314\n",
      "Epoch 22/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.0372 - precision: 0.6127\n",
      "Epoch 22: val_loss did not improve from 1.05809\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0414 - precision: 0.6112 - val_loss: 1.0719 - val_precision: 0.6138\n",
      "Epoch 23/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0356 - precision: 0.6104\n",
      "Epoch 23: val_loss did not improve from 1.05809\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0352 - precision: 0.6107 - val_loss: 1.0648 - val_precision: 0.6227\n",
      "Epoch 24/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0354 - precision: 0.6128\n",
      "Epoch 24: val_loss did not improve from 1.05809\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0363 - precision: 0.6124 - val_loss: 1.0621 - val_precision: 0.6278\n",
      "Epoch 25/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0303 - precision: 0.6142\n",
      "Epoch 25: val_loss did not improve from 1.05809\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0323 - precision: 0.6123 - val_loss: 1.0650 - val_precision: 0.6246\n",
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0278 - precision: 0.6153\n",
      "Epoch 26: val_loss did not improve from 1.05809\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0271 - precision: 0.6167 - val_loss: 1.0658 - val_precision: 0.6227\n",
      "Epoch 27/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0259 - precision: 0.6178\n",
      "Epoch 27: val_loss improved from 1.05809 to 1.05688, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0241 - precision: 0.6183 - val_loss: 1.0569 - val_precision: 0.6293\n",
      "Epoch 28/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0385 - precision: 0.6162\n",
      "Epoch 28: val_loss did not improve from 1.05688\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0377 - precision: 0.6167 - val_loss: 1.0623 - val_precision: 0.6221\n",
      "Epoch 29/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0202 - precision: 0.6198\n",
      "Epoch 29: val_loss did not improve from 1.05688\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0235 - precision: 0.6173 - val_loss: 1.0601 - val_precision: 0.6185\n",
      "Epoch 30/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0279 - precision: 0.6071\n",
      "Epoch 30: val_loss improved from 1.05688 to 1.05472, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0316 - precision: 0.6075 - val_loss: 1.0547 - val_precision: 0.6276\n",
      "Epoch 31/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0214 - precision: 0.6158\n",
      "Epoch 31: val_loss did not improve from 1.05472\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0277 - precision: 0.6143 - val_loss: 1.0601 - val_precision: 0.6261\n",
      "Epoch 32/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0176 - precision: 0.6171\n",
      "Epoch 32: val_loss did not improve from 1.05472\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0164 - precision: 0.6169 - val_loss: 1.0624 - val_precision: 0.6198\n",
      "Epoch 33/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0160 - precision: 0.6276\n",
      "Epoch 33: val_loss did not improve from 1.05472\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0160 - precision: 0.6272 - val_loss: 1.0613 - val_precision: 0.6274\n",
      "Epoch 34/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0202 - precision: 0.6161\n",
      "Epoch 34: val_loss did not improve from 1.05472\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0175 - precision: 0.6154 - val_loss: 1.0566 - val_precision: 0.6270\n",
      "Epoch 35/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0151 - precision: 0.6188\n",
      "Epoch 35: val_loss did not improve from 1.05472\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0176 - precision: 0.6167 - val_loss: 1.0620 - val_precision: 0.6155\n",
      "Epoch 36/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0120 - precision: 0.6121\n",
      "Epoch 36: val_loss did not improve from 1.05472\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0154 - precision: 0.6125 - val_loss: 1.0563 - val_precision: 0.6221\n",
      "Epoch 37/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0125 - precision: 0.6148\n",
      "Epoch 37: val_loss did not improve from 1.05472\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0146 - precision: 0.6146 - val_loss: 1.0579 - val_precision: 0.6226\n",
      "Epoch 38/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0104 - precision: 0.6172\n",
      "Epoch 38: val_loss improved from 1.05472 to 1.05417, saving model to model_ent77.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0126 - precision: 0.6163 - val_loss: 1.0542 - val_precision: 0.6297\n",
      "Epoch 39/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0107 - precision: 0.6188\n",
      "Epoch 39: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0115 - precision: 0.6190 - val_loss: 1.0618 - val_precision: 0.6156\n",
      "Epoch 40/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0114 - precision: 0.6165\n",
      "Epoch 40: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0118 - precision: 0.6160 - val_loss: 1.0620 - val_precision: 0.6222\n",
      "Epoch 41/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0098 - precision: 0.6165\n",
      "Epoch 41: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0057 - precision: 0.6172 - val_loss: 1.0576 - val_precision: 0.6240\n",
      "Epoch 42/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0090 - precision: 0.6136\n",
      "Epoch 42: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0129 - precision: 0.6127 - val_loss: 1.0551 - val_precision: 0.6258\n",
      "Epoch 43/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0078 - precision: 0.6133\n",
      "Epoch 43: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0064 - precision: 0.6148 - val_loss: 1.0624 - val_precision: 0.6146\n",
      "Epoch 44/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0059 - precision: 0.6149\n",
      "Epoch 44: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0065 - precision: 0.6130 - val_loss: 1.0592 - val_precision: 0.6173\n",
      "Epoch 45/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9975 - precision: 0.6209\n",
      "Epoch 45: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9984 - precision: 0.6219 - val_loss: 1.0601 - val_precision: 0.6161\n",
      "Epoch 46/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0034 - precision: 0.6170\n",
      "Epoch 46: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0031 - precision: 0.6173 - val_loss: 1.0623 - val_precision: 0.6121\n",
      "Epoch 47/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0045 - precision: 0.6161\n",
      "Epoch 47: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0036 - precision: 0.6165 - val_loss: 1.0574 - val_precision: 0.6206\n",
      "Epoch 48/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9999 - precision: 0.6185\n",
      "Epoch 48: val_loss did not improve from 1.05417\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9999 - precision: 0.6185 - val_loss: 1.0611 - val_precision: 0.6180\n",
      "Epoch 48: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0176 - precision: 0.6285\n",
      "Combinación 76 = (False, True, False, 8, 0.25) \n",
      " precision train: [1.0176109075546265, 0.6285085082054138]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 78: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.5860 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.50197, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.5826 - precision: 1.0000 - val_loss: 1.5020 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.4475 - precision: 0.5210\n",
      "Epoch 2: val_loss improved from 1.50197 to 1.35300, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.4445 - precision: 0.5244 - val_loss: 1.3530 - val_precision: 0.0000e+00\n",
      "Epoch 3/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.3767 - precision: 0.5420\n",
      "Epoch 3: val_loss improved from 1.35300 to 1.31598, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3777 - precision: 0.5384 - val_loss: 1.3160 - val_precision: 0.0000e+00\n",
      "Epoch 4/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3540 - precision: 0.5485\n",
      "Epoch 4: val_loss improved from 1.31598 to 1.30041, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3570 - precision: 0.5435 - val_loss: 1.3004 - val_precision: 0.7339\n",
      "Epoch 5/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.3367 - precision: 0.5354\n",
      "Epoch 5: val_loss improved from 1.30041 to 1.27980, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3369 - precision: 0.5367 - val_loss: 1.2798 - val_precision: 0.7029\n",
      "Epoch 6/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.3298 - precision: 0.5734\n",
      "Epoch 6: val_loss improved from 1.27980 to 1.27088, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3272 - precision: 0.5722 - val_loss: 1.2709 - val_precision: 0.6898\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.3181 - precision: 0.5821\n",
      "Epoch 7: val_loss improved from 1.27088 to 1.26290, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3175 - precision: 0.5820 - val_loss: 1.2629 - val_precision: 0.6918\n",
      "Epoch 8/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.3099 - precision: 0.5857\n",
      "Epoch 8: val_loss improved from 1.26290 to 1.25422, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3097 - precision: 0.5848 - val_loss: 1.2542 - val_precision: 0.6827\n",
      "Epoch 9/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2950 - precision: 0.6169\n",
      "Epoch 9: val_loss did not improve from 1.25422\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2950 - precision: 0.6169 - val_loss: 1.2577 - val_precision: 0.6766\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2994 - precision: 0.6142\n",
      "Epoch 10: val_loss improved from 1.25422 to 1.23703, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3000 - precision: 0.6117 - val_loss: 1.2370 - val_precision: 0.6683\n",
      "Epoch 11/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2917 - precision: 0.6136\n",
      "Epoch 11: val_loss improved from 1.23703 to 1.23649, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2914 - precision: 0.6104 - val_loss: 1.2365 - val_precision: 0.6643\n",
      "Epoch 12/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2799 - precision: 0.6168\n",
      "Epoch 12: val_loss improved from 1.23649 to 1.23032, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2801 - precision: 0.6176 - val_loss: 1.2303 - val_precision: 0.6587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2858 - precision: 0.6224\n",
      "Epoch 13: val_loss improved from 1.23032 to 1.22858, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2849 - precision: 0.6243 - val_loss: 1.2286 - val_precision: 0.6628\n",
      "Epoch 14/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2805 - precision: 0.6021\n",
      "Epoch 14: val_loss did not improve from 1.22858\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2827 - precision: 0.5995 - val_loss: 1.2292 - val_precision: 0.6699\n",
      "Epoch 15/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2844 - precision: 0.6117\n",
      "Epoch 15: val_loss improved from 1.22858 to 1.22472, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2818 - precision: 0.6086 - val_loss: 1.2247 - val_precision: 0.6714\n",
      "Epoch 16/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2834 - precision: 0.5733\n",
      "Epoch 16: val_loss improved from 1.22472 to 1.22380, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2822 - precision: 0.5758 - val_loss: 1.2238 - val_precision: 0.6674\n",
      "Epoch 17/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2653 - precision: 0.6279\n",
      "Epoch 17: val_loss did not improve from 1.22380\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2682 - precision: 0.6245 - val_loss: 1.2250 - val_precision: 0.6791\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2705 - precision: 0.6031\n",
      "Epoch 18: val_loss improved from 1.22380 to 1.22358, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2707 - precision: 0.6036 - val_loss: 1.2236 - val_precision: 0.6738\n",
      "Epoch 19/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2707 - precision: 0.5914\n",
      "Epoch 19: val_loss did not improve from 1.22358\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.2707 - precision: 0.5914 - val_loss: 1.2239 - val_precision: 0.6773\n",
      "Epoch 20/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2722 - precision: 0.6015\n",
      "Epoch 20: val_loss improved from 1.22358 to 1.22035, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.2709 - precision: 0.6027 - val_loss: 1.2203 - val_precision: 0.6636\n",
      "Epoch 21/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2691 - precision: 0.5921\n",
      "Epoch 21: val_loss did not improve from 1.22035\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2714 - precision: 0.5918 - val_loss: 1.2287 - val_precision: 0.6729\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2697 - precision: 0.5924\n",
      "Epoch 22: val_loss did not improve from 1.22035\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2693 - precision: 0.5937 - val_loss: 1.2274 - val_precision: 0.6729\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2565 - precision: 0.6159\n",
      "Epoch 23: val_loss did not improve from 1.22035\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2557 - precision: 0.6128 - val_loss: 1.2206 - val_precision: 0.6667\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2621 - precision: 0.5878\n",
      "Epoch 24: val_loss improved from 1.22035 to 1.21758, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2620 - precision: 0.5878 - val_loss: 1.2176 - val_precision: 0.6714\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2650 - precision: 0.6006\n",
      "Epoch 25: val_loss did not improve from 1.21758\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2654 - precision: 0.5991 - val_loss: 1.2236 - val_precision: 0.6722\n",
      "Epoch 26/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2698 - precision: 0.5903\n",
      "Epoch 26: val_loss improved from 1.21758 to 1.21740, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2679 - precision: 0.5930 - val_loss: 1.2174 - val_precision: 0.6723\n",
      "Epoch 27/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2590 - precision: 0.6018\n",
      "Epoch 27: val_loss improved from 1.21740 to 1.21397, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2566 - precision: 0.6055 - val_loss: 1.2140 - val_precision: 0.6752\n",
      "Epoch 28/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2537 - precision: 0.5890\n",
      "Epoch 28: val_loss improved from 1.21397 to 1.21268, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2537 - precision: 0.5890 - val_loss: 1.2127 - val_precision: 0.6674\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2573 - precision: 0.5890\n",
      "Epoch 29: val_loss did not improve from 1.21268\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2570 - precision: 0.5905 - val_loss: 1.2156 - val_precision: 0.6652\n",
      "Epoch 30/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2460 - precision: 0.5955\n",
      "Epoch 30: val_loss did not improve from 1.21268\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2469 - precision: 0.6003 - val_loss: 1.2132 - val_precision: 0.6516\n",
      "Epoch 31/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2558 - precision: 0.5909\n",
      "Epoch 31: val_loss improved from 1.21268 to 1.20882, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2564 - precision: 0.5909 - val_loss: 1.2088 - val_precision: 0.6592\n",
      "Epoch 32/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2520 - precision: 0.6122\n",
      "Epoch 32: val_loss did not improve from 1.20882\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2498 - precision: 0.6124 - val_loss: 1.2123 - val_precision: 0.6544\n",
      "Epoch 33/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2546 - precision: 0.5783\n",
      "Epoch 33: val_loss improved from 1.20882 to 1.20769, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2541 - precision: 0.5807 - val_loss: 1.2077 - val_precision: 0.6570\n",
      "Epoch 34/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2526 - precision: 0.5928\n",
      "Epoch 34: val_loss did not improve from 1.20769\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2567 - precision: 0.5910 - val_loss: 1.2112 - val_precision: 0.6590\n",
      "Epoch 35/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2424 - precision: 0.5898\n",
      "Epoch 35: val_loss did not improve from 1.20769\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2442 - precision: 0.5907 - val_loss: 1.2133 - val_precision: 0.6460\n",
      "Epoch 36/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2523 - precision: 0.5637\n",
      "Epoch 36: val_loss did not improve from 1.20769\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2539 - precision: 0.5646 - val_loss: 1.2144 - val_precision: 0.6416\n",
      "Epoch 37/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2468 - precision: 0.5854\n",
      "Epoch 37: val_loss did not improve from 1.20769\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2465 - precision: 0.5927 - val_loss: 1.2102 - val_precision: 0.6407\n",
      "Epoch 38/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2544 - precision: 0.5852\n",
      "Epoch 38: val_loss did not improve from 1.20769\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2547 - precision: 0.5853 - val_loss: 1.2083 - val_precision: 0.6512\n",
      "Epoch 39/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2293 - precision: 0.5968\n",
      "Epoch 39: val_loss did not improve from 1.20769\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2293 - precision: 0.5968 - val_loss: 1.2086 - val_precision: 0.6270\n",
      "Epoch 40/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2395 - precision: 0.5900\n",
      "Epoch 40: val_loss did not improve from 1.20769\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2391 - precision: 0.5876 - val_loss: 1.2156 - val_precision: 0.6422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.2429 - precision: 0.5872\n",
      "Epoch 41: val_loss improved from 1.20769 to 1.20747, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2439 - precision: 0.5851 - val_loss: 1.2075 - val_precision: 0.6321\n",
      "Epoch 42/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2446 - precision: 0.5780\n",
      "Epoch 42: val_loss did not improve from 1.20747\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2444 - precision: 0.5780 - val_loss: 1.2091 - val_precision: 0.6448\n",
      "Epoch 43/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2367 - precision: 0.5886\n",
      "Epoch 43: val_loss did not improve from 1.20747\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2365 - precision: 0.5888 - val_loss: 1.2117 - val_precision: 0.6409\n",
      "Epoch 44/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2414 - precision: 0.5768\n",
      "Epoch 44: val_loss improved from 1.20747 to 1.20595, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2398 - precision: 0.5807 - val_loss: 1.2060 - val_precision: 0.6345\n",
      "Epoch 45/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2477 - precision: 0.5799\n",
      "Epoch 45: val_loss did not improve from 1.20595\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2464 - precision: 0.5798 - val_loss: 1.2082 - val_precision: 0.6451\n",
      "Epoch 46/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2494 - precision: 0.5835\n",
      "Epoch 46: val_loss improved from 1.20595 to 1.19958, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2494 - precision: 0.5835 - val_loss: 1.1996 - val_precision: 0.6544\n",
      "Epoch 47/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2424 - precision: 0.5872\n",
      "Epoch 47: val_loss did not improve from 1.19958\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2437 - precision: 0.5877 - val_loss: 1.2016 - val_precision: 0.6280\n",
      "Epoch 48/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2365 - precision: 0.5899\n",
      "Epoch 48: val_loss improved from 1.19958 to 1.19870, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2362 - precision: 0.5915 - val_loss: 1.1987 - val_precision: 0.6317\n",
      "Epoch 49/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2405 - precision: 0.5801\n",
      "Epoch 49: val_loss improved from 1.19870 to 1.19657, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2398 - precision: 0.5805 - val_loss: 1.1966 - val_precision: 0.6352\n",
      "Epoch 50/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2405 - precision: 0.5687\n",
      "Epoch 50: val_loss improved from 1.19657 to 1.19457, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2406 - precision: 0.5692 - val_loss: 1.1946 - val_precision: 0.6377\n",
      "Epoch 51/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2385 - precision: 0.5822\n",
      "Epoch 51: val_loss did not improve from 1.19457\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2385 - precision: 0.5805 - val_loss: 1.2064 - val_precision: 0.6193\n",
      "Epoch 52/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2368 - precision: 0.5826\n",
      "Epoch 52: val_loss improved from 1.19457 to 1.18949, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2375 - precision: 0.5811 - val_loss: 1.1895 - val_precision: 0.6352\n",
      "Epoch 53/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2286 - precision: 0.5911\n",
      "Epoch 53: val_loss improved from 1.18949 to 1.18884, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2274 - precision: 0.5921 - val_loss: 1.1888 - val_precision: 0.6614\n",
      "Epoch 54/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2376 - precision: 0.5850\n",
      "Epoch 54: val_loss improved from 1.18884 to 1.18658, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2383 - precision: 0.5834 - val_loss: 1.1866 - val_precision: 0.6576\n",
      "Epoch 55/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2403 - precision: 0.5695\n",
      "Epoch 55: val_loss did not improve from 1.18658\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2391 - precision: 0.5687 - val_loss: 1.1915 - val_precision: 0.6544\n",
      "Epoch 56/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2325 - precision: 0.5793\n",
      "Epoch 56: val_loss did not improve from 1.18658\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2325 - precision: 0.5793 - val_loss: 1.1967 - val_precision: 0.6728\n",
      "Epoch 57/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.2452 - precision: 0.5748\n",
      "Epoch 57: val_loss improved from 1.18658 to 1.17846, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2374 - precision: 0.5766 - val_loss: 1.1785 - val_precision: 0.6635\n",
      "Epoch 58/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2264 - precision: 0.5820\n",
      "Epoch 58: val_loss improved from 1.17846 to 1.17345, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2279 - precision: 0.5846 - val_loss: 1.1734 - val_precision: 0.6835\n",
      "Epoch 59/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.2238 - precision: 0.5892\n",
      "Epoch 59: val_loss improved from 1.17345 to 1.16553, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2254 - precision: 0.5822 - val_loss: 1.1655 - val_precision: 0.6803\n",
      "Epoch 60/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2333 - precision: 0.5817\n",
      "Epoch 60: val_loss did not improve from 1.16553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2361 - precision: 0.5828 - val_loss: 1.1705 - val_precision: 0.6773\n",
      "Epoch 61/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2192 - precision: 0.5830\n",
      "Epoch 61: val_loss did not improve from 1.16553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2194 - precision: 0.5832 - val_loss: 1.1673 - val_precision: 0.6733\n",
      "Epoch 62/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2162 - precision: 0.5918\n",
      "Epoch 62: val_loss did not improve from 1.16553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2169 - precision: 0.5929 - val_loss: 1.1688 - val_precision: 0.6718\n",
      "Epoch 63/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.2158 - precision: 0.5902\n",
      "Epoch 63: val_loss improved from 1.16553 to 1.15623, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2097 - precision: 0.5942 - val_loss: 1.1562 - val_precision: 0.6716\n",
      "Epoch 64/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.2140 - precision: 0.5903\n",
      "Epoch 64: val_loss improved from 1.15623 to 1.15527, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2173 - precision: 0.5910 - val_loss: 1.1553 - val_precision: 0.6676\n",
      "Epoch 65/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2110 - precision: 0.5893\n",
      "Epoch 65: val_loss did not improve from 1.15527\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2135 - precision: 0.5894 - val_loss: 1.1628 - val_precision: 0.6625\n",
      "Epoch 66/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.2105 - precision: 0.5962\n",
      "Epoch 66: val_loss improved from 1.15527 to 1.14890, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2119 - precision: 0.5963 - val_loss: 1.1489 - val_precision: 0.6707\n",
      "Epoch 67/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2137 - precision: 0.5894\n",
      "Epoch 67: val_loss improved from 1.14890 to 1.14397, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2123 - precision: 0.5894 - val_loss: 1.1440 - val_precision: 0.6619\n",
      "Epoch 68/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2072 - precision: 0.5906\n",
      "Epoch 68: val_loss did not improve from 1.14397\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2109 - precision: 0.5901 - val_loss: 1.1581 - val_precision: 0.6595\n",
      "Epoch 69/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2035 - precision: 0.5923\n",
      "Epoch 69: val_loss improved from 1.14397 to 1.13792, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2061 - precision: 0.5918 - val_loss: 1.1379 - val_precision: 0.6508\n",
      "Epoch 70/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2085 - precision: 0.5930\n",
      "Epoch 70: val_loss improved from 1.13792 to 1.13580, saving model to model_ent78.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2079 - precision: 0.5960 - val_loss: 1.1358 - val_precision: 0.6593\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.1154 - precision: 0.6607\n",
      "Combinación 77 = (False, True, False, 8, 0.5) \n",
      " precision train: [1.115404725074768, 0.6607112288475037]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 79: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.4309 - precision: 0.5797\n",
      "Epoch 1: val_loss improved from inf to 1.23922, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 6s 7ms/step - loss: 1.4189 - precision: 0.5976 - val_loss: 1.2392 - val_precision: 0.6757\n",
      "Epoch 2/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1193 - precision: 0.6296\n",
      "Epoch 2: val_loss improved from 1.23922 to 1.11976, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1186 - precision: 0.6292 - val_loss: 1.1198 - val_precision: 0.6534\n",
      "Epoch 3/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0444 - precision: 0.6272\n",
      "Epoch 3: val_loss improved from 1.11976 to 1.09369, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0440 - precision: 0.6289 - val_loss: 1.0937 - val_precision: 0.6191\n",
      "Epoch 4/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0167 - precision: 0.6002\n",
      "Epoch 4: val_loss improved from 1.09369 to 1.07506, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0163 - precision: 0.6012 - val_loss: 1.0751 - val_precision: 0.6134\n",
      "Epoch 5/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0010 - precision: 0.5975\n",
      "Epoch 5: val_loss improved from 1.07506 to 1.05711, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0003 - precision: 0.5998 - val_loss: 1.0571 - val_precision: 0.6175\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9934 - precision: 0.6070\n",
      "Epoch 6: val_loss improved from 1.05711 to 1.05067, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9923 - precision: 0.6070 - val_loss: 1.0507 - val_precision: 0.6136\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9850 - precision: 0.6081\n",
      "Epoch 7: val_loss did not improve from 1.05067\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9849 - precision: 0.6082 - val_loss: 1.0513 - val_precision: 0.6126\n",
      "Epoch 8/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9804 - precision: 0.6041\n",
      "Epoch 8: val_loss improved from 1.05067 to 1.04986, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9813 - precision: 0.6045 - val_loss: 1.0499 - val_precision: 0.6087\n",
      "Epoch 9/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9730 - precision: 0.6032\n",
      "Epoch 9: val_loss improved from 1.04986 to 1.04274, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9730 - precision: 0.6032 - val_loss: 1.0427 - val_precision: 0.6128\n",
      "Epoch 10/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9699 - precision: 0.6080\n",
      "Epoch 10: val_loss improved from 1.04274 to 1.03716, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9682 - precision: 0.6100 - val_loss: 1.0372 - val_precision: 0.6160\n",
      "Epoch 11/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9523 - precision: 0.6106\n",
      "Epoch 11: val_loss improved from 1.03716 to 1.03617, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9557 - precision: 0.6109 - val_loss: 1.0362 - val_precision: 0.6138\n",
      "Epoch 12/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9519 - precision: 0.6113\n",
      "Epoch 12: val_loss improved from 1.03617 to 1.03084, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9518 - precision: 0.6112 - val_loss: 1.0308 - val_precision: 0.6225\n",
      "Epoch 13/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9520 - precision: 0.6098\n",
      "Epoch 13: val_loss did not improve from 1.03084\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9498 - precision: 0.6106 - val_loss: 1.0346 - val_precision: 0.6226\n",
      "Epoch 14/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9410 - precision: 0.6160\n",
      "Epoch 14: val_loss did not improve from 1.03084\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9382 - precision: 0.6155 - val_loss: 1.0345 - val_precision: 0.6157\n",
      "Epoch 15/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9323 - precision: 0.6191\n",
      "Epoch 15: val_loss improved from 1.03084 to 1.02715, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9365 - precision: 0.6149 - val_loss: 1.0272 - val_precision: 0.6200\n",
      "Epoch 16/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9340 - precision: 0.6149\n",
      "Epoch 16: val_loss did not improve from 1.02715\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9341 - precision: 0.6147 - val_loss: 1.0312 - val_precision: 0.6162\n",
      "Epoch 17/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9269 - precision: 0.6126\n",
      "Epoch 17: val_loss did not improve from 1.02715\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9270 - precision: 0.6138 - val_loss: 1.0310 - val_precision: 0.6149\n",
      "Epoch 18/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9302 - precision: 0.6137\n",
      "Epoch 18: val_loss improved from 1.02715 to 1.02676, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9214 - precision: 0.6168 - val_loss: 1.0268 - val_precision: 0.6097\n",
      "Epoch 19/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9164 - precision: 0.6183\n",
      "Epoch 19: val_loss improved from 1.02676 to 1.01630, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9153 - precision: 0.6188 - val_loss: 1.0163 - val_precision: 0.6221\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9117 - precision: 0.6192\n",
      "Epoch 20: val_loss did not improve from 1.01630\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9098 - precision: 0.6195 - val_loss: 1.0176 - val_precision: 0.6203\n",
      "Epoch 21/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9085 - precision: 0.6212\n",
      "Epoch 21: val_loss did not improve from 1.01630\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9085 - precision: 0.6212 - val_loss: 1.0277 - val_precision: 0.6184\n",
      "Epoch 22/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9061 - precision: 0.6259\n",
      "Epoch 22: val_loss did not improve from 1.01630\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9041 - precision: 0.6251 - val_loss: 1.0172 - val_precision: 0.6278\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8977 - precision: 0.6227\n",
      "Epoch 23: val_loss did not improve from 1.01630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8983 - precision: 0.6244 - val_loss: 1.0293 - val_precision: 0.6140\n",
      "Epoch 24/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8979 - precision: 0.6320\n",
      "Epoch 24: val_loss improved from 1.01630 to 1.01134, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8969 - precision: 0.6337 - val_loss: 1.0113 - val_precision: 0.6190\n",
      "Epoch 25/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.8939 - precision: 0.6298\n",
      "Epoch 25: val_loss did not improve from 1.01134\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8945 - precision: 0.6283 - val_loss: 1.0152 - val_precision: 0.6283\n",
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8895 - precision: 0.6286\n",
      "Epoch 26: val_loss did not improve from 1.01134\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8899 - precision: 0.6291 - val_loss: 1.0177 - val_precision: 0.6199\n",
      "Epoch 27/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8832 - precision: 0.6286\n",
      "Epoch 27: val_loss did not improve from 1.01134\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8838 - precision: 0.6282 - val_loss: 1.0251 - val_precision: 0.6083\n",
      "Epoch 28/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8825 - precision: 0.6281\n",
      "Epoch 28: val_loss did not improve from 1.01134\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8819 - precision: 0.6284 - val_loss: 1.0215 - val_precision: 0.6173\n",
      "Epoch 29/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8787 - precision: 0.6345\n",
      "Epoch 29: val_loss did not improve from 1.01134\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8784 - precision: 0.6347 - val_loss: 1.0240 - val_precision: 0.6183\n",
      "Epoch 30/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8736 - precision: 0.6333\n",
      "Epoch 30: val_loss did not improve from 1.01134\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8717 - precision: 0.6345 - val_loss: 1.0188 - val_precision: 0.6220\n",
      "Epoch 31/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8721 - precision: 0.6322\n",
      "Epoch 31: val_loss did not improve from 1.01134\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8741 - precision: 0.6299 - val_loss: 1.0232 - val_precision: 0.6160\n",
      "Epoch 32/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8685 - precision: 0.6293\n",
      "Epoch 32: val_loss did not improve from 1.01134\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8697 - precision: 0.6292 - val_loss: 1.0150 - val_precision: 0.6162\n",
      "Epoch 33/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8628 - precision: 0.6362\n",
      "Epoch 33: val_loss did not improve from 1.01134\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8627 - precision: 0.6363 - val_loss: 1.0213 - val_precision: 0.6188\n",
      "Epoch 34/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8608 - precision: 0.6301\n",
      "Epoch 34: val_loss improved from 1.01134 to 1.00020, saving model to model_ent79.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8631 - precision: 0.6296 - val_loss: 1.0002 - val_precision: 0.6349\n",
      "Epoch 35/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8511 - precision: 0.6408\n",
      "Epoch 35: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8542 - precision: 0.6401 - val_loss: 1.0249 - val_precision: 0.6179\n",
      "Epoch 36/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8555 - precision: 0.6368\n",
      "Epoch 36: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8543 - precision: 0.6368 - val_loss: 1.0288 - val_precision: 0.6131\n",
      "Epoch 37/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8495 - precision: 0.6408\n",
      "Epoch 37: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8494 - precision: 0.6405 - val_loss: 1.0271 - val_precision: 0.6125\n",
      "Epoch 38/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8477 - precision: 0.6391\n",
      "Epoch 38: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8457 - precision: 0.6400 - val_loss: 1.0164 - val_precision: 0.6176\n",
      "Epoch 39/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8425 - precision: 0.6384\n",
      "Epoch 39: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8426 - precision: 0.6384 - val_loss: 1.0215 - val_precision: 0.6241\n",
      "Epoch 40/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8387 - precision: 0.6422\n",
      "Epoch 40: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8396 - precision: 0.6422 - val_loss: 1.0151 - val_precision: 0.6220\n",
      "Epoch 41/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8341 - precision: 0.6469\n",
      "Epoch 41: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8341 - precision: 0.6464 - val_loss: 1.0262 - val_precision: 0.6070\n",
      "Epoch 42/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8333 - precision: 0.6428\n",
      "Epoch 42: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8349 - precision: 0.6417 - val_loss: 1.0312 - val_precision: 0.6122\n",
      "Epoch 43/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8361 - precision: 0.6429\n",
      "Epoch 43: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8375 - precision: 0.6420 - val_loss: 1.0125 - val_precision: 0.6167\n",
      "Epoch 44/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8253 - precision: 0.6469\n",
      "Epoch 44: val_loss did not improve from 1.00020\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8265 - precision: 0.6461 - val_loss: 1.0204 - val_precision: 0.6181\n",
      "Epoch 44: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9120 - precision: 0.6485\n",
      "Combinación 78 = (False, True, False, 16, 0.1) \n",
      " precision train: [0.9119760990142822, 0.6485345363616943]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 80: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.5046 - precision: 0.5124\n",
      "Epoch 1: val_loss improved from inf to 1.30229, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 6s 8ms/step - loss: 1.4877 - precision: 0.5114 - val_loss: 1.3023 - val_precision: 0.5872\n",
      "Epoch 2/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1550 - precision: 0.6030\n",
      "Epoch 2: val_loss improved from 1.30229 to 1.12806, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1487 - precision: 0.6029 - val_loss: 1.1281 - val_precision: 0.6215\n",
      "Epoch 3/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0780 - precision: 0.5921\n",
      "Epoch 3: val_loss improved from 1.12806 to 1.07777, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0759 - precision: 0.5927 - val_loss: 1.0778 - val_precision: 0.6132\n",
      "Epoch 4/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0486 - precision: 0.5968\n",
      "Epoch 4: val_loss improved from 1.07777 to 1.07728, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0466 - precision: 0.5981 - val_loss: 1.0773 - val_precision: 0.6009\n",
      "Epoch 5/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0354 - precision: 0.5893\n",
      "Epoch 5: val_loss improved from 1.07728 to 1.06375, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0364 - precision: 0.5884 - val_loss: 1.0637 - val_precision: 0.6037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0266 - precision: 0.5975\n",
      "Epoch 6: val_loss did not improve from 1.06375\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0286 - precision: 0.5965 - val_loss: 1.0731 - val_precision: 0.5979\n",
      "Epoch 7/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0223 - precision: 0.5956\n",
      "Epoch 7: val_loss did not improve from 1.06375\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0207 - precision: 0.5969 - val_loss: 1.0656 - val_precision: 0.6028\n",
      "Epoch 8/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0164 - precision: 0.6022\n",
      "Epoch 8: val_loss improved from 1.06375 to 1.05813, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0215 - precision: 0.5972 - val_loss: 1.0581 - val_precision: 0.6055\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9983 - precision: 0.6062\n",
      "Epoch 9: val_loss improved from 1.05813 to 1.05080, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9973 - precision: 0.6064 - val_loss: 1.0508 - val_precision: 0.6054\n",
      "Epoch 10/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0148 - precision: 0.5996\n",
      "Epoch 10: val_loss improved from 1.05080 to 1.04562, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0098 - precision: 0.6005 - val_loss: 1.0456 - val_precision: 0.6137\n",
      "Epoch 11/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0000 - precision: 0.6043\n",
      "Epoch 11: val_loss did not improve from 1.04562\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9948 - precision: 0.6082 - val_loss: 1.0500 - val_precision: 0.6095\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9859 - precision: 0.6066\n",
      "Epoch 12: val_loss did not improve from 1.04562\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9841 - precision: 0.6077 - val_loss: 1.0499 - val_precision: 0.6067\n",
      "Epoch 13/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9930 - precision: 0.6069\n",
      "Epoch 13: val_loss improved from 1.04562 to 1.04135, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9892 - precision: 0.6091 - val_loss: 1.0414 - val_precision: 0.6164\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9778 - precision: 0.6049\n",
      "Epoch 14: val_loss did not improve from 1.04135\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9778 - precision: 0.6049 - val_loss: 1.0426 - val_precision: 0.6163\n",
      "Epoch 15/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9856 - precision: 0.6038\n",
      "Epoch 15: val_loss did not improve from 1.04135\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9838 - precision: 0.6058 - val_loss: 1.0509 - val_precision: 0.6124\n",
      "Epoch 16/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9845 - precision: 0.6052\n",
      "Epoch 16: val_loss improved from 1.04135 to 1.04125, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9827 - precision: 0.6039 - val_loss: 1.0413 - val_precision: 0.6166\n",
      "Epoch 17/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9709 - precision: 0.6063\n",
      "Epoch 17: val_loss improved from 1.04125 to 1.03875, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9696 - precision: 0.6051 - val_loss: 1.0388 - val_precision: 0.6124\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9680 - precision: 0.6089\n",
      "Epoch 18: val_loss improved from 1.03875 to 1.03601, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9692 - precision: 0.6086 - val_loss: 1.0360 - val_precision: 0.6132\n",
      "Epoch 19/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9650 - precision: 0.6105\n",
      "Epoch 19: val_loss did not improve from 1.03601\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9688 - precision: 0.6109 - val_loss: 1.0382 - val_precision: 0.6192\n",
      "Epoch 20/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9679 - precision: 0.6103\n",
      "Epoch 20: val_loss did not improve from 1.03601\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9676 - precision: 0.6105 - val_loss: 1.0407 - val_precision: 0.6160\n",
      "Epoch 21/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9533 - precision: 0.6089\n",
      "Epoch 21: val_loss did not improve from 1.03601\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9551 - precision: 0.6080 - val_loss: 1.0409 - val_precision: 0.6145\n",
      "Epoch 22/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9669 - precision: 0.6058\n",
      "Epoch 22: val_loss improved from 1.03601 to 1.02977, saving model to model_ent80.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9662 - precision: 0.6047 - val_loss: 1.0298 - val_precision: 0.6184\n",
      "Epoch 23/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9579 - precision: 0.6086\n",
      "Epoch 23: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9581 - precision: 0.6095 - val_loss: 1.0374 - val_precision: 0.6142\n",
      "Epoch 24/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9576 - precision: 0.6086\n",
      "Epoch 24: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9567 - precision: 0.6092 - val_loss: 1.0379 - val_precision: 0.6144\n",
      "Epoch 25/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9479 - precision: 0.6150\n",
      "Epoch 25: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9450 - precision: 0.6155 - val_loss: 1.0414 - val_precision: 0.6119\n",
      "Epoch 26/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9536 - precision: 0.6141\n",
      "Epoch 26: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9504 - precision: 0.6175 - val_loss: 1.0460 - val_precision: 0.6118\n",
      "Epoch 27/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9445 - precision: 0.6120\n",
      "Epoch 27: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9454 - precision: 0.6103 - val_loss: 1.0354 - val_precision: 0.6184\n",
      "Epoch 28/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9360 - precision: 0.6154\n",
      "Epoch 28: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9398 - precision: 0.6151 - val_loss: 1.0423 - val_precision: 0.6072\n",
      "Epoch 29/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9428 - precision: 0.6141\n",
      "Epoch 29: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9405 - precision: 0.6159 - val_loss: 1.0305 - val_precision: 0.6210\n",
      "Epoch 30/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9385 - precision: 0.6126\n",
      "Epoch 30: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9376 - precision: 0.6127 - val_loss: 1.0327 - val_precision: 0.6192\n",
      "Epoch 31/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9423 - precision: 0.6126\n",
      "Epoch 31: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9462 - precision: 0.6127 - val_loss: 1.0529 - val_precision: 0.5988\n",
      "Epoch 32/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9339 - precision: 0.6139\n",
      "Epoch 32: val_loss did not improve from 1.02977\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9350 - precision: 0.6133 - val_loss: 1.0332 - val_precision: 0.6175\n",
      "Epoch 32: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9868 - precision: 0.6214\n",
      "Combinación 79 = (False, True, False, 16, 0.25) \n",
      " precision train: [0.9868094325065613, 0.6214401125907898]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 81: \n",
      "\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.5385 - precision: 0.5860\n",
      "Epoch 1: val_loss improved from inf to 1.32326, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 7s 10ms/step - loss: 1.5286 - precision: 0.5755 - val_loss: 1.3233 - val_precision: 0.6879\n",
      "Epoch 2/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.3329 - precision: 0.5882\n",
      "Epoch 2: val_loss improved from 1.32326 to 1.24498, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.3293 - precision: 0.5906 - val_loss: 1.2450 - val_precision: 0.6925\n",
      "Epoch 3/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2683 - precision: 0.6162\n",
      "Epoch 3: val_loss improved from 1.24498 to 1.18773, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2681 - precision: 0.6155 - val_loss: 1.1877 - val_precision: 0.6977\n",
      "Epoch 4/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2222 - precision: 0.6195\n",
      "Epoch 4: val_loss improved from 1.18773 to 1.15035, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2216 - precision: 0.6235 - val_loss: 1.1504 - val_precision: 0.6644\n",
      "Epoch 5/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1787 - precision: 0.6208\n",
      "Epoch 5: val_loss improved from 1.15035 to 1.13989, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1839 - precision: 0.6194 - val_loss: 1.1399 - val_precision: 0.6706\n",
      "Epoch 6/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1777 - precision: 0.6046\n",
      "Epoch 6: val_loss improved from 1.13989 to 1.11498, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1741 - precision: 0.6071 - val_loss: 1.1150 - val_precision: 0.6574\n",
      "Epoch 7/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1618 - precision: 0.6033\n",
      "Epoch 7: val_loss improved from 1.11498 to 1.10519, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1621 - precision: 0.6030 - val_loss: 1.1052 - val_precision: 0.6595\n",
      "Epoch 8/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.1426 - precision: 0.6214\n",
      "Epoch 8: val_loss improved from 1.10519 to 1.10054, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1380 - precision: 0.6216 - val_loss: 1.1005 - val_precision: 0.6415\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1367 - precision: 0.6194\n",
      "Epoch 9: val_loss did not improve from 1.10054\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1372 - precision: 0.6193 - val_loss: 1.1032 - val_precision: 0.6333\n",
      "Epoch 10/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1278 - precision: 0.6106\n",
      "Epoch 10: val_loss did not improve from 1.10054\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1268 - precision: 0.6095 - val_loss: 1.1011 - val_precision: 0.6291\n",
      "Epoch 11/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1295 - precision: 0.6128\n",
      "Epoch 11: val_loss improved from 1.10054 to 1.09449, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1276 - precision: 0.6121 - val_loss: 1.0945 - val_precision: 0.6365\n",
      "Epoch 12/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1287 - precision: 0.6179\n",
      "Epoch 12: val_loss improved from 1.09449 to 1.08575, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1273 - precision: 0.6182 - val_loss: 1.0857 - val_precision: 0.6441\n",
      "Epoch 13/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1087 - precision: 0.6164\n",
      "Epoch 13: val_loss did not improve from 1.08575\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1087 - precision: 0.6164 - val_loss: 1.0863 - val_precision: 0.6379\n",
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1043 - precision: 0.6203\n",
      "Epoch 14: val_loss improved from 1.08575 to 1.07982, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1043 - precision: 0.6201 - val_loss: 1.0798 - val_precision: 0.6331\n",
      "Epoch 15/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1091 - precision: 0.6109\n",
      "Epoch 15: val_loss did not improve from 1.07982\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1107 - precision: 0.6111 - val_loss: 1.0859 - val_precision: 0.6262\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1023 - precision: 0.6208\n",
      "Epoch 16: val_loss did not improve from 1.07982\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1002 - precision: 0.6216 - val_loss: 1.0859 - val_precision: 0.6212\n",
      "Epoch 17/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0951 - precision: 0.6142\n",
      "Epoch 17: val_loss did not improve from 1.07982\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0979 - precision: 0.6129 - val_loss: 1.0799 - val_precision: 0.6362\n",
      "Epoch 18/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0996 - precision: 0.6105\n",
      "Epoch 18: val_loss improved from 1.07982 to 1.07904, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0970 - precision: 0.6110 - val_loss: 1.0790 - val_precision: 0.6236\n",
      "Epoch 19/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1029 - precision: 0.6129\n",
      "Epoch 19: val_loss did not improve from 1.07904\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1049 - precision: 0.6125 - val_loss: 1.0814 - val_precision: 0.6281\n",
      "Epoch 20/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0863 - precision: 0.6062\n",
      "Epoch 20: val_loss did not improve from 1.07904\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0899 - precision: 0.6043 - val_loss: 1.0876 - val_precision: 0.6238\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0880 - precision: 0.6074\n",
      "Epoch 21: val_loss improved from 1.07904 to 1.07650, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0873 - precision: 0.6086 - val_loss: 1.0765 - val_precision: 0.6319\n",
      "Epoch 22/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0710 - precision: 0.6207\n",
      "Epoch 22: val_loss did not improve from 1.07650\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0731 - precision: 0.6222 - val_loss: 1.0801 - val_precision: 0.6214\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0871 - precision: 0.6146\n",
      "Epoch 23: val_loss did not improve from 1.07650\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0866 - precision: 0.6159 - val_loss: 1.0813 - val_precision: 0.6163\n",
      "Epoch 24/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0879 - precision: 0.6177\n",
      "Epoch 24: val_loss did not improve from 1.07650\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0843 - precision: 0.6194 - val_loss: 1.0809 - val_precision: 0.6184\n",
      "Epoch 25/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0825 - precision: 0.6061\n",
      "Epoch 25: val_loss did not improve from 1.07650\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0796 - precision: 0.6094 - val_loss: 1.0820 - val_precision: 0.6169\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0848 - precision: 0.6200\n",
      "Epoch 26: val_loss improved from 1.07650 to 1.07610, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0848 - precision: 0.6200 - val_loss: 1.0761 - val_precision: 0.6222\n",
      "Epoch 27/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0630 - precision: 0.6206\n",
      "Epoch 27: val_loss did not improve from 1.07610\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0663 - precision: 0.6199 - val_loss: 1.0795 - val_precision: 0.6103\n",
      "Epoch 28/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0693 - precision: 0.6194\n",
      "Epoch 28: val_loss did not improve from 1.07610\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0691 - precision: 0.6198 - val_loss: 1.0856 - val_precision: 0.6113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0697 - precision: 0.6167\n",
      "Epoch 29: val_loss did not improve from 1.07610\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0671 - precision: 0.6202 - val_loss: 1.0766 - val_precision: 0.6182\n",
      "Epoch 30/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0557 - precision: 0.6198\n",
      "Epoch 30: val_loss did not improve from 1.07610\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0554 - precision: 0.6199 - val_loss: 1.0861 - val_precision: 0.6129\n",
      "Epoch 31/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0734 - precision: 0.6129\n",
      "Epoch 31: val_loss improved from 1.07610 to 1.06529, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0670 - precision: 0.6159 - val_loss: 1.0653 - val_precision: 0.6269\n",
      "Epoch 32/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0677 - precision: 0.6079\n",
      "Epoch 32: val_loss did not improve from 1.06529\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0666 - precision: 0.6069 - val_loss: 1.0688 - val_precision: 0.6210\n",
      "Epoch 33/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0526 - precision: 0.6227\n",
      "Epoch 33: val_loss did not improve from 1.06529\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0526 - precision: 0.6227 - val_loss: 1.0721 - val_precision: 0.6146\n",
      "Epoch 34/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0556 - precision: 0.6192\n",
      "Epoch 34: val_loss improved from 1.06529 to 1.06336, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0548 - precision: 0.6194 - val_loss: 1.0634 - val_precision: 0.6212\n",
      "Epoch 35/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0505 - precision: 0.6222\n",
      "Epoch 35: val_loss did not improve from 1.06336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0505 - precision: 0.6222 - val_loss: 1.0760 - val_precision: 0.6186\n",
      "Epoch 36/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0623 - precision: 0.6116\n",
      "Epoch 36: val_loss did not improve from 1.06336\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0623 - precision: 0.6116 - val_loss: 1.0814 - val_precision: 0.6125\n",
      "Epoch 37/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0555 - precision: 0.6070\n",
      "Epoch 37: val_loss did not improve from 1.06336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0557 - precision: 0.6074 - val_loss: 1.0710 - val_precision: 0.6166\n",
      "Epoch 38/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0526 - precision: 0.6178\n",
      "Epoch 38: val_loss did not improve from 1.06336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0527 - precision: 0.6182 - val_loss: 1.0851 - val_precision: 0.6069\n",
      "Epoch 39/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0505 - precision: 0.6171\n",
      "Epoch 39: val_loss did not improve from 1.06336\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0509 - precision: 0.6170 - val_loss: 1.0746 - val_precision: 0.6158\n",
      "Epoch 40/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0548 - precision: 0.6163\n",
      "Epoch 40: val_loss improved from 1.06336 to 1.06195, saving model to model_ent81.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0548 - precision: 0.6163 - val_loss: 1.0620 - val_precision: 0.6185\n",
      "Epoch 41/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0495 - precision: 0.6182\n",
      "Epoch 41: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0485 - precision: 0.6182 - val_loss: 1.0649 - val_precision: 0.6193\n",
      "Epoch 42/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0453 - precision: 0.6164\n",
      "Epoch 42: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0460 - precision: 0.6174 - val_loss: 1.0645 - val_precision: 0.6146\n",
      "Epoch 43/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0429 - precision: 0.6251\n",
      "Epoch 43: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0416 - precision: 0.6246 - val_loss: 1.0717 - val_precision: 0.6111\n",
      "Epoch 44/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0430 - precision: 0.6199\n",
      "Epoch 44: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0416 - precision: 0.6196 - val_loss: 1.0692 - val_precision: 0.6110\n",
      "Epoch 45/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0523 - precision: 0.6153\n",
      "Epoch 45: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0490 - precision: 0.6170 - val_loss: 1.0670 - val_precision: 0.6128\n",
      "Epoch 46/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0322 - precision: 0.6218\n",
      "Epoch 46: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0327 - precision: 0.6198 - val_loss: 1.0628 - val_precision: 0.6160\n",
      "Epoch 47/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0548 - precision: 0.6226\n",
      "Epoch 47: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0507 - precision: 0.6235 - val_loss: 1.0650 - val_precision: 0.6177\n",
      "Epoch 48/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0369 - precision: 0.6200\n",
      "Epoch 48: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0363 - precision: 0.6197 - val_loss: 1.0794 - val_precision: 0.6130\n",
      "Epoch 49/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0245 - precision: 0.6283\n",
      "Epoch 49: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0250 - precision: 0.6268 - val_loss: 1.0790 - val_precision: 0.6055\n",
      "Epoch 50/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0236 - precision: 0.6223\n",
      "Epoch 50: val_loss did not improve from 1.06195\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0270 - precision: 0.6210 - val_loss: 1.0647 - val_precision: 0.6134\n",
      "Epoch 50: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0307 - precision: 0.6240\n",
      "Combinación 80 = (False, True, False, 16, 0.5) \n",
      " precision train: [1.0307400226593018, 0.6240251660346985]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 82: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2953 - precision: 0.6470\n",
      "Epoch 1: val_loss improved from inf to 1.11395, saving model to model_ent82.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.2932 - precision: 0.6468 - val_loss: 1.1140 - val_precision: 0.6435\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0287 - precision: 0.6133\n",
      "Epoch 2: val_loss improved from 1.11395 to 1.05788, saving model to model_ent82.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0298 - precision: 0.6128 - val_loss: 1.0579 - val_precision: 0.6316\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9876 - precision: 0.6021\n",
      "Epoch 3: val_loss improved from 1.05788 to 1.04730, saving model to model_ent82.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9876 - precision: 0.6023 - val_loss: 1.0473 - val_precision: 0.6147\n",
      "Epoch 4/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9778 - precision: 0.6038\n",
      "Epoch 4: val_loss improved from 1.04730 to 1.02759, saving model to model_ent82.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9778 - precision: 0.6038 - val_loss: 1.0276 - val_precision: 0.6256\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9632 - precision: 0.6054\n",
      "Epoch 5: val_loss improved from 1.02759 to 1.02472, saving model to model_ent82.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9646 - precision: 0.6049 - val_loss: 1.0247 - val_precision: 0.6265\n",
      "Epoch 6/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9478 - precision: 0.6086\n",
      "Epoch 6: val_loss did not improve from 1.02472\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9457 - precision: 0.6110 - val_loss: 1.0382 - val_precision: 0.6206\n",
      "Epoch 7/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9380 - precision: 0.6073\n",
      "Epoch 7: val_loss did not improve from 1.02472\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9383 - precision: 0.6064 - val_loss: 1.0291 - val_precision: 0.6222\n",
      "Epoch 8/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9347 - precision: 0.6083\n",
      "Epoch 8: val_loss improved from 1.02472 to 1.01310, saving model to model_ent82.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9324 - precision: 0.6060 - val_loss: 1.0131 - val_precision: 0.6240\n",
      "Epoch 9/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9251 - precision: 0.6115\n",
      "Epoch 9: val_loss did not improve from 1.01310\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9270 - precision: 0.6084 - val_loss: 1.0326 - val_precision: 0.6122\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9128 - precision: 0.6175\n",
      "Epoch 10: val_loss did not improve from 1.01310\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9173 - precision: 0.6169 - val_loss: 1.0143 - val_precision: 0.6212\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9109 - precision: 0.6139\n",
      "Epoch 11: val_loss did not improve from 1.01310\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9109 - precision: 0.6137 - val_loss: 1.0323 - val_precision: 0.6171\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9023 - precision: 0.6161\n",
      "Epoch 12: val_loss improved from 1.01310 to 0.99702, saving model to model_ent82.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9020 - precision: 0.6167 - val_loss: 0.9970 - val_precision: 0.6364\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8990 - precision: 0.6157\n",
      "Epoch 13: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8955 - precision: 0.6184 - val_loss: 1.0046 - val_precision: 0.6262\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8918 - precision: 0.6232\n",
      "Epoch 14: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8910 - precision: 0.6235 - val_loss: 1.0285 - val_precision: 0.6090\n",
      "Epoch 15/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.8849 - precision: 0.6209\n",
      "Epoch 15: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8876 - precision: 0.6194 - val_loss: 1.0129 - val_precision: 0.6255\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8805 - precision: 0.6217\n",
      "Epoch 16: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8805 - precision: 0.6216 - val_loss: 0.9994 - val_precision: 0.6316\n",
      "Epoch 17/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8731 - precision: 0.6287\n",
      "Epoch 17: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8742 - precision: 0.6270 - val_loss: 1.0264 - val_precision: 0.6158\n",
      "Epoch 18/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8673 - precision: 0.6282\n",
      "Epoch 18: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8693 - precision: 0.6253 - val_loss: 1.0142 - val_precision: 0.6236\n",
      "Epoch 19/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8642 - precision: 0.6303\n",
      "Epoch 19: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8642 - precision: 0.6303 - val_loss: 1.0156 - val_precision: 0.6217\n",
      "Epoch 20/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8584 - precision: 0.6298\n",
      "Epoch 20: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8579 - precision: 0.6299 - val_loss: 1.0352 - val_precision: 0.6144\n",
      "Epoch 21/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8582 - precision: 0.6280\n",
      "Epoch 21: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8560 - precision: 0.6297 - val_loss: 1.0217 - val_precision: 0.6198\n",
      "Epoch 22/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8485 - precision: 0.6306\n",
      "Epoch 22: val_loss did not improve from 0.99702\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8474 - precision: 0.6305 - val_loss: 1.0021 - val_precision: 0.6314\n",
      "Epoch 22: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9165 - precision: 0.6425\n",
      "Combinación 81 = (False, True, False, 32, 0.1) \n",
      " precision train: [0.916492223739624, 0.6425084471702576]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 83: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.3370 - precision: 0.6513\n",
      "Epoch 1: val_loss improved from inf to 1.13112, saving model to model_ent83.h5\n",
      "236/236 [==============================] - 6s 8ms/step - loss: 1.3211 - precision: 0.6417 - val_loss: 1.1311 - val_precision: 0.6353\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0422 - precision: 0.6031\n",
      "Epoch 2: val_loss improved from 1.13112 to 1.06876, saving model to model_ent83.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0448 - precision: 0.6024 - val_loss: 1.0688 - val_precision: 0.6219\n",
      "Epoch 3/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0093 - precision: 0.6008\n",
      "Epoch 3: val_loss improved from 1.06876 to 1.05264, saving model to model_ent83.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0090 - precision: 0.6009 - val_loss: 1.0526 - val_precision: 0.6115\n",
      "Epoch 4/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9953 - precision: 0.5992\n",
      "Epoch 4: val_loss improved from 1.05264 to 1.04861, saving model to model_ent83.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9917 - precision: 0.6003 - val_loss: 1.0486 - val_precision: 0.6092\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9797 - precision: 0.6066\n",
      "Epoch 5: val_loss did not improve from 1.04861\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9807 - precision: 0.6065 - val_loss: 1.0507 - val_precision: 0.6039\n",
      "Epoch 6/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9704 - precision: 0.6096\n",
      "Epoch 6: val_loss did not improve from 1.04861\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9681 - precision: 0.6093 - val_loss: 1.0508 - val_precision: 0.6136\n",
      "Epoch 7/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9643 - precision: 0.6082\n",
      "Epoch 7: val_loss improved from 1.04861 to 1.03258, saving model to model_ent83.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9641 - precision: 0.6072 - val_loss: 1.0326 - val_precision: 0.6105\n",
      "Epoch 8/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9580 - precision: 0.6065\n",
      "Epoch 8: val_loss did not improve from 1.03258\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9593 - precision: 0.6045 - val_loss: 1.0331 - val_precision: 0.6083\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9590 - precision: 0.6097\n",
      "Epoch 9: val_loss improved from 1.03258 to 1.01866, saving model to model_ent83.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9584 - precision: 0.6099 - val_loss: 1.0187 - val_precision: 0.6260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9508 - precision: 0.6146\n",
      "Epoch 10: val_loss did not improve from 1.01866\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9530 - precision: 0.6145 - val_loss: 1.0210 - val_precision: 0.6164\n",
      "Epoch 11/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9472 - precision: 0.6124\n",
      "Epoch 11: val_loss did not improve from 1.01866\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9456 - precision: 0.6129 - val_loss: 1.0282 - val_precision: 0.6139\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9390 - precision: 0.6136\n",
      "Epoch 12: val_loss did not improve from 1.01866\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9375 - precision: 0.6143 - val_loss: 1.0367 - val_precision: 0.6062\n",
      "Epoch 13/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9339 - precision: 0.6144\n",
      "Epoch 13: val_loss did not improve from 1.01866\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9335 - precision: 0.6144 - val_loss: 1.0369 - val_precision: 0.6130\n",
      "Epoch 14/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9299 - precision: 0.6135\n",
      "Epoch 14: val_loss improved from 1.01866 to 1.00512, saving model to model_ent83.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9321 - precision: 0.6139 - val_loss: 1.0051 - val_precision: 0.6314\n",
      "Epoch 15/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9217 - precision: 0.6184\n",
      "Epoch 15: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9244 - precision: 0.6172 - val_loss: 1.0221 - val_precision: 0.6158\n",
      "Epoch 16/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9185 - precision: 0.6229\n",
      "Epoch 16: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9194 - precision: 0.6218 - val_loss: 1.0191 - val_precision: 0.6234\n",
      "Epoch 17/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9165 - precision: 0.6226\n",
      "Epoch 17: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9157 - precision: 0.6262 - val_loss: 1.0189 - val_precision: 0.6213\n",
      "Epoch 18/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8988 - precision: 0.6218\n",
      "Epoch 18: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9008 - precision: 0.6232 - val_loss: 1.0177 - val_precision: 0.6187\n",
      "Epoch 19/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9052 - precision: 0.6241\n",
      "Epoch 19: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9051 - precision: 0.6242 - val_loss: 1.0250 - val_precision: 0.6281\n",
      "Epoch 20/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8998 - precision: 0.6252\n",
      "Epoch 20: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8996 - precision: 0.6255 - val_loss: 1.0113 - val_precision: 0.6234\n",
      "Epoch 21/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8927 - precision: 0.6283\n",
      "Epoch 21: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8942 - precision: 0.6280 - val_loss: 1.0247 - val_precision: 0.6146\n",
      "Epoch 22/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8916 - precision: 0.6224\n",
      "Epoch 22: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8933 - precision: 0.6228 - val_loss: 1.0158 - val_precision: 0.6270\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8844 - precision: 0.6249\n",
      "Epoch 23: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8853 - precision: 0.6256 - val_loss: 1.0239 - val_precision: 0.6185\n",
      "Epoch 24/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8858 - precision: 0.6342\n",
      "Epoch 24: val_loss did not improve from 1.00512\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8848 - precision: 0.6342 - val_loss: 1.0181 - val_precision: 0.6202\n",
      "Epoch 24: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9476 - precision: 0.6344\n",
      "Combinación 82 = (False, True, False, 32, 0.25) \n",
      " precision train: [0.9476000070571899, 0.6344495415687561]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 84: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.4543 - precision: 0.6449\n",
      "Epoch 1: val_loss improved from inf to 1.22533, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 6s 9ms/step - loss: 1.4473 - precision: 0.6439 - val_loss: 1.2253 - val_precision: 0.6869\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1724 - precision: 0.6305\n",
      "Epoch 2: val_loss improved from 1.22533 to 1.10932, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1723 - precision: 0.6309 - val_loss: 1.1093 - val_precision: 0.6294\n",
      "Epoch 3/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0959 - precision: 0.6058\n",
      "Epoch 3: val_loss improved from 1.10932 to 1.08552, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0950 - precision: 0.6059 - val_loss: 1.0855 - val_precision: 0.6199\n",
      "Epoch 4/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0656 - precision: 0.5992\n",
      "Epoch 4: val_loss improved from 1.08552 to 1.07957, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0676 - precision: 0.5985 - val_loss: 1.0796 - val_precision: 0.6176\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0671 - precision: 0.5984\n",
      "Epoch 5: val_loss improved from 1.07957 to 1.07349, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0670 - precision: 0.5987 - val_loss: 1.0735 - val_precision: 0.6129\n",
      "Epoch 6/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0560 - precision: 0.6011\n",
      "Epoch 6: val_loss improved from 1.07349 to 1.06029, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0563 - precision: 0.5997 - val_loss: 1.0603 - val_precision: 0.6184\n",
      "Epoch 7/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0456 - precision: 0.6034\n",
      "Epoch 7: val_loss did not improve from 1.06029\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0446 - precision: 0.6044 - val_loss: 1.0696 - val_precision: 0.6095\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0362 - precision: 0.6044\n",
      "Epoch 8: val_loss improved from 1.06029 to 1.04887, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0366 - precision: 0.6047 - val_loss: 1.0489 - val_precision: 0.6208\n",
      "Epoch 9/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0289 - precision: 0.6086\n",
      "Epoch 9: val_loss did not improve from 1.04887\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0302 - precision: 0.6073 - val_loss: 1.0598 - val_precision: 0.6101\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0303 - precision: 0.5982\n",
      "Epoch 10: val_loss did not improve from 1.04887\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0303 - precision: 0.5982 - val_loss: 1.0582 - val_precision: 0.6116\n",
      "Epoch 11/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0170 - precision: 0.6066\n",
      "Epoch 11: val_loss did not improve from 1.04887\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0170 - precision: 0.6066 - val_loss: 1.0591 - val_precision: 0.6097\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0114 - precision: 0.6115\n",
      "Epoch 12: val_loss did not improve from 1.04887\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0108 - precision: 0.6106 - val_loss: 1.0609 - val_precision: 0.6119\n",
      "Epoch 13/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0129 - precision: 0.6076\n",
      "Epoch 13: val_loss improved from 1.04887 to 1.04336, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0127 - precision: 0.6069 - val_loss: 1.0434 - val_precision: 0.6204\n",
      "Epoch 14/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0172 - precision: 0.6043\n",
      "Epoch 14: val_loss improved from 1.04336 to 1.03966, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0152 - precision: 0.6046 - val_loss: 1.0397 - val_precision: 0.6246\n",
      "Epoch 15/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0039 - precision: 0.6059\n",
      "Epoch 15: val_loss did not improve from 1.03966\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0060 - precision: 0.6054 - val_loss: 1.0439 - val_precision: 0.6149\n",
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0027 - precision: 0.6076\n",
      "Epoch 16: val_loss did not improve from 1.03966\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0035 - precision: 0.6074 - val_loss: 1.0468 - val_precision: 0.6161\n",
      "Epoch 17/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0072 - precision: 0.6072\n",
      "Epoch 17: val_loss improved from 1.03966 to 1.03581, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0067 - precision: 0.6072 - val_loss: 1.0358 - val_precision: 0.6212\n",
      "Epoch 18/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9956 - precision: 0.6147\n",
      "Epoch 18: val_loss did not improve from 1.03581\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9945 - precision: 0.6142 - val_loss: 1.0473 - val_precision: 0.6097\n",
      "Epoch 19/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9889 - precision: 0.6194\n",
      "Epoch 19: val_loss did not improve from 1.03581\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9926 - precision: 0.6178 - val_loss: 1.0670 - val_precision: 0.6023\n",
      "Epoch 20/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9897 - precision: 0.6105\n",
      "Epoch 20: val_loss did not improve from 1.03581\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9897 - precision: 0.6105 - val_loss: 1.0425 - val_precision: 0.6203\n",
      "Epoch 21/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9885 - precision: 0.6069\n",
      "Epoch 21: val_loss did not improve from 1.03581\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9889 - precision: 0.6096 - val_loss: 1.0381 - val_precision: 0.6161\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9842 - precision: 0.6148\n",
      "Epoch 22: val_loss did not improve from 1.03581\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9839 - precision: 0.6145 - val_loss: 1.0440 - val_precision: 0.6166\n",
      "Epoch 23/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9774 - precision: 0.6066\n",
      "Epoch 23: val_loss improved from 1.03581 to 1.03384, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9782 - precision: 0.6088 - val_loss: 1.0338 - val_precision: 0.6213\n",
      "Epoch 24/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9877 - precision: 0.6172\n",
      "Epoch 24: val_loss improved from 1.03384 to 1.02949, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9854 - precision: 0.6178 - val_loss: 1.0295 - val_precision: 0.6233\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9913 - precision: 0.6169\n",
      "Epoch 25: val_loss did not improve from 1.02949\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9901 - precision: 0.6169 - val_loss: 1.0361 - val_precision: 0.6176\n",
      "Epoch 26/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9801 - precision: 0.6120\n",
      "Epoch 26: val_loss did not improve from 1.02949\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9797 - precision: 0.6120 - val_loss: 1.0368 - val_precision: 0.6257\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9753 - precision: 0.6145\n",
      "Epoch 27: val_loss improved from 1.02949 to 1.02459, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9738 - precision: 0.6145 - val_loss: 1.0246 - val_precision: 0.6318\n",
      "Epoch 28/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9702 - precision: 0.6207\n",
      "Epoch 28: val_loss did not improve from 1.02459\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9701 - precision: 0.6207 - val_loss: 1.0322 - val_precision: 0.6241\n",
      "Epoch 29/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9701 - precision: 0.6144\n",
      "Epoch 29: val_loss did not improve from 1.02459\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9709 - precision: 0.6132 - val_loss: 1.0332 - val_precision: 0.6256\n",
      "Epoch 30/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9642 - precision: 0.6189\n",
      "Epoch 30: val_loss did not improve from 1.02459\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9660 - precision: 0.6201 - val_loss: 1.0436 - val_precision: 0.6151\n",
      "Epoch 31/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9693 - precision: 0.6192\n",
      "Epoch 31: val_loss did not improve from 1.02459\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9694 - precision: 0.6188 - val_loss: 1.0294 - val_precision: 0.6301\n",
      "Epoch 32/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9584 - precision: 0.6194\n",
      "Epoch 32: val_loss did not improve from 1.02459\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9659 - precision: 0.6173 - val_loss: 1.0381 - val_precision: 0.6209\n",
      "Epoch 33/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9586 - precision: 0.6225\n",
      "Epoch 33: val_loss did not improve from 1.02459\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9596 - precision: 0.6225 - val_loss: 1.0282 - val_precision: 0.6248\n",
      "Epoch 34/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9474 - precision: 0.6225\n",
      "Epoch 34: val_loss did not improve from 1.02459\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9482 - precision: 0.6221 - val_loss: 1.0382 - val_precision: 0.6150\n",
      "Epoch 35/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9531 - precision: 0.6210\n",
      "Epoch 35: val_loss did not improve from 1.02459\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9533 - precision: 0.6199 - val_loss: 1.0446 - val_precision: 0.6148\n",
      "Epoch 36/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9608 - precision: 0.6184\n",
      "Epoch 36: val_loss improved from 1.02459 to 1.02294, saving model to model_ent84.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9610 - precision: 0.6186 - val_loss: 1.0229 - val_precision: 0.6268\n",
      "Epoch 37/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9598 - precision: 0.6239\n",
      "Epoch 37: val_loss did not improve from 1.02294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9596 - precision: 0.6223 - val_loss: 1.0431 - val_precision: 0.6141\n",
      "Epoch 38/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9593 - precision: 0.6153\n",
      "Epoch 38: val_loss did not improve from 1.02294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9586 - precision: 0.6157 - val_loss: 1.0346 - val_precision: 0.6226\n",
      "Epoch 39/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9576 - precision: 0.6198\n",
      "Epoch 39: val_loss did not improve from 1.02294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9582 - precision: 0.6201 - val_loss: 1.0402 - val_precision: 0.6133\n",
      "Epoch 40/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9417 - precision: 0.6288\n",
      "Epoch 40: val_loss did not improve from 1.02294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9444 - precision: 0.6291 - val_loss: 1.0328 - val_precision: 0.6191\n",
      "Epoch 41/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9528 - precision: 0.6228\n",
      "Epoch 41: val_loss did not improve from 1.02294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9506 - precision: 0.6241 - val_loss: 1.0422 - val_precision: 0.6124\n",
      "Epoch 42/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9538 - precision: 0.6139\n",
      "Epoch 42: val_loss did not improve from 1.02294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9524 - precision: 0.6145 - val_loss: 1.0342 - val_precision: 0.6178\n",
      "Epoch 43/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9436 - precision: 0.6214\n",
      "Epoch 43: val_loss did not improve from 1.02294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9423 - precision: 0.6220 - val_loss: 1.0318 - val_precision: 0.6202\n",
      "Epoch 44/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9476 - precision: 0.6209\n",
      "Epoch 44: val_loss did not improve from 1.02294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9467 - precision: 0.6215 - val_loss: 1.0276 - val_precision: 0.6176\n",
      "Epoch 45/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9397 - precision: 0.6274\n",
      "Epoch 45: val_loss did not improve from 1.02294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9397 - precision: 0.6274 - val_loss: 1.0358 - val_precision: 0.6146\n",
      "Epoch 46/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9423 - precision: 0.6201\n",
      "Epoch 46: val_loss did not improve from 1.02294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9414 - precision: 0.6207 - val_loss: 1.0450 - val_precision: 0.6041\n",
      "Epoch 46: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9981 - precision: 0.6144\n",
      "Combinación 83 = (False, True, False, 32, 0.5) \n",
      " precision train: [0.9980574250221252, 0.6144307851791382]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 85: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.2415 - precision: 0.6226\n",
      "Epoch 1: val_loss improved from inf to 1.07323, saving model to model_ent85.h5\n",
      "236/236 [==============================] - 6s 8ms/step - loss: 1.2335 - precision: 0.6154 - val_loss: 1.0732 - val_precision: 0.6283\n",
      "Epoch 2/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9855 - precision: 0.6102\n",
      "Epoch 2: val_loss improved from 1.07323 to 1.03909, saving model to model_ent85.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9875 - precision: 0.6085 - val_loss: 1.0391 - val_precision: 0.6159\n",
      "Epoch 3/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9627 - precision: 0.6064\n",
      "Epoch 3: val_loss did not improve from 1.03909\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9638 - precision: 0.6047 - val_loss: 1.0537 - val_precision: 0.6236\n",
      "Epoch 4/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9476 - precision: 0.6125\n",
      "Epoch 4: val_loss improved from 1.03909 to 1.00925, saving model to model_ent85.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9458 - precision: 0.6118 - val_loss: 1.0093 - val_precision: 0.6326\n",
      "Epoch 5/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9257 - precision: 0.6155\n",
      "Epoch 5: val_loss did not improve from 1.00925\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9252 - precision: 0.6164 - val_loss: 1.0243 - val_precision: 0.6216\n",
      "Epoch 6/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9125 - precision: 0.6175\n",
      "Epoch 6: val_loss did not improve from 1.00925\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9164 - precision: 0.6168 - val_loss: 1.0679 - val_precision: 0.6011\n",
      "Epoch 7/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9035 - precision: 0.6190\n",
      "Epoch 7: val_loss did not improve from 1.00925\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9071 - precision: 0.6160 - val_loss: 1.0252 - val_precision: 0.6010\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8985 - precision: 0.6197\n",
      "Epoch 8: val_loss did not improve from 1.00925\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8975 - precision: 0.6201 - val_loss: 1.0265 - val_precision: 0.6109\n",
      "Epoch 9/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8934 - precision: 0.6198\n",
      "Epoch 9: val_loss did not improve from 1.00925\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8946 - precision: 0.6199 - val_loss: 1.0136 - val_precision: 0.6299\n",
      "Epoch 10/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.8855 - precision: 0.6204\n",
      "Epoch 10: val_loss improved from 1.00925 to 1.00615, saving model to model_ent85.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8851 - precision: 0.6212 - val_loss: 1.0062 - val_precision: 0.6303\n",
      "Epoch 11/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8773 - precision: 0.6281\n",
      "Epoch 11: val_loss improved from 1.00615 to 1.00053, saving model to model_ent85.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8757 - precision: 0.6284 - val_loss: 1.0005 - val_precision: 0.6339\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8703 - precision: 0.6284\n",
      "Epoch 12: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8693 - precision: 0.6282 - val_loss: 1.0088 - val_precision: 0.6195\n",
      "Epoch 13/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8586 - precision: 0.6244\n",
      "Epoch 13: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8593 - precision: 0.6240 - val_loss: 1.0281 - val_precision: 0.6174\n",
      "Epoch 14/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8548 - precision: 0.6238\n",
      "Epoch 14: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8545 - precision: 0.6249 - val_loss: 1.0165 - val_precision: 0.6331\n",
      "Epoch 15/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8452 - precision: 0.6310\n",
      "Epoch 15: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8487 - precision: 0.6315 - val_loss: 1.0232 - val_precision: 0.6175\n",
      "Epoch 16/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8421 - precision: 0.6303\n",
      "Epoch 16: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8407 - precision: 0.6319 - val_loss: 1.0302 - val_precision: 0.6178\n",
      "Epoch 17/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8428 - precision: 0.6324\n",
      "Epoch 17: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8423 - precision: 0.6327 - val_loss: 1.0038 - val_precision: 0.6330\n",
      "Epoch 18/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8338 - precision: 0.6324\n",
      "Epoch 18: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8324 - precision: 0.6317 - val_loss: 1.0168 - val_precision: 0.6129\n",
      "Epoch 19/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8183 - precision: 0.6416\n",
      "Epoch 19: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8220 - precision: 0.6415 - val_loss: 1.0140 - val_precision: 0.6226\n",
      "Epoch 20/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8159 - precision: 0.6369\n",
      "Epoch 20: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8150 - precision: 0.6373 - val_loss: 1.0407 - val_precision: 0.5934\n",
      "Epoch 21/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8041 - precision: 0.6407\n",
      "Epoch 21: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8087 - precision: 0.6413 - val_loss: 1.0574 - val_precision: 0.5992\n",
      "Epoch 21: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9497 - precision: 0.6241\n",
      "Combinación 84 = (False, True, False, 64, 0.1) \n",
      " precision train: [0.9496979713439941, 0.6241276264190674]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 86: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2574 - precision: 0.6333\n",
      "Epoch 1: val_loss improved from inf to 1.07539, saving model to model_ent86.h5\n",
      "236/236 [==============================] - 6s 8ms/step - loss: 1.2419 - precision: 0.6325 - val_loss: 1.0754 - val_precision: 0.6281\n",
      "Epoch 2/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0141 - precision: 0.6050\n",
      "Epoch 2: val_loss improved from 1.07539 to 1.04910, saving model to model_ent86.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0117 - precision: 0.6056 - val_loss: 1.0491 - val_precision: 0.6294\n",
      "Epoch 3/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9818 - precision: 0.6106\n",
      "Epoch 3: val_loss did not improve from 1.04910\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9803 - precision: 0.6108 - val_loss: 1.0548 - val_precision: 0.6004\n",
      "Epoch 4/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9683 - precision: 0.6074\n",
      "Epoch 4: val_loss improved from 1.04910 to 1.04223, saving model to model_ent86.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9736 - precision: 0.6061 - val_loss: 1.0422 - val_precision: 0.6124\n",
      "Epoch 5/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9514 - precision: 0.6099\n",
      "Epoch 5: val_loss improved from 1.04223 to 1.02807, saving model to model_ent86.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9505 - precision: 0.6098 - val_loss: 1.0281 - val_precision: 0.6140\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9492 - precision: 0.6080\n",
      "Epoch 6: val_loss improved from 1.02807 to 1.00891, saving model to model_ent86.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9492 - precision: 0.6080 - val_loss: 1.0089 - val_precision: 0.6302\n",
      "Epoch 7/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9381 - precision: 0.6136\n",
      "Epoch 7: val_loss did not improve from 1.00891\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9354 - precision: 0.6145 - val_loss: 1.0321 - val_precision: 0.6154\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9239 - precision: 0.6133\n",
      "Epoch 8: val_loss did not improve from 1.00891\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9242 - precision: 0.6139 - val_loss: 1.0427 - val_precision: 0.6119\n",
      "Epoch 9/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9144 - precision: 0.6193\n",
      "Epoch 9: val_loss improved from 1.00891 to 1.00621, saving model to model_ent86.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9156 - precision: 0.6165 - val_loss: 1.0062 - val_precision: 0.6242\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9113 - precision: 0.6144\n",
      "Epoch 10: val_loss improved from 1.00621 to 1.00432, saving model to model_ent86.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9113 - precision: 0.6144 - val_loss: 1.0043 - val_precision: 0.6302\n",
      "Epoch 11/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9001 - precision: 0.6180\n",
      "Epoch 11: val_loss did not improve from 1.00432\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9019 - precision: 0.6174 - val_loss: 1.0175 - val_precision: 0.6221\n",
      "Epoch 12/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8980 - precision: 0.6207\n",
      "Epoch 12: val_loss did not improve from 1.00432\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8987 - precision: 0.6197 - val_loss: 1.0251 - val_precision: 0.6189\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8952 - precision: 0.6231\n",
      "Epoch 13: val_loss did not improve from 1.00432\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8928 - precision: 0.6228 - val_loss: 1.0138 - val_precision: 0.6252\n",
      "Epoch 14/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8869 - precision: 0.6225\n",
      "Epoch 14: val_loss improved from 1.00432 to 1.00109, saving model to model_ent86.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8880 - precision: 0.6228 - val_loss: 1.0011 - val_precision: 0.6359\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8784 - precision: 0.6234\n",
      "Epoch 15: val_loss did not improve from 1.00109\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8784 - precision: 0.6234 - val_loss: 1.0260 - val_precision: 0.6095\n",
      "Epoch 16/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8737 - precision: 0.6241\n",
      "Epoch 16: val_loss did not improve from 1.00109\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8736 - precision: 0.6239 - val_loss: 1.0121 - val_precision: 0.6257\n",
      "Epoch 17/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8665 - precision: 0.6291\n",
      "Epoch 17: val_loss did not improve from 1.00109\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8678 - precision: 0.6280 - val_loss: 1.0162 - val_precision: 0.6199\n",
      "Epoch 18/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8639 - precision: 0.6306\n",
      "Epoch 18: val_loss did not improve from 1.00109\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8643 - precision: 0.6289 - val_loss: 1.0249 - val_precision: 0.6104\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8675 - precision: 0.6249\n",
      "Epoch 19: val_loss improved from 1.00109 to 0.99590, saving model to model_ent86.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8669 - precision: 0.6251 - val_loss: 0.9959 - val_precision: 0.6328\n",
      "Epoch 20/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8578 - precision: 0.6277\n",
      "Epoch 20: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8571 - precision: 0.6285 - val_loss: 1.0283 - val_precision: 0.6127\n",
      "Epoch 21/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8532 - precision: 0.6288\n",
      "Epoch 21: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8526 - precision: 0.6283 - val_loss: 1.0198 - val_precision: 0.6145\n",
      "Epoch 22/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.8423 - precision: 0.6306\n",
      "Epoch 22: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8417 - precision: 0.6317 - val_loss: 1.0216 - val_precision: 0.6108\n",
      "Epoch 23/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8432 - precision: 0.6317\n",
      "Epoch 23: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8420 - precision: 0.6304 - val_loss: 1.0107 - val_precision: 0.6297\n",
      "Epoch 24/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8340 - precision: 0.6352\n",
      "Epoch 24: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8350 - precision: 0.6348 - val_loss: 1.0093 - val_precision: 0.6237\n",
      "Epoch 25/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8321 - precision: 0.6400\n",
      "Epoch 25: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8317 - precision: 0.6390 - val_loss: 1.0296 - val_precision: 0.6049\n",
      "Epoch 26/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - ETA: 0s - loss: 0.8259 - precision: 0.6388\n",
      "Epoch 26: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8259 - precision: 0.6388 - val_loss: 1.0249 - val_precision: 0.6056\n",
      "Epoch 27/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8257 - precision: 0.6323\n",
      "Epoch 27: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8258 - precision: 0.6337 - val_loss: 1.0362 - val_precision: 0.6033\n",
      "Epoch 28/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8149 - precision: 0.6387\n",
      "Epoch 28: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8175 - precision: 0.6394 - val_loss: 1.0219 - val_precision: 0.6213\n",
      "Epoch 29/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8089 - precision: 0.6425\n",
      "Epoch 29: val_loss did not improve from 0.99590\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8109 - precision: 0.6407 - val_loss: 1.0253 - val_precision: 0.6117\n",
      "Epoch 29: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9020 - precision: 0.6400\n",
      "Combinación 85 = (False, True, False, 64, 0.25) \n",
      " precision train: [0.9020323753356934, 0.6399950385093689]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 87: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.3338 - precision: 0.6341\n",
      "Epoch 1: val_loss improved from inf to 1.09298, saving model to model_ent87.h5\n",
      "236/236 [==============================] - 6s 8ms/step - loss: 1.3182 - precision: 0.6274 - val_loss: 1.0930 - val_precision: 0.6484\n",
      "Epoch 2/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0564 - precision: 0.6075\n",
      "Epoch 2: val_loss improved from 1.09298 to 1.06610, saving model to model_ent87.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0585 - precision: 0.6060 - val_loss: 1.0661 - val_precision: 0.6190\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0218 - precision: 0.6120\n",
      "Epoch 3: val_loss improved from 1.06610 to 1.05471, saving model to model_ent87.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0247 - precision: 0.6115 - val_loss: 1.0547 - val_precision: 0.6266\n",
      "Epoch 4/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0164 - precision: 0.6005\n",
      "Epoch 4: val_loss improved from 1.05471 to 1.03664, saving model to model_ent87.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0132 - precision: 0.6020 - val_loss: 1.0366 - val_precision: 0.6260\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0066 - precision: 0.6073\n",
      "Epoch 5: val_loss did not improve from 1.03664\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0057 - precision: 0.6082 - val_loss: 1.0432 - val_precision: 0.6206\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9980 - precision: 0.6103\n",
      "Epoch 6: val_loss improved from 1.03664 to 1.02014, saving model to model_ent87.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9968 - precision: 0.6104 - val_loss: 1.0201 - val_precision: 0.6362\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9913 - precision: 0.6082\n",
      "Epoch 7: val_loss did not improve from 1.02014\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9903 - precision: 0.6095 - val_loss: 1.0353 - val_precision: 0.6108\n",
      "Epoch 8/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9785 - precision: 0.6137\n",
      "Epoch 8: val_loss did not improve from 1.02014\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9790 - precision: 0.6146 - val_loss: 1.0305 - val_precision: 0.6155\n",
      "Epoch 9/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9638 - precision: 0.6147\n",
      "Epoch 9: val_loss did not improve from 1.02014\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9702 - precision: 0.6108 - val_loss: 1.0346 - val_precision: 0.6170\n",
      "Epoch 10/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9650 - precision: 0.6115\n",
      "Epoch 10: val_loss did not improve from 1.02014\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9657 - precision: 0.6115 - val_loss: 1.0343 - val_precision: 0.6062\n",
      "Epoch 11/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9617 - precision: 0.6091\n",
      "Epoch 11: val_loss did not improve from 1.02014\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9610 - precision: 0.6098 - val_loss: 1.0218 - val_precision: 0.6173\n",
      "Epoch 12/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9553 - precision: 0.6138\n",
      "Epoch 12: val_loss did not improve from 1.02014\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9535 - precision: 0.6148 - val_loss: 1.0412 - val_precision: 0.6192\n",
      "Epoch 13/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9543 - precision: 0.6098\n",
      "Epoch 13: val_loss did not improve from 1.02014\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9529 - precision: 0.6115 - val_loss: 1.0314 - val_precision: 0.6141\n",
      "Epoch 14/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9454 - precision: 0.6170\n",
      "Epoch 14: val_loss did not improve from 1.02014\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9471 - precision: 0.6159 - val_loss: 1.0305 - val_precision: 0.6091\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9391 - precision: 0.6159\n",
      "Epoch 15: val_loss improved from 1.02014 to 1.00918, saving model to model_ent87.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9385 - precision: 0.6161 - val_loss: 1.0092 - val_precision: 0.6283\n",
      "Epoch 16/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9354 - precision: 0.6205\n",
      "Epoch 16: val_loss did not improve from 1.00918\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9361 - precision: 0.6194 - val_loss: 1.0356 - val_precision: 0.6086\n",
      "Epoch 17/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9360 - precision: 0.6174\n",
      "Epoch 17: val_loss did not improve from 1.00918\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9365 - precision: 0.6171 - val_loss: 1.0207 - val_precision: 0.6145\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9335 - precision: 0.6193\n",
      "Epoch 18: val_loss did not improve from 1.00918\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9342 - precision: 0.6187 - val_loss: 1.0115 - val_precision: 0.6225\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9306 - precision: 0.6191\n",
      "Epoch 19: val_loss improved from 1.00918 to 1.00504, saving model to model_ent87.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9301 - precision: 0.6192 - val_loss: 1.0050 - val_precision: 0.6229\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9216 - precision: 0.6223\n",
      "Epoch 20: val_loss did not improve from 1.00504\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9220 - precision: 0.6233 - val_loss: 1.0065 - val_precision: 0.6245\n",
      "Epoch 21/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9159 - precision: 0.6228\n",
      "Epoch 21: val_loss did not improve from 1.00504\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9168 - precision: 0.6216 - val_loss: 1.0283 - val_precision: 0.6146\n",
      "Epoch 22/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9207 - precision: 0.6173\n",
      "Epoch 22: val_loss did not improve from 1.00504\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9194 - precision: 0.6173 - val_loss: 1.0102 - val_precision: 0.6191\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9163 - precision: 0.6205\n",
      "Epoch 23: val_loss did not improve from 1.00504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9132 - precision: 0.6205 - val_loss: 1.0088 - val_precision: 0.6233\n",
      "Epoch 24/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9076 - precision: 0.6214\n",
      "Epoch 24: val_loss did not improve from 1.00504\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9055 - precision: 0.6213 - val_loss: 1.0200 - val_precision: 0.6236\n",
      "Epoch 25/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9015 - precision: 0.6212\n",
      "Epoch 25: val_loss did not improve from 1.00504\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9044 - precision: 0.6205 - val_loss: 1.0152 - val_precision: 0.6175\n",
      "Epoch 26/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9040 - precision: 0.6258\n",
      "Epoch 26: val_loss did not improve from 1.00504\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9018 - precision: 0.6262 - val_loss: 1.0065 - val_precision: 0.6260\n",
      "Epoch 27/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9066 - precision: 0.6226\n",
      "Epoch 27: val_loss did not improve from 1.00504\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9046 - precision: 0.6234 - val_loss: 1.0140 - val_precision: 0.6181\n",
      "Epoch 28/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9021 - precision: 0.6244\n",
      "Epoch 28: val_loss did not improve from 1.00504\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9013 - precision: 0.6267 - val_loss: 1.0053 - val_precision: 0.6200\n",
      "Epoch 29/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8916 - precision: 0.6230\n",
      "Epoch 29: val_loss did not improve from 1.00504\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8916 - precision: 0.6231 - val_loss: 1.0316 - val_precision: 0.6062\n",
      "Epoch 29: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9669 - precision: 0.6179\n",
      "Combinación 86 = (False, True, False, 64, 0.5) \n",
      " precision train: [0.9668629169464111, 0.6179127097129822]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 88: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1816 - precision: 0.6129\n",
      "Epoch 1: val_loss improved from inf to 1.05399, saving model to model_ent88.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.1696 - precision: 0.6120 - val_loss: 1.0540 - val_precision: 0.6426\n",
      "Epoch 2/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9833 - precision: 0.6086\n",
      "Epoch 2: val_loss improved from 1.05399 to 1.05055, saving model to model_ent88.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9818 - precision: 0.6096 - val_loss: 1.0505 - val_precision: 0.6162\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9511 - precision: 0.6111\n",
      "Epoch 3: val_loss improved from 1.05055 to 1.01293, saving model to model_ent88.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9492 - precision: 0.6136 - val_loss: 1.0129 - val_precision: 0.6268\n",
      "Epoch 4/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9284 - precision: 0.6169\n",
      "Epoch 4: val_loss did not improve from 1.01293\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9291 - precision: 0.6160 - val_loss: 1.0357 - val_precision: 0.6234\n",
      "Epoch 5/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9102 - precision: 0.6185\n",
      "Epoch 5: val_loss did not improve from 1.01293\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9123 - precision: 0.6188 - val_loss: 1.0220 - val_precision: 0.6197\n",
      "Epoch 6/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9057 - precision: 0.6165\n",
      "Epoch 6: val_loss improved from 1.01293 to 1.00714, saving model to model_ent88.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9036 - precision: 0.6169 - val_loss: 1.0071 - val_precision: 0.6328\n",
      "Epoch 7/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8903 - precision: 0.6203\n",
      "Epoch 7: val_loss did not improve from 1.00714\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8927 - precision: 0.6192 - val_loss: 1.0216 - val_precision: 0.6267\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8824 - precision: 0.6266\n",
      "Epoch 8: val_loss did not improve from 1.00714\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8828 - precision: 0.6262 - val_loss: 1.0337 - val_precision: 0.6108\n",
      "Epoch 9/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8722 - precision: 0.6265\n",
      "Epoch 9: val_loss did not improve from 1.00714\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8736 - precision: 0.6242 - val_loss: 1.0300 - val_precision: 0.6008\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8642 - precision: 0.6263\n",
      "Epoch 10: val_loss did not improve from 1.00714\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8647 - precision: 0.6270 - val_loss: 1.0346 - val_precision: 0.6193\n",
      "Epoch 11/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8538 - precision: 0.6306\n",
      "Epoch 11: val_loss did not improve from 1.00714\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8561 - precision: 0.6291 - val_loss: 1.0264 - val_precision: 0.6122\n",
      "Epoch 12/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8528 - precision: 0.6272\n",
      "Epoch 12: val_loss improved from 1.00714 to 0.99979, saving model to model_ent88.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8509 - precision: 0.6285 - val_loss: 0.9998 - val_precision: 0.6274\n",
      "Epoch 13/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8415 - precision: 0.6297\n",
      "Epoch 13: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8415 - precision: 0.6290 - val_loss: 1.0203 - val_precision: 0.6183\n",
      "Epoch 14/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8313 - precision: 0.6362\n",
      "Epoch 14: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8317 - precision: 0.6369 - val_loss: 1.0285 - val_precision: 0.6100\n",
      "Epoch 15/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8237 - precision: 0.6353\n",
      "Epoch 15: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8259 - precision: 0.6350 - val_loss: 1.0154 - val_precision: 0.6217\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8184 - precision: 0.6378\n",
      "Epoch 16: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8174 - precision: 0.6392 - val_loss: 1.0314 - val_precision: 0.6099\n",
      "Epoch 17/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8105 - precision: 0.6378\n",
      "Epoch 17: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8110 - precision: 0.6375 - val_loss: 1.0307 - val_precision: 0.6115\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.7971 - precision: 0.6431\n",
      "Epoch 18: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7993 - precision: 0.6426 - val_loss: 1.0492 - val_precision: 0.6095\n",
      "Epoch 19/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.7903 - precision: 0.6457\n",
      "Epoch 19: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7919 - precision: 0.6455 - val_loss: 1.0326 - val_precision: 0.6103\n",
      "Epoch 20/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.7824 - precision: 0.6445\n",
      "Epoch 20: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.7824 - precision: 0.6445 - val_loss: 1.0297 - val_precision: 0.6136\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.7733 - precision: 0.6479\n",
      "Epoch 21: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.7737 - precision: 0.6477 - val_loss: 1.0310 - val_precision: 0.6050\n",
      "Epoch 22/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.7634 - precision: 0.6562\n",
      "Epoch 22: val_loss did not improve from 0.99979\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.7632 - precision: 0.6561 - val_loss: 1.0314 - val_precision: 0.6184\n",
      "Epoch 22: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.8848 - precision: 0.6547\n",
      "Combinación 87 = (False, True, False, 128, 0.1) \n",
      " precision train: [0.8847503662109375, 0.6547279953956604]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 89: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1793 - precision: 0.6209\n",
      "Epoch 1: val_loss improved from inf to 1.05655, saving model to model_ent89.h5\n",
      "236/236 [==============================] - 7s 11ms/step - loss: 1.1772 - precision: 0.6191 - val_loss: 1.0565 - val_precision: 0.6301\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9893 - precision: 0.6092\n",
      "Epoch 2: val_loss improved from 1.05655 to 1.01211, saving model to model_ent89.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9890 - precision: 0.6093 - val_loss: 1.0121 - val_precision: 0.6456\n",
      "Epoch 3/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9561 - precision: 0.6181\n",
      "Epoch 3: val_loss did not improve from 1.01211\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9554 - precision: 0.6187 - val_loss: 1.0453 - val_precision: 0.6056\n",
      "Epoch 4/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9387 - precision: 0.6124\n",
      "Epoch 4: val_loss did not improve from 1.01211\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9372 - precision: 0.6130 - val_loss: 1.0426 - val_precision: 0.6125\n",
      "Epoch 5/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9275 - precision: 0.6133\n",
      "Epoch 5: val_loss improved from 1.01211 to 1.00645, saving model to model_ent89.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9269 - precision: 0.6128 - val_loss: 1.0065 - val_precision: 0.6305\n",
      "Epoch 6/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9143 - precision: 0.6156\n",
      "Epoch 6: val_loss improved from 1.00645 to 1.00053, saving model to model_ent89.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9143 - precision: 0.6154 - val_loss: 1.0005 - val_precision: 0.6217\n",
      "Epoch 7/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9056 - precision: 0.6184\n",
      "Epoch 7: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9064 - precision: 0.6193 - val_loss: 1.0283 - val_precision: 0.6294\n",
      "Epoch 8/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8962 - precision: 0.6234\n",
      "Epoch 8: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8958 - precision: 0.6236 - val_loss: 1.0274 - val_precision: 0.6239\n",
      "Epoch 9/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8919 - precision: 0.6187\n",
      "Epoch 9: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8919 - precision: 0.6187 - val_loss: 1.0394 - val_precision: 0.6169\n",
      "Epoch 10/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8829 - precision: 0.6271\n",
      "Epoch 10: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8830 - precision: 0.6272 - val_loss: 1.0142 - val_precision: 0.6213\n",
      "Epoch 11/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8744 - precision: 0.6224\n",
      "Epoch 11: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8753 - precision: 0.6221 - val_loss: 1.0041 - val_precision: 0.6274\n",
      "Epoch 12/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8786 - precision: 0.6263\n",
      "Epoch 12: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8754 - precision: 0.6278 - val_loss: 1.0440 - val_precision: 0.6038\n",
      "Epoch 13/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8649 - precision: 0.6218\n",
      "Epoch 13: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8649 - precision: 0.6218 - val_loss: 1.0134 - val_precision: 0.6237\n",
      "Epoch 14/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8591 - precision: 0.6266\n",
      "Epoch 14: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8608 - precision: 0.6256 - val_loss: 1.0225 - val_precision: 0.6234\n",
      "Epoch 15/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8525 - precision: 0.6286\n",
      "Epoch 15: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8517 - precision: 0.6282 - val_loss: 1.0221 - val_precision: 0.6165\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8426 - precision: 0.6311\n",
      "Epoch 16: val_loss did not improve from 1.00053\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8412 - precision: 0.6305 - val_loss: 1.0163 - val_precision: 0.6202\n",
      "Epoch 16: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9305 - precision: 0.6357\n",
      "Combinación 88 = (False, True, False, 128, 0.25) \n",
      " precision train: [0.9305134415626526, 0.635748028755188]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 90: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2449 - precision: 0.6285\n",
      "Epoch 1: val_loss improved from inf to 1.08171, saving model to model_ent90.h5\n",
      "236/236 [==============================] - 8s 11ms/step - loss: 1.2388 - precision: 0.6272 - val_loss: 1.0817 - val_precision: 0.6341\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0289 - precision: 0.6048\n",
      "Epoch 2: val_loss improved from 1.08171 to 1.03922, saving model to model_ent90.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0277 - precision: 0.6054 - val_loss: 1.0392 - val_precision: 0.6333\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9938 - precision: 0.6124\n",
      "Epoch 3: val_loss did not improve from 1.03922\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9950 - precision: 0.6117 - val_loss: 1.0407 - val_precision: 0.6201\n",
      "Epoch 4/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9838 - precision: 0.6083\n",
      "Epoch 4: val_loss improved from 1.03922 to 1.02067, saving model to model_ent90.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9849 - precision: 0.6062 - val_loss: 1.0207 - val_precision: 0.6255\n",
      "Epoch 5/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9585 - precision: 0.6078\n",
      "Epoch 5: val_loss did not improve from 1.02067\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9608 - precision: 0.6063 - val_loss: 1.0395 - val_precision: 0.6127\n",
      "Epoch 6/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9500 - precision: 0.6124\n",
      "Epoch 6: val_loss improved from 1.02067 to 1.01460, saving model to model_ent90.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9503 - precision: 0.6126 - val_loss: 1.0146 - val_precision: 0.6241\n",
      "Epoch 7/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/236 [============================>.] - ETA: 0s - loss: 0.9472 - precision: 0.6153\n",
      "Epoch 7: val_loss did not improve from 1.01460\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9458 - precision: 0.6162 - val_loss: 1.0168 - val_precision: 0.6310\n",
      "Epoch 8/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9331 - precision: 0.6178\n",
      "Epoch 8: val_loss did not improve from 1.01460\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9324 - precision: 0.6178 - val_loss: 1.0382 - val_precision: 0.6023\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9256 - precision: 0.6199\n",
      "Epoch 9: val_loss did not improve from 1.01460\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.9260 - precision: 0.6202 - val_loss: 1.0178 - val_precision: 0.6235\n",
      "Epoch 10/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9256 - precision: 0.6133\n",
      "Epoch 10: val_loss did not improve from 1.01460\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9249 - precision: 0.6141 - val_loss: 1.0290 - val_precision: 0.6160\n",
      "Epoch 11/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9171 - precision: 0.6170\n",
      "Epoch 11: val_loss did not improve from 1.01460\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9159 - precision: 0.6178 - val_loss: 1.0209 - val_precision: 0.6197\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9159 - precision: 0.6174\n",
      "Epoch 12: val_loss did not improve from 1.01460\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.9168 - precision: 0.6180 - val_loss: 1.0249 - val_precision: 0.6142\n",
      "Epoch 13/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9098 - precision: 0.6206\n",
      "Epoch 13: val_loss improved from 1.01460 to 1.00597, saving model to model_ent90.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9074 - precision: 0.6216 - val_loss: 1.0060 - val_precision: 0.6259\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9088 - precision: 0.6268\n",
      "Epoch 14: val_loss did not improve from 1.00597\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9077 - precision: 0.6263 - val_loss: 1.0150 - val_precision: 0.6225\n",
      "Epoch 15/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8923 - precision: 0.6254\n",
      "Epoch 15: val_loss did not improve from 1.00597\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8929 - precision: 0.6257 - val_loss: 1.0090 - val_precision: 0.6269\n",
      "Epoch 16/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8970 - precision: 0.6227\n",
      "Epoch 16: val_loss did not improve from 1.00597\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8992 - precision: 0.6229 - val_loss: 1.0183 - val_precision: 0.6197\n",
      "Epoch 17/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8915 - precision: 0.6136\n",
      "Epoch 17: val_loss improved from 1.00597 to 1.00478, saving model to model_ent90.h5\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8930 - precision: 0.6131 - val_loss: 1.0048 - val_precision: 0.6313\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8895 - precision: 0.6235\n",
      "Epoch 18: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8881 - precision: 0.6240 - val_loss: 1.0222 - val_precision: 0.6210\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8776 - precision: 0.6232\n",
      "Epoch 19: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8767 - precision: 0.6234 - val_loss: 1.0082 - val_precision: 0.6305\n",
      "Epoch 20/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8825 - precision: 0.6250\n",
      "Epoch 20: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8825 - precision: 0.6250 - val_loss: 1.0167 - val_precision: 0.6184\n",
      "Epoch 21/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8758 - precision: 0.6254\n",
      "Epoch 21: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8762 - precision: 0.6248 - val_loss: 1.0155 - val_precision: 0.6193\n",
      "Epoch 22/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8712 - precision: 0.6277\n",
      "Epoch 22: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8704 - precision: 0.6264 - val_loss: 1.0175 - val_precision: 0.6114\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8743 - precision: 0.6269\n",
      "Epoch 23: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8723 - precision: 0.6269 - val_loss: 1.0325 - val_precision: 0.6065\n",
      "Epoch 24/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8603 - precision: 0.6289\n",
      "Epoch 24: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8604 - precision: 0.6272 - val_loss: 1.0099 - val_precision: 0.6292\n",
      "Epoch 25/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8571 - precision: 0.6233\n",
      "Epoch 25: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8577 - precision: 0.6237 - val_loss: 1.0054 - val_precision: 0.6323\n",
      "Epoch 26/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8607 - precision: 0.6298\n",
      "Epoch 26: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8607 - precision: 0.6295 - val_loss: 1.0214 - val_precision: 0.5999\n",
      "Epoch 27/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8458 - precision: 0.6306\n",
      "Epoch 27: val_loss did not improve from 1.00478\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8457 - precision: 0.6307 - val_loss: 1.0234 - val_precision: 0.6167\n",
      "Epoch 27: early stopping\n",
      "295/295 [==============================] - 1s 3ms/step - loss: 0.9312 - precision: 0.6314\n",
      "Combinación 89 = (False, True, False, 128, 0.5) \n",
      " precision train: [0.9311630725860596, 0.6313701272010803]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 91: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.5002 - precision: 0.7121\n",
      "Epoch 1: val_loss improved from inf to 1.33993, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 9s 12ms/step - loss: 1.4952 - precision: 0.7125 - val_loss: 1.3399 - val_precision: 0.7300\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3031 - precision: 0.7032\n",
      "Epoch 2: val_loss improved from 1.33993 to 1.27175, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.3009 - precision: 0.7074 - val_loss: 1.2718 - val_precision: 0.7169\n",
      "Epoch 3/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.2346 - precision: 0.6916\n",
      "Epoch 3: val_loss improved from 1.27175 to 1.21879, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.2313 - precision: 0.6929 - val_loss: 1.2188 - val_precision: 0.6791\n",
      "Epoch 4/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1753 - precision: 0.6479\n",
      "Epoch 4: val_loss improved from 1.21879 to 1.16856, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1754 - precision: 0.6483 - val_loss: 1.1686 - val_precision: 0.6625\n",
      "Epoch 5/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1294 - precision: 0.6354\n",
      "Epoch 5: val_loss improved from 1.16856 to 1.14677, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1277 - precision: 0.6365 - val_loss: 1.1468 - val_precision: 0.6536\n",
      "Epoch 6/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0922 - precision: 0.6380\n",
      "Epoch 6: val_loss improved from 1.14677 to 1.11275, saving model to model_ent91.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0918 - precision: 0.6390 - val_loss: 1.1127 - val_precision: 0.6508\n",
      "Epoch 7/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0634 - precision: 0.6379\n",
      "Epoch 7: val_loss improved from 1.11275 to 1.10259, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0703 - precision: 0.6375 - val_loss: 1.1026 - val_precision: 0.6352\n",
      "Epoch 8/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0416 - precision: 0.6366\n",
      "Epoch 8: val_loss improved from 1.10259 to 1.09301, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0429 - precision: 0.6356 - val_loss: 1.0930 - val_precision: 0.6503\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0305 - precision: 0.6237\n",
      "Epoch 9: val_loss improved from 1.09301 to 1.07367, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0304 - precision: 0.6246 - val_loss: 1.0737 - val_precision: 0.6199\n",
      "Epoch 10/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0175 - precision: 0.6101\n",
      "Epoch 10: val_loss improved from 1.07367 to 1.06186, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0170 - precision: 0.6093 - val_loss: 1.0619 - val_precision: 0.6176\n",
      "Epoch 11/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0141 - precision: 0.6009\n",
      "Epoch 11: val_loss improved from 1.06186 to 1.05938, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0140 - precision: 0.6005 - val_loss: 1.0594 - val_precision: 0.6179\n",
      "Epoch 12/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0092 - precision: 0.6003\n",
      "Epoch 12: val_loss improved from 1.05938 to 1.05840, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0056 - precision: 0.6022 - val_loss: 1.0584 - val_precision: 0.6086\n",
      "Epoch 13/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9942 - precision: 0.6029\n",
      "Epoch 13: val_loss improved from 1.05840 to 1.04585, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9946 - precision: 0.6025 - val_loss: 1.0459 - val_precision: 0.6220\n",
      "Epoch 14/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9905 - precision: 0.6012\n",
      "Epoch 14: val_loss did not improve from 1.04585\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9915 - precision: 0.6008 - val_loss: 1.0598 - val_precision: 0.6075\n",
      "Epoch 15/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9906 - precision: 0.6018\n",
      "Epoch 15: val_loss improved from 1.04585 to 1.03922, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9884 - precision: 0.6030 - val_loss: 1.0392 - val_precision: 0.6219\n",
      "Epoch 16/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9799 - precision: 0.6071\n",
      "Epoch 16: val_loss did not improve from 1.03922\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9793 - precision: 0.6055 - val_loss: 1.0458 - val_precision: 0.6200\n",
      "Epoch 17/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9808 - precision: 0.6094\n",
      "Epoch 17: val_loss improved from 1.03922 to 1.03890, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9819 - precision: 0.6092 - val_loss: 1.0389 - val_precision: 0.6211\n",
      "Epoch 18/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9775 - precision: 0.6080\n",
      "Epoch 18: val_loss did not improve from 1.03890\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9795 - precision: 0.6065 - val_loss: 1.0402 - val_precision: 0.6212\n",
      "Epoch 19/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9674 - precision: 0.6146\n",
      "Epoch 19: val_loss improved from 1.03890 to 1.03656, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9705 - precision: 0.6115 - val_loss: 1.0366 - val_precision: 0.6203\n",
      "Epoch 20/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9671 - precision: 0.6084\n",
      "Epoch 20: val_loss improved from 1.03656 to 1.02906, saving model to model_ent91.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9670 - precision: 0.6085 - val_loss: 1.0291 - val_precision: 0.6236\n",
      "Epoch 21/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9647 - precision: 0.6125\n",
      "Epoch 21: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9642 - precision: 0.6117 - val_loss: 1.0420 - val_precision: 0.6192\n",
      "Epoch 22/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9550 - precision: 0.6138\n",
      "Epoch 22: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9560 - precision: 0.6136 - val_loss: 1.0314 - val_precision: 0.6249\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9622 - precision: 0.6094\n",
      "Epoch 23: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9590 - precision: 0.6117 - val_loss: 1.0386 - val_precision: 0.6222\n",
      "Epoch 24/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9532 - precision: 0.6170\n",
      "Epoch 24: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9561 - precision: 0.6160 - val_loss: 1.0304 - val_precision: 0.6229\n",
      "Epoch 25/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9549 - precision: 0.6104\n",
      "Epoch 25: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9576 - precision: 0.6108 - val_loss: 1.0365 - val_precision: 0.6202\n",
      "Epoch 26/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9478 - precision: 0.6206\n",
      "Epoch 26: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9477 - precision: 0.6184 - val_loss: 1.0419 - val_precision: 0.6229\n",
      "Epoch 27/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9369 - precision: 0.6176\n",
      "Epoch 27: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9377 - precision: 0.6185 - val_loss: 1.0381 - val_precision: 0.6220\n",
      "Epoch 28/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9396 - precision: 0.6245\n",
      "Epoch 28: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9401 - precision: 0.6251 - val_loss: 1.0468 - val_precision: 0.6169\n",
      "Epoch 29/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9439 - precision: 0.6207\n",
      "Epoch 29: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9434 - precision: 0.6204 - val_loss: 1.0563 - val_precision: 0.6119\n",
      "Epoch 30/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9329 - precision: 0.6138\n",
      "Epoch 30: val_loss did not improve from 1.02906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9344 - precision: 0.6140 - val_loss: 1.0324 - val_precision: 0.6274\n",
      "Epoch 30: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9916 - precision: 0.6292\n",
      "Combinación 90 = (False, False, True, 8, 0.1) \n",
      " precision train: [0.9915860891342163, 0.6292166113853455]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 92: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.5484 - precision: 0.7250  \n",
      "Epoch 1: val_loss improved from inf to 1.37710, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 6s 8ms/step - loss: 1.5425 - precision: 0.6923 - val_loss: 1.3771 - val_precision: 0.7607\n",
      "Epoch 2/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.3170 - precision: 0.6515\n",
      "Epoch 2: val_loss improved from 1.37710 to 1.21518, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3129 - precision: 0.6462 - val_loss: 1.2152 - val_precision: 0.6887\n",
      "Epoch 3/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2238 - precision: 0.6356\n",
      "Epoch 3: val_loss improved from 1.21518 to 1.17175, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2250 - precision: 0.6319 - val_loss: 1.1718 - val_precision: 0.6556\n",
      "Epoch 4/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1865 - precision: 0.6281\n",
      "Epoch 4: val_loss improved from 1.17175 to 1.16117, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1873 - precision: 0.6282 - val_loss: 1.1612 - val_precision: 0.6527\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1663 - precision: 0.6332\n",
      "Epoch 5: val_loss improved from 1.16117 to 1.13885, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1663 - precision: 0.6332 - val_loss: 1.1388 - val_precision: 0.6424\n",
      "Epoch 6/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.1476 - precision: 0.6212\n",
      "Epoch 6: val_loss improved from 1.13885 to 1.13744, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1483 - precision: 0.6251 - val_loss: 1.1374 - val_precision: 0.6536\n",
      "Epoch 7/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.1429 - precision: 0.6243\n",
      "Epoch 7: val_loss did not improve from 1.13744\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1438 - precision: 0.6252 - val_loss: 1.1443 - val_precision: 0.6594\n",
      "Epoch 8/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1273 - precision: 0.6253\n",
      "Epoch 8: val_loss improved from 1.13744 to 1.11637, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1273 - precision: 0.6253 - val_loss: 1.1164 - val_precision: 0.6664\n",
      "Epoch 9/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1181 - precision: 0.6289\n",
      "Epoch 9: val_loss improved from 1.11637 to 1.10997, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1153 - precision: 0.6303 - val_loss: 1.1100 - val_precision: 0.6583\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1031 - precision: 0.6394\n",
      "Epoch 10: val_loss improved from 1.10997 to 1.10479, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1042 - precision: 0.6383 - val_loss: 1.1048 - val_precision: 0.6503\n",
      "Epoch 11/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0922 - precision: 0.6359\n",
      "Epoch 11: val_loss improved from 1.10479 to 1.09596, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0904 - precision: 0.6396 - val_loss: 1.0960 - val_precision: 0.6452\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0885 - precision: 0.6276\n",
      "Epoch 12: val_loss did not improve from 1.09596\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0913 - precision: 0.6269 - val_loss: 1.1009 - val_precision: 0.6381\n",
      "Epoch 13/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0780 - precision: 0.6235\n",
      "Epoch 13: val_loss improved from 1.09596 to 1.07946, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0819 - precision: 0.6222 - val_loss: 1.0795 - val_precision: 0.6511\n",
      "Epoch 14/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0803 - precision: 0.6195\n",
      "Epoch 14: val_loss improved from 1.07946 to 1.07779, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0795 - precision: 0.6200 - val_loss: 1.0778 - val_precision: 0.6550\n",
      "Epoch 15/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0751 - precision: 0.6165\n",
      "Epoch 15: val_loss did not improve from 1.07779\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0723 - precision: 0.6163 - val_loss: 1.0835 - val_precision: 0.6510\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0694 - precision: 0.6092\n",
      "Epoch 16: val_loss improved from 1.07779 to 1.06261, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0670 - precision: 0.6073 - val_loss: 1.0626 - val_precision: 0.6460\n",
      "Epoch 17/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0704 - precision: 0.6160\n",
      "Epoch 17: val_loss did not improve from 1.06261\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0715 - precision: 0.6145 - val_loss: 1.0632 - val_precision: 0.6408\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0540 - precision: 0.6113\n",
      "Epoch 18: val_loss did not improve from 1.06261\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0556 - precision: 0.6096 - val_loss: 1.0820 - val_precision: 0.6243\n",
      "Epoch 19/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0472 - precision: 0.6066\n",
      "Epoch 19: val_loss did not improve from 1.06261\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0476 - precision: 0.6053 - val_loss: 1.0659 - val_precision: 0.6287\n",
      "Epoch 20/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0636 - precision: 0.6046\n",
      "Epoch 20: val_loss improved from 1.06261 to 1.06035, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0676 - precision: 0.6021 - val_loss: 1.0603 - val_precision: 0.6350\n",
      "Epoch 21/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0438 - precision: 0.6190\n",
      "Epoch 21: val_loss did not improve from 1.06035\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0477 - precision: 0.6145 - val_loss: 1.0681 - val_precision: 0.6235\n",
      "Epoch 22/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0517 - precision: 0.6112\n",
      "Epoch 22: val_loss improved from 1.06035 to 1.05690, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0516 - precision: 0.6099 - val_loss: 1.0569 - val_precision: 0.6336\n",
      "Epoch 23/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0418 - precision: 0.6047\n",
      "Epoch 23: val_loss did not improve from 1.05690\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0399 - precision: 0.6050 - val_loss: 1.0676 - val_precision: 0.6191\n",
      "Epoch 24/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0446 - precision: 0.6081\n",
      "Epoch 24: val_loss did not improve from 1.05690\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0444 - precision: 0.6075 - val_loss: 1.0576 - val_precision: 0.6219\n",
      "Epoch 25/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0343 - precision: 0.6162\n",
      "Epoch 25: val_loss improved from 1.05690 to 1.05449, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0342 - precision: 0.6161 - val_loss: 1.0545 - val_precision: 0.6240\n",
      "Epoch 26/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0276 - precision: 0.6094\n",
      "Epoch 26: val_loss did not improve from 1.05449\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0291 - precision: 0.6089 - val_loss: 1.0599 - val_precision: 0.6164\n",
      "Epoch 27/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0383 - precision: 0.6069\n",
      "Epoch 27: val_loss improved from 1.05449 to 1.04906, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0380 - precision: 0.6070 - val_loss: 1.0491 - val_precision: 0.6270\n",
      "Epoch 28/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0318 - precision: 0.6084\n",
      "Epoch 28: val_loss did not improve from 1.04906\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0309 - precision: 0.6095 - val_loss: 1.0493 - val_precision: 0.6219\n",
      "Epoch 29/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0178 - precision: 0.6133\n",
      "Epoch 29: val_loss did not improve from 1.04906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0230 - precision: 0.6121 - val_loss: 1.0566 - val_precision: 0.6129\n",
      "Epoch 30/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0150 - precision: 0.6078\n",
      "Epoch 30: val_loss did not improve from 1.04906\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0140 - precision: 0.6079 - val_loss: 1.0493 - val_precision: 0.6198\n",
      "Epoch 31/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0251 - precision: 0.6131\n",
      "Epoch 31: val_loss improved from 1.04906 to 1.04789, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0280 - precision: 0.6099 - val_loss: 1.0479 - val_precision: 0.6211\n",
      "Epoch 32/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0325 - precision: 0.6137\n",
      "Epoch 32: val_loss did not improve from 1.04789\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0309 - precision: 0.6143 - val_loss: 1.0533 - val_precision: 0.6233\n",
      "Epoch 33/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0235 - precision: 0.6115\n",
      "Epoch 33: val_loss did not improve from 1.04789\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0222 - precision: 0.6119 - val_loss: 1.0503 - val_precision: 0.6214\n",
      "Epoch 34/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0213 - precision: 0.6059\n",
      "Epoch 34: val_loss improved from 1.04789 to 1.04563, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0270 - precision: 0.6032 - val_loss: 1.0456 - val_precision: 0.6230\n",
      "Epoch 35/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0147 - precision: 0.6132\n",
      "Epoch 35: val_loss improved from 1.04563 to 1.04294, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0159 - precision: 0.6130 - val_loss: 1.0429 - val_precision: 0.6217\n",
      "Epoch 36/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0281 - precision: 0.6083\n",
      "Epoch 36: val_loss did not improve from 1.04294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0266 - precision: 0.6082 - val_loss: 1.0561 - val_precision: 0.6094\n",
      "Epoch 37/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0146 - precision: 0.6111\n",
      "Epoch 37: val_loss did not improve from 1.04294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0154 - precision: 0.6110 - val_loss: 1.0486 - val_precision: 0.6150\n",
      "Epoch 38/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0158 - precision: 0.6069\n",
      "Epoch 38: val_loss did not improve from 1.04294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0130 - precision: 0.6068 - val_loss: 1.0440 - val_precision: 0.6215\n",
      "Epoch 39/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0085 - precision: 0.6165\n",
      "Epoch 39: val_loss did not improve from 1.04294\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0090 - precision: 0.6169 - val_loss: 1.0445 - val_precision: 0.6194\n",
      "Epoch 40/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0108 - precision: 0.6126\n",
      "Epoch 40: val_loss did not improve from 1.04294\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0098 - precision: 0.6109 - val_loss: 1.0523 - val_precision: 0.6121\n",
      "Epoch 41/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0096 - precision: 0.6078\n",
      "Epoch 41: val_loss improved from 1.04294 to 1.04173, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0110 - precision: 0.6060 - val_loss: 1.0417 - val_precision: 0.6203\n",
      "Epoch 42/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0111 - precision: 0.6140\n",
      "Epoch 42: val_loss improved from 1.04173 to 1.03931, saving model to model_ent92.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0121 - precision: 0.6126 - val_loss: 1.0393 - val_precision: 0.6197\n",
      "Epoch 43/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0084 - precision: 0.6163\n",
      "Epoch 43: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0119 - precision: 0.6158 - val_loss: 1.0519 - val_precision: 0.6089\n",
      "Epoch 44/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0134 - precision: 0.6139\n",
      "Epoch 44: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0138 - precision: 0.6143 - val_loss: 1.0470 - val_precision: 0.6171\n",
      "Epoch 45/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0063 - precision: 0.6140\n",
      "Epoch 45: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0079 - precision: 0.6132 - val_loss: 1.0504 - val_precision: 0.6165\n",
      "Epoch 46/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0041 - precision: 0.6112\n",
      "Epoch 46: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0022 - precision: 0.6110 - val_loss: 1.0435 - val_precision: 0.6186\n",
      "Epoch 47/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0004 - precision: 0.6134\n",
      "Epoch 47: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0004 - precision: 0.6134 - val_loss: 1.0409 - val_precision: 0.6184\n",
      "Epoch 48/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0033 - precision: 0.6117\n",
      "Epoch 48: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0033 - precision: 0.6117 - val_loss: 1.0408 - val_precision: 0.6212\n",
      "Epoch 49/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0026 - precision: 0.6165\n",
      "Epoch 49: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0002 - precision: 0.6177 - val_loss: 1.0420 - val_precision: 0.6218\n",
      "Epoch 50/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9983 - precision: 0.6162\n",
      "Epoch 50: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9976 - precision: 0.6173 - val_loss: 1.0438 - val_precision: 0.6143\n",
      "Epoch 51/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9973 - precision: 0.6164\n",
      "Epoch 51: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0004 - precision: 0.6131 - val_loss: 1.0452 - val_precision: 0.6160\n",
      "Epoch 52/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9914 - precision: 0.6141\n",
      "Epoch 52: val_loss did not improve from 1.03931\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9890 - precision: 0.6149 - val_loss: 1.0433 - val_precision: 0.6222\n",
      "Epoch 52: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0013 - precision: 0.6279\n",
      "Combinación 91 = (False, False, True, 8, 0.25) \n",
      " precision train: [1.001328945159912, 0.6278784871101379]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 93: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.5876 - precision: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.51738, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.5880 - precision: 0.0000e+00 - val_loss: 1.5174 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.4286 - precision: 0.6111\n",
      "Epoch 2: val_loss improved from 1.51738 to 1.28523, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.4274 - precision: 0.6103 - val_loss: 1.2852 - val_precision: 0.6981\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3407 - precision: 0.5791\n",
      "Epoch 3: val_loss improved from 1.28523 to 1.21351, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3405 - precision: 0.5801 - val_loss: 1.2135 - val_precision: 0.6683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.2921 - precision: 0.5841\n",
      "Epoch 4: val_loss improved from 1.21351 to 1.18085, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2900 - precision: 0.5838 - val_loss: 1.1808 - val_precision: 0.6609\n",
      "Epoch 5/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2915 - precision: 0.5615\n",
      "Epoch 5: val_loss improved from 1.18085 to 1.16372, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2906 - precision: 0.5624 - val_loss: 1.1637 - val_precision: 0.6677\n",
      "Epoch 6/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2680 - precision: 0.5834\n",
      "Epoch 6: val_loss improved from 1.16372 to 1.15255, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2663 - precision: 0.5814 - val_loss: 1.1526 - val_precision: 0.6500\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2547 - precision: 0.5755\n",
      "Epoch 7: val_loss improved from 1.15255 to 1.14537, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2559 - precision: 0.5743 - val_loss: 1.1454 - val_precision: 0.6477\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2470 - precision: 0.5796\n",
      "Epoch 8: val_loss improved from 1.14537 to 1.13074, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2471 - precision: 0.5774 - val_loss: 1.1307 - val_precision: 0.6560\n",
      "Epoch 9/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2460 - precision: 0.5814\n",
      "Epoch 9: val_loss improved from 1.13074 to 1.12820, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2456 - precision: 0.5817 - val_loss: 1.1282 - val_precision: 0.6495\n",
      "Epoch 10/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2558 - precision: 0.5914\n",
      "Epoch 10: val_loss improved from 1.12820 to 1.12720, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2565 - precision: 0.5903 - val_loss: 1.1272 - val_precision: 0.6618\n",
      "Epoch 11/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2463 - precision: 0.5937\n",
      "Epoch 11: val_loss improved from 1.12720 to 1.12012, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2463 - precision: 0.5937 - val_loss: 1.1201 - val_precision: 0.6540\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2195 - precision: 0.5981\n",
      "Epoch 12: val_loss improved from 1.12012 to 1.11877, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2206 - precision: 0.5974 - val_loss: 1.1188 - val_precision: 0.6448\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2254 - precision: 0.5903\n",
      "Epoch 13: val_loss improved from 1.11877 to 1.11440, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2263 - precision: 0.5900 - val_loss: 1.1144 - val_precision: 0.6544\n",
      "Epoch 14/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2288 - precision: 0.5907\n",
      "Epoch 14: val_loss improved from 1.11440 to 1.11134, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2295 - precision: 0.5892 - val_loss: 1.1113 - val_precision: 0.6544\n",
      "Epoch 15/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2217 - precision: 0.5955\n",
      "Epoch 15: val_loss improved from 1.11134 to 1.11011, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2216 - precision: 0.5953 - val_loss: 1.1101 - val_precision: 0.6545\n",
      "Epoch 16/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2342 - precision: 0.5922\n",
      "Epoch 16: val_loss improved from 1.11011 to 1.10910, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2342 - precision: 0.5922 - val_loss: 1.1091 - val_precision: 0.6510\n",
      "Epoch 17/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.2161 - precision: 0.5921\n",
      "Epoch 17: val_loss did not improve from 1.10910\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2152 - precision: 0.5918 - val_loss: 1.1154 - val_precision: 0.6497\n",
      "Epoch 18/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2088 - precision: 0.5897\n",
      "Epoch 18: val_loss improved from 1.10910 to 1.10564, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2094 - precision: 0.5904 - val_loss: 1.1056 - val_precision: 0.6516\n",
      "Epoch 19/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2137 - precision: 0.6006\n",
      "Epoch 19: val_loss did not improve from 1.10564\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2137 - precision: 0.6006 - val_loss: 1.1150 - val_precision: 0.6468\n",
      "Epoch 20/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2158 - precision: 0.5938\n",
      "Epoch 20: val_loss did not improve from 1.10564\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2149 - precision: 0.5953 - val_loss: 1.1072 - val_precision: 0.6423\n",
      "Epoch 21/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2101 - precision: 0.5938\n",
      "Epoch 21: val_loss improved from 1.10564 to 1.10157, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2097 - precision: 0.5944 - val_loss: 1.1016 - val_precision: 0.6453\n",
      "Epoch 22/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1995 - precision: 0.6043\n",
      "Epoch 22: val_loss improved from 1.10157 to 1.09905, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1995 - precision: 0.6043 - val_loss: 1.0990 - val_precision: 0.6467\n",
      "Epoch 23/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1993 - precision: 0.5952\n",
      "Epoch 23: val_loss did not improve from 1.09905\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1993 - precision: 0.5952 - val_loss: 1.1129 - val_precision: 0.6432\n",
      "Epoch 24/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.1859 - precision: 0.6056\n",
      "Epoch 24: val_loss did not improve from 1.09905\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1919 - precision: 0.6054 - val_loss: 1.1049 - val_precision: 0.6414\n",
      "Epoch 25/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2081 - precision: 0.5982\n",
      "Epoch 25: val_loss improved from 1.09905 to 1.09890, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2072 - precision: 0.5971 - val_loss: 1.0989 - val_precision: 0.6479\n",
      "Epoch 26/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1995 - precision: 0.6108\n",
      "Epoch 26: val_loss did not improve from 1.09890\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2005 - precision: 0.6091 - val_loss: 1.1022 - val_precision: 0.6439\n",
      "Epoch 27/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2053 - precision: 0.5965\n",
      "Epoch 27: val_loss did not improve from 1.09890\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2024 - precision: 0.5944 - val_loss: 1.1067 - val_precision: 0.6475\n",
      "Epoch 28/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1776 - precision: 0.6186\n",
      "Epoch 28: val_loss did not improve from 1.09890\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1780 - precision: 0.6174 - val_loss: 1.1043 - val_precision: 0.6365\n",
      "Epoch 29/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1895 - precision: 0.6022\n",
      "Epoch 29: val_loss did not improve from 1.09890\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1872 - precision: 0.6012 - val_loss: 1.1014 - val_precision: 0.6418\n",
      "Epoch 30/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1824 - precision: 0.6044\n",
      "Epoch 30: val_loss did not improve from 1.09890\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1833 - precision: 0.6053 - val_loss: 1.1043 - val_precision: 0.6352\n",
      "Epoch 31/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1831 - precision: 0.6064\n",
      "Epoch 31: val_loss improved from 1.09890 to 1.09674, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1842 - precision: 0.6062 - val_loss: 1.0967 - val_precision: 0.6364\n",
      "Epoch 32/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1857 - precision: 0.6131\n",
      "Epoch 32: val_loss improved from 1.09674 to 1.09661, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1844 - precision: 0.6145 - val_loss: 1.0966 - val_precision: 0.6419\n",
      "Epoch 33/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1771 - precision: 0.6085\n",
      "Epoch 33: val_loss did not improve from 1.09661\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1771 - precision: 0.6085 - val_loss: 1.0974 - val_precision: 0.6387\n",
      "Epoch 34/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1742 - precision: 0.6125\n",
      "Epoch 34: val_loss did not improve from 1.09661\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1745 - precision: 0.6113 - val_loss: 1.0993 - val_precision: 0.6351\n",
      "Epoch 35/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1747 - precision: 0.6046\n",
      "Epoch 35: val_loss did not improve from 1.09661\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1739 - precision: 0.6030 - val_loss: 1.0982 - val_precision: 0.6324\n",
      "Epoch 36/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1582 - precision: 0.6063\n",
      "Epoch 36: val_loss did not improve from 1.09661\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1641 - precision: 0.6064 - val_loss: 1.1024 - val_precision: 0.6360\n",
      "Epoch 37/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1719 - precision: 0.6138\n",
      "Epoch 37: val_loss did not improve from 1.09661\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1702 - precision: 0.6152 - val_loss: 1.1021 - val_precision: 0.6270\n",
      "Epoch 38/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1597 - precision: 0.6195\n",
      "Epoch 38: val_loss did not improve from 1.09661\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1599 - precision: 0.6178 - val_loss: 1.1016 - val_precision: 0.6314\n",
      "Epoch 39/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1715 - precision: 0.6048\n",
      "Epoch 39: val_loss improved from 1.09661 to 1.09178, saving model to model_ent93.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1742 - precision: 0.6047 - val_loss: 1.0918 - val_precision: 0.6399\n",
      "Epoch 40/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1780 - precision: 0.6122\n",
      "Epoch 40: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1780 - precision: 0.6122 - val_loss: 1.1020 - val_precision: 0.6362\n",
      "Epoch 41/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1729 - precision: 0.6116\n",
      "Epoch 41: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1742 - precision: 0.6122 - val_loss: 1.0963 - val_precision: 0.6385\n",
      "Epoch 42/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1629 - precision: 0.6052\n",
      "Epoch 42: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1629 - precision: 0.6052 - val_loss: 1.0956 - val_precision: 0.6435\n",
      "Epoch 43/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.1686 - precision: 0.6138\n",
      "Epoch 43: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1660 - precision: 0.6142 - val_loss: 1.1018 - val_precision: 0.6347\n",
      "Epoch 44/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1711 - precision: 0.6140\n",
      "Epoch 44: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1739 - precision: 0.6130 - val_loss: 1.0991 - val_precision: 0.6333\n",
      "Epoch 45/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1820 - precision: 0.6032\n",
      "Epoch 45: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1794 - precision: 0.6044 - val_loss: 1.0989 - val_precision: 0.6347\n",
      "Epoch 46/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1585 - precision: 0.6252\n",
      "Epoch 46: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1587 - precision: 0.6252 - val_loss: 1.0956 - val_precision: 0.6352\n",
      "Epoch 47/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1687 - precision: 0.6098\n",
      "Epoch 47: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1689 - precision: 0.6127 - val_loss: 1.0989 - val_precision: 0.6294\n",
      "Epoch 48/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1709 - precision: 0.6014\n",
      "Epoch 48: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1696 - precision: 0.6032 - val_loss: 1.0929 - val_precision: 0.6397\n",
      "Epoch 49/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.1709 - precision: 0.6081\n",
      "Epoch 49: val_loss did not improve from 1.09178\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1739 - precision: 0.6069 - val_loss: 1.0975 - val_precision: 0.6373\n",
      "Epoch 49: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0757 - precision: 0.6385\n",
      "Combinación 92 = (False, False, True, 8, 0.5) \n",
      " precision train: [1.0757052898406982, 0.6384603977203369]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 94: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.4221 - precision: 0.5912\n",
      "Epoch 1: val_loss improved from inf to 1.24829, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 6s 8ms/step - loss: 1.4149 - precision: 0.5852 - val_loss: 1.2483 - val_precision: 0.5931\n",
      "Epoch 2/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1113 - precision: 0.5989\n",
      "Epoch 2: val_loss improved from 1.24829 to 1.11186, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1122 - precision: 0.6045 - val_loss: 1.1119 - val_precision: 0.6354\n",
      "Epoch 3/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0308 - precision: 0.6111\n",
      "Epoch 3: val_loss improved from 1.11186 to 1.08922, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0290 - precision: 0.6107 - val_loss: 1.0892 - val_precision: 0.6140\n",
      "Epoch 4/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0065 - precision: 0.6055\n",
      "Epoch 4: val_loss improved from 1.08922 to 1.06543, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0028 - precision: 0.6072 - val_loss: 1.0654 - val_precision: 0.6107\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9964 - precision: 0.6008\n",
      "Epoch 5: val_loss did not improve from 1.06543\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9957 - precision: 0.6006 - val_loss: 1.0770 - val_precision: 0.6124\n",
      "Epoch 6/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9792 - precision: 0.6039\n",
      "Epoch 6: val_loss improved from 1.06543 to 1.04525, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9792 - precision: 0.6030 - val_loss: 1.0452 - val_precision: 0.6141\n",
      "Epoch 7/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9700 - precision: 0.6057\n",
      "Epoch 7: val_loss did not improve from 1.04525\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9705 - precision: 0.6052 - val_loss: 1.0481 - val_precision: 0.6093\n",
      "Epoch 8/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9650 - precision: 0.6077\n",
      "Epoch 8: val_loss improved from 1.04525 to 1.04053, saving model to model_ent94.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9650 - precision: 0.6077 - val_loss: 1.0405 - val_precision: 0.6117\n",
      "Epoch 9/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9577 - precision: 0.6082\n",
      "Epoch 9: val_loss improved from 1.04053 to 1.03083, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9562 - precision: 0.6079 - val_loss: 1.0308 - val_precision: 0.6250\n",
      "Epoch 10/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9536 - precision: 0.6073\n",
      "Epoch 10: val_loss did not improve from 1.03083\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9535 - precision: 0.6071 - val_loss: 1.0321 - val_precision: 0.6197\n",
      "Epoch 11/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9491 - precision: 0.6104\n",
      "Epoch 11: val_loss improved from 1.03083 to 1.02175, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9509 - precision: 0.6098 - val_loss: 1.0218 - val_precision: 0.6216\n",
      "Epoch 12/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9373 - precision: 0.6100\n",
      "Epoch 12: val_loss improved from 1.02175 to 1.02152, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9385 - precision: 0.6083 - val_loss: 1.0215 - val_precision: 0.6254\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9396 - precision: 0.6118\n",
      "Epoch 13: val_loss did not improve from 1.02152\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9457 - precision: 0.6086 - val_loss: 1.0269 - val_precision: 0.6168\n",
      "Epoch 14/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9338 - precision: 0.6147\n",
      "Epoch 14: val_loss did not improve from 1.02152\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9327 - precision: 0.6134 - val_loss: 1.0263 - val_precision: 0.6121\n",
      "Epoch 15/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9337 - precision: 0.6132\n",
      "Epoch 15: val_loss did not improve from 1.02152\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9328 - precision: 0.6133 - val_loss: 1.0274 - val_precision: 0.6104\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9227 - precision: 0.6151\n",
      "Epoch 16: val_loss improved from 1.02152 to 1.01859, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9227 - precision: 0.6153 - val_loss: 1.0186 - val_precision: 0.6228\n",
      "Epoch 17/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9175 - precision: 0.6191\n",
      "Epoch 17: val_loss did not improve from 1.01859\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9174 - precision: 0.6176 - val_loss: 1.0387 - val_precision: 0.6083\n",
      "Epoch 18/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9180 - precision: 0.6200\n",
      "Epoch 18: val_loss did not improve from 1.01859\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9191 - precision: 0.6199 - val_loss: 1.0195 - val_precision: 0.6177\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9079 - precision: 0.6239\n",
      "Epoch 19: val_loss did not improve from 1.01859\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9116 - precision: 0.6225 - val_loss: 1.0298 - val_precision: 0.6132\n",
      "Epoch 20/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9095 - precision: 0.6220\n",
      "Epoch 20: val_loss did not improve from 1.01859\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9082 - precision: 0.6213 - val_loss: 1.0277 - val_precision: 0.6155\n",
      "Epoch 21/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9013 - precision: 0.6236\n",
      "Epoch 21: val_loss did not improve from 1.01859\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9014 - precision: 0.6211 - val_loss: 1.0199 - val_precision: 0.6200\n",
      "Epoch 22/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9037 - precision: 0.6233\n",
      "Epoch 22: val_loss improved from 1.01859 to 1.01111, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9037 - precision: 0.6238 - val_loss: 1.0111 - val_precision: 0.6255\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8992 - precision: 0.6285\n",
      "Epoch 23: val_loss did not improve from 1.01111\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8998 - precision: 0.6288 - val_loss: 1.0137 - val_precision: 0.6282\n",
      "Epoch 24/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8941 - precision: 0.6236\n",
      "Epoch 24: val_loss did not improve from 1.01111\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8952 - precision: 0.6226 - val_loss: 1.0146 - val_precision: 0.6263\n",
      "Epoch 25/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8867 - precision: 0.6283\n",
      "Epoch 25: val_loss did not improve from 1.01111\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8864 - precision: 0.6292 - val_loss: 1.0218 - val_precision: 0.6179\n",
      "Epoch 26/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8785 - precision: 0.6325\n",
      "Epoch 26: val_loss improved from 1.01111 to 1.00998, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8768 - precision: 0.6322 - val_loss: 1.0100 - val_precision: 0.6208\n",
      "Epoch 27/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8730 - precision: 0.6336\n",
      "Epoch 27: val_loss did not improve from 1.00998\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8758 - precision: 0.6316 - val_loss: 1.0283 - val_precision: 0.6146\n",
      "Epoch 28/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8747 - precision: 0.6313\n",
      "Epoch 28: val_loss did not improve from 1.00998\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8768 - precision: 0.6305 - val_loss: 1.0173 - val_precision: 0.6189\n",
      "Epoch 29/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8769 - precision: 0.6304\n",
      "Epoch 29: val_loss improved from 1.00998 to 1.00625, saving model to model_ent94.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8788 - precision: 0.6286 - val_loss: 1.0063 - val_precision: 0.6257\n",
      "Epoch 30/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8777 - precision: 0.6268\n",
      "Epoch 30: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8759 - precision: 0.6265 - val_loss: 1.0188 - val_precision: 0.6212\n",
      "Epoch 31/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8687 - precision: 0.6331\n",
      "Epoch 31: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8680 - precision: 0.6340 - val_loss: 1.0284 - val_precision: 0.6098\n",
      "Epoch 32/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8677 - precision: 0.6328\n",
      "Epoch 32: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8646 - precision: 0.6328 - val_loss: 1.0190 - val_precision: 0.6200\n",
      "Epoch 33/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8652 - precision: 0.6350\n",
      "Epoch 33: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8650 - precision: 0.6343 - val_loss: 1.0142 - val_precision: 0.6184\n",
      "Epoch 34/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8603 - precision: 0.6339\n",
      "Epoch 34: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8589 - precision: 0.6342 - val_loss: 1.0117 - val_precision: 0.6246\n",
      "Epoch 35/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8554 - precision: 0.6412\n",
      "Epoch 35: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8553 - precision: 0.6408 - val_loss: 1.0219 - val_precision: 0.6162\n",
      "Epoch 36/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8508 - precision: 0.6419\n",
      "Epoch 36: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8504 - precision: 0.6425 - val_loss: 1.0107 - val_precision: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8500 - precision: 0.6406\n",
      "Epoch 37: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8462 - precision: 0.6413 - val_loss: 1.0188 - val_precision: 0.6174\n",
      "Epoch 38/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8467 - precision: 0.6321\n",
      "Epoch 38: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8444 - precision: 0.6338 - val_loss: 1.0094 - val_precision: 0.6238\n",
      "Epoch 39/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8443 - precision: 0.6326\n",
      "Epoch 39: val_loss did not improve from 1.00625\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8443 - precision: 0.6326 - val_loss: 1.0265 - val_precision: 0.6108\n",
      "Epoch 39: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9413 - precision: 0.6411\n",
      "Combinación 93 = (False, False, True, 16, 0.1) \n",
      " precision train: [0.9412546753883362, 0.6411367654800415]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 95: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.4424 - precision: 0.5411\n",
      "Epoch 1: val_loss improved from inf to 1.31002, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 6s 8ms/step - loss: 1.4419 - precision: 0.5470 - val_loss: 1.3100 - val_precision: 0.0000e+00\n",
      "Epoch 2/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2339 - precision: 0.6216\n",
      "Epoch 2: val_loss improved from 1.31002 to 1.17509, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2293 - precision: 0.6231 - val_loss: 1.1751 - val_precision: 0.6518\n",
      "Epoch 3/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1395 - precision: 0.6226\n",
      "Epoch 3: val_loss improved from 1.17509 to 1.12760, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1358 - precision: 0.6225 - val_loss: 1.1276 - val_precision: 0.6644\n",
      "Epoch 4/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0926 - precision: 0.6307\n",
      "Epoch 4: val_loss improved from 1.12760 to 1.08963, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0940 - precision: 0.6289 - val_loss: 1.0896 - val_precision: 0.6488\n",
      "Epoch 5/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0694 - precision: 0.6147\n",
      "Epoch 5: val_loss improved from 1.08963 to 1.08923, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0696 - precision: 0.6138 - val_loss: 1.0892 - val_precision: 0.6285\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0500 - precision: 0.6003\n",
      "Epoch 6: val_loss improved from 1.08923 to 1.05433, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0503 - precision: 0.6016 - val_loss: 1.0543 - val_precision: 0.6321\n",
      "Epoch 7/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0283 - precision: 0.6036\n",
      "Epoch 7: val_loss improved from 1.05433 to 1.04850, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0276 - precision: 0.6045 - val_loss: 1.0485 - val_precision: 0.6129\n",
      "Epoch 8/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0175 - precision: 0.6042\n",
      "Epoch 8: val_loss did not improve from 1.04850\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0176 - precision: 0.6022 - val_loss: 1.0543 - val_precision: 0.6129\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0075 - precision: 0.6018\n",
      "Epoch 9: val_loss improved from 1.04850 to 1.04717, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0062 - precision: 0.6022 - val_loss: 1.0472 - val_precision: 0.6134\n",
      "Epoch 10/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0017 - precision: 0.6035\n",
      "Epoch 10: val_loss improved from 1.04717 to 1.04409, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0013 - precision: 0.6030 - val_loss: 1.0441 - val_precision: 0.6157\n",
      "Epoch 11/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9865 - precision: 0.6068\n",
      "Epoch 11: val_loss improved from 1.04409 to 1.04364, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9905 - precision: 0.6059 - val_loss: 1.0436 - val_precision: 0.6112\n",
      "Epoch 12/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9830 - precision: 0.6100\n",
      "Epoch 12: val_loss improved from 1.04364 to 1.03963, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9848 - precision: 0.6087 - val_loss: 1.0396 - val_precision: 0.6058\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9827 - precision: 0.6078\n",
      "Epoch 13: val_loss did not improve from 1.03963\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9844 - precision: 0.6079 - val_loss: 1.0475 - val_precision: 0.6077\n",
      "Epoch 14/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9807 - precision: 0.6051\n",
      "Epoch 14: val_loss improved from 1.03963 to 1.03795, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9808 - precision: 0.6046 - val_loss: 1.0380 - val_precision: 0.6124\n",
      "Epoch 15/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9727 - precision: 0.6098\n",
      "Epoch 15: val_loss improved from 1.03795 to 1.03335, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9738 - precision: 0.6092 - val_loss: 1.0333 - val_precision: 0.6168\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9733 - precision: 0.6056\n",
      "Epoch 16: val_loss did not improve from 1.03335\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9727 - precision: 0.6052 - val_loss: 1.0456 - val_precision: 0.6057\n",
      "Epoch 17/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9630 - precision: 0.6109\n",
      "Epoch 17: val_loss improved from 1.03335 to 1.03274, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9635 - precision: 0.6087 - val_loss: 1.0327 - val_precision: 0.6143\n",
      "Epoch 18/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9607 - precision: 0.6086\n",
      "Epoch 18: val_loss did not improve from 1.03274\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9645 - precision: 0.6094 - val_loss: 1.0355 - val_precision: 0.6163\n",
      "Epoch 19/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9607 - precision: 0.6144\n",
      "Epoch 19: val_loss did not improve from 1.03274\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9617 - precision: 0.6145 - val_loss: 1.0391 - val_precision: 0.6189\n",
      "Epoch 20/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9644 - precision: 0.6068\n",
      "Epoch 20: val_loss improved from 1.03274 to 1.02683, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9667 - precision: 0.6053 - val_loss: 1.0268 - val_precision: 0.6218\n",
      "Epoch 21/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9588 - precision: 0.6106\n",
      "Epoch 21: val_loss did not improve from 1.02683\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9561 - precision: 0.6105 - val_loss: 1.0307 - val_precision: 0.6234\n",
      "Epoch 22/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9485 - precision: 0.6143\n",
      "Epoch 22: val_loss did not improve from 1.02683\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9485 - precision: 0.6143 - val_loss: 1.0465 - val_precision: 0.6069\n",
      "Epoch 23/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9530 - precision: 0.6075\n",
      "Epoch 23: val_loss did not improve from 1.02683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9514 - precision: 0.6069 - val_loss: 1.0323 - val_precision: 0.6153\n",
      "Epoch 24/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9507 - precision: 0.6140\n",
      "Epoch 24: val_loss did not improve from 1.02683\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9462 - precision: 0.6138 - val_loss: 1.0322 - val_precision: 0.6139\n",
      "Epoch 25/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9464 - precision: 0.6099\n",
      "Epoch 25: val_loss did not improve from 1.02683\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9441 - precision: 0.6104 - val_loss: 1.0322 - val_precision: 0.6181\n",
      "Epoch 26/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9442 - precision: 0.6133\n",
      "Epoch 26: val_loss improved from 1.02683 to 1.01901, saving model to model_ent95.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9429 - precision: 0.6139 - val_loss: 1.0190 - val_precision: 0.6258\n",
      "Epoch 27/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9402 - precision: 0.6146\n",
      "Epoch 27: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9405 - precision: 0.6151 - val_loss: 1.0332 - val_precision: 0.6174\n",
      "Epoch 28/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9403 - precision: 0.6163\n",
      "Epoch 28: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9398 - precision: 0.6164 - val_loss: 1.0227 - val_precision: 0.6194\n",
      "Epoch 29/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9389 - precision: 0.6197\n",
      "Epoch 29: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9385 - precision: 0.6186 - val_loss: 1.0240 - val_precision: 0.6209\n",
      "Epoch 30/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9302 - precision: 0.6158\n",
      "Epoch 30: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9284 - precision: 0.6165 - val_loss: 1.0271 - val_precision: 0.6173\n",
      "Epoch 31/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9297 - precision: 0.6160\n",
      "Epoch 31: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9313 - precision: 0.6167 - val_loss: 1.0339 - val_precision: 0.6117\n",
      "Epoch 32/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9252 - precision: 0.6132\n",
      "Epoch 32: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9252 - precision: 0.6132 - val_loss: 1.0501 - val_precision: 0.6008\n",
      "Epoch 33/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9254 - precision: 0.6205\n",
      "Epoch 33: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9254 - precision: 0.6195 - val_loss: 1.0257 - val_precision: 0.6153\n",
      "Epoch 34/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9175 - precision: 0.6156\n",
      "Epoch 34: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9202 - precision: 0.6147 - val_loss: 1.0265 - val_precision: 0.6139\n",
      "Epoch 35/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9149 - precision: 0.6200\n",
      "Epoch 35: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9179 - precision: 0.6194 - val_loss: 1.0222 - val_precision: 0.6223\n",
      "Epoch 36/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9109 - precision: 0.6200\n",
      "Epoch 36: val_loss did not improve from 1.01901\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9133 - precision: 0.6193 - val_loss: 1.0268 - val_precision: 0.6150\n",
      "Epoch 36: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9659 - precision: 0.6281\n",
      "Combinación 94 = (False, False, True, 16, 0.25) \n",
      " precision train: [0.9658637642860413, 0.6280519366264343]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 96: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.5556 - precision: 0.6105  \n",
      "Epoch 1: val_loss improved from inf to 1.34470, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.5447 - precision: 0.5867 - val_loss: 1.3447 - val_precision: 0.6718\n",
      "Epoch 2/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.3331 - precision: 0.6018\n",
      "Epoch 2: val_loss improved from 1.34470 to 1.22960, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3302 - precision: 0.6034 - val_loss: 1.2296 - val_precision: 0.6926\n",
      "Epoch 3/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.2589 - precision: 0.6065\n",
      "Epoch 3: val_loss improved from 1.22960 to 1.16560, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2572 - precision: 0.6074 - val_loss: 1.1656 - val_precision: 0.6687\n",
      "Epoch 4/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1990 - precision: 0.6182\n",
      "Epoch 4: val_loss improved from 1.16560 to 1.14523, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2034 - precision: 0.6171 - val_loss: 1.1452 - val_precision: 0.6604\n",
      "Epoch 5/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1820 - precision: 0.6196\n",
      "Epoch 5: val_loss improved from 1.14523 to 1.11584, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1805 - precision: 0.6192 - val_loss: 1.1158 - val_precision: 0.6531\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1529 - precision: 0.6106\n",
      "Epoch 6: val_loss improved from 1.11584 to 1.10730, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1536 - precision: 0.6104 - val_loss: 1.1073 - val_precision: 0.6575\n",
      "Epoch 7/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1434 - precision: 0.6110\n",
      "Epoch 7: val_loss improved from 1.10730 to 1.09301, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1416 - precision: 0.6110 - val_loss: 1.0930 - val_precision: 0.6328\n",
      "Epoch 8/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1271 - precision: 0.6095\n",
      "Epoch 8: val_loss improved from 1.09301 to 1.08520, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1281 - precision: 0.6106 - val_loss: 1.0852 - val_precision: 0.6320\n",
      "Epoch 9/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1282 - precision: 0.5998\n",
      "Epoch 9: val_loss improved from 1.08520 to 1.07258, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1290 - precision: 0.6011 - val_loss: 1.0726 - val_precision: 0.6300\n",
      "Epoch 10/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1152 - precision: 0.6032\n",
      "Epoch 10: val_loss did not improve from 1.07258\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1153 - precision: 0.6033 - val_loss: 1.0740 - val_precision: 0.6255\n",
      "Epoch 11/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1027 - precision: 0.6084\n",
      "Epoch 11: val_loss did not improve from 1.07258\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1038 - precision: 0.6087 - val_loss: 1.0884 - val_precision: 0.6179\n",
      "Epoch 12/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1102 - precision: 0.6017\n",
      "Epoch 12: val_loss did not improve from 1.07258\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1139 - precision: 0.6001 - val_loss: 1.0727 - val_precision: 0.6214\n",
      "Epoch 13/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1156 - precision: 0.5986\n",
      "Epoch 13: val_loss improved from 1.07258 to 1.07057, saving model to model_ent96.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1179 - precision: 0.5977 - val_loss: 1.0706 - val_precision: 0.6187\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0898 - precision: 0.6058\n",
      "Epoch 14: val_loss improved from 1.07057 to 1.06513, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0896 - precision: 0.6063 - val_loss: 1.0651 - val_precision: 0.6177\n",
      "Epoch 15/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0939 - precision: 0.6046\n",
      "Epoch 15: val_loss did not improve from 1.06513\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0952 - precision: 0.6033 - val_loss: 1.0701 - val_precision: 0.6158\n",
      "Epoch 16/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0954 - precision: 0.6014\n",
      "Epoch 16: val_loss did not improve from 1.06513\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0952 - precision: 0.6007 - val_loss: 1.0708 - val_precision: 0.6128\n",
      "Epoch 17/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1007 - precision: 0.6048\n",
      "Epoch 17: val_loss did not improve from 1.06513\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1028 - precision: 0.6034 - val_loss: 1.0689 - val_precision: 0.6142\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0962 - precision: 0.5989\n",
      "Epoch 18: val_loss did not improve from 1.06513\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0958 - precision: 0.5989 - val_loss: 1.0663 - val_precision: 0.6151\n",
      "Epoch 19/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.0887 - precision: 0.5980\n",
      "Epoch 19: val_loss improved from 1.06513 to 1.05947, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0910 - precision: 0.5978 - val_loss: 1.0595 - val_precision: 0.6122\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0810 - precision: 0.6051\n",
      "Epoch 20: val_loss did not improve from 1.05947\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0801 - precision: 0.6054 - val_loss: 1.0632 - val_precision: 0.6140\n",
      "Epoch 21/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0839 - precision: 0.5995\n",
      "Epoch 21: val_loss did not improve from 1.05947\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0831 - precision: 0.6000 - val_loss: 1.0631 - val_precision: 0.6165\n",
      "Epoch 22/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0750 - precision: 0.6068\n",
      "Epoch 22: val_loss improved from 1.05947 to 1.05728, saving model to model_ent96.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0748 - precision: 0.6077 - val_loss: 1.0573 - val_precision: 0.6156\n",
      "Epoch 23/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0731 - precision: 0.6142\n",
      "Epoch 23: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0790 - precision: 0.6065 - val_loss: 1.0717 - val_precision: 0.6139\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0694 - precision: 0.6019\n",
      "Epoch 24: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0697 - precision: 0.6018 - val_loss: 1.0671 - val_precision: 0.6084\n",
      "Epoch 25/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0577 - precision: 0.6134\n",
      "Epoch 25: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0582 - precision: 0.6118 - val_loss: 1.0694 - val_precision: 0.6085\n",
      "Epoch 26/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0707 - precision: 0.6057\n",
      "Epoch 26: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0701 - precision: 0.6060 - val_loss: 1.0589 - val_precision: 0.6193\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0784 - precision: 0.6010\n",
      "Epoch 27: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0782 - precision: 0.6011 - val_loss: 1.0629 - val_precision: 0.6121\n",
      "Epoch 28/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0622 - precision: 0.6086\n",
      "Epoch 28: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0595 - precision: 0.6107 - val_loss: 1.0751 - val_precision: 0.6004\n",
      "Epoch 29/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0625 - precision: 0.6050\n",
      "Epoch 29: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0618 - precision: 0.6052 - val_loss: 1.0609 - val_precision: 0.6119\n",
      "Epoch 30/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0640 - precision: 0.6033\n",
      "Epoch 30: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0613 - precision: 0.6052 - val_loss: 1.0677 - val_precision: 0.6127\n",
      "Epoch 31/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0574 - precision: 0.6047\n",
      "Epoch 31: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0574 - precision: 0.6047 - val_loss: 1.0704 - val_precision: 0.6047\n",
      "Epoch 32/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0541 - precision: 0.6125\n",
      "Epoch 32: val_loss did not improve from 1.05728\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0528 - precision: 0.6140 - val_loss: 1.0635 - val_precision: 0.6100\n",
      "Epoch 32: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0461 - precision: 0.6094\n",
      "Combinación 95 = (False, False, True, 16, 0.5) \n",
      " precision train: [1.0460776090621948, 0.609414279460907]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 97: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3124 - precision: 0.6064\n",
      "Epoch 1: val_loss improved from inf to 1.09188, saving model to model_ent97.h5\n",
      "236/236 [==============================] - 25s 84ms/step - loss: 1.3099 - precision: 0.6070 - val_loss: 1.0919 - val_precision: 0.6350\n",
      "Epoch 2/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0171 - precision: 0.6043\n",
      "Epoch 2: val_loss improved from 1.09188 to 1.05401, saving model to model_ent97.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.0186 - precision: 0.6044 - val_loss: 1.0540 - val_precision: 0.6218\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9812 - precision: 0.6063\n",
      "Epoch 3: val_loss improved from 1.05401 to 1.03251, saving model to model_ent97.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9839 - precision: 0.6070 - val_loss: 1.0325 - val_precision: 0.6261\n",
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9674 - precision: 0.6068\n",
      "Epoch 4: val_loss did not improve from 1.03251\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9667 - precision: 0.6070 - val_loss: 1.0456 - val_precision: 0.6145\n",
      "Epoch 5/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9569 - precision: 0.6074\n",
      "Epoch 5: val_loss improved from 1.03251 to 1.01074, saving model to model_ent97.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9564 - precision: 0.6073 - val_loss: 1.0107 - val_precision: 0.6340\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9458 - precision: 0.6117\n",
      "Epoch 6: val_loss did not improve from 1.01074\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9447 - precision: 0.6124 - val_loss: 1.0183 - val_precision: 0.6187\n",
      "Epoch 7/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9336 - precision: 0.6124\n",
      "Epoch 7: val_loss did not improve from 1.01074\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9331 - precision: 0.6121 - val_loss: 1.0121 - val_precision: 0.6268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9282 - precision: 0.6161\n",
      "Epoch 8: val_loss did not improve from 1.01074\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9258 - precision: 0.6164 - val_loss: 1.0176 - val_precision: 0.6178\n",
      "Epoch 9/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9137 - precision: 0.6161\n",
      "Epoch 9: val_loss did not improve from 1.01074\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9144 - precision: 0.6154 - val_loss: 1.0430 - val_precision: 0.6094\n",
      "Epoch 10/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9156 - precision: 0.6140\n",
      "Epoch 10: val_loss improved from 1.01074 to 1.00356, saving model to model_ent97.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9146 - precision: 0.6157 - val_loss: 1.0036 - val_precision: 0.6290\n",
      "Epoch 11/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9086 - precision: 0.6119\n",
      "Epoch 11: val_loss improved from 1.00356 to 1.00255, saving model to model_ent97.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9093 - precision: 0.6118 - val_loss: 1.0025 - val_precision: 0.6351\n",
      "Epoch 12/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8980 - precision: 0.6226\n",
      "Epoch 12: val_loss did not improve from 1.00255\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8978 - precision: 0.6228 - val_loss: 1.0059 - val_precision: 0.6263\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8927 - precision: 0.6231\n",
      "Epoch 13: val_loss improved from 1.00255 to 1.00080, saving model to model_ent97.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8928 - precision: 0.6229 - val_loss: 1.0008 - val_precision: 0.6288\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8812 - precision: 0.6281\n",
      "Epoch 14: val_loss improved from 1.00080 to 0.99984, saving model to model_ent97.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8821 - precision: 0.6264 - val_loss: 0.9998 - val_precision: 0.6306\n",
      "Epoch 15/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8819 - precision: 0.6256\n",
      "Epoch 15: val_loss did not improve from 0.99984\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8814 - precision: 0.6255 - val_loss: 1.0040 - val_precision: 0.6282\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8785 - precision: 0.6273\n",
      "Epoch 16: val_loss did not improve from 0.99984\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8789 - precision: 0.6268 - val_loss: 1.0115 - val_precision: 0.6334\n",
      "Epoch 17/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8669 - precision: 0.6291\n",
      "Epoch 17: val_loss did not improve from 0.99984\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8667 - precision: 0.6297 - val_loss: 1.0055 - val_precision: 0.6269\n",
      "Epoch 18/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8637 - precision: 0.6315\n",
      "Epoch 18: val_loss improved from 0.99984 to 0.99958, saving model to model_ent97.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8637 - precision: 0.6315 - val_loss: 0.9996 - val_precision: 0.6304\n",
      "Epoch 19/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8606 - precision: 0.6301\n",
      "Epoch 19: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8616 - precision: 0.6299 - val_loss: 1.0104 - val_precision: 0.6231\n",
      "Epoch 20/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8469 - precision: 0.6335\n",
      "Epoch 20: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8508 - precision: 0.6324 - val_loss: 1.0191 - val_precision: 0.6230\n",
      "Epoch 21/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8449 - precision: 0.6357\n",
      "Epoch 21: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8449 - precision: 0.6357 - val_loss: 1.0211 - val_precision: 0.6232\n",
      "Epoch 22/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8428 - precision: 0.6300\n",
      "Epoch 22: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8428 - precision: 0.6300 - val_loss: 1.0091 - val_precision: 0.6281\n",
      "Epoch 23/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8419 - precision: 0.6338\n",
      "Epoch 23: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8399 - precision: 0.6340 - val_loss: 1.0072 - val_precision: 0.6326\n",
      "Epoch 24/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8318 - precision: 0.6351\n",
      "Epoch 24: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8318 - precision: 0.6368 - val_loss: 1.0339 - val_precision: 0.6142\n",
      "Epoch 25/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8364 - precision: 0.6369\n",
      "Epoch 25: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8363 - precision: 0.6373 - val_loss: 1.0304 - val_precision: 0.6142\n",
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8260 - precision: 0.6366\n",
      "Epoch 26: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8251 - precision: 0.6370 - val_loss: 1.0249 - val_precision: 0.6287\n",
      "Epoch 27/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8220 - precision: 0.6390\n",
      "Epoch 27: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8220 - precision: 0.6390 - val_loss: 1.0280 - val_precision: 0.6182\n",
      "Epoch 28/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8107 - precision: 0.6423\n",
      "Epoch 28: val_loss did not improve from 0.99958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8117 - precision: 0.6415 - val_loss: 1.0263 - val_precision: 0.6161\n",
      "Epoch 28: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9260 - precision: 0.6395\n",
      "Combinación 96 = (False, False, True, 32, 0.1) \n",
      " precision train: [0.9259911775588989, 0.6394855380058289]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 98: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.3093 - precision: 0.6501\n",
      "Epoch 1: val_loss improved from inf to 1.13891, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.3093 - precision: 0.6501 - val_loss: 1.1389 - val_precision: 0.6256\n",
      "Epoch 2/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0468 - precision: 0.6059\n",
      "Epoch 2: val_loss improved from 1.13891 to 1.06364, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0450 - precision: 0.6062 - val_loss: 1.0636 - val_precision: 0.6224\n",
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0124 - precision: 0.5933\n",
      "Epoch 3: val_loss did not improve from 1.06364\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0096 - precision: 0.5959 - val_loss: 1.0703 - val_precision: 0.6069\n",
      "Epoch 4/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9918 - precision: 0.6024\n",
      "Epoch 4: val_loss improved from 1.06364 to 1.04064, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9968 - precision: 0.6024 - val_loss: 1.0406 - val_precision: 0.6194\n",
      "Epoch 5/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9777 - precision: 0.6065\n",
      "Epoch 5: val_loss improved from 1.04064 to 1.03537, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9859 - precision: 0.6034 - val_loss: 1.0354 - val_precision: 0.6241\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9707 - precision: 0.6061\n",
      "Epoch 6: val_loss improved from 1.03537 to 1.02728, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9693 - precision: 0.6068 - val_loss: 1.0273 - val_precision: 0.6214\n",
      "Epoch 7/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9690 - precision: 0.6057\n",
      "Epoch 7: val_loss improved from 1.02728 to 1.02619, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9695 - precision: 0.6037 - val_loss: 1.0262 - val_precision: 0.6144\n",
      "Epoch 8/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9627 - precision: 0.6084\n",
      "Epoch 8: val_loss did not improve from 1.02619\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9639 - precision: 0.6082 - val_loss: 1.0353 - val_precision: 0.6106\n",
      "Epoch 9/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9634 - precision: 0.6036\n",
      "Epoch 9: val_loss improved from 1.02619 to 1.01528, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9613 - precision: 0.6037 - val_loss: 1.0153 - val_precision: 0.6220\n",
      "Epoch 10/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9380 - precision: 0.6121\n",
      "Epoch 10: val_loss did not improve from 1.01528\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9389 - precision: 0.6122 - val_loss: 1.0250 - val_precision: 0.6236\n",
      "Epoch 11/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9435 - precision: 0.6112\n",
      "Epoch 11: val_loss did not improve from 1.01528\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9414 - precision: 0.6113 - val_loss: 1.0189 - val_precision: 0.6270\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9403 - precision: 0.6156\n",
      "Epoch 12: val_loss did not improve from 1.01528\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9403 - precision: 0.6156 - val_loss: 1.0235 - val_precision: 0.6075\n",
      "Epoch 13/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9320 - precision: 0.6130\n",
      "Epoch 13: val_loss improved from 1.01528 to 1.01518, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9317 - precision: 0.6128 - val_loss: 1.0152 - val_precision: 0.6213\n",
      "Epoch 14/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9305 - precision: 0.6146\n",
      "Epoch 14: val_loss improved from 1.01518 to 1.01284, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9321 - precision: 0.6137 - val_loss: 1.0128 - val_precision: 0.6215\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9247 - precision: 0.6183\n",
      "Epoch 15: val_loss did not improve from 1.01284\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9240 - precision: 0.6180 - val_loss: 1.0146 - val_precision: 0.6186\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9181 - precision: 0.6201\n",
      "Epoch 16: val_loss did not improve from 1.01284\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9179 - precision: 0.6203 - val_loss: 1.0227 - val_precision: 0.6103\n",
      "Epoch 17/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9057 - precision: 0.6195\n",
      "Epoch 17: val_loss did not improve from 1.01284\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9050 - precision: 0.6199 - val_loss: 1.0151 - val_precision: 0.6152\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9081 - precision: 0.6223\n",
      "Epoch 18: val_loss improved from 1.01284 to 1.00825, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9086 - precision: 0.6228 - val_loss: 1.0082 - val_precision: 0.6228\n",
      "Epoch 19/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9048 - precision: 0.6208\n",
      "Epoch 19: val_loss did not improve from 1.00825\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9009 - precision: 0.6215 - val_loss: 1.0118 - val_precision: 0.6213\n",
      "Epoch 20/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8961 - precision: 0.6258\n",
      "Epoch 20: val_loss did not improve from 1.00825\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8970 - precision: 0.6250 - val_loss: 1.0083 - val_precision: 0.6227\n",
      "Epoch 21/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8952 - precision: 0.6223\n",
      "Epoch 21: val_loss improved from 1.00825 to 1.00669, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8957 - precision: 0.6219 - val_loss: 1.0067 - val_precision: 0.6198\n",
      "Epoch 22/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8873 - precision: 0.6249\n",
      "Epoch 22: val_loss did not improve from 1.00669\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8906 - precision: 0.6243 - val_loss: 1.0221 - val_precision: 0.6160\n",
      "Epoch 23/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8863 - precision: 0.6282\n",
      "Epoch 23: val_loss did not improve from 1.00669\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8836 - precision: 0.6292 - val_loss: 1.0090 - val_precision: 0.6205\n",
      "Epoch 24/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8825 - precision: 0.6296\n",
      "Epoch 24: val_loss improved from 1.00669 to 1.00668, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8848 - precision: 0.6292 - val_loss: 1.0067 - val_precision: 0.6218\n",
      "Epoch 25/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8806 - precision: 0.6229\n",
      "Epoch 25: val_loss did not improve from 1.00668\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8818 - precision: 0.6230 - val_loss: 1.0082 - val_precision: 0.6219\n",
      "Epoch 26/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8777 - precision: 0.6283\n",
      "Epoch 26: val_loss did not improve from 1.00668\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8784 - precision: 0.6282 - val_loss: 1.0261 - val_precision: 0.6179\n",
      "Epoch 27/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8721 - precision: 0.6288\n",
      "Epoch 27: val_loss did not improve from 1.00668\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8722 - precision: 0.6277 - val_loss: 1.0285 - val_precision: 0.6122\n",
      "Epoch 28/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8735 - precision: 0.6292\n",
      "Epoch 28: val_loss did not improve from 1.00668\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8737 - precision: 0.6296 - val_loss: 1.0407 - val_precision: 0.6057\n",
      "Epoch 29/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8638 - precision: 0.6317\n",
      "Epoch 29: val_loss did not improve from 1.00668\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8633 - precision: 0.6316 - val_loss: 1.0184 - val_precision: 0.6201\n",
      "Epoch 30/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8617 - precision: 0.6303\n",
      "Epoch 30: val_loss did not improve from 1.00668\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8618 - precision: 0.6317 - val_loss: 1.0267 - val_precision: 0.6121\n",
      "Epoch 31/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8556 - precision: 0.6278\n",
      "Epoch 31: val_loss improved from 1.00668 to 1.00092, saving model to model_ent98.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8565 - precision: 0.6287 - val_loss: 1.0009 - val_precision: 0.6225\n",
      "Epoch 32/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8542 - precision: 0.6358\n",
      "Epoch 32: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8549 - precision: 0.6357 - val_loss: 1.0248 - val_precision: 0.6108\n",
      "Epoch 33/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8496 - precision: 0.6340\n",
      "Epoch 33: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8500 - precision: 0.6333 - val_loss: 1.0173 - val_precision: 0.6206\n",
      "Epoch 34/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/236 [============================>.] - ETA: 0s - loss: 0.8456 - precision: 0.6349\n",
      "Epoch 34: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8455 - precision: 0.6348 - val_loss: 1.0069 - val_precision: 0.6236\n",
      "Epoch 35/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8481 - precision: 0.6389\n",
      "Epoch 35: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8481 - precision: 0.6389 - val_loss: 1.0120 - val_precision: 0.6206\n",
      "Epoch 36/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8471 - precision: 0.6321\n",
      "Epoch 36: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8473 - precision: 0.6314 - val_loss: 1.0144 - val_precision: 0.6151\n",
      "Epoch 37/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8384 - precision: 0.6420\n",
      "Epoch 37: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8409 - precision: 0.6409 - val_loss: 1.0477 - val_precision: 0.5949\n",
      "Epoch 38/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8400 - precision: 0.6339\n",
      "Epoch 38: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8407 - precision: 0.6352 - val_loss: 1.0118 - val_precision: 0.6179\n",
      "Epoch 39/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8213 - precision: 0.6419\n",
      "Epoch 39: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8217 - precision: 0.6409 - val_loss: 1.0145 - val_precision: 0.6169\n",
      "Epoch 40/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8307 - precision: 0.6350\n",
      "Epoch 40: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8331 - precision: 0.6352 - val_loss: 1.0255 - val_precision: 0.6148\n",
      "Epoch 41/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8255 - precision: 0.6442\n",
      "Epoch 41: val_loss did not improve from 1.00092\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8258 - precision: 0.6441 - val_loss: 1.0082 - val_precision: 0.6214\n",
      "Epoch 41: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.8963 - precision: 0.6486\n",
      "Combinación 97 = (False, False, True, 32, 0.25) \n",
      " precision train: [0.8963068127632141, 0.6486083269119263]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 99: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.4525 - precision: 0.6038\n",
      "Epoch 1: val_loss improved from inf to 1.24249, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 7s 8ms/step - loss: 1.4460 - precision: 0.6034 - val_loss: 1.2425 - val_precision: 0.6556\n",
      "Epoch 2/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1797 - precision: 0.5956\n",
      "Epoch 2: val_loss improved from 1.24249 to 1.11346, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1778 - precision: 0.5955 - val_loss: 1.1135 - val_precision: 0.6263\n",
      "Epoch 3/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1006 - precision: 0.6068\n",
      "Epoch 3: val_loss improved from 1.11346 to 1.07941, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1012 - precision: 0.6071 - val_loss: 1.0794 - val_precision: 0.6346\n",
      "Epoch 4/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0731 - precision: 0.6051\n",
      "Epoch 4: val_loss improved from 1.07941 to 1.07281, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0738 - precision: 0.6028 - val_loss: 1.0728 - val_precision: 0.6153\n",
      "Epoch 5/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0688 - precision: 0.6045\n",
      "Epoch 5: val_loss improved from 1.07281 to 1.07016, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0673 - precision: 0.6042 - val_loss: 1.0702 - val_precision: 0.6182\n",
      "Epoch 6/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0562 - precision: 0.5954\n",
      "Epoch 6: val_loss improved from 1.07016 to 1.05897, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0535 - precision: 0.5970 - val_loss: 1.0590 - val_precision: 0.6228\n",
      "Epoch 7/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0429 - precision: 0.6115\n",
      "Epoch 7: val_loss did not improve from 1.05897\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0402 - precision: 0.6120 - val_loss: 1.0686 - val_precision: 0.6165\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0415 - precision: 0.6011\n",
      "Epoch 8: val_loss did not improve from 1.05897\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0430 - precision: 0.5993 - val_loss: 1.0651 - val_precision: 0.6083\n",
      "Epoch 9/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0410 - precision: 0.6018\n",
      "Epoch 9: val_loss improved from 1.05897 to 1.05497, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0357 - precision: 0.6045 - val_loss: 1.0550 - val_precision: 0.6125\n",
      "Epoch 10/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0230 - precision: 0.6178\n",
      "Epoch 10: val_loss improved from 1.05497 to 1.05418, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0245 - precision: 0.6170 - val_loss: 1.0542 - val_precision: 0.6121\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0267 - precision: 0.6095\n",
      "Epoch 11: val_loss improved from 1.05418 to 1.04311, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0252 - precision: 0.6106 - val_loss: 1.0431 - val_precision: 0.6206\n",
      "Epoch 12/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0163 - precision: 0.6109\n",
      "Epoch 12: val_loss did not improve from 1.04311\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0174 - precision: 0.6111 - val_loss: 1.0499 - val_precision: 0.6108\n",
      "Epoch 13/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0086 - precision: 0.6046\n",
      "Epoch 13: val_loss did not improve from 1.04311\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0156 - precision: 0.6017 - val_loss: 1.0586 - val_precision: 0.6201\n",
      "Epoch 14/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0146 - precision: 0.6052\n",
      "Epoch 14: val_loss did not improve from 1.04311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0108 - precision: 0.6050 - val_loss: 1.0446 - val_precision: 0.6211\n",
      "Epoch 15/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0014 - precision: 0.6118\n",
      "Epoch 15: val_loss did not improve from 1.04311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0009 - precision: 0.6121 - val_loss: 1.0569 - val_precision: 0.5989\n",
      "Epoch 16/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9963 - precision: 0.6095\n",
      "Epoch 16: val_loss did not improve from 1.04311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9963 - precision: 0.6095 - val_loss: 1.0454 - val_precision: 0.6142\n",
      "Epoch 17/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0023 - precision: 0.6120\n",
      "Epoch 17: val_loss did not improve from 1.04311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0023 - precision: 0.6120 - val_loss: 1.0437 - val_precision: 0.6121\n",
      "Epoch 18/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9989 - precision: 0.6060\n",
      "Epoch 18: val_loss improved from 1.04311 to 1.03319, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9989 - precision: 0.6060 - val_loss: 1.0332 - val_precision: 0.6305\n",
      "Epoch 19/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9992 - precision: 0.6113\n",
      "Epoch 19: val_loss did not improve from 1.03319\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9999 - precision: 0.6109 - val_loss: 1.0431 - val_precision: 0.6158\n",
      "Epoch 20/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9835 - precision: 0.6116\n",
      "Epoch 20: val_loss did not improve from 1.03319\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9878 - precision: 0.6106 - val_loss: 1.0418 - val_precision: 0.6132\n",
      "Epoch 21/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9844 - precision: 0.6154\n",
      "Epoch 21: val_loss did not improve from 1.03319\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9842 - precision: 0.6139 - val_loss: 1.0358 - val_precision: 0.6171\n",
      "Epoch 22/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9828 - precision: 0.6209\n",
      "Epoch 22: val_loss did not improve from 1.03319\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9869 - precision: 0.6187 - val_loss: 1.0373 - val_precision: 0.6238\n",
      "Epoch 23/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9827 - precision: 0.6159\n",
      "Epoch 23: val_loss did not improve from 1.03319\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9805 - precision: 0.6142 - val_loss: 1.0417 - val_precision: 0.6164\n",
      "Epoch 24/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9846 - precision: 0.6137\n",
      "Epoch 24: val_loss did not improve from 1.03319\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9843 - precision: 0.6138 - val_loss: 1.0350 - val_precision: 0.6180\n",
      "Epoch 25/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9833 - precision: 0.6118\n",
      "Epoch 25: val_loss did not improve from 1.03319\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9821 - precision: 0.6120 - val_loss: 1.0436 - val_precision: 0.6136\n",
      "Epoch 26/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9814 - precision: 0.6157\n",
      "Epoch 26: val_loss improved from 1.03319 to 1.02712, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9807 - precision: 0.6159 - val_loss: 1.0271 - val_precision: 0.6259\n",
      "Epoch 27/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9680 - precision: 0.6219\n",
      "Epoch 27: val_loss did not improve from 1.02712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9676 - precision: 0.6214 - val_loss: 1.0482 - val_precision: 0.6070\n",
      "Epoch 28/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9751 - precision: 0.6134\n",
      "Epoch 28: val_loss did not improve from 1.02712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9737 - precision: 0.6125 - val_loss: 1.0362 - val_precision: 0.6121\n",
      "Epoch 29/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9715 - precision: 0.6199\n",
      "Epoch 29: val_loss did not improve from 1.02712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9715 - precision: 0.6202 - val_loss: 1.0416 - val_precision: 0.6077\n",
      "Epoch 30/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9678 - precision: 0.6182\n",
      "Epoch 30: val_loss did not improve from 1.02712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9678 - precision: 0.6182 - val_loss: 1.0361 - val_precision: 0.6186\n",
      "Epoch 31/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9634 - precision: 0.6137\n",
      "Epoch 31: val_loss did not improve from 1.02712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9633 - precision: 0.6142 - val_loss: 1.0427 - val_precision: 0.6114\n",
      "Epoch 32/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9672 - precision: 0.6164\n",
      "Epoch 32: val_loss did not improve from 1.02712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9648 - precision: 0.6154 - val_loss: 1.0295 - val_precision: 0.6204\n",
      "Epoch 33/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9606 - precision: 0.6143\n",
      "Epoch 33: val_loss did not improve from 1.02712\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9612 - precision: 0.6147 - val_loss: 1.0306 - val_precision: 0.6151\n",
      "Epoch 34/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9521 - precision: 0.6170\n",
      "Epoch 34: val_loss improved from 1.02712 to 1.02311, saving model to model_ent99.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9514 - precision: 0.6167 - val_loss: 1.0231 - val_precision: 0.6259\n",
      "Epoch 35/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9585 - precision: 0.6188\n",
      "Epoch 35: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9583 - precision: 0.6189 - val_loss: 1.0283 - val_precision: 0.6220\n",
      "Epoch 36/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9585 - precision: 0.6186\n",
      "Epoch 36: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9589 - precision: 0.6186 - val_loss: 1.0424 - val_precision: 0.6069\n",
      "Epoch 37/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9624 - precision: 0.6118\n",
      "Epoch 37: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9637 - precision: 0.6105 - val_loss: 1.0278 - val_precision: 0.6276\n",
      "Epoch 38/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9557 - precision: 0.6228\n",
      "Epoch 38: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9559 - precision: 0.6212 - val_loss: 1.0341 - val_precision: 0.6158\n",
      "Epoch 39/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9487 - precision: 0.6205\n",
      "Epoch 39: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9507 - precision: 0.6191 - val_loss: 1.0360 - val_precision: 0.6137\n",
      "Epoch 40/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9486 - precision: 0.6214\n",
      "Epoch 40: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9490 - precision: 0.6214 - val_loss: 1.0355 - val_precision: 0.6182\n",
      "Epoch 41/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9490 - precision: 0.6217\n",
      "Epoch 41: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9542 - precision: 0.6201 - val_loss: 1.0238 - val_precision: 0.6264\n",
      "Epoch 42/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9516 - precision: 0.6240\n",
      "Epoch 42: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9530 - precision: 0.6220 - val_loss: 1.0367 - val_precision: 0.6089\n",
      "Epoch 43/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9461 - precision: 0.6163\n",
      "Epoch 43: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9437 - precision: 0.6171 - val_loss: 1.0267 - val_precision: 0.6195\n",
      "Epoch 44/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9412 - precision: 0.6183\n",
      "Epoch 44: val_loss did not improve from 1.02311\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9399 - precision: 0.6203 - val_loss: 1.0381 - val_precision: 0.6111\n",
      "Epoch 44: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9907 - precision: 0.6208\n",
      "Combinación 98 = (False, False, True, 32, 0.5) \n",
      " precision train: [0.990650475025177, 0.6208000183105469]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 100: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2242 - precision: 0.6202\n",
      "Epoch 1: val_loss improved from inf to 1.07509, saving model to model_ent100.h5\n",
      "236/236 [==============================] - 7s 10ms/step - loss: 1.2144 - precision: 0.6176 - val_loss: 1.0751 - val_precision: 0.6238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9879 - precision: 0.6058\n",
      "Epoch 2: val_loss improved from 1.07509 to 1.05156, saving model to model_ent100.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9873 - precision: 0.6056 - val_loss: 1.0516 - val_precision: 0.6197\n",
      "Epoch 3/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9612 - precision: 0.6051\n",
      "Epoch 3: val_loss improved from 1.05156 to 1.03221, saving model to model_ent100.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9624 - precision: 0.6051 - val_loss: 1.0322 - val_precision: 0.6243\n",
      "Epoch 4/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9446 - precision: 0.6062\n",
      "Epoch 4: val_loss improved from 1.03221 to 1.01935, saving model to model_ent100.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9444 - precision: 0.6054 - val_loss: 1.0194 - val_precision: 0.6183\n",
      "Epoch 5/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9295 - precision: 0.6067\n",
      "Epoch 5: val_loss improved from 1.01935 to 1.00884, saving model to model_ent100.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9307 - precision: 0.6049 - val_loss: 1.0088 - val_precision: 0.6271\n",
      "Epoch 6/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9199 - precision: 0.6114\n",
      "Epoch 6: val_loss did not improve from 1.00884\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9200 - precision: 0.6117 - val_loss: 1.0164 - val_precision: 0.6164\n",
      "Epoch 7/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9097 - precision: 0.6144\n",
      "Epoch 7: val_loss did not improve from 1.00884\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9093 - precision: 0.6145 - val_loss: 1.0182 - val_precision: 0.6148\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9093 - precision: 0.6129\n",
      "Epoch 8: val_loss did not improve from 1.00884\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9093 - precision: 0.6132 - val_loss: 1.0304 - val_precision: 0.6246\n",
      "Epoch 9/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8921 - precision: 0.6183\n",
      "Epoch 9: val_loss did not improve from 1.00884\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8938 - precision: 0.6191 - val_loss: 1.0442 - val_precision: 0.6052\n",
      "Epoch 10/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8907 - precision: 0.6201\n",
      "Epoch 10: val_loss did not improve from 1.00884\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8899 - precision: 0.6204 - val_loss: 1.0276 - val_precision: 0.6108\n",
      "Epoch 11/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8718 - precision: 0.6222\n",
      "Epoch 11: val_loss did not improve from 1.00884\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8780 - precision: 0.6215 - val_loss: 1.0128 - val_precision: 0.6200\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8714 - precision: 0.6214\n",
      "Epoch 12: val_loss improved from 1.00884 to 0.99289, saving model to model_ent100.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8719 - precision: 0.6218 - val_loss: 0.9929 - val_precision: 0.6328\n",
      "Epoch 13/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8643 - precision: 0.6289\n",
      "Epoch 13: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8643 - precision: 0.6277 - val_loss: 1.0134 - val_precision: 0.6335\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8605 - precision: 0.6284\n",
      "Epoch 14: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8605 - precision: 0.6284 - val_loss: 1.0083 - val_precision: 0.6275\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8511 - precision: 0.6298\n",
      "Epoch 15: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8513 - precision: 0.6296 - val_loss: 0.9974 - val_precision: 0.6337\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8432 - precision: 0.6366\n",
      "Epoch 16: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8453 - precision: 0.6351 - val_loss: 1.0249 - val_precision: 0.6113\n",
      "Epoch 17/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8280 - precision: 0.6372\n",
      "Epoch 17: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8364 - precision: 0.6347 - val_loss: 1.0697 - val_precision: 0.6019\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8331 - precision: 0.6393\n",
      "Epoch 18: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8330 - precision: 0.6390 - val_loss: 1.0306 - val_precision: 0.6158\n",
      "Epoch 19/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8245 - precision: 0.6397\n",
      "Epoch 19: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8249 - precision: 0.6399 - val_loss: 0.9981 - val_precision: 0.6335\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8193 - precision: 0.6397\n",
      "Epoch 20: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8199 - precision: 0.6399 - val_loss: 1.0158 - val_precision: 0.6296\n",
      "Epoch 21/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8063 - precision: 0.6400\n",
      "Epoch 21: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8109 - precision: 0.6388 - val_loss: 1.0167 - val_precision: 0.6275\n",
      "Epoch 22/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8020 - precision: 0.6426\n",
      "Epoch 22: val_loss did not improve from 0.99289\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8040 - precision: 0.6416 - val_loss: 1.0248 - val_precision: 0.6242\n",
      "Epoch 22: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9117 - precision: 0.6456\n",
      "Combinación 99 = (False, False, True, 64, 0.1) \n",
      " precision train: [0.9116532802581787, 0.6456403136253357]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 101: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2593 - precision: 0.6308\n",
      "Epoch 1: val_loss improved from inf to 1.10356, saving model to model_ent101.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.2496 - precision: 0.6266 - val_loss: 1.1036 - val_precision: 0.6203\n",
      "Epoch 2/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0084 - precision: 0.6035\n",
      "Epoch 2: val_loss improved from 1.10356 to 1.05127, saving model to model_ent101.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0110 - precision: 0.6050 - val_loss: 1.0513 - val_precision: 0.6281\n",
      "Epoch 3/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9799 - precision: 0.6087\n",
      "Epoch 3: val_loss did not improve from 1.05127\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9825 - precision: 0.6070 - val_loss: 1.0548 - val_precision: 0.6116\n",
      "Epoch 4/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9698 - precision: 0.6106\n",
      "Epoch 4: val_loss improved from 1.05127 to 1.03444, saving model to model_ent101.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9698 - precision: 0.6105 - val_loss: 1.0344 - val_precision: 0.6140\n",
      "Epoch 5/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9523 - precision: 0.6058\n",
      "Epoch 5: val_loss improved from 1.03444 to 1.01465, saving model to model_ent101.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9533 - precision: 0.6059 - val_loss: 1.0147 - val_precision: 0.6263\n",
      "Epoch 6/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9457 - precision: 0.6071\n",
      "Epoch 6: val_loss improved from 1.01465 to 1.01247, saving model to model_ent101.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9451 - precision: 0.6075 - val_loss: 1.0125 - val_precision: 0.6294\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9305 - precision: 0.6179\n",
      "Epoch 7: val_loss did not improve from 1.01247\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9332 - precision: 0.6157 - val_loss: 1.0382 - val_precision: 0.6107\n",
      "Epoch 8/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9281 - precision: 0.6137\n",
      "Epoch 8: val_loss did not improve from 1.01247\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9281 - precision: 0.6147 - val_loss: 1.0222 - val_precision: 0.6211\n",
      "Epoch 9/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9211 - precision: 0.6159\n",
      "Epoch 9: val_loss improved from 1.01247 to 1.00618, saving model to model_ent101.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9211 - precision: 0.6159 - val_loss: 1.0062 - val_precision: 0.6283\n",
      "Epoch 10/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9225 - precision: 0.6176\n",
      "Epoch 10: val_loss did not improve from 1.00618\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9209 - precision: 0.6177 - val_loss: 1.0079 - val_precision: 0.6311\n",
      "Epoch 11/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9064 - precision: 0.6229\n",
      "Epoch 11: val_loss did not improve from 1.00618\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9101 - precision: 0.6211 - val_loss: 1.0191 - val_precision: 0.6285\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8940 - precision: 0.6217\n",
      "Epoch 12: val_loss did not improve from 1.00618\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8942 - precision: 0.6212 - val_loss: 1.0225 - val_precision: 0.6155\n",
      "Epoch 13/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8954 - precision: 0.6182\n",
      "Epoch 13: val_loss did not improve from 1.00618\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8954 - precision: 0.6182 - val_loss: 1.0217 - val_precision: 0.6131\n",
      "Epoch 14/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8877 - precision: 0.6149\n",
      "Epoch 14: val_loss improved from 1.00618 to 1.00199, saving model to model_ent101.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8881 - precision: 0.6162 - val_loss: 1.0020 - val_precision: 0.6324\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8845 - precision: 0.6243\n",
      "Epoch 15: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8841 - precision: 0.6242 - val_loss: 1.0023 - val_precision: 0.6334\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8691 - precision: 0.6288\n",
      "Epoch 16: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8732 - precision: 0.6273 - val_loss: 1.0143 - val_precision: 0.6158\n",
      "Epoch 17/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8752 - precision: 0.6215\n",
      "Epoch 17: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8706 - precision: 0.6238 - val_loss: 1.0023 - val_precision: 0.6304\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8685 - precision: 0.6281\n",
      "Epoch 18: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8678 - precision: 0.6285 - val_loss: 1.0220 - val_precision: 0.6153\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8598 - precision: 0.6262\n",
      "Epoch 19: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8602 - precision: 0.6258 - val_loss: 1.0038 - val_precision: 0.6227\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8642 - precision: 0.6317\n",
      "Epoch 20: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8630 - precision: 0.6321 - val_loss: 1.0114 - val_precision: 0.6320\n",
      "Epoch 21/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8556 - precision: 0.6306\n",
      "Epoch 21: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8546 - precision: 0.6319 - val_loss: 1.0061 - val_precision: 0.6326\n",
      "Epoch 22/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8459 - precision: 0.6306\n",
      "Epoch 22: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8459 - precision: 0.6306 - val_loss: 1.0346 - val_precision: 0.6166\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8390 - precision: 0.6388\n",
      "Epoch 23: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8406 - precision: 0.6386 - val_loss: 1.0048 - val_precision: 0.6247\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8333 - precision: 0.6356\n",
      "Epoch 24: val_loss did not improve from 1.00199\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8329 - precision: 0.6356 - val_loss: 1.0170 - val_precision: 0.6233\n",
      "Epoch 24: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9215 - precision: 0.6408\n",
      "Combinación 100 = (False, False, True, 64, 0.25) \n",
      " precision train: [0.9215472340583801, 0.6408424377441406]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 102: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.3211 - precision: 0.6405\n",
      "Epoch 1: val_loss improved from inf to 1.12220, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.3115 - precision: 0.6340 - val_loss: 1.1222 - val_precision: 0.6337\n",
      "Epoch 2/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0601 - precision: 0.6052\n",
      "Epoch 2: val_loss improved from 1.12220 to 1.05008, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0585 - precision: 0.6051 - val_loss: 1.0501 - val_precision: 0.6310\n",
      "Epoch 3/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0294 - precision: 0.6022\n",
      "Epoch 3: val_loss improved from 1.05008 to 1.04970, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0294 - precision: 0.6022 - val_loss: 1.0497 - val_precision: 0.6199\n",
      "Epoch 4/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0177 - precision: 0.6005\n",
      "Epoch 4: val_loss improved from 1.04970 to 1.03506, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0185 - precision: 0.6008 - val_loss: 1.0351 - val_precision: 0.6298\n",
      "Epoch 5/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0040 - precision: 0.6038\n",
      "Epoch 5: val_loss did not improve from 1.03506\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0028 - precision: 0.6036 - val_loss: 1.0490 - val_precision: 0.6031\n",
      "Epoch 6/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9942 - precision: 0.6053\n",
      "Epoch 6: val_loss improved from 1.03506 to 1.02958, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9909 - precision: 0.6036 - val_loss: 1.0296 - val_precision: 0.6129\n",
      "Epoch 7/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9808 - precision: 0.6105\n",
      "Epoch 7: val_loss did not improve from 1.02958\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9818 - precision: 0.6101 - val_loss: 1.0378 - val_precision: 0.6127\n",
      "Epoch 8/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9827 - precision: 0.6075\n",
      "Epoch 8: val_loss improved from 1.02958 to 1.02857, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9800 - precision: 0.6080 - val_loss: 1.0286 - val_precision: 0.6091\n",
      "Epoch 9/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9661 - precision: 0.6110\n",
      "Epoch 9: val_loss did not improve from 1.02857\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9689 - precision: 0.6087 - val_loss: 1.0382 - val_precision: 0.6059\n",
      "Epoch 10/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9614 - precision: 0.6016\n",
      "Epoch 10: val_loss improved from 1.02857 to 1.02552, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9617 - precision: 0.6014 - val_loss: 1.0255 - val_precision: 0.6121\n",
      "Epoch 11/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9579 - precision: 0.6101\n",
      "Epoch 11: val_loss did not improve from 1.02552\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9593 - precision: 0.6097 - val_loss: 1.0272 - val_precision: 0.6178\n",
      "Epoch 12/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9612 - precision: 0.6111\n",
      "Epoch 12: val_loss improved from 1.02552 to 1.01669, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9657 - precision: 0.6112 - val_loss: 1.0167 - val_precision: 0.6210\n",
      "Epoch 13/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9492 - precision: 0.6160\n",
      "Epoch 13: val_loss did not improve from 1.01669\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9528 - precision: 0.6153 - val_loss: 1.0215 - val_precision: 0.6058\n",
      "Epoch 14/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9350 - precision: 0.6137\n",
      "Epoch 14: val_loss did not improve from 1.01669\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9396 - precision: 0.6124 - val_loss: 1.0260 - val_precision: 0.6153\n",
      "Epoch 15/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9465 - precision: 0.6097\n",
      "Epoch 15: val_loss did not improve from 1.01669\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9422 - precision: 0.6123 - val_loss: 1.0338 - val_precision: 0.6241\n",
      "Epoch 16/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9414 - precision: 0.6172\n",
      "Epoch 16: val_loss did not improve from 1.01669\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9391 - precision: 0.6177 - val_loss: 1.0333 - val_precision: 0.6124\n",
      "Epoch 17/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9305 - precision: 0.6142\n",
      "Epoch 17: val_loss did not improve from 1.01669\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9305 - precision: 0.6139 - val_loss: 1.0226 - val_precision: 0.6217\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9350 - precision: 0.6162\n",
      "Epoch 18: val_loss improved from 1.01669 to 1.01356, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9339 - precision: 0.6163 - val_loss: 1.0136 - val_precision: 0.6268\n",
      "Epoch 19/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9248 - precision: 0.6207\n",
      "Epoch 19: val_loss did not improve from 1.01356\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9248 - precision: 0.6207 - val_loss: 1.0339 - val_precision: 0.6160\n",
      "Epoch 20/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9237 - precision: 0.6238\n",
      "Epoch 20: val_loss did not improve from 1.01356\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9250 - precision: 0.6223 - val_loss: 1.0199 - val_precision: 0.6227\n",
      "Epoch 21/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9254 - precision: 0.6195\n",
      "Epoch 21: val_loss improved from 1.01356 to 1.00145, saving model to model_ent102.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9206 - precision: 0.6215 - val_loss: 1.0014 - val_precision: 0.6327\n",
      "Epoch 22/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9266 - precision: 0.6205\n",
      "Epoch 22: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9266 - precision: 0.6205 - val_loss: 1.0191 - val_precision: 0.6205\n",
      "Epoch 23/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9135 - precision: 0.6208\n",
      "Epoch 23: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9123 - precision: 0.6219 - val_loss: 1.0128 - val_precision: 0.6241\n",
      "Epoch 24/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9113 - precision: 0.6199\n",
      "Epoch 24: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9104 - precision: 0.6205 - val_loss: 1.0180 - val_precision: 0.6183\n",
      "Epoch 25/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9080 - precision: 0.6216\n",
      "Epoch 25: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9095 - precision: 0.6214 - val_loss: 1.0224 - val_precision: 0.6201\n",
      "Epoch 26/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9026 - precision: 0.6241\n",
      "Epoch 26: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9020 - precision: 0.6239 - val_loss: 1.0214 - val_precision: 0.6166\n",
      "Epoch 27/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9028 - precision: 0.6230\n",
      "Epoch 27: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9030 - precision: 0.6231 - val_loss: 1.0125 - val_precision: 0.6221\n",
      "Epoch 28/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8945 - precision: 0.6211\n",
      "Epoch 28: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8950 - precision: 0.6206 - val_loss: 1.0136 - val_precision: 0.6232\n",
      "Epoch 29/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8927 - precision: 0.6285\n",
      "Epoch 29: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8940 - precision: 0.6280 - val_loss: 1.0180 - val_precision: 0.6212\n",
      "Epoch 30/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8925 - precision: 0.6250\n",
      "Epoch 30: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8921 - precision: 0.6258 - val_loss: 1.0037 - val_precision: 0.6305\n",
      "Epoch 31/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8933 - precision: 0.6259\n",
      "Epoch 31: val_loss did not improve from 1.00145\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8945 - precision: 0.6246 - val_loss: 1.0223 - val_precision: 0.6138\n",
      "Epoch 31: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9512 - precision: 0.6283\n",
      "Combinación 101 = (False, False, True, 64, 0.5) \n",
      " precision train: [0.9512355327606201, 0.628326416015625]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 103: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.1652 - precision: 0.6243\n",
      "Epoch 1: val_loss improved from inf to 1.06373, saving model to model_ent103.h5\n",
      "236/236 [==============================] - 7s 10ms/step - loss: 1.1614 - precision: 0.6215 - val_loss: 1.0637 - val_precision: 0.6288\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9715 - precision: 0.6115\n",
      "Epoch 2: val_loss improved from 1.06373 to 1.02817, saving model to model_ent103.h5\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.9724 - precision: 0.6094 - val_loss: 1.0282 - val_precision: 0.6263\n",
      "Epoch 3/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9438 - precision: 0.6080\n",
      "Epoch 3: val_loss improved from 1.02817 to 1.00064, saving model to model_ent103.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 2s 10ms/step - loss: 0.9418 - precision: 0.6103 - val_loss: 1.0006 - val_precision: 0.6318\n",
      "Epoch 4/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9227 - precision: 0.6157\n",
      "Epoch 4: val_loss did not improve from 1.00064\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9235 - precision: 0.6148 - val_loss: 1.0385 - val_precision: 0.6030\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9103 - precision: 0.6141\n",
      "Epoch 5: val_loss did not improve from 1.00064\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9103 - precision: 0.6141 - val_loss: 1.0309 - val_precision: 0.6156\n",
      "Epoch 6/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9054 - precision: 0.6178\n",
      "Epoch 6: val_loss did not improve from 1.00064\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9038 - precision: 0.6176 - val_loss: 1.0042 - val_precision: 0.6285\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8894 - precision: 0.6215\n",
      "Epoch 7: val_loss did not improve from 1.00064\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8912 - precision: 0.6216 - val_loss: 1.0200 - val_precision: 0.6220\n",
      "Epoch 8/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8789 - precision: 0.6271\n",
      "Epoch 8: val_loss did not improve from 1.00064\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8799 - precision: 0.6273 - val_loss: 1.0061 - val_precision: 0.6334\n",
      "Epoch 9/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8718 - precision: 0.6261\n",
      "Epoch 9: val_loss improved from 1.00064 to 0.99197, saving model to model_ent103.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8708 - precision: 0.6264 - val_loss: 0.9920 - val_precision: 0.6335\n",
      "Epoch 10/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8614 - precision: 0.6269\n",
      "Epoch 10: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8609 - precision: 0.6277 - val_loss: 0.9948 - val_precision: 0.6410\n",
      "Epoch 11/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8546 - precision: 0.6300\n",
      "Epoch 11: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8546 - precision: 0.6300 - val_loss: 1.0258 - val_precision: 0.6205\n",
      "Epoch 12/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8483 - precision: 0.6284\n",
      "Epoch 12: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8483 - precision: 0.6284 - val_loss: 1.0243 - val_precision: 0.6074\n",
      "Epoch 13/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8388 - precision: 0.6340\n",
      "Epoch 13: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8384 - precision: 0.6344 - val_loss: 0.9992 - val_precision: 0.6310\n",
      "Epoch 14/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8281 - precision: 0.6380\n",
      "Epoch 14: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8287 - precision: 0.6372 - val_loss: 1.0162 - val_precision: 0.6217\n",
      "Epoch 15/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8182 - precision: 0.6358\n",
      "Epoch 15: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8182 - precision: 0.6360 - val_loss: 1.0282 - val_precision: 0.6128\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8139 - precision: 0.6391\n",
      "Epoch 16: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8157 - precision: 0.6376 - val_loss: 1.0150 - val_precision: 0.6116\n",
      "Epoch 17/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8030 - precision: 0.6430\n",
      "Epoch 17: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8051 - precision: 0.6426 - val_loss: 1.0191 - val_precision: 0.6190\n",
      "Epoch 18/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.7965 - precision: 0.6445\n",
      "Epoch 18: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7965 - precision: 0.6445 - val_loss: 1.0097 - val_precision: 0.6302\n",
      "Epoch 19/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.7916 - precision: 0.6405\n",
      "Epoch 19: val_loss did not improve from 0.99197\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.7916 - precision: 0.6405 - val_loss: 1.0334 - val_precision: 0.6089\n",
      "Epoch 19: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9152 - precision: 0.6402\n",
      "Combinación 102 = (False, False, True, 128, 0.1) \n",
      " precision train: [0.915233314037323, 0.6401950716972351]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 104: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1680 - precision: 0.6106\n",
      "Epoch 1: val_loss improved from inf to 1.06092, saving model to model_ent104.h5\n",
      "236/236 [==============================] - 9s 12ms/step - loss: 1.1678 - precision: 0.6100 - val_loss: 1.0609 - val_precision: 0.6362\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9863 - precision: 0.6078\n",
      "Epoch 2: val_loss improved from 1.06092 to 1.04567, saving model to model_ent104.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9854 - precision: 0.6080 - val_loss: 1.0457 - val_precision: 0.6321\n",
      "Epoch 3/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9584 - precision: 0.6116\n",
      "Epoch 3: val_loss improved from 1.04567 to 1.03932, saving model to model_ent104.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9600 - precision: 0.6111 - val_loss: 1.0393 - val_precision: 0.6062\n",
      "Epoch 4/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9441 - precision: 0.6091\n",
      "Epoch 4: val_loss improved from 1.03932 to 0.99726, saving model to model_ent104.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9439 - precision: 0.6093 - val_loss: 0.9973 - val_precision: 0.6348\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9309 - precision: 0.6160\n",
      "Epoch 5: val_loss did not improve from 0.99726\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9309 - precision: 0.6160 - val_loss: 1.0374 - val_precision: 0.6129\n",
      "Epoch 6/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9181 - precision: 0.6139\n",
      "Epoch 6: val_loss improved from 0.99726 to 0.99345, saving model to model_ent104.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9192 - precision: 0.6127 - val_loss: 0.9935 - val_precision: 0.6310\n",
      "Epoch 7/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9054 - precision: 0.6160\n",
      "Epoch 7: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9046 - precision: 0.6160 - val_loss: 1.0141 - val_precision: 0.6233\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8988 - precision: 0.6259\n",
      "Epoch 8: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.8991 - precision: 0.6245 - val_loss: 1.0273 - val_precision: 0.6224\n",
      "Epoch 9/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8962 - precision: 0.6177\n",
      "Epoch 9: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8962 - precision: 0.6177 - val_loss: 1.0342 - val_precision: 0.6116\n",
      "Epoch 10/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8870 - precision: 0.6218\n",
      "Epoch 10: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.8870 - precision: 0.6218 - val_loss: 1.0190 - val_precision: 0.6108\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8806 - precision: 0.6190\n",
      "Epoch 11: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8806 - precision: 0.6184 - val_loss: 1.0259 - val_precision: 0.6255\n",
      "Epoch 12/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8703 - precision: 0.6239\n",
      "Epoch 12: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 2s 6ms/step - loss: 0.8703 - precision: 0.6235 - val_loss: 1.0393 - val_precision: 0.6051\n",
      "Epoch 13/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8634 - precision: 0.6283\n",
      "Epoch 13: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8650 - precision: 0.6284 - val_loss: 1.0029 - val_precision: 0.6364\n",
      "Epoch 14/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8567 - precision: 0.6273\n",
      "Epoch 14: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8571 - precision: 0.6271 - val_loss: 1.0120 - val_precision: 0.6170\n",
      "Epoch 15/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8564 - precision: 0.6225\n",
      "Epoch 15: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8521 - precision: 0.6256 - val_loss: 1.0160 - val_precision: 0.6200\n",
      "Epoch 16/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8452 - precision: 0.6292\n",
      "Epoch 16: val_loss did not improve from 0.99345\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8456 - precision: 0.6319 - val_loss: 1.0186 - val_precision: 0.6195\n",
      "Epoch 16: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9389 - precision: 0.6350\n",
      "Combinación 103 = (False, False, True, 128, 0.25) \n",
      " precision train: [0.938930869102478, 0.6349942088127136]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 105: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.2300 - precision: 0.6157\n",
      "Epoch 1: val_loss improved from inf to 1.06962, saving model to model_ent105.h5\n",
      "236/236 [==============================] - 8s 11ms/step - loss: 1.2272 - precision: 0.6142 - val_loss: 1.0696 - val_precision: 0.6334\n",
      "Epoch 2/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0269 - precision: 0.6100\n",
      "Epoch 2: val_loss improved from 1.06962 to 1.06908, saving model to model_ent105.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 1.0262 - precision: 0.6096 - val_loss: 1.0691 - val_precision: 0.6196\n",
      "Epoch 3/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9916 - precision: 0.6037\n",
      "Epoch 3: val_loss improved from 1.06908 to 1.04574, saving model to model_ent105.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9919 - precision: 0.6045 - val_loss: 1.0457 - val_precision: 0.6132\n",
      "Epoch 4/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9719 - precision: 0.6122\n",
      "Epoch 4: val_loss did not improve from 1.04574\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9748 - precision: 0.6100 - val_loss: 1.0665 - val_precision: 0.6028\n",
      "Epoch 5/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9636 - precision: 0.6133\n",
      "Epoch 5: val_loss improved from 1.04574 to 1.03479, saving model to model_ent105.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9643 - precision: 0.6137 - val_loss: 1.0348 - val_precision: 0.6135\n",
      "Epoch 6/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9506 - precision: 0.6130\n",
      "Epoch 6: val_loss improved from 1.03479 to 1.01791, saving model to model_ent105.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9505 - precision: 0.6136 - val_loss: 1.0179 - val_precision: 0.6148\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9423 - precision: 0.6140\n",
      "Epoch 7: val_loss did not improve from 1.01791\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9421 - precision: 0.6149 - val_loss: 1.0387 - val_precision: 0.6111\n",
      "Epoch 8/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9385 - precision: 0.6118\n",
      "Epoch 8: val_loss did not improve from 1.01791\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9397 - precision: 0.6114 - val_loss: 1.0183 - val_precision: 0.6221\n",
      "Epoch 9/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9271 - precision: 0.6232\n",
      "Epoch 9: val_loss did not improve from 1.01791\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9281 - precision: 0.6217 - val_loss: 1.0347 - val_precision: 0.6009\n",
      "Epoch 10/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9220 - precision: 0.6126\n",
      "Epoch 10: val_loss improved from 1.01791 to 0.99339, saving model to model_ent105.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9249 - precision: 0.6120 - val_loss: 0.9934 - val_precision: 0.6293\n",
      "Epoch 11/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9153 - precision: 0.6205\n",
      "Epoch 11: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9173 - precision: 0.6199 - val_loss: 1.0159 - val_precision: 0.6239\n",
      "Epoch 12/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9064 - precision: 0.6222\n",
      "Epoch 12: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9075 - precision: 0.6202 - val_loss: 1.0433 - val_precision: 0.6052\n",
      "Epoch 13/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9084 - precision: 0.6166\n",
      "Epoch 13: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9076 - precision: 0.6173 - val_loss: 1.0139 - val_precision: 0.6181\n",
      "Epoch 14/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9050 - precision: 0.6195\n",
      "Epoch 14: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9073 - precision: 0.6193 - val_loss: 1.0229 - val_precision: 0.6174\n",
      "Epoch 15/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8900 - precision: 0.6198\n",
      "Epoch 15: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8928 - precision: 0.6177 - val_loss: 1.0240 - val_precision: 0.6194\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9030 - precision: 0.6166\n",
      "Epoch 16: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9001 - precision: 0.6173 - val_loss: 1.0167 - val_precision: 0.6238\n",
      "Epoch 17/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8861 - precision: 0.6225\n",
      "Epoch 17: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8869 - precision: 0.6218 - val_loss: 1.0043 - val_precision: 0.6230\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8845 - precision: 0.6291\n",
      "Epoch 18: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8833 - precision: 0.6293 - val_loss: 1.0207 - val_precision: 0.6126\n",
      "Epoch 19/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8810 - precision: 0.6257\n",
      "Epoch 19: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8786 - precision: 0.6274 - val_loss: 1.0055 - val_precision: 0.6279\n",
      "Epoch 20/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8820 - precision: 0.6262\n",
      "Epoch 20: val_loss did not improve from 0.99339\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.8817 - precision: 0.6262 - val_loss: 1.0190 - val_precision: 0.6167\n",
      "Epoch 20: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9497 - precision: 0.6297\n",
      "Combinación 104 = (False, False, True, 128, 0.5) \n",
      " precision train: [0.9496785998344421, 0.6296820640563965]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 106: \n",
      "\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.4869 - precision: 0.7273  \n",
      "Epoch 1: val_loss improved from inf to 1.30264, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.4769 - precision: 0.7476 - val_loss: 1.3026 - val_precision: 0.8036\n",
      "Epoch 2/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.1760 - precision: 0.6554\n",
      "Epoch 2: val_loss improved from 1.30264 to 1.14782, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1727 - precision: 0.6550 - val_loss: 1.1478 - val_precision: 0.6571\n",
      "Epoch 3/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0705 - precision: 0.6161\n",
      "Epoch 3: val_loss improved from 1.14782 to 1.09651, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0687 - precision: 0.6151 - val_loss: 1.0965 - val_precision: 0.6475\n",
      "Epoch 4/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0352 - precision: 0.6040\n",
      "Epoch 4: val_loss improved from 1.09651 to 1.07712, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0356 - precision: 0.6039 - val_loss: 1.0771 - val_precision: 0.6331\n",
      "Epoch 5/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0239 - precision: 0.6054\n",
      "Epoch 5: val_loss improved from 1.07712 to 1.07482, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0181 - precision: 0.6071 - val_loss: 1.0748 - val_precision: 0.6276\n",
      "Epoch 6/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0055 - precision: 0.6093\n",
      "Epoch 6: val_loss improved from 1.07482 to 1.04857, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0029 - precision: 0.6118 - val_loss: 1.0486 - val_precision: 0.6386\n",
      "Epoch 7/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.0006 - precision: 0.6139\n",
      "Epoch 7: val_loss did not improve from 1.04857\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0006 - precision: 0.6139 - val_loss: 1.0493 - val_precision: 0.6304\n",
      "Epoch 8/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9892 - precision: 0.6101\n",
      "Epoch 8: val_loss improved from 1.04857 to 1.03870, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9928 - precision: 0.6099 - val_loss: 1.0387 - val_precision: 0.6376\n",
      "Epoch 9/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9744 - precision: 0.6135\n",
      "Epoch 9: val_loss did not improve from 1.03870\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9765 - precision: 0.6131 - val_loss: 1.0427 - val_precision: 0.6276\n",
      "Epoch 10/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9787 - precision: 0.6164\n",
      "Epoch 10: val_loss improved from 1.03870 to 1.03396, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9742 - precision: 0.6184 - val_loss: 1.0340 - val_precision: 0.6382\n",
      "Epoch 11/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9694 - precision: 0.6211\n",
      "Epoch 11: val_loss improved from 1.03396 to 1.03355, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9697 - precision: 0.6226 - val_loss: 1.0336 - val_precision: 0.6373\n",
      "Epoch 12/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9678 - precision: 0.6206\n",
      "Epoch 12: val_loss did not improve from 1.03355\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9688 - precision: 0.6176 - val_loss: 1.0378 - val_precision: 0.6366\n",
      "Epoch 13/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9609 - precision: 0.6162\n",
      "Epoch 13: val_loss did not improve from 1.03355\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9639 - precision: 0.6160 - val_loss: 1.0361 - val_precision: 0.6324\n",
      "Epoch 14/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9627 - precision: 0.6171\n",
      "Epoch 14: val_loss improved from 1.03355 to 1.02266, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9611 - precision: 0.6168 - val_loss: 1.0227 - val_precision: 0.6396\n",
      "Epoch 15/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9617 - precision: 0.6252\n",
      "Epoch 15: val_loss did not improve from 1.02266\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9626 - precision: 0.6244 - val_loss: 1.0394 - val_precision: 0.6301\n",
      "Epoch 16/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9599 - precision: 0.6152\n",
      "Epoch 16: val_loss did not improve from 1.02266\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9605 - precision: 0.6145 - val_loss: 1.0413 - val_precision: 0.6299\n",
      "Epoch 17/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9496 - precision: 0.6216\n",
      "Epoch 17: val_loss did not improve from 1.02266\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9540 - precision: 0.6219 - val_loss: 1.0272 - val_precision: 0.6399\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9452 - precision: 0.6238\n",
      "Epoch 18: val_loss did not improve from 1.02266\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9439 - precision: 0.6240 - val_loss: 1.0272 - val_precision: 0.6366\n",
      "Epoch 19/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9514 - precision: 0.6229\n",
      "Epoch 19: val_loss did not improve from 1.02266\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9487 - precision: 0.6217 - val_loss: 1.0286 - val_precision: 0.6358\n",
      "Epoch 20/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9429 - precision: 0.6238\n",
      "Epoch 20: val_loss improved from 1.02266 to 1.02169, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9447 - precision: 0.6239 - val_loss: 1.0217 - val_precision: 0.6393\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9412 - precision: 0.6238\n",
      "Epoch 21: val_loss improved from 1.02169 to 1.01663, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9414 - precision: 0.6237 - val_loss: 1.0166 - val_precision: 0.6454\n",
      "Epoch 22/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9369 - precision: 0.6268\n",
      "Epoch 22: val_loss did not improve from 1.01663\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9381 - precision: 0.6256 - val_loss: 1.0196 - val_precision: 0.6345\n",
      "Epoch 23/70\n",
      "214/236 [==========================>...] - ETA: 0s - loss: 0.9398 - precision: 0.6234\n",
      "Epoch 23: val_loss improved from 1.01663 to 1.00891, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9388 - precision: 0.6239 - val_loss: 1.0089 - val_precision: 0.6465\n",
      "Epoch 24/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 0.9361 - precision: 0.6281\n",
      "Epoch 24: val_loss did not improve from 1.00891\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9308 - precision: 0.6303 - val_loss: 1.0170 - val_precision: 0.6377\n",
      "Epoch 25/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9265 - precision: 0.6305\n",
      "Epoch 25: val_loss did not improve from 1.00891\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9260 - precision: 0.6296 - val_loss: 1.0229 - val_precision: 0.6353\n",
      "Epoch 26/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9316 - precision: 0.6216\n",
      "Epoch 26: val_loss did not improve from 1.00891\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9304 - precision: 0.6248 - val_loss: 1.0122 - val_precision: 0.6420\n",
      "Epoch 27/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 0.9176 - precision: 0.6316\n",
      "Epoch 27: val_loss did not improve from 1.00891\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9200 - precision: 0.6296 - val_loss: 1.0128 - val_precision: 0.6368\n",
      "Epoch 28/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9278 - precision: 0.6204\n",
      "Epoch 28: val_loss did not improve from 1.00891\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9288 - precision: 0.6223 - val_loss: 1.0191 - val_precision: 0.6342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9249 - precision: 0.6305\n",
      "Epoch 29: val_loss did not improve from 1.00891\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9249 - precision: 0.6305 - val_loss: 1.0135 - val_precision: 0.6442\n",
      "Epoch 30/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.9233 - precision: 0.6286\n",
      "Epoch 30: val_loss improved from 1.00891 to 1.00859, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9204 - precision: 0.6303 - val_loss: 1.0086 - val_precision: 0.6418\n",
      "Epoch 31/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9112 - precision: 0.6306\n",
      "Epoch 31: val_loss did not improve from 1.00859\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9137 - precision: 0.6307 - val_loss: 1.0094 - val_precision: 0.6391\n",
      "Epoch 32/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 0.9108 - precision: 0.6322\n",
      "Epoch 32: val_loss did not improve from 1.00859\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9159 - precision: 0.6289 - val_loss: 1.0220 - val_precision: 0.6289\n",
      "Epoch 33/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9097 - precision: 0.6304\n",
      "Epoch 33: val_loss improved from 1.00859 to 1.00816, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9091 - precision: 0.6305 - val_loss: 1.0082 - val_precision: 0.6369\n",
      "Epoch 34/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.9058 - precision: 0.6335\n",
      "Epoch 34: val_loss did not improve from 1.00816\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9074 - precision: 0.6317 - val_loss: 1.0099 - val_precision: 0.6337\n",
      "Epoch 35/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9050 - precision: 0.6324\n",
      "Epoch 35: val_loss did not improve from 1.00816\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9062 - precision: 0.6323 - val_loss: 1.0112 - val_precision: 0.6364\n",
      "Epoch 36/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9065 - precision: 0.6325\n",
      "Epoch 36: val_loss improved from 1.00816 to 1.00673, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9064 - precision: 0.6329 - val_loss: 1.0067 - val_precision: 0.6377\n",
      "Epoch 37/70\n",
      "213/236 [==========================>...] - ETA: 0s - loss: 0.8977 - precision: 0.6380\n",
      "Epoch 37: val_loss did not improve from 1.00673\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9001 - precision: 0.6358 - val_loss: 1.0139 - val_precision: 0.6333\n",
      "Epoch 38/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8992 - precision: 0.6354\n",
      "Epoch 38: val_loss did not improve from 1.00673\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8992 - precision: 0.6354 - val_loss: 1.0089 - val_precision: 0.6361\n",
      "Epoch 39/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8978 - precision: 0.6380\n",
      "Epoch 39: val_loss did not improve from 1.00673\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8973 - precision: 0.6394 - val_loss: 1.0181 - val_precision: 0.6352\n",
      "Epoch 40/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8923 - precision: 0.6312\n",
      "Epoch 40: val_loss improved from 1.00673 to 1.00062, saving model to model_ent106.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8923 - precision: 0.6312 - val_loss: 1.0006 - val_precision: 0.6475\n",
      "Epoch 41/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.8930 - precision: 0.6384\n",
      "Epoch 41: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.8898 - precision: 0.6394 - val_loss: 1.0067 - val_precision: 0.6349\n",
      "Epoch 42/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.9039 - precision: 0.6342\n",
      "Epoch 42: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8942 - precision: 0.6386 - val_loss: 1.0087 - val_precision: 0.6354\n",
      "Epoch 43/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8971 - precision: 0.6352\n",
      "Epoch 43: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8969 - precision: 0.6353 - val_loss: 1.0091 - val_precision: 0.6369\n",
      "Epoch 44/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8900 - precision: 0.6345\n",
      "Epoch 44: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.8898 - precision: 0.6342 - val_loss: 1.0152 - val_precision: 0.6300\n",
      "Epoch 45/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.8828 - precision: 0.6380\n",
      "Epoch 45: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.8875 - precision: 0.6340 - val_loss: 1.0100 - val_precision: 0.6379\n",
      "Epoch 46/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 0.8864 - precision: 0.6400\n",
      "Epoch 46: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.8859 - precision: 0.6403 - val_loss: 1.0066 - val_precision: 0.6396\n",
      "Epoch 47/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8875 - precision: 0.6303\n",
      "Epoch 47: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.8867 - precision: 0.6309 - val_loss: 1.0017 - val_precision: 0.6380\n",
      "Epoch 48/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.8745 - precision: 0.6426\n",
      "Epoch 48: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.8776 - precision: 0.6418 - val_loss: 1.0099 - val_precision: 0.6341\n",
      "Epoch 49/70\n",
      "214/236 [==========================>...] - ETA: 0s - loss: 0.8810 - precision: 0.6386\n",
      "Epoch 49: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.8809 - precision: 0.6378 - val_loss: 1.0107 - val_precision: 0.6337\n",
      "Epoch 50/70\n",
      "214/236 [==========================>...] - ETA: 0s - loss: 0.8748 - precision: 0.6399\n",
      "Epoch 50: val_loss did not improve from 1.00062\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.8756 - precision: 0.6376 - val_loss: 1.0029 - val_precision: 0.6355\n",
      "Epoch 50: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9382 - precision: 0.6492\n",
      "Combinación 105 = (False, False, False, 8, 0.1) \n",
      " precision train: [0.9382172226905823, 0.6491798758506775]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 107: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "213/236 [==========================>...] - ETA: 0s - loss: 1.4908 - precision: 0.6335 \n",
      "Epoch 1: val_loss improved from inf to 1.30496, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 4s 6ms/step - loss: 1.4682 - precision: 0.6455 - val_loss: 1.3050 - val_precision: 0.6584\n",
      "Epoch 2/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.2573 - precision: 0.6294\n",
      "Epoch 2: val_loss improved from 1.30496 to 1.20328, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2541 - precision: 0.6286 - val_loss: 1.2033 - val_precision: 0.6688\n",
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1821 - precision: 0.6232\n",
      "Epoch 3: val_loss improved from 1.20328 to 1.16081, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1847 - precision: 0.6183 - val_loss: 1.1608 - val_precision: 0.6720\n",
      "Epoch 4/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.1307 - precision: 0.6327\n",
      "Epoch 4: val_loss improved from 1.16081 to 1.15757, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1358 - precision: 0.6284 - val_loss: 1.1576 - val_precision: 0.6393\n",
      "Epoch 5/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1268 - precision: 0.6302\n",
      "Epoch 5: val_loss improved from 1.15757 to 1.13010, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1237 - precision: 0.6312 - val_loss: 1.1301 - val_precision: 0.6502\n",
      "Epoch 6/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1079 - precision: 0.6246\n",
      "Epoch 6: val_loss improved from 1.13010 to 1.10845, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1066 - precision: 0.6250 - val_loss: 1.1084 - val_precision: 0.6575\n",
      "Epoch 7/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0914 - precision: 0.6280\n",
      "Epoch 7: val_loss improved from 1.10845 to 1.09078, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0901 - precision: 0.6283 - val_loss: 1.0908 - val_precision: 0.6546\n",
      "Epoch 8/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0703 - precision: 0.6273\n",
      "Epoch 8: val_loss improved from 1.09078 to 1.08727, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0700 - precision: 0.6268 - val_loss: 1.0873 - val_precision: 0.6378\n",
      "Epoch 9/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0559 - precision: 0.6231\n",
      "Epoch 9: val_loss improved from 1.08727 to 1.08354, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0568 - precision: 0.6204 - val_loss: 1.0835 - val_precision: 0.6286\n",
      "Epoch 10/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0516 - precision: 0.6116\n",
      "Epoch 10: val_loss improved from 1.08354 to 1.05812, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0486 - precision: 0.6125 - val_loss: 1.0581 - val_precision: 0.6331\n",
      "Epoch 11/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0494 - precision: 0.6194\n",
      "Epoch 11: val_loss improved from 1.05812 to 1.05535, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0513 - precision: 0.6189 - val_loss: 1.0554 - val_precision: 0.6331\n",
      "Epoch 12/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0410 - precision: 0.6144\n",
      "Epoch 12: val_loss improved from 1.05535 to 1.05110, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0406 - precision: 0.6123 - val_loss: 1.0511 - val_precision: 0.6308\n",
      "Epoch 13/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0431 - precision: 0.6090\n",
      "Epoch 13: val_loss improved from 1.05110 to 1.05039, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0428 - precision: 0.6089 - val_loss: 1.0504 - val_precision: 0.6320\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0369 - precision: 0.6099\n",
      "Epoch 14: val_loss improved from 1.05039 to 1.04928, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0371 - precision: 0.6109 - val_loss: 1.0493 - val_precision: 0.6311\n",
      "Epoch 15/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0396 - precision: 0.6058\n",
      "Epoch 15: val_loss improved from 1.04928 to 1.04744, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0409 - precision: 0.6056 - val_loss: 1.0474 - val_precision: 0.6297\n",
      "Epoch 16/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.0333 - precision: 0.6133\n",
      "Epoch 16: val_loss did not improve from 1.04744\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0299 - precision: 0.6138 - val_loss: 1.0572 - val_precision: 0.6189\n",
      "Epoch 17/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0291 - precision: 0.6060\n",
      "Epoch 17: val_loss improved from 1.04744 to 1.04694, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0277 - precision: 0.6059 - val_loss: 1.0469 - val_precision: 0.6270\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0280 - precision: 0.6109\n",
      "Epoch 18: val_loss improved from 1.04694 to 1.04370, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0284 - precision: 0.6100 - val_loss: 1.0437 - val_precision: 0.6278\n",
      "Epoch 19/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0245 - precision: 0.6127\n",
      "Epoch 19: val_loss did not improve from 1.04370\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0264 - precision: 0.6119 - val_loss: 1.0496 - val_precision: 0.6247\n",
      "Epoch 20/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0095 - precision: 0.6148\n",
      "Epoch 20: val_loss did not improve from 1.04370\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0090 - precision: 0.6156 - val_loss: 1.0452 - val_precision: 0.6312\n",
      "Epoch 21/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.0122 - precision: 0.6178\n",
      "Epoch 21: val_loss did not improve from 1.04370\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0158 - precision: 0.6171 - val_loss: 1.0469 - val_precision: 0.6257\n",
      "Epoch 22/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0057 - precision: 0.6208\n",
      "Epoch 22: val_loss improved from 1.04370 to 1.04077, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0063 - precision: 0.6202 - val_loss: 1.0408 - val_precision: 0.6280\n",
      "Epoch 23/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0037 - precision: 0.6186\n",
      "Epoch 23: val_loss did not improve from 1.04077\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0038 - precision: 0.6179 - val_loss: 1.0413 - val_precision: 0.6392\n",
      "Epoch 24/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9946 - precision: 0.6188\n",
      "Epoch 24: val_loss did not improve from 1.04077\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9946 - precision: 0.6181 - val_loss: 1.0432 - val_precision: 0.6268\n",
      "Epoch 25/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0026 - precision: 0.6196\n",
      "Epoch 25: val_loss did not improve from 1.04077\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0035 - precision: 0.6190 - val_loss: 1.0440 - val_precision: 0.6236\n",
      "Epoch 26/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9949 - precision: 0.6186\n",
      "Epoch 26: val_loss did not improve from 1.04077\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9934 - precision: 0.6211 - val_loss: 1.0526 - val_precision: 0.6204\n",
      "Epoch 27/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9965 - precision: 0.6185\n",
      "Epoch 27: val_loss did not improve from 1.04077\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9942 - precision: 0.6199 - val_loss: 1.0414 - val_precision: 0.6296\n",
      "Epoch 28/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9945 - precision: 0.6227\n",
      "Epoch 28: val_loss improved from 1.04077 to 1.04011, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9964 - precision: 0.6213 - val_loss: 1.0401 - val_precision: 0.6316\n",
      "Epoch 29/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9962 - precision: 0.6236\n",
      "Epoch 29: val_loss improved from 1.04011 to 1.03819, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9994 - precision: 0.6228 - val_loss: 1.0382 - val_precision: 0.6286\n",
      "Epoch 30/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9910 - precision: 0.6270\n",
      "Epoch 30: val_loss did not improve from 1.03819\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9887 - precision: 0.6286 - val_loss: 1.0409 - val_precision: 0.6279\n",
      "Epoch 31/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0010 - precision: 0.6137\n",
      "Epoch 31: val_loss did not improve from 1.03819\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0022 - precision: 0.6125 - val_loss: 1.0413 - val_precision: 0.6263\n",
      "Epoch 32/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9937 - precision: 0.6231\n",
      "Epoch 32: val_loss did not improve from 1.03819\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9962 - precision: 0.6215 - val_loss: 1.0425 - val_precision: 0.6266\n",
      "Epoch 33/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9875 - precision: 0.6226\n",
      "Epoch 33: val_loss did not improve from 1.03819\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9847 - precision: 0.6228 - val_loss: 1.0476 - val_precision: 0.6247\n",
      "Epoch 34/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9864 - precision: 0.6213\n",
      "Epoch 34: val_loss did not improve from 1.03819\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9891 - precision: 0.6176 - val_loss: 1.0423 - val_precision: 0.6269\n",
      "Epoch 35/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9864 - precision: 0.6145\n",
      "Epoch 35: val_loss improved from 1.03819 to 1.03168, saving model to model_ent107.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9890 - precision: 0.6144 - val_loss: 1.0317 - val_precision: 0.6345\n",
      "Epoch 36/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9821 - precision: 0.6201\n",
      "Epoch 36: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9827 - precision: 0.6205 - val_loss: 1.0362 - val_precision: 0.6301\n",
      "Epoch 37/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9871 - precision: 0.6170\n",
      "Epoch 37: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9869 - precision: 0.6175 - val_loss: 1.0356 - val_precision: 0.6298\n",
      "Epoch 38/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9866 - precision: 0.6152\n",
      "Epoch 38: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9837 - precision: 0.6174 - val_loss: 1.0375 - val_precision: 0.6237\n",
      "Epoch 39/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9822 - precision: 0.6163\n",
      "Epoch 39: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9868 - precision: 0.6126 - val_loss: 1.0372 - val_precision: 0.6322\n",
      "Epoch 40/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9761 - precision: 0.6247\n",
      "Epoch 40: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9770 - precision: 0.6228 - val_loss: 1.0351 - val_precision: 0.6280\n",
      "Epoch 41/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9802 - precision: 0.6283\n",
      "Epoch 41: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9816 - precision: 0.6270 - val_loss: 1.0407 - val_precision: 0.6233\n",
      "Epoch 42/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9755 - precision: 0.6267\n",
      "Epoch 42: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9767 - precision: 0.6244 - val_loss: 1.0407 - val_precision: 0.6307\n",
      "Epoch 43/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9824 - precision: 0.6193\n",
      "Epoch 43: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9812 - precision: 0.6210 - val_loss: 1.0371 - val_precision: 0.6268\n",
      "Epoch 44/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.9694 - precision: 0.6314\n",
      "Epoch 44: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9725 - precision: 0.6260 - val_loss: 1.0391 - val_precision: 0.6326\n",
      "Epoch 45/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9694 - precision: 0.6275\n",
      "Epoch 45: val_loss did not improve from 1.03168\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.9663 - precision: 0.6298 - val_loss: 1.0347 - val_precision: 0.6323\n",
      "Epoch 45: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9905 - precision: 0.6368\n",
      "Combinación 106 = (False, False, False, 8, 0.25) \n",
      " precision train: [0.9904681444168091, 0.6368180513381958]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 108: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.5252 - precision: 0.6500 \n",
      "Epoch 1: val_loss improved from inf to 1.37115, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 4s 6ms/step - loss: 1.5227 - precision: 0.6831 - val_loss: 1.3711 - val_precision: 1.0000\n",
      "Epoch 2/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.3666 - precision: 0.6786\n",
      "Epoch 2: val_loss improved from 1.37115 to 1.26540, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3667 - precision: 0.6791 - val_loss: 1.2654 - val_precision: 0.7064\n",
      "Epoch 3/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.3150 - precision: 0.6652\n",
      "Epoch 3: val_loss improved from 1.26540 to 1.20748, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3131 - precision: 0.6675 - val_loss: 1.2075 - val_precision: 0.6868\n",
      "Epoch 4/70\n",
      "214/236 [==========================>...] - ETA: 0s - loss: 1.2888 - precision: 0.6603\n",
      "Epoch 4: val_loss improved from 1.20748 to 1.18086, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2857 - precision: 0.6697 - val_loss: 1.1809 - val_precision: 0.6873\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2657 - precision: 0.6306\n",
      "Epoch 5: val_loss improved from 1.18086 to 1.15740, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2657 - precision: 0.6306 - val_loss: 1.1574 - val_precision: 0.6803\n",
      "Epoch 6/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.2402 - precision: 0.6358\n",
      "Epoch 6: val_loss improved from 1.15740 to 1.12944, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.2439 - precision: 0.6300 - val_loss: 1.1294 - val_precision: 0.6747\n",
      "Epoch 7/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2119 - precision: 0.6414\n",
      "Epoch 7: val_loss improved from 1.12944 to 1.11806, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.2129 - precision: 0.6382 - val_loss: 1.1181 - val_precision: 0.6702\n",
      "Epoch 8/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.2153 - precision: 0.6097\n",
      "Epoch 8: val_loss improved from 1.11806 to 1.10702, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.2148 - precision: 0.6101 - val_loss: 1.1070 - val_precision: 0.6707\n",
      "Epoch 9/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2029 - precision: 0.6174\n",
      "Epoch 9: val_loss improved from 1.10702 to 1.09682, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2011 - precision: 0.6191 - val_loss: 1.0968 - val_precision: 0.6608\n",
      "Epoch 10/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2005 - precision: 0.6086\n",
      "Epoch 10: val_loss improved from 1.09682 to 1.08941, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1998 - precision: 0.6092 - val_loss: 1.0894 - val_precision: 0.6635\n",
      "Epoch 11/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1888 - precision: 0.6110\n",
      "Epoch 11: val_loss did not improve from 1.08941\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1884 - precision: 0.6109 - val_loss: 1.0944 - val_precision: 0.6641\n",
      "Epoch 12/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.1849 - precision: 0.5951\n",
      "Epoch 12: val_loss improved from 1.08941 to 1.08608, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1814 - precision: 0.5995 - val_loss: 1.0861 - val_precision: 0.6573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1872 - precision: 0.6094\n",
      "Epoch 13: val_loss improved from 1.08608 to 1.08505, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1852 - precision: 0.6115 - val_loss: 1.0851 - val_precision: 0.6561\n",
      "Epoch 14/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.1872 - precision: 0.6114\n",
      "Epoch 14: val_loss improved from 1.08505 to 1.08130, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1850 - precision: 0.6099 - val_loss: 1.0813 - val_precision: 0.6553\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1955 - precision: 0.5916\n",
      "Epoch 15: val_loss did not improve from 1.08130\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1975 - precision: 0.5909 - val_loss: 1.0822 - val_precision: 0.6560\n",
      "Epoch 16/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1787 - precision: 0.6222\n",
      "Epoch 16: val_loss improved from 1.08130 to 1.08098, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1814 - precision: 0.6207 - val_loss: 1.0810 - val_precision: 0.6503\n",
      "Epoch 17/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1800 - precision: 0.6153\n",
      "Epoch 17: val_loss improved from 1.08098 to 1.07640, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1791 - precision: 0.6150 - val_loss: 1.0764 - val_precision: 0.6588\n",
      "Epoch 18/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1679 - precision: 0.6146\n",
      "Epoch 18: val_loss improved from 1.07640 to 1.07051, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1675 - precision: 0.6144 - val_loss: 1.0705 - val_precision: 0.6588\n",
      "Epoch 19/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1630 - precision: 0.6096\n",
      "Epoch 19: val_loss improved from 1.07051 to 1.06984, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1626 - precision: 0.6101 - val_loss: 1.0698 - val_precision: 0.6538\n",
      "Epoch 20/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1797 - precision: 0.6079\n",
      "Epoch 20: val_loss improved from 1.06984 to 1.06934, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1773 - precision: 0.6088 - val_loss: 1.0693 - val_precision: 0.6562\n",
      "Epoch 21/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1506 - precision: 0.6167\n",
      "Epoch 21: val_loss improved from 1.06934 to 1.06634, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1511 - precision: 0.6131 - val_loss: 1.0663 - val_precision: 0.6512\n",
      "Epoch 22/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.1850 - precision: 0.5957\n",
      "Epoch 22: val_loss did not improve from 1.06634\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1783 - precision: 0.5961 - val_loss: 1.0690 - val_precision: 0.6551\n",
      "Epoch 23/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1620 - precision: 0.6051\n",
      "Epoch 23: val_loss improved from 1.06634 to 1.06597, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1608 - precision: 0.6052 - val_loss: 1.0660 - val_precision: 0.6545\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1584 - precision: 0.6163\n",
      "Epoch 24: val_loss did not improve from 1.06597\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1584 - precision: 0.6166 - val_loss: 1.0715 - val_precision: 0.6501\n",
      "Epoch 25/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1726 - precision: 0.6129\n",
      "Epoch 25: val_loss did not improve from 1.06597\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1701 - precision: 0.6135 - val_loss: 1.0731 - val_precision: 0.6443\n",
      "Epoch 26/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1455 - precision: 0.6188\n",
      "Epoch 26: val_loss improved from 1.06597 to 1.06330, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1449 - precision: 0.6186 - val_loss: 1.0633 - val_precision: 0.6504\n",
      "Epoch 27/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1494 - precision: 0.6118\n",
      "Epoch 27: val_loss did not improve from 1.06330\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1508 - precision: 0.6140 - val_loss: 1.0654 - val_precision: 0.6506\n",
      "Epoch 28/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1578 - precision: 0.6189\n",
      "Epoch 28: val_loss did not improve from 1.06330\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1561 - precision: 0.6204 - val_loss: 1.0705 - val_precision: 0.6420\n",
      "Epoch 29/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1649 - precision: 0.6062\n",
      "Epoch 29: val_loss did not improve from 1.06330\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1627 - precision: 0.6066 - val_loss: 1.0694 - val_precision: 0.6554\n",
      "Epoch 30/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1481 - precision: 0.6166\n",
      "Epoch 30: val_loss did not improve from 1.06330\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1489 - precision: 0.6169 - val_loss: 1.0639 - val_precision: 0.6504\n",
      "Epoch 31/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1534 - precision: 0.6136\n",
      "Epoch 31: val_loss did not improve from 1.06330\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1524 - precision: 0.6149 - val_loss: 1.0642 - val_precision: 0.6538\n",
      "Epoch 32/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1450 - precision: 0.6132\n",
      "Epoch 32: val_loss improved from 1.06330 to 1.06246, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1456 - precision: 0.6126 - val_loss: 1.0625 - val_precision: 0.6515\n",
      "Epoch 33/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.1502 - precision: 0.6129\n",
      "Epoch 33: val_loss improved from 1.06246 to 1.06242, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1485 - precision: 0.6161 - val_loss: 1.0624 - val_precision: 0.6537\n",
      "Epoch 34/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1406 - precision: 0.6208\n",
      "Epoch 34: val_loss did not improve from 1.06242\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1411 - precision: 0.6195 - val_loss: 1.0656 - val_precision: 0.6500\n",
      "Epoch 35/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1539 - precision: 0.6123\n",
      "Epoch 35: val_loss improved from 1.06242 to 1.06161, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1565 - precision: 0.6138 - val_loss: 1.0616 - val_precision: 0.6560\n",
      "Epoch 36/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1294 - precision: 0.6160\n",
      "Epoch 36: val_loss did not improve from 1.06161\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1340 - precision: 0.6141 - val_loss: 1.0643 - val_precision: 0.6411\n",
      "Epoch 37/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1358 - precision: 0.6256\n",
      "Epoch 37: val_loss did not improve from 1.06161\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1393 - precision: 0.6221 - val_loss: 1.0644 - val_precision: 0.6362\n",
      "Epoch 38/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.1332 - precision: 0.6142\n",
      "Epoch 38: val_loss improved from 1.06161 to 1.05886, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1315 - precision: 0.6153 - val_loss: 1.0589 - val_precision: 0.6508\n",
      "Epoch 39/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1397 - precision: 0.6148\n",
      "Epoch 39: val_loss did not improve from 1.05886\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1405 - precision: 0.6146 - val_loss: 1.0600 - val_precision: 0.6379\n",
      "Epoch 40/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1384 - precision: 0.6125\n",
      "Epoch 40: val_loss did not improve from 1.05886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1373 - precision: 0.6139 - val_loss: 1.0648 - val_precision: 0.6371\n",
      "Epoch 41/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1399 - precision: 0.6059\n",
      "Epoch 41: val_loss did not improve from 1.05886\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1398 - precision: 0.6074 - val_loss: 1.0647 - val_precision: 0.6477\n",
      "Epoch 42/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1489 - precision: 0.6160\n",
      "Epoch 42: val_loss did not improve from 1.05886\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1484 - precision: 0.6158 - val_loss: 1.0666 - val_precision: 0.6473\n",
      "Epoch 43/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1342 - precision: 0.6216\n",
      "Epoch 43: val_loss did not improve from 1.05886\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1362 - precision: 0.6220 - val_loss: 1.0605 - val_precision: 0.6469\n",
      "Epoch 44/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1364 - precision: 0.6241\n",
      "Epoch 44: val_loss improved from 1.05886 to 1.05822, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1383 - precision: 0.6225 - val_loss: 1.0582 - val_precision: 0.6562\n",
      "Epoch 45/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1368 - precision: 0.6117\n",
      "Epoch 45: val_loss did not improve from 1.05822\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1348 - precision: 0.6113 - val_loss: 1.0619 - val_precision: 0.6531\n",
      "Epoch 46/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.1283 - precision: 0.6233\n",
      "Epoch 46: val_loss did not improve from 1.05822\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1249 - precision: 0.6218 - val_loss: 1.0597 - val_precision: 0.6362\n",
      "Epoch 47/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1318 - precision: 0.6185\n",
      "Epoch 47: val_loss did not improve from 1.05822\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1318 - precision: 0.6185 - val_loss: 1.0697 - val_precision: 0.6353\n",
      "Epoch 48/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.1354 - precision: 0.6183\n",
      "Epoch 48: val_loss did not improve from 1.05822\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1350 - precision: 0.6193 - val_loss: 1.0601 - val_precision: 0.6417\n",
      "Epoch 49/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1341 - precision: 0.6183\n",
      "Epoch 49: val_loss improved from 1.05822 to 1.05707, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1356 - precision: 0.6172 - val_loss: 1.0571 - val_precision: 0.6458\n",
      "Epoch 50/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1234 - precision: 0.6224\n",
      "Epoch 50: val_loss improved from 1.05707 to 1.05420, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1242 - precision: 0.6216 - val_loss: 1.0542 - val_precision: 0.6434\n",
      "Epoch 51/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1311 - precision: 0.6231\n",
      "Epoch 51: val_loss improved from 1.05420 to 1.05355, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1328 - precision: 0.6212 - val_loss: 1.0536 - val_precision: 0.6474\n",
      "Epoch 52/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1399 - precision: 0.6212\n",
      "Epoch 52: val_loss improved from 1.05355 to 1.05202, saving model to model_ent108.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1440 - precision: 0.6201 - val_loss: 1.0520 - val_precision: 0.6595\n",
      "Epoch 53/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1159 - precision: 0.6229\n",
      "Epoch 53: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1165 - precision: 0.6226 - val_loss: 1.0531 - val_precision: 0.6493\n",
      "Epoch 54/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1400 - precision: 0.6142\n",
      "Epoch 54: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1418 - precision: 0.6154 - val_loss: 1.0625 - val_precision: 0.6362\n",
      "Epoch 55/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1255 - precision: 0.6226\n",
      "Epoch 55: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1255 - precision: 0.6226 - val_loss: 1.0579 - val_precision: 0.6411\n",
      "Epoch 56/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1201 - precision: 0.6255\n",
      "Epoch 56: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1168 - precision: 0.6255 - val_loss: 1.0593 - val_precision: 0.6393\n",
      "Epoch 57/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1202 - precision: 0.6195\n",
      "Epoch 57: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1180 - precision: 0.6203 - val_loss: 1.0638 - val_precision: 0.6442\n",
      "Epoch 58/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.1254 - precision: 0.6232\n",
      "Epoch 58: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1238 - precision: 0.6211 - val_loss: 1.0592 - val_precision: 0.6402\n",
      "Epoch 59/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1156 - precision: 0.6158\n",
      "Epoch 59: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1154 - precision: 0.6153 - val_loss: 1.0606 - val_precision: 0.6417\n",
      "Epoch 60/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1252 - precision: 0.6251\n",
      "Epoch 60: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 1.1259 - precision: 0.6266 - val_loss: 1.0521 - val_precision: 0.6488\n",
      "Epoch 61/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.1141 - precision: 0.6227\n",
      "Epoch 61: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 1.1125 - precision: 0.6217 - val_loss: 1.0537 - val_precision: 0.6489\n",
      "Epoch 62/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1266 - precision: 0.6155\n",
      "Epoch 62: val_loss did not improve from 1.05202\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1247 - precision: 0.6137 - val_loss: 1.0551 - val_precision: 0.6504\n",
      "Epoch 62: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0338 - precision: 0.6442\n",
      "Combinación 107 = (False, False, False, 8, 0.5) \n",
      " precision train: [1.0338022708892822, 0.6442292928695679]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 109: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.3642 - precision: 0.6923\n",
      "Epoch 1: val_loss improved from inf to 1.12174, saving model to model_ent109.h5\n",
      "236/236 [==============================] - 7s 9ms/step - loss: 1.3552 - precision: 0.6888 - val_loss: 1.1217 - val_precision: 0.6656\n",
      "Epoch 2/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0291 - precision: 0.6200\n",
      "Epoch 2: val_loss improved from 1.12174 to 1.05771, saving model to model_ent109.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0312 - precision: 0.6172 - val_loss: 1.0577 - val_precision: 0.6369\n",
      "Epoch 3/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9877 - precision: 0.6178\n",
      "Epoch 3: val_loss did not improve from 1.05771\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9886 - precision: 0.6169 - val_loss: 1.0602 - val_precision: 0.6227\n",
      "Epoch 4/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9726 - precision: 0.6183\n",
      "Epoch 4: val_loss improved from 1.05771 to 1.04255, saving model to model_ent109.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9726 - precision: 0.6183 - val_loss: 1.0426 - val_precision: 0.6236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9618 - precision: 0.6126\n",
      "Epoch 5: val_loss improved from 1.04255 to 1.02588, saving model to model_ent109.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9620 - precision: 0.6124 - val_loss: 1.0259 - val_precision: 0.6356\n",
      "Epoch 6/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9579 - precision: 0.6197\n",
      "Epoch 6: val_loss did not improve from 1.02588\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9548 - precision: 0.6200 - val_loss: 1.0359 - val_precision: 0.6305\n",
      "Epoch 7/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9499 - precision: 0.6185\n",
      "Epoch 7: val_loss did not improve from 1.02588\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9506 - precision: 0.6178 - val_loss: 1.0416 - val_precision: 0.6122\n",
      "Epoch 8/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9345 - precision: 0.6240\n",
      "Epoch 8: val_loss did not improve from 1.02588\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9382 - precision: 0.6222 - val_loss: 1.0310 - val_precision: 0.6247\n",
      "Epoch 9/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9298 - precision: 0.6246\n",
      "Epoch 9: val_loss improved from 1.02588 to 1.01346, saving model to model_ent109.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9298 - precision: 0.6254 - val_loss: 1.0135 - val_precision: 0.6296\n",
      "Epoch 10/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9258 - precision: 0.6240\n",
      "Epoch 10: val_loss improved from 1.01346 to 1.01192, saving model to model_ent109.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9257 - precision: 0.6231 - val_loss: 1.0119 - val_precision: 0.6238\n",
      "Epoch 11/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9215 - precision: 0.6267\n",
      "Epoch 11: val_loss improved from 1.01192 to 1.01021, saving model to model_ent109.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9203 - precision: 0.6258 - val_loss: 1.0102 - val_precision: 0.6290\n",
      "Epoch 12/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9147 - precision: 0.6258\n",
      "Epoch 12: val_loss did not improve from 1.01021\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9156 - precision: 0.6258 - val_loss: 1.0219 - val_precision: 0.6253\n",
      "Epoch 13/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9157 - precision: 0.6271\n",
      "Epoch 13: val_loss improved from 1.01021 to 1.00529, saving model to model_ent109.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9155 - precision: 0.6266 - val_loss: 1.0053 - val_precision: 0.6267\n",
      "Epoch 14/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9094 - precision: 0.6286\n",
      "Epoch 14: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9121 - precision: 0.6270 - val_loss: 1.0151 - val_precision: 0.6274\n",
      "Epoch 15/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9106 - precision: 0.6261\n",
      "Epoch 15: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9122 - precision: 0.6262 - val_loss: 1.0206 - val_precision: 0.6205\n",
      "Epoch 16/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9046 - precision: 0.6249\n",
      "Epoch 16: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9015 - precision: 0.6258 - val_loss: 1.0069 - val_precision: 0.6325\n",
      "Epoch 17/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8994 - precision: 0.6276\n",
      "Epoch 17: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9027 - precision: 0.6258 - val_loss: 1.0125 - val_precision: 0.6302\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8917 - precision: 0.6319\n",
      "Epoch 18: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8914 - precision: 0.6325 - val_loss: 1.0157 - val_precision: 0.6276\n",
      "Epoch 19/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8938 - precision: 0.6299\n",
      "Epoch 19: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8935 - precision: 0.6298 - val_loss: 1.0136 - val_precision: 0.6315\n",
      "Epoch 20/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8881 - precision: 0.6319\n",
      "Epoch 20: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8883 - precision: 0.6318 - val_loss: 1.0189 - val_precision: 0.6217\n",
      "Epoch 21/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8872 - precision: 0.6320\n",
      "Epoch 21: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8873 - precision: 0.6317 - val_loss: 1.0283 - val_precision: 0.6250\n",
      "Epoch 22/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.8826 - precision: 0.6334\n",
      "Epoch 22: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8825 - precision: 0.6345 - val_loss: 1.0054 - val_precision: 0.6309\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8791 - precision: 0.6298\n",
      "Epoch 23: val_loss did not improve from 1.00529\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8795 - precision: 0.6295 - val_loss: 1.0134 - val_precision: 0.6283\n",
      "Epoch 23: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9598 - precision: 0.6354\n",
      "Combinación 108 = (False, False, False, 16, 0.1) \n",
      " precision train: [0.9597640633583069, 0.6353647708892822]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 110: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.3989 - precision: 0.6341\n",
      "Epoch 1: val_loss improved from inf to 1.18609, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 5s 6ms/step - loss: 1.3935 - precision: 0.6217 - val_loss: 1.1861 - val_precision: 0.6859\n",
      "Epoch 2/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0966 - precision: 0.6242\n",
      "Epoch 2: val_loss improved from 1.18609 to 1.09687, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0952 - precision: 0.6236 - val_loss: 1.0969 - val_precision: 0.6351\n",
      "Epoch 3/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0340 - precision: 0.6116\n",
      "Epoch 3: val_loss improved from 1.09687 to 1.06917, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0345 - precision: 0.6110 - val_loss: 1.0692 - val_precision: 0.6266\n",
      "Epoch 4/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0234 - precision: 0.6063\n",
      "Epoch 4: val_loss improved from 1.06917 to 1.05692, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0233 - precision: 0.6067 - val_loss: 1.0569 - val_precision: 0.6247\n",
      "Epoch 5/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0088 - precision: 0.6125\n",
      "Epoch 5: val_loss improved from 1.05692 to 1.04272, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0074 - precision: 0.6125 - val_loss: 1.0427 - val_precision: 0.6289\n",
      "Epoch 6/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0084 - precision: 0.6088\n",
      "Epoch 6: val_loss improved from 1.04272 to 1.02410, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0058 - precision: 0.6108 - val_loss: 1.0241 - val_precision: 0.6396\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9877 - precision: 0.6136\n",
      "Epoch 7: val_loss did not improve from 1.02410\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9869 - precision: 0.6148 - val_loss: 1.0376 - val_precision: 0.6232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9775 - precision: 0.6181\n",
      "Epoch 8: val_loss did not improve from 1.02410\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9808 - precision: 0.6175 - val_loss: 1.0241 - val_precision: 0.6351\n",
      "Epoch 9/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9681 - precision: 0.6162\n",
      "Epoch 9: val_loss improved from 1.02410 to 1.00854, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9715 - precision: 0.6165 - val_loss: 1.0085 - val_precision: 0.6393\n",
      "Epoch 10/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9768 - precision: 0.6200\n",
      "Epoch 10: val_loss did not improve from 1.00854\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9762 - precision: 0.6204 - val_loss: 1.0228 - val_precision: 0.6256\n",
      "Epoch 11/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9640 - precision: 0.6195\n",
      "Epoch 11: val_loss did not improve from 1.00854\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9607 - precision: 0.6214 - val_loss: 1.0298 - val_precision: 0.6254\n",
      "Epoch 12/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9574 - precision: 0.6290\n",
      "Epoch 12: val_loss did not improve from 1.00854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9572 - precision: 0.6289 - val_loss: 1.0290 - val_precision: 0.6266\n",
      "Epoch 13/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9604 - precision: 0.6216\n",
      "Epoch 13: val_loss did not improve from 1.00854\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9610 - precision: 0.6192 - val_loss: 1.0202 - val_precision: 0.6244\n",
      "Epoch 14/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9527 - precision: 0.6185\n",
      "Epoch 14: val_loss did not improve from 1.00854\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9532 - precision: 0.6178 - val_loss: 1.0145 - val_precision: 0.6346\n",
      "Epoch 15/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9550 - precision: 0.6242\n",
      "Epoch 15: val_loss did not improve from 1.00854\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9521 - precision: 0.6265 - val_loss: 1.0087 - val_precision: 0.6352\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9545 - precision: 0.6207\n",
      "Epoch 16: val_loss did not improve from 1.00854\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9493 - precision: 0.6225 - val_loss: 1.0101 - val_precision: 0.6366\n",
      "Epoch 17/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9366 - precision: 0.6251\n",
      "Epoch 17: val_loss did not improve from 1.00854\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9366 - precision: 0.6251 - val_loss: 1.0131 - val_precision: 0.6313\n",
      "Epoch 18/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9353 - precision: 0.6222\n",
      "Epoch 18: val_loss improved from 1.00854 to 1.00230, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9367 - precision: 0.6220 - val_loss: 1.0023 - val_precision: 0.6414\n",
      "Epoch 19/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9373 - precision: 0.6276\n",
      "Epoch 19: val_loss did not improve from 1.00230\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9332 - precision: 0.6280 - val_loss: 1.0124 - val_precision: 0.6344\n",
      "Epoch 20/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9352 - precision: 0.6223\n",
      "Epoch 20: val_loss did not improve from 1.00230\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9393 - precision: 0.6226 - val_loss: 1.0183 - val_precision: 0.6330\n",
      "Epoch 21/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9350 - precision: 0.6240\n",
      "Epoch 21: val_loss improved from 1.00230 to 1.00181, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9314 - precision: 0.6246 - val_loss: 1.0018 - val_precision: 0.6378\n",
      "Epoch 22/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9279 - precision: 0.6244\n",
      "Epoch 22: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9351 - precision: 0.6236 - val_loss: 1.0122 - val_precision: 0.6342\n",
      "Epoch 23/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9201 - precision: 0.6303\n",
      "Epoch 23: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9172 - precision: 0.6322 - val_loss: 1.0220 - val_precision: 0.6258\n",
      "Epoch 24/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9241 - precision: 0.6249\n",
      "Epoch 24: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9260 - precision: 0.6235 - val_loss: 1.0150 - val_precision: 0.6335\n",
      "Epoch 25/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9242 - precision: 0.6261\n",
      "Epoch 25: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9244 - precision: 0.6275 - val_loss: 1.0103 - val_precision: 0.6373\n",
      "Epoch 26/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9158 - precision: 0.6271\n",
      "Epoch 26: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9185 - precision: 0.6266 - val_loss: 1.0055 - val_precision: 0.6404\n",
      "Epoch 27/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9197 - precision: 0.6300\n",
      "Epoch 27: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9186 - precision: 0.6306 - val_loss: 1.0144 - val_precision: 0.6332\n",
      "Epoch 28/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9081 - precision: 0.6306\n",
      "Epoch 28: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9119 - precision: 0.6284 - val_loss: 1.0024 - val_precision: 0.6351\n",
      "Epoch 29/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9077 - precision: 0.6356\n",
      "Epoch 29: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9092 - precision: 0.6324 - val_loss: 1.0091 - val_precision: 0.6346\n",
      "Epoch 30/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9120 - precision: 0.6323\n",
      "Epoch 30: val_loss did not improve from 1.00181\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9127 - precision: 0.6326 - val_loss: 1.0104 - val_precision: 0.6276\n",
      "Epoch 31/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9116 - precision: 0.6271\n",
      "Epoch 31: val_loss improved from 1.00181 to 0.99880, saving model to model_ent110.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9106 - precision: 0.6269 - val_loss: 0.9988 - val_precision: 0.6414\n",
      "Epoch 32/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9026 - precision: 0.6299\n",
      "Epoch 32: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9003 - precision: 0.6302 - val_loss: 1.0186 - val_precision: 0.6273\n",
      "Epoch 33/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.8992 - precision: 0.6261\n",
      "Epoch 33: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9021 - precision: 0.6260 - val_loss: 1.0129 - val_precision: 0.6299\n",
      "Epoch 34/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8907 - precision: 0.6406\n",
      "Epoch 34: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8935 - precision: 0.6399 - val_loss: 1.0048 - val_precision: 0.6344\n",
      "Epoch 35/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9070 - precision: 0.6313\n",
      "Epoch 35: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9016 - precision: 0.6320 - val_loss: 1.0082 - val_precision: 0.6332\n",
      "Epoch 36/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9055 - precision: 0.6263\n",
      "Epoch 36: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8997 - precision: 0.6271 - val_loss: 1.0033 - val_precision: 0.6373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8856 - precision: 0.6295\n",
      "Epoch 37: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8841 - precision: 0.6315 - val_loss: 1.0075 - val_precision: 0.6336\n",
      "Epoch 38/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8893 - precision: 0.6419\n",
      "Epoch 38: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8896 - precision: 0.6398 - val_loss: 0.9993 - val_precision: 0.6398\n",
      "Epoch 39/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8989 - precision: 0.6304\n",
      "Epoch 39: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9000 - precision: 0.6295 - val_loss: 0.9993 - val_precision: 0.6361\n",
      "Epoch 40/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8908 - precision: 0.6313\n",
      "Epoch 40: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8902 - precision: 0.6327 - val_loss: 1.0011 - val_precision: 0.6391\n",
      "Epoch 41/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8882 - precision: 0.6372\n",
      "Epoch 41: val_loss did not improve from 0.99880\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8899 - precision: 0.6352 - val_loss: 1.0015 - val_precision: 0.6356\n",
      "Epoch 41: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9339 - precision: 0.6456\n",
      "Combinación 109 = (False, False, False, 16, 0.25) \n",
      " precision train: [0.9339233636856079, 0.645594596862793]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 111: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.4931 - precision: 0.6725\n",
      "Epoch 1: val_loss improved from inf to 1.22861, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.4748 - precision: 0.6667 - val_loss: 1.2286 - val_precision: 0.7061\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2077 - precision: 0.6272\n",
      "Epoch 2: val_loss improved from 1.22861 to 1.13064, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2071 - precision: 0.6257 - val_loss: 1.1306 - val_precision: 0.6638\n",
      "Epoch 3/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1391 - precision: 0.6131\n",
      "Epoch 3: val_loss improved from 1.13064 to 1.10752, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1367 - precision: 0.6165 - val_loss: 1.1075 - val_precision: 0.6375\n",
      "Epoch 4/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1135 - precision: 0.6057\n",
      "Epoch 4: val_loss improved from 1.10752 to 1.09821, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1135 - precision: 0.6057 - val_loss: 1.0982 - val_precision: 0.6300\n",
      "Epoch 5/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0987 - precision: 0.6158\n",
      "Epoch 5: val_loss improved from 1.09821 to 1.07346, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0952 - precision: 0.6150 - val_loss: 1.0735 - val_precision: 0.6443\n",
      "Epoch 6/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0958 - precision: 0.6080\n",
      "Epoch 6: val_loss did not improve from 1.07346\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0972 - precision: 0.6067 - val_loss: 1.0771 - val_precision: 0.6360\n",
      "Epoch 7/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0919 - precision: 0.6090\n",
      "Epoch 7: val_loss improved from 1.07346 to 1.06249, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0946 - precision: 0.6083 - val_loss: 1.0625 - val_precision: 0.6360\n",
      "Epoch 8/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0734 - precision: 0.6089\n",
      "Epoch 8: val_loss improved from 1.06249 to 1.05452, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0769 - precision: 0.6059 - val_loss: 1.0545 - val_precision: 0.6441\n",
      "Epoch 9/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0794 - precision: 0.6119\n",
      "Epoch 9: val_loss did not improve from 1.05452\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0807 - precision: 0.6100 - val_loss: 1.0546 - val_precision: 0.6386\n",
      "Epoch 10/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0694 - precision: 0.6125\n",
      "Epoch 10: val_loss improved from 1.05452 to 1.05436, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0712 - precision: 0.6152 - val_loss: 1.0544 - val_precision: 0.6337\n",
      "Epoch 11/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0651 - precision: 0.6074\n",
      "Epoch 11: val_loss improved from 1.05436 to 1.04798, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0680 - precision: 0.6059 - val_loss: 1.0480 - val_precision: 0.6372\n",
      "Epoch 12/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0467 - precision: 0.6186\n",
      "Epoch 12: val_loss improved from 1.04798 to 1.04482, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0546 - precision: 0.6175 - val_loss: 1.0448 - val_precision: 0.6382\n",
      "Epoch 13/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0686 - precision: 0.6113\n",
      "Epoch 13: val_loss did not improve from 1.04482\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0675 - precision: 0.6101 - val_loss: 1.0543 - val_precision: 0.6431\n",
      "Epoch 14/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0587 - precision: 0.6089\n",
      "Epoch 14: val_loss improved from 1.04482 to 1.04043, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0591 - precision: 0.6090 - val_loss: 1.0404 - val_precision: 0.6477\n",
      "Epoch 15/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0498 - precision: 0.6139\n",
      "Epoch 15: val_loss did not improve from 1.04043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0476 - precision: 0.6168 - val_loss: 1.0439 - val_precision: 0.6354\n",
      "Epoch 16/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0492 - precision: 0.6124\n",
      "Epoch 16: val_loss did not improve from 1.04043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0487 - precision: 0.6133 - val_loss: 1.0470 - val_precision: 0.6362\n",
      "Epoch 17/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0531 - precision: 0.6060\n",
      "Epoch 17: val_loss did not improve from 1.04043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0513 - precision: 0.6077 - val_loss: 1.0453 - val_precision: 0.6223\n",
      "Epoch 18/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0390 - precision: 0.6199\n",
      "Epoch 18: val_loss improved from 1.04043 to 1.04018, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0391 - precision: 0.6198 - val_loss: 1.0402 - val_precision: 0.6392\n",
      "Epoch 19/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0476 - precision: 0.6117\n",
      "Epoch 19: val_loss improved from 1.04018 to 1.03727, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0472 - precision: 0.6129 - val_loss: 1.0373 - val_precision: 0.6385\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0474 - precision: 0.6111\n",
      "Epoch 20: val_loss did not improve from 1.03727\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0455 - precision: 0.6125 - val_loss: 1.0407 - val_precision: 0.6316\n",
      "Epoch 21/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0337 - precision: 0.6111\n",
      "Epoch 21: val_loss did not improve from 1.03727\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0339 - precision: 0.6121 - val_loss: 1.0398 - val_precision: 0.6306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0435 - precision: 0.6092\n",
      "Epoch 22: val_loss improved from 1.03727 to 1.03681, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0455 - precision: 0.6081 - val_loss: 1.0368 - val_precision: 0.6362\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0301 - precision: 0.6099\n",
      "Epoch 23: val_loss did not improve from 1.03681\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0324 - precision: 0.6097 - val_loss: 1.0404 - val_precision: 0.6333\n",
      "Epoch 24/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0310 - precision: 0.6123\n",
      "Epoch 24: val_loss did not improve from 1.03681\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0314 - precision: 0.6126 - val_loss: 1.0411 - val_precision: 0.6342\n",
      "Epoch 25/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.0251 - precision: 0.6194\n",
      "Epoch 25: val_loss did not improve from 1.03681\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0262 - precision: 0.6210 - val_loss: 1.0394 - val_precision: 0.6342\n",
      "Epoch 26/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0314 - precision: 0.6090\n",
      "Epoch 26: val_loss improved from 1.03681 to 1.03057, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0327 - precision: 0.6093 - val_loss: 1.0306 - val_precision: 0.6428\n",
      "Epoch 27/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0129 - precision: 0.6242\n",
      "Epoch 27: val_loss did not improve from 1.03057\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0144 - precision: 0.6227 - val_loss: 1.0356 - val_precision: 0.6286\n",
      "Epoch 28/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.0283 - precision: 0.6179\n",
      "Epoch 28: val_loss did not improve from 1.03057\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0261 - precision: 0.6189 - val_loss: 1.0371 - val_precision: 0.6251\n",
      "Epoch 29/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0280 - precision: 0.6145\n",
      "Epoch 29: val_loss improved from 1.03057 to 1.02936, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0263 - precision: 0.6145 - val_loss: 1.0294 - val_precision: 0.6378\n",
      "Epoch 30/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.0193 - precision: 0.6249\n",
      "Epoch 30: val_loss did not improve from 1.02936\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0161 - precision: 0.6267 - val_loss: 1.0326 - val_precision: 0.6319\n",
      "Epoch 31/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0208 - precision: 0.6173\n",
      "Epoch 31: val_loss did not improve from 1.02936\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0203 - precision: 0.6177 - val_loss: 1.0300 - val_precision: 0.6309\n",
      "Epoch 32/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0139 - precision: 0.6267\n",
      "Epoch 32: val_loss did not improve from 1.02936\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0148 - precision: 0.6263 - val_loss: 1.0364 - val_precision: 0.6347\n",
      "Epoch 33/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.0091 - precision: 0.6195\n",
      "Epoch 33: val_loss did not improve from 1.02936\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0045 - precision: 0.6211 - val_loss: 1.0416 - val_precision: 0.6267\n",
      "Epoch 34/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.0084 - precision: 0.6205\n",
      "Epoch 34: val_loss improved from 1.02936 to 1.02717, saving model to model_ent111.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0127 - precision: 0.6203 - val_loss: 1.0272 - val_precision: 0.6339\n",
      "Epoch 35/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0163 - precision: 0.6189\n",
      "Epoch 35: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0164 - precision: 0.6185 - val_loss: 1.0481 - val_precision: 0.6252\n",
      "Epoch 36/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.0146 - precision: 0.6260\n",
      "Epoch 36: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0193 - precision: 0.6259 - val_loss: 1.0352 - val_precision: 0.6263\n",
      "Epoch 37/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.0117 - precision: 0.6176\n",
      "Epoch 37: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0122 - precision: 0.6174 - val_loss: 1.0432 - val_precision: 0.6313\n",
      "Epoch 38/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0008 - precision: 0.6304\n",
      "Epoch 38: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0050 - precision: 0.6276 - val_loss: 1.0418 - val_precision: 0.6262\n",
      "Epoch 39/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.0076 - precision: 0.6241\n",
      "Epoch 39: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0079 - precision: 0.6255 - val_loss: 1.0384 - val_precision: 0.6364\n",
      "Epoch 40/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0078 - precision: 0.6275\n",
      "Epoch 40: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0100 - precision: 0.6253 - val_loss: 1.0341 - val_precision: 0.6347\n",
      "Epoch 41/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0077 - precision: 0.6180\n",
      "Epoch 41: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0074 - precision: 0.6173 - val_loss: 1.0368 - val_precision: 0.6267\n",
      "Epoch 42/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9924 - precision: 0.6288\n",
      "Epoch 42: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0026 - precision: 0.6259 - val_loss: 1.0329 - val_precision: 0.6291\n",
      "Epoch 43/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9973 - precision: 0.6222\n",
      "Epoch 43: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9940 - precision: 0.6237 - val_loss: 1.0424 - val_precision: 0.6293\n",
      "Epoch 44/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0096 - precision: 0.6239\n",
      "Epoch 44: val_loss did not improve from 1.02717\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0118 - precision: 0.6221 - val_loss: 1.0338 - val_precision: 0.6356\n",
      "Epoch 44: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 1.0012 - precision: 0.6315\n",
      "Combinación 110 = (False, False, False, 16, 0.5) \n",
      " precision train: [1.001193881034851, 0.6315118670463562]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 112: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2583 - precision: 0.6310\n",
      "Epoch 1: val_loss improved from inf to 1.08169, saving model to model_ent112.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.2553 - precision: 0.6319 - val_loss: 1.0817 - val_precision: 0.6430\n",
      "Epoch 2/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9969 - precision: 0.6200\n",
      "Epoch 2: val_loss improved from 1.08169 to 1.05074, saving model to model_ent112.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9948 - precision: 0.6193 - val_loss: 1.0507 - val_precision: 0.6335\n",
      "Epoch 3/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9702 - precision: 0.6179\n",
      "Epoch 3: val_loss improved from 1.05074 to 1.02579, saving model to model_ent112.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9691 - precision: 0.6185 - val_loss: 1.0258 - val_precision: 0.6389\n",
      "Epoch 4/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9507 - precision: 0.6200\n",
      "Epoch 4: val_loss improved from 1.02579 to 1.02107, saving model to model_ent112.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9493 - precision: 0.6211 - val_loss: 1.0211 - val_precision: 0.6412\n",
      "Epoch 5/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9298 - precision: 0.6205\n",
      "Epoch 5: val_loss improved from 1.02107 to 1.01242, saving model to model_ent112.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9316 - precision: 0.6193 - val_loss: 1.0124 - val_precision: 0.6330\n",
      "Epoch 6/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9261 - precision: 0.6205\n",
      "Epoch 6: val_loss improved from 1.01242 to 1.00860, saving model to model_ent112.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9232 - precision: 0.6199 - val_loss: 1.0086 - val_precision: 0.6351\n",
      "Epoch 7/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.9145 - precision: 0.6194\n",
      "Epoch 7: val_loss did not improve from 1.00860\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9130 - precision: 0.6214 - val_loss: 1.0136 - val_precision: 0.6195\n",
      "Epoch 8/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9068 - precision: 0.6243\n",
      "Epoch 8: val_loss did not improve from 1.00860\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9069 - precision: 0.6236 - val_loss: 1.0149 - val_precision: 0.6291\n",
      "Epoch 9/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8945 - precision: 0.6255\n",
      "Epoch 9: val_loss improved from 1.00860 to 0.98705, saving model to model_ent112.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9000 - precision: 0.6233 - val_loss: 0.9871 - val_precision: 0.6462\n",
      "Epoch 10/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8931 - precision: 0.6272\n",
      "Epoch 10: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8931 - precision: 0.6266 - val_loss: 1.0065 - val_precision: 0.6334\n",
      "Epoch 11/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.8939 - precision: 0.6247\n",
      "Epoch 11: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8924 - precision: 0.6249 - val_loss: 1.0099 - val_precision: 0.6265\n",
      "Epoch 12/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.8816 - precision: 0.6289\n",
      "Epoch 12: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8843 - precision: 0.6275 - val_loss: 1.0274 - val_precision: 0.6162\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8818 - precision: 0.6299\n",
      "Epoch 13: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8809 - precision: 0.6292 - val_loss: 0.9901 - val_precision: 0.6415\n",
      "Epoch 14/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8722 - precision: 0.6261\n",
      "Epoch 14: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8720 - precision: 0.6261 - val_loss: 1.0272 - val_precision: 0.6219\n",
      "Epoch 15/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.8723 - precision: 0.6322\n",
      "Epoch 15: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8707 - precision: 0.6309 - val_loss: 1.0017 - val_precision: 0.6304\n",
      "Epoch 16/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8690 - precision: 0.6300\n",
      "Epoch 16: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8660 - precision: 0.6290 - val_loss: 0.9967 - val_precision: 0.6329\n",
      "Epoch 17/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8597 - precision: 0.6381\n",
      "Epoch 17: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8598 - precision: 0.6356 - val_loss: 1.0009 - val_precision: 0.6338\n",
      "Epoch 18/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8571 - precision: 0.6349\n",
      "Epoch 18: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8583 - precision: 0.6343 - val_loss: 1.0156 - val_precision: 0.6253\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8540 - precision: 0.6361\n",
      "Epoch 19: val_loss did not improve from 0.98705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8540 - precision: 0.6363 - val_loss: 1.0025 - val_precision: 0.6334\n",
      "Epoch 19: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9298 - precision: 0.6435\n",
      "Combinación 111 = (False, False, False, 32, 0.1) \n",
      " precision train: [0.9297925233840942, 0.6434704661369324]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 113: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.2865 - precision: 0.6493\n",
      "Epoch 1: val_loss improved from inf to 1.09711, saving model to model_ent113.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.2846 - precision: 0.6487 - val_loss: 1.0971 - val_precision: 0.6422\n",
      "Epoch 2/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0277 - precision: 0.6144\n",
      "Epoch 2: val_loss improved from 1.09711 to 1.05094, saving model to model_ent113.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0275 - precision: 0.6149 - val_loss: 1.0509 - val_precision: 0.6407\n",
      "Epoch 3/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9959 - precision: 0.6162\n",
      "Epoch 3: val_loss did not improve from 1.05094\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9964 - precision: 0.6143 - val_loss: 1.0614 - val_precision: 0.6234\n",
      "Epoch 4/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9824 - precision: 0.6157\n",
      "Epoch 4: val_loss improved from 1.05094 to 1.02571, saving model to model_ent113.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9814 - precision: 0.6163 - val_loss: 1.0257 - val_precision: 0.6394\n",
      "Epoch 5/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9654 - precision: 0.6219\n",
      "Epoch 5: val_loss improved from 1.02571 to 1.01870, saving model to model_ent113.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9650 - precision: 0.6220 - val_loss: 1.0187 - val_precision: 0.6424\n",
      "Epoch 6/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9569 - precision: 0.6229\n",
      "Epoch 6: val_loss did not improve from 1.01870\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9563 - precision: 0.6238 - val_loss: 1.0252 - val_precision: 0.6238\n",
      "Epoch 7/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9494 - precision: 0.6247\n",
      "Epoch 7: val_loss improved from 1.01870 to 1.01173, saving model to model_ent113.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9483 - precision: 0.6247 - val_loss: 1.0117 - val_precision: 0.6266\n",
      "Epoch 8/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9449 - precision: 0.6230\n",
      "Epoch 8: val_loss improved from 1.01173 to 1.00427, saving model to model_ent113.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9443 - precision: 0.6229 - val_loss: 1.0043 - val_precision: 0.6439\n",
      "Epoch 9/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9367 - precision: 0.6229\n",
      "Epoch 9: val_loss improved from 1.00427 to 1.00151, saving model to model_ent113.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9388 - precision: 0.6230 - val_loss: 1.0015 - val_precision: 0.6319\n",
      "Epoch 10/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9272 - precision: 0.6276\n",
      "Epoch 10: val_loss did not improve from 1.00151\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9292 - precision: 0.6265 - val_loss: 1.0094 - val_precision: 0.6417\n",
      "Epoch 11/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9252 - precision: 0.6268\n",
      "Epoch 11: val_loss did not improve from 1.00151\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9254 - precision: 0.6252 - val_loss: 1.0149 - val_precision: 0.6350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9151 - precision: 0.6272\n",
      "Epoch 12: val_loss improved from 1.00151 to 0.99458, saving model to model_ent113.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9164 - precision: 0.6262 - val_loss: 0.9946 - val_precision: 0.6368\n",
      "Epoch 13/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9189 - precision: 0.6249\n",
      "Epoch 13: val_loss did not improve from 0.99458\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9192 - precision: 0.6228 - val_loss: 1.0075 - val_precision: 0.6288\n",
      "Epoch 14/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9083 - precision: 0.6283\n",
      "Epoch 14: val_loss improved from 0.99458 to 0.98824, saving model to model_ent113.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9088 - precision: 0.6288 - val_loss: 0.9882 - val_precision: 0.6424\n",
      "Epoch 15/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9004 - precision: 0.6345\n",
      "Epoch 15: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9018 - precision: 0.6346 - val_loss: 1.0121 - val_precision: 0.6269\n",
      "Epoch 16/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9030 - precision: 0.6280\n",
      "Epoch 16: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9027 - precision: 0.6274 - val_loss: 0.9912 - val_precision: 0.6387\n",
      "Epoch 17/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8974 - precision: 0.6291\n",
      "Epoch 17: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8980 - precision: 0.6291 - val_loss: 1.0114 - val_precision: 0.6243\n",
      "Epoch 18/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8951 - precision: 0.6322\n",
      "Epoch 18: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8948 - precision: 0.6321 - val_loss: 1.0000 - val_precision: 0.6373\n",
      "Epoch 19/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8903 - precision: 0.6342\n",
      "Epoch 19: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8902 - precision: 0.6350 - val_loss: 1.0039 - val_precision: 0.6275\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8828 - precision: 0.6335\n",
      "Epoch 20: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8844 - precision: 0.6332 - val_loss: 0.9918 - val_precision: 0.6342\n",
      "Epoch 21/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8860 - precision: 0.6374\n",
      "Epoch 21: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8849 - precision: 0.6374 - val_loss: 0.9994 - val_precision: 0.6385\n",
      "Epoch 22/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8774 - precision: 0.6318\n",
      "Epoch 22: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8778 - precision: 0.6319 - val_loss: 0.9926 - val_precision: 0.6374\n",
      "Epoch 23/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8828 - precision: 0.6346\n",
      "Epoch 23: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8834 - precision: 0.6343 - val_loss: 1.0053 - val_precision: 0.6336\n",
      "Epoch 24/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8697 - precision: 0.6317\n",
      "Epoch 24: val_loss did not improve from 0.98824\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8722 - precision: 0.6310 - val_loss: 0.9944 - val_precision: 0.6352\n",
      "Epoch 24: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9303 - precision: 0.6430\n",
      "Combinación 112 = (False, False, False, 32, 0.25) \n",
      " precision train: [0.9303355813026428, 0.6429967284202576]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 114: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.3629 - precision: 0.6329\n",
      "Epoch 1: val_loss improved from inf to 1.12129, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 4s 6ms/step - loss: 1.3523 - precision: 0.6309 - val_loss: 1.1213 - val_precision: 0.6681\n",
      "Epoch 2/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.0945 - precision: 0.6179\n",
      "Epoch 2: val_loss improved from 1.12129 to 1.08409, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0916 - precision: 0.6175 - val_loss: 1.0841 - val_precision: 0.6374\n",
      "Epoch 3/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 1.0608 - precision: 0.6093\n",
      "Epoch 3: val_loss improved from 1.08409 to 1.06484, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0595 - precision: 0.6082 - val_loss: 1.0648 - val_precision: 0.6399\n",
      "Epoch 4/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.0405 - precision: 0.6125\n",
      "Epoch 4: val_loss improved from 1.06484 to 1.05094, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0434 - precision: 0.6142 - val_loss: 1.0509 - val_precision: 0.6324\n",
      "Epoch 5/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.0267 - precision: 0.6179\n",
      "Epoch 5: val_loss improved from 1.05094 to 1.04087, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0255 - precision: 0.6168 - val_loss: 1.0409 - val_precision: 0.6355\n",
      "Epoch 6/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0159 - precision: 0.6144\n",
      "Epoch 6: val_loss improved from 1.04087 to 1.03220, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0135 - precision: 0.6134 - val_loss: 1.0322 - val_precision: 0.6422\n",
      "Epoch 7/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.0035 - precision: 0.6092\n",
      "Epoch 7: val_loss did not improve from 1.03220\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0062 - precision: 0.6115 - val_loss: 1.0380 - val_precision: 0.6186\n",
      "Epoch 8/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.0115 - precision: 0.6087\n",
      "Epoch 8: val_loss did not improve from 1.03220\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0072 - precision: 0.6112 - val_loss: 1.0411 - val_precision: 0.6179\n",
      "Epoch 9/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9910 - precision: 0.6108\n",
      "Epoch 9: val_loss did not improve from 1.03220\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9905 - precision: 0.6109 - val_loss: 1.0330 - val_precision: 0.6242\n",
      "Epoch 10/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9954 - precision: 0.6182\n",
      "Epoch 10: val_loss improved from 1.03220 to 1.02605, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9909 - precision: 0.6195 - val_loss: 1.0260 - val_precision: 0.6226\n",
      "Epoch 11/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9888 - precision: 0.6183\n",
      "Epoch 11: val_loss improved from 1.02605 to 1.02149, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9889 - precision: 0.6184 - val_loss: 1.0215 - val_precision: 0.6239\n",
      "Epoch 12/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9795 - precision: 0.6177\n",
      "Epoch 12: val_loss improved from 1.02149 to 1.01564, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9798 - precision: 0.6176 - val_loss: 1.0156 - val_precision: 0.6262\n",
      "Epoch 13/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9801 - precision: 0.6185\n",
      "Epoch 13: val_loss did not improve from 1.01564\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9841 - precision: 0.6136 - val_loss: 1.0214 - val_precision: 0.6369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9736 - precision: 0.6177\n",
      "Epoch 14: val_loss improved from 1.01564 to 1.00931, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9735 - precision: 0.6180 - val_loss: 1.0093 - val_precision: 0.6298\n",
      "Epoch 15/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9759 - precision: 0.6149\n",
      "Epoch 15: val_loss did not improve from 1.00931\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9751 - precision: 0.6169 - val_loss: 1.0180 - val_precision: 0.6224\n",
      "Epoch 16/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9618 - precision: 0.6173\n",
      "Epoch 16: val_loss did not improve from 1.00931\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9629 - precision: 0.6162 - val_loss: 1.0152 - val_precision: 0.6298\n",
      "Epoch 17/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9624 - precision: 0.6181\n",
      "Epoch 17: val_loss improved from 1.00931 to 1.00165, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9597 - precision: 0.6192 - val_loss: 1.0016 - val_precision: 0.6313\n",
      "Epoch 18/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9639 - precision: 0.6254\n",
      "Epoch 18: val_loss did not improve from 1.00165\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9650 - precision: 0.6259 - val_loss: 1.0260 - val_precision: 0.6236\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9625 - precision: 0.6234\n",
      "Epoch 19: val_loss did not improve from 1.00165\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9609 - precision: 0.6239 - val_loss: 1.0128 - val_precision: 0.6260\n",
      "Epoch 20/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.9616 - precision: 0.6211\n",
      "Epoch 20: val_loss did not improve from 1.00165\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9587 - precision: 0.6207 - val_loss: 1.0143 - val_precision: 0.6258\n",
      "Epoch 21/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9543 - precision: 0.6282\n",
      "Epoch 21: val_loss did not improve from 1.00165\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9541 - precision: 0.6281 - val_loss: 1.0068 - val_precision: 0.6282\n",
      "Epoch 22/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9484 - precision: 0.6251\n",
      "Epoch 22: val_loss did not improve from 1.00165\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9495 - precision: 0.6246 - val_loss: 1.0105 - val_precision: 0.6245\n",
      "Epoch 23/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9459 - precision: 0.6225\n",
      "Epoch 23: val_loss did not improve from 1.00165\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9437 - precision: 0.6234 - val_loss: 1.0061 - val_precision: 0.6264\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9454 - precision: 0.6255\n",
      "Epoch 24: val_loss did not improve from 1.00165\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9448 - precision: 0.6261 - val_loss: 1.0206 - val_precision: 0.6256\n",
      "Epoch 25/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9524 - precision: 0.6210\n",
      "Epoch 25: val_loss improved from 1.00165 to 0.99633, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9492 - precision: 0.6234 - val_loss: 0.9963 - val_precision: 0.6369\n",
      "Epoch 26/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9407 - precision: 0.6340\n",
      "Epoch 26: val_loss did not improve from 0.99633\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9377 - precision: 0.6343 - val_loss: 1.0186 - val_precision: 0.6237\n",
      "Epoch 27/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9410 - precision: 0.6312\n",
      "Epoch 27: val_loss did not improve from 0.99633\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9453 - precision: 0.6294 - val_loss: 1.0077 - val_precision: 0.6250\n",
      "Epoch 28/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9371 - precision: 0.6262\n",
      "Epoch 28: val_loss did not improve from 0.99633\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9380 - precision: 0.6259 - val_loss: 0.9966 - val_precision: 0.6347\n",
      "Epoch 29/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9251 - precision: 0.6300\n",
      "Epoch 29: val_loss improved from 0.99633 to 0.99043, saving model to model_ent114.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9251 - precision: 0.6300 - val_loss: 0.9904 - val_precision: 0.6299\n",
      "Epoch 30/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9334 - precision: 0.6208\n",
      "Epoch 30: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9322 - precision: 0.6228 - val_loss: 1.0024 - val_precision: 0.6309\n",
      "Epoch 31/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9250 - precision: 0.6298\n",
      "Epoch 31: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9227 - precision: 0.6302 - val_loss: 1.0212 - val_precision: 0.6220\n",
      "Epoch 32/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9291 - precision: 0.6271\n",
      "Epoch 32: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9300 - precision: 0.6267 - val_loss: 1.0038 - val_precision: 0.6299\n",
      "Epoch 33/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9227 - precision: 0.6295\n",
      "Epoch 33: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9234 - precision: 0.6294 - val_loss: 1.0101 - val_precision: 0.6234\n",
      "Epoch 34/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9281 - precision: 0.6306\n",
      "Epoch 34: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9261 - precision: 0.6328 - val_loss: 1.0135 - val_precision: 0.6261\n",
      "Epoch 35/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9129 - precision: 0.6334\n",
      "Epoch 35: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9140 - precision: 0.6334 - val_loss: 1.0024 - val_precision: 0.6326\n",
      "Epoch 36/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9091 - precision: 0.6318\n",
      "Epoch 36: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9097 - precision: 0.6316 - val_loss: 1.0096 - val_precision: 0.6299\n",
      "Epoch 37/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9161 - precision: 0.6286\n",
      "Epoch 37: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9174 - precision: 0.6285 - val_loss: 0.9944 - val_precision: 0.6375\n",
      "Epoch 38/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9183 - precision: 0.6359\n",
      "Epoch 38: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9182 - precision: 0.6361 - val_loss: 1.0166 - val_precision: 0.6230\n",
      "Epoch 39/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9195 - precision: 0.6316\n",
      "Epoch 39: val_loss did not improve from 0.99043\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9181 - precision: 0.6320 - val_loss: 0.9995 - val_precision: 0.6339\n",
      "Epoch 39: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9423 - precision: 0.6402\n",
      "Combinación 113 = (False, False, False, 32, 0.5) \n",
      " precision train: [0.9423319101333618, 0.640178918838501]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 115: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1861 - precision: 0.6302\n",
      "Epoch 1: val_loss improved from inf to 1.08988, saving model to model_ent115.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.1768 - precision: 0.6322 - val_loss: 1.0899 - val_precision: 0.6224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9801 - precision: 0.6193\n",
      "Epoch 2: val_loss improved from 1.08988 to 1.05251, saving model to model_ent115.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9785 - precision: 0.6197 - val_loss: 1.0525 - val_precision: 0.6200\n",
      "Epoch 3/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9464 - precision: 0.6208\n",
      "Epoch 3: val_loss improved from 1.05251 to 1.04235, saving model to model_ent115.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9442 - precision: 0.6209 - val_loss: 1.0423 - val_precision: 0.6160\n",
      "Epoch 4/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9280 - precision: 0.6194\n",
      "Epoch 4: val_loss improved from 1.04235 to 1.00947, saving model to model_ent115.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9282 - precision: 0.6194 - val_loss: 1.0095 - val_precision: 0.6378\n",
      "Epoch 5/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9171 - precision: 0.6211\n",
      "Epoch 5: val_loss improved from 1.00947 to 1.00887, saving model to model_ent115.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9167 - precision: 0.6210 - val_loss: 1.0089 - val_precision: 0.6260\n",
      "Epoch 6/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9094 - precision: 0.6213\n",
      "Epoch 6: val_loss improved from 1.00887 to 1.00457, saving model to model_ent115.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9063 - precision: 0.6218 - val_loss: 1.0046 - val_precision: 0.6300\n",
      "Epoch 7/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8985 - precision: 0.6218\n",
      "Epoch 7: val_loss did not improve from 1.00457\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8999 - precision: 0.6212 - val_loss: 1.0173 - val_precision: 0.6218\n",
      "Epoch 8/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8949 - precision: 0.6222\n",
      "Epoch 8: val_loss improved from 1.00457 to 0.99052, saving model to model_ent115.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8918 - precision: 0.6217 - val_loss: 0.9905 - val_precision: 0.6397\n",
      "Epoch 9/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8825 - precision: 0.6275\n",
      "Epoch 9: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8831 - precision: 0.6272 - val_loss: 1.0182 - val_precision: 0.6250\n",
      "Epoch 10/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.8734 - precision: 0.6303\n",
      "Epoch 10: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8735 - precision: 0.6301 - val_loss: 1.0029 - val_precision: 0.6313\n",
      "Epoch 11/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8674 - precision: 0.6317\n",
      "Epoch 11: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8693 - precision: 0.6316 - val_loss: 1.0080 - val_precision: 0.6279\n",
      "Epoch 12/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8657 - precision: 0.6346\n",
      "Epoch 12: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8641 - precision: 0.6348 - val_loss: 1.0106 - val_precision: 0.6378\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8584 - precision: 0.6329\n",
      "Epoch 13: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8603 - precision: 0.6337 - val_loss: 0.9974 - val_precision: 0.6335\n",
      "Epoch 14/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8541 - precision: 0.6312\n",
      "Epoch 14: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8518 - precision: 0.6310 - val_loss: 1.0026 - val_precision: 0.6295\n",
      "Epoch 15/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8445 - precision: 0.6326\n",
      "Epoch 15: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8459 - precision: 0.6327 - val_loss: 1.0244 - val_precision: 0.6217\n",
      "Epoch 16/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8342 - precision: 0.6399\n",
      "Epoch 16: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8384 - precision: 0.6380 - val_loss: 1.0175 - val_precision: 0.6258\n",
      "Epoch 17/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8348 - precision: 0.6383\n",
      "Epoch 17: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8345 - precision: 0.6383 - val_loss: 1.0152 - val_precision: 0.6294\n",
      "Epoch 18/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.8309 - precision: 0.6365\n",
      "Epoch 18: val_loss did not improve from 0.99052\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8279 - precision: 0.6383 - val_loss: 1.0221 - val_precision: 0.6230\n",
      "Epoch 18: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9286 - precision: 0.6417\n",
      "Combinación 114 = (False, False, False, 64, 0.1) \n",
      " precision train: [0.9285706877708435, 0.6417267918586731]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 116: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.2208 - precision: 0.6474\n",
      "Epoch 1: val_loss improved from inf to 1.09512, saving model to model_ent116.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.2147 - precision: 0.6402 - val_loss: 1.0951 - val_precision: 0.6431\n",
      "Epoch 2/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9959 - precision: 0.6222\n",
      "Epoch 2: val_loss improved from 1.09512 to 1.02412, saving model to model_ent116.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9965 - precision: 0.6218 - val_loss: 1.0241 - val_precision: 0.6466\n",
      "Epoch 3/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9644 - precision: 0.6222\n",
      "Epoch 3: val_loss did not improve from 1.02412\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9630 - precision: 0.6227 - val_loss: 1.0250 - val_precision: 0.6394\n",
      "Epoch 4/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9490 - precision: 0.6250\n",
      "Epoch 4: val_loss improved from 1.02412 to 1.01705, saving model to model_ent116.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9467 - precision: 0.6260 - val_loss: 1.0171 - val_precision: 0.6364\n",
      "Epoch 5/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9400 - precision: 0.6232\n",
      "Epoch 5: val_loss did not improve from 1.01705\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9400 - precision: 0.6232 - val_loss: 1.0352 - val_precision: 0.6265\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9231 - precision: 0.6241\n",
      "Epoch 6: val_loss improved from 1.01705 to 1.01169, saving model to model_ent116.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9231 - precision: 0.6241 - val_loss: 1.0117 - val_precision: 0.6297\n",
      "Epoch 7/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9221 - precision: 0.6213\n",
      "Epoch 7: val_loss did not improve from 1.01169\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9171 - precision: 0.6226 - val_loss: 1.0157 - val_precision: 0.6281\n",
      "Epoch 8/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9115 - precision: 0.6219\n",
      "Epoch 8: val_loss improved from 1.01169 to 0.99147, saving model to model_ent116.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9135 - precision: 0.6214 - val_loss: 0.9915 - val_precision: 0.6527\n",
      "Epoch 9/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9014 - precision: 0.6246\n",
      "Epoch 9: val_loss improved from 0.99147 to 0.98553, saving model to model_ent116.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9015 - precision: 0.6250 - val_loss: 0.9855 - val_precision: 0.6449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8931 - precision: 0.6322\n",
      "Epoch 10: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8943 - precision: 0.6289 - val_loss: 1.0113 - val_precision: 0.6319\n",
      "Epoch 11/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8905 - precision: 0.6265\n",
      "Epoch 11: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8928 - precision: 0.6237 - val_loss: 0.9877 - val_precision: 0.6397\n",
      "Epoch 12/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8901 - precision: 0.6306\n",
      "Epoch 12: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8896 - precision: 0.6296 - val_loss: 1.0150 - val_precision: 0.6246\n",
      "Epoch 13/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8749 - precision: 0.6320\n",
      "Epoch 13: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8789 - precision: 0.6308 - val_loss: 0.9939 - val_precision: 0.6392\n",
      "Epoch 14/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.8704 - precision: 0.6334\n",
      "Epoch 14: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8747 - precision: 0.6314 - val_loss: 1.0124 - val_precision: 0.6328\n",
      "Epoch 15/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8700 - precision: 0.6327\n",
      "Epoch 15: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8722 - precision: 0.6322 - val_loss: 0.9982 - val_precision: 0.6401\n",
      "Epoch 16/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8640 - precision: 0.6320\n",
      "Epoch 16: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8676 - precision: 0.6334 - val_loss: 1.0175 - val_precision: 0.6224\n",
      "Epoch 17/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.8636 - precision: 0.6377\n",
      "Epoch 17: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8629 - precision: 0.6372 - val_loss: 0.9980 - val_precision: 0.6353\n",
      "Epoch 18/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8565 - precision: 0.6359\n",
      "Epoch 18: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8572 - precision: 0.6356 - val_loss: 1.0179 - val_precision: 0.6273\n",
      "Epoch 19/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.8515 - precision: 0.6331\n",
      "Epoch 19: val_loss did not improve from 0.98553\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8514 - precision: 0.6349 - val_loss: 0.9989 - val_precision: 0.6356\n",
      "Epoch 19: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9227 - precision: 0.6490\n",
      "Combinación 115 = (False, False, False, 64, 0.25) \n",
      " precision train: [0.9227341413497925, 0.6490118503570557]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 117: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2688 - precision: 0.6332\n",
      "Epoch 1: val_loss improved from inf to 1.10424, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 5s 7ms/step - loss: 1.2688 - precision: 0.6332 - val_loss: 1.1042 - val_precision: 0.6341\n",
      "Epoch 2/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.0338 - precision: 0.6208\n",
      "Epoch 2: val_loss improved from 1.10424 to 1.06129, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0335 - precision: 0.6214 - val_loss: 1.0613 - val_precision: 0.6246\n",
      "Epoch 3/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.0103 - precision: 0.6142\n",
      "Epoch 3: val_loss improved from 1.06129 to 1.05440, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0101 - precision: 0.6119 - val_loss: 1.0544 - val_precision: 0.6275\n",
      "Epoch 4/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.9919 - precision: 0.6180\n",
      "Epoch 4: val_loss improved from 1.05440 to 1.02262, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9912 - precision: 0.6180 - val_loss: 1.0226 - val_precision: 0.6313\n",
      "Epoch 5/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.9755 - precision: 0.6190\n",
      "Epoch 5: val_loss improved from 1.02262 to 1.01977, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9762 - precision: 0.6198 - val_loss: 1.0198 - val_precision: 0.6289\n",
      "Epoch 6/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9673 - precision: 0.6231\n",
      "Epoch 6: val_loss improved from 1.01977 to 1.01967, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9679 - precision: 0.6205 - val_loss: 1.0197 - val_precision: 0.6318\n",
      "Epoch 7/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9572 - precision: 0.6226\n",
      "Epoch 7: val_loss improved from 1.01967 to 1.00889, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9571 - precision: 0.6231 - val_loss: 1.0089 - val_precision: 0.6377\n",
      "Epoch 8/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9603 - precision: 0.6163\n",
      "Epoch 8: val_loss did not improve from 1.00889\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9603 - precision: 0.6163 - val_loss: 1.0241 - val_precision: 0.6282\n",
      "Epoch 9/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9546 - precision: 0.6176\n",
      "Epoch 9: val_loss improved from 1.00889 to 1.00870, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9506 - precision: 0.6176 - val_loss: 1.0087 - val_precision: 0.6296\n",
      "Epoch 10/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.9386 - precision: 0.6252\n",
      "Epoch 10: val_loss did not improve from 1.00870\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9391 - precision: 0.6232 - val_loss: 1.0188 - val_precision: 0.6239\n",
      "Epoch 11/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9373 - precision: 0.6208\n",
      "Epoch 11: val_loss did not improve from 1.00870\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9371 - precision: 0.6214 - val_loss: 1.0166 - val_precision: 0.6368\n",
      "Epoch 12/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9348 - precision: 0.6202\n",
      "Epoch 12: val_loss improved from 1.00870 to 1.00315, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9341 - precision: 0.6205 - val_loss: 1.0032 - val_precision: 0.6353\n",
      "Epoch 13/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9348 - precision: 0.6184\n",
      "Epoch 13: val_loss improved from 1.00315 to 0.99714, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9318 - precision: 0.6186 - val_loss: 0.9971 - val_precision: 0.6364\n",
      "Epoch 14/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9358 - precision: 0.6229\n",
      "Epoch 14: val_loss did not improve from 0.99714\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9311 - precision: 0.6228 - val_loss: 1.0120 - val_precision: 0.6274\n",
      "Epoch 15/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9272 - precision: 0.6255\n",
      "Epoch 15: val_loss did not improve from 0.99714\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9257 - precision: 0.6242 - val_loss: 1.0045 - val_precision: 0.6264\n",
      "Epoch 16/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9129 - precision: 0.6262\n",
      "Epoch 16: val_loss did not improve from 0.99714\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9125 - precision: 0.6263 - val_loss: 1.0170 - val_precision: 0.6307\n",
      "Epoch 17/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/236 [============================>.] - ETA: 0s - loss: 0.9152 - precision: 0.6251\n",
      "Epoch 17: val_loss did not improve from 0.99714\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9154 - precision: 0.6252 - val_loss: 1.0142 - val_precision: 0.6267\n",
      "Epoch 18/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9094 - precision: 0.6219\n",
      "Epoch 18: val_loss improved from 0.99714 to 0.99501, saving model to model_ent117.h5\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9062 - precision: 0.6234 - val_loss: 0.9950 - val_precision: 0.6375\n",
      "Epoch 19/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9064 - precision: 0.6253\n",
      "Epoch 19: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9056 - precision: 0.6249 - val_loss: 1.0185 - val_precision: 0.6192\n",
      "Epoch 20/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.8991 - precision: 0.6324\n",
      "Epoch 20: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8995 - precision: 0.6308 - val_loss: 1.0061 - val_precision: 0.6319\n",
      "Epoch 21/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.9052 - precision: 0.6215\n",
      "Epoch 21: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9045 - precision: 0.6226 - val_loss: 1.0121 - val_precision: 0.6305\n",
      "Epoch 22/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.8967 - precision: 0.6322\n",
      "Epoch 22: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8965 - precision: 0.6324 - val_loss: 1.0076 - val_precision: 0.6324\n",
      "Epoch 23/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8859 - precision: 0.6344\n",
      "Epoch 23: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8910 - precision: 0.6326 - val_loss: 1.0207 - val_precision: 0.6243\n",
      "Epoch 24/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.8853 - precision: 0.6292\n",
      "Epoch 24: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8856 - precision: 0.6296 - val_loss: 1.0060 - val_precision: 0.6297\n",
      "Epoch 25/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.8841 - precision: 0.6325\n",
      "Epoch 25: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8835 - precision: 0.6309 - val_loss: 1.0128 - val_precision: 0.6235\n",
      "Epoch 26/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8861 - precision: 0.6328\n",
      "Epoch 26: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8861 - precision: 0.6328 - val_loss: 1.0036 - val_precision: 0.6299\n",
      "Epoch 27/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.8776 - precision: 0.6346\n",
      "Epoch 27: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8808 - precision: 0.6339 - val_loss: 1.0092 - val_precision: 0.6281\n",
      "Epoch 28/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 0.8695 - precision: 0.6302\n",
      "Epoch 28: val_loss did not improve from 0.99501\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8757 - precision: 0.6299 - val_loss: 1.0027 - val_precision: 0.6307\n",
      "Epoch 28: early stopping\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.9292 - precision: 0.6439\n",
      "Combinación 116 = (False, False, False, 64, 0.5) \n",
      " precision train: [0.9291688203811646, 0.6438891291618347]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 118: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 1.1337 - precision: 0.6305\n",
      "Epoch 1: val_loss improved from inf to 1.05728, saving model to model_ent118.h5\n",
      "236/236 [==============================] - 5s 8ms/step - loss: 1.1327 - precision: 0.6294 - val_loss: 1.0573 - val_precision: 0.6345\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.9623 - precision: 0.6205\n",
      "Epoch 2: val_loss improved from 1.05728 to 1.02349, saving model to model_ent118.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9624 - precision: 0.6209 - val_loss: 1.0235 - val_precision: 0.6388\n",
      "Epoch 3/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9341 - precision: 0.6212\n",
      "Epoch 3: val_loss did not improve from 1.02349\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9305 - precision: 0.6226 - val_loss: 1.0245 - val_precision: 0.6323\n",
      "Epoch 4/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9165 - precision: 0.6187\n",
      "Epoch 4: val_loss improved from 1.02349 to 1.00906, saving model to model_ent118.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9130 - precision: 0.6208 - val_loss: 1.0091 - val_precision: 0.6447\n",
      "Epoch 5/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.9028 - precision: 0.6213\n",
      "Epoch 5: val_loss did not improve from 1.00906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9064 - precision: 0.6210 - val_loss: 1.0166 - val_precision: 0.6208\n",
      "Epoch 6/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8956 - precision: 0.6217\n",
      "Epoch 6: val_loss did not improve from 1.00906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8943 - precision: 0.6219 - val_loss: 1.0166 - val_precision: 0.6332\n",
      "Epoch 7/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8842 - precision: 0.6301\n",
      "Epoch 7: val_loss did not improve from 1.00906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8840 - precision: 0.6305 - val_loss: 1.0151 - val_precision: 0.6254\n",
      "Epoch 8/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8811 - precision: 0.6246\n",
      "Epoch 8: val_loss did not improve from 1.00906\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8795 - precision: 0.6266 - val_loss: 1.0275 - val_precision: 0.6270\n",
      "Epoch 9/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8674 - precision: 0.6324\n",
      "Epoch 9: val_loss improved from 1.00906 to 1.00469, saving model to model_ent118.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8668 - precision: 0.6311 - val_loss: 1.0047 - val_precision: 0.6297\n",
      "Epoch 10/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8595 - precision: 0.6345\n",
      "Epoch 10: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8595 - precision: 0.6328 - val_loss: 1.0412 - val_precision: 0.6189\n",
      "Epoch 11/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8532 - precision: 0.6333\n",
      "Epoch 11: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8521 - precision: 0.6336 - val_loss: 1.0419 - val_precision: 0.6131\n",
      "Epoch 12/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8426 - precision: 0.6318\n",
      "Epoch 12: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8453 - precision: 0.6312 - val_loss: 1.0518 - val_precision: 0.6139\n",
      "Epoch 13/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8407 - precision: 0.6354\n",
      "Epoch 13: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8392 - precision: 0.6345 - val_loss: 1.0259 - val_precision: 0.6235\n",
      "Epoch 14/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8257 - precision: 0.6395\n",
      "Epoch 14: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8280 - precision: 0.6397 - val_loss: 1.0424 - val_precision: 0.6145\n",
      "Epoch 15/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8282 - precision: 0.6371\n",
      "Epoch 15: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8282 - precision: 0.6371 - val_loss: 1.0201 - val_precision: 0.6201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.8196 - precision: 0.6389\n",
      "Epoch 16: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8174 - precision: 0.6393 - val_loss: 1.0067 - val_precision: 0.6350\n",
      "Epoch 17/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8077 - precision: 0.6412\n",
      "Epoch 17: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8084 - precision: 0.6406 - val_loss: 1.0122 - val_precision: 0.6276\n",
      "Epoch 18/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.7925 - precision: 0.6506\n",
      "Epoch 18: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7933 - precision: 0.6521 - val_loss: 1.0154 - val_precision: 0.6237\n",
      "Epoch 19/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.7932 - precision: 0.6466\n",
      "Epoch 19: val_loss did not improve from 1.00469\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7949 - precision: 0.6465 - val_loss: 1.0349 - val_precision: 0.6092\n",
      "Epoch 19: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 0.9044 - precision: 0.6471\n",
      "Combinación 117 = (False, False, False, 128, 0.1) \n",
      " precision train: [0.9044097661972046, 0.6470513343811035]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 119: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1522 - precision: 0.6324\n",
      "Epoch 1: val_loss improved from inf to 1.03637, saving model to model_ent119.h5\n",
      "236/236 [==============================] - 5s 8ms/step - loss: 1.1509 - precision: 0.6319 - val_loss: 1.0364 - val_precision: 0.6516\n",
      "Epoch 2/70\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.9754 - precision: 0.6201\n",
      "Epoch 2: val_loss improved from 1.03637 to 1.03092, saving model to model_ent119.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9756 - precision: 0.6188 - val_loss: 1.0309 - val_precision: 0.6458\n",
      "Epoch 3/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.9466 - precision: 0.6237\n",
      "Epoch 3: val_loss improved from 1.03092 to 1.00457, saving model to model_ent119.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9466 - precision: 0.6237 - val_loss: 1.0046 - val_precision: 0.6407\n",
      "Epoch 4/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9279 - precision: 0.6194\n",
      "Epoch 4: val_loss improved from 1.00457 to 0.99509, saving model to model_ent119.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9271 - precision: 0.6196 - val_loss: 0.9951 - val_precision: 0.6378\n",
      "Epoch 5/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9058 - precision: 0.6269\n",
      "Epoch 5: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9079 - precision: 0.6271 - val_loss: 1.0344 - val_precision: 0.6377\n",
      "Epoch 6/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9073 - precision: 0.6267\n",
      "Epoch 6: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9054 - precision: 0.6260 - val_loss: 1.0094 - val_precision: 0.6375\n",
      "Epoch 7/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8960 - precision: 0.6270\n",
      "Epoch 7: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8969 - precision: 0.6284 - val_loss: 1.0227 - val_precision: 0.6243\n",
      "Epoch 8/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8889 - precision: 0.6283\n",
      "Epoch 8: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8897 - precision: 0.6277 - val_loss: 1.0041 - val_precision: 0.6303\n",
      "Epoch 9/70\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.8805 - precision: 0.6296\n",
      "Epoch 9: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8813 - precision: 0.6284 - val_loss: 0.9998 - val_precision: 0.6320\n",
      "Epoch 10/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.8768 - precision: 0.6315\n",
      "Epoch 10: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8743 - precision: 0.6318 - val_loss: 1.0218 - val_precision: 0.6195\n",
      "Epoch 11/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8619 - precision: 0.6339\n",
      "Epoch 11: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8691 - precision: 0.6313 - val_loss: 0.9999 - val_precision: 0.6392\n",
      "Epoch 12/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8657 - precision: 0.6289\n",
      "Epoch 12: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8653 - precision: 0.6299 - val_loss: 1.0099 - val_precision: 0.6298\n",
      "Epoch 13/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8609 - precision: 0.6306\n",
      "Epoch 13: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8606 - precision: 0.6316 - val_loss: 1.0126 - val_precision: 0.6286\n",
      "Epoch 14/70\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.8528 - precision: 0.6371\n",
      "Epoch 14: val_loss did not improve from 0.99509\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8535 - precision: 0.6344 - val_loss: 1.0083 - val_precision: 0.6297\n",
      "Epoch 14: early stopping\n",
      "295/295 [==============================] - 0s 2ms/step - loss: 0.9320 - precision: 0.6424\n",
      "Combinación 118 = (False, False, False, 128, 0.25) \n",
      " precision train: [0.9319606423377991, 0.642436146736145]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "Combinación 120: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Epoch 1/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 1.2105 - precision: 0.6271\n",
      "Epoch 1: val_loss improved from inf to 1.08031, saving model to model_ent120.h5\n",
      "236/236 [==============================] - 5s 8ms/step - loss: 1.2049 - precision: 0.6291 - val_loss: 1.0803 - val_precision: 0.6449\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.0081 - precision: 0.6202\n",
      "Epoch 2: val_loss did not improve from 1.08031\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.0071 - precision: 0.6202 - val_loss: 1.0814 - val_precision: 0.6111\n",
      "Epoch 3/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.9773 - precision: 0.6220\n",
      "Epoch 3: val_loss improved from 1.08031 to 1.02268, saving model to model_ent120.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9758 - precision: 0.6229 - val_loss: 1.0227 - val_precision: 0.6351\n",
      "Epoch 4/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9591 - precision: 0.6203\n",
      "Epoch 4: val_loss improved from 1.02268 to 1.02128, saving model to model_ent120.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9587 - precision: 0.6201 - val_loss: 1.0213 - val_precision: 0.6288\n",
      "Epoch 5/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.9480 - precision: 0.6223\n",
      "Epoch 5: val_loss improved from 1.02128 to 1.01197, saving model to model_ent120.h5\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.9464 - precision: 0.6237 - val_loss: 1.0120 - val_precision: 0.6370\n",
      "Epoch 6/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.9363 - precision: 0.6166\n",
      "Epoch 6: val_loss did not improve from 1.01197\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9364 - precision: 0.6183 - val_loss: 1.0213 - val_precision: 0.6248\n",
      "Epoch 7/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.9276 - precision: 0.6237\n",
      "Epoch 7: val_loss did not improve from 1.01197\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9273 - precision: 0.6244 - val_loss: 1.0195 - val_precision: 0.6261\n",
      "Epoch 8/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.9151 - precision: 0.6220\n",
      "Epoch 8: val_loss did not improve from 1.01197\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9161 - precision: 0.6216 - val_loss: 1.0167 - val_precision: 0.6280\n",
      "Epoch 9/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9192 - precision: 0.6214\n",
      "Epoch 9: val_loss improved from 1.01197 to 1.00705, saving model to model_ent120.h5\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9187 - precision: 0.6205 - val_loss: 1.0070 - val_precision: 0.6295\n",
      "Epoch 10/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.9149 - precision: 0.6215\n",
      "Epoch 10: val_loss did not improve from 1.00705\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.9146 - precision: 0.6217 - val_loss: 1.0282 - val_precision: 0.6191\n",
      "Epoch 11/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.9039 - precision: 0.6259\n",
      "Epoch 11: val_loss did not improve from 1.00705\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.9037 - precision: 0.6246 - val_loss: 1.0075 - val_precision: 0.6200\n",
      "Epoch 12/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8987 - precision: 0.6261\n",
      "Epoch 12: val_loss did not improve from 1.00705\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8980 - precision: 0.6268 - val_loss: 1.0185 - val_precision: 0.6237\n",
      "Epoch 13/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8969 - precision: 0.6204\n",
      "Epoch 13: val_loss did not improve from 1.00705\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8964 - precision: 0.6220 - val_loss: 1.0093 - val_precision: 0.6290\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.8823 - precision: 0.6267\n",
      "Epoch 14: val_loss improved from 1.00705 to 0.99924, saving model to model_ent120.h5\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8823 - precision: 0.6267 - val_loss: 0.9992 - val_precision: 0.6393\n",
      "Epoch 15/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8897 - precision: 0.6266\n",
      "Epoch 15: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8912 - precision: 0.6258 - val_loss: 1.0038 - val_precision: 0.6354\n",
      "Epoch 16/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8803 - precision: 0.6301\n",
      "Epoch 16: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8806 - precision: 0.6302 - val_loss: 1.0035 - val_precision: 0.6340\n",
      "Epoch 17/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.8739 - precision: 0.6326\n",
      "Epoch 17: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8753 - precision: 0.6318 - val_loss: 1.0053 - val_precision: 0.6300\n",
      "Epoch 18/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.8744 - precision: 0.6320\n",
      "Epoch 18: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8737 - precision: 0.6313 - val_loss: 1.0184 - val_precision: 0.6208\n",
      "Epoch 19/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.8693 - precision: 0.6310\n",
      "Epoch 19: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8699 - precision: 0.6321 - val_loss: 1.0165 - val_precision: 0.6225\n",
      "Epoch 20/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.8629 - precision: 0.6339\n",
      "Epoch 20: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8620 - precision: 0.6351 - val_loss: 1.0258 - val_precision: 0.6237\n",
      "Epoch 21/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8617 - precision: 0.6340\n",
      "Epoch 21: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8623 - precision: 0.6330 - val_loss: 1.0095 - val_precision: 0.6295\n",
      "Epoch 22/70\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.8580 - precision: 0.6326\n",
      "Epoch 22: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8579 - precision: 0.6339 - val_loss: 1.0350 - val_precision: 0.6114\n",
      "Epoch 23/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8464 - precision: 0.6388\n",
      "Epoch 23: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8464 - precision: 0.6394 - val_loss: 1.0073 - val_precision: 0.6279\n",
      "Epoch 24/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8468 - precision: 0.6361\n",
      "Epoch 24: val_loss did not improve from 0.99924\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.8461 - precision: 0.6355 - val_loss: 1.0096 - val_precision: 0.6201\n",
      "Epoch 24: early stopping\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.9238 - precision: 0.6375\n",
      "Combinación 119 = (False, False, False, 128, 0.5) \n",
      " precision train: [0.9237693548202515, 0.6374920010566711]\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "new_config = [[True, False], [True, False], [True, False], [8, 16, 32, 64, 128], [0.1, 0.25, 0.5]]  \n",
    "hist_entities = LSTM_hiperparametros(new_config, x_train=embedded_entities, y_train=Y_ent, is_ent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb984d",
   "metadata": {},
   "source": [
    "Veamos cuál fue el modelo con mejores desempeños:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e554a257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>model_73.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x1ac68cfd0&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.8396868705749512, 0.6724470257759094]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>model_28.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x18449d1c0&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.8492178320884705, 0.6613441109657288]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>model_70.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x1a93c8af0&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.8515021800994873, 0.6680382490158081]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>model_25.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x1812abb20&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.8667892217636108, 0.6612138152122498]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model_13.h5</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x174c7c460&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.8687023520469666, 0.6613000631332397]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                1      2     3  \\\n",
       "72  model_73.h5  <keras.callbacks.History object at 0x1ac68cfd0>  False  True   \n",
       "27  model_28.h5  <keras.callbacks.History object at 0x18449d1c0>   True  True   \n",
       "69  model_70.h5  <keras.callbacks.History object at 0x1a93c8af0>  False  True   \n",
       "24  model_25.h5  <keras.callbacks.History object at 0x1812abb20>   True  True   \n",
       "12  model_13.h5  <keras.callbacks.History object at 0x174c7c460>   True  True   \n",
       "\n",
       "        4    5    6                                         7  \n",
       "72   True  128  0.1  [0.8396868705749512, 0.6724470257759094]  \n",
       "27  False  128  0.1  [0.8492178320884705, 0.6613441109657288]  \n",
       "69   True   64  0.1  [0.8515021800994873, 0.6680382490158081]  \n",
       "24  False   64  0.1  [0.8667892217636108, 0.6612138152122498]  \n",
       "12   True  128  0.1  [0.8687023520469666, 0.6613000631332397]  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_entities_ = pd.DataFrame(hist_entities)\n",
    "hist_entities_ = hist_entities_.sort_values(by=[7], ascending=True)\n",
    "hist_entities_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bc097f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinacion: \n",
      " primera_capa_adicional = False\n",
      " segunda_capa_adicional = True\n",
      " tercera_capa_adicional = True\n",
      " n_neuronas = 128\n",
      " dropout = 0.1\n",
      "**************************\n",
      "Resultados despues de tuneo con hiperparametros: 0.6724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Mejor combinacion: \\n primera_capa_adicional = {hist_entities_.iloc[0, 2]}\\n segunda_capa_adicional = {hist_entities_.iloc[0, 3]}\\n tercera_capa_adicional = {hist_entities_.iloc[0, 4]}\\n n_neuronas = {hist_entities_.iloc[0, 5]}\\n dropout = {hist_entities_.iloc[0, 6]}')\n",
    "print('**************************')\n",
    "print(f'Resultados despues de tuneo con hiperparametros: {np.round(hist_entities_.iloc[0, -1], 4)[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eba262c",
   "metadata": {},
   "source": [
    "Vemos entonces que el modelo con mejores métricas para este caso fue el que no escogió dos capas adicionales, donde cada capa tenía 128 neuronas, con una tasa de pérdida de 0.1 (la más baja). Podemos ver que este modelo corresponde al añmacenado en el archivo ```model_ent73.h5```.\n",
    "\n",
    "Finalmente, veamos las métricas de precisión y pérdida para este modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1dc590d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cd83acd0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,7))\n",
    "fig.add_subplot(121)\n",
    "# Precision\n",
    "best_cv_2 = load_model('model_ent73.h5')\n",
    "plt.plot(hist_entities_.iloc[0, 1].epoch, hist_entities_.iloc[0, 1].history['precision'], label = \"precision\")\n",
    "\n",
    "plt.title(\"Precisión\", fontsize=18)\n",
    "plt.xlabel(\"Épocas\", fontsize=15)\n",
    "plt.ylabel(\"Precisión\", fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Pérdida\n",
    "fig.add_subplot(122)\n",
    "\n",
    "plt.plot(hist_entities_.iloc[0, 1].epoch, hist_entities_.iloc[0, 1].history['loss'], label=\"loss\")\n",
    "\n",
    "plt.title(\"Pérdida\", fontsize=18)\n",
    "plt.xlabel(\"Épocas\", fontsize=15)\n",
    "plt.ylabel(\"Pérdida\", fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def6d2e",
   "metadata": {},
   "source": [
    "Podemos ver claramente que el modelo paró en la época de mejor precisión y menor pérdida. No obstante, esta precisión sigue siendo muy baja con respecto a lo que esperaríamos para que sea un modelo realmente bueno. Veamos el reporte de clasificación y la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b97bcac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reporte para el modelo construido---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.81      0.76      2099\n",
      "           2       0.52      0.78      0.62       988\n",
      "           3       0.45      0.76      0.57      1208\n",
      "           4       0.68      0.78      0.73      2014\n",
      "           5       0.65      0.26      0.37      3112\n",
      "\n",
      "    accuracy                           0.61      9421\n",
      "   macro avg       0.60      0.68      0.61      9421\n",
      "weighted avg       0.63      0.61      0.58      9421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_2 = best_cv_2.predict(embedded_entities)\n",
    "y_pred_2 = y_pred_2.argmax(1) + 1 # Sumamos 1 para que las clases nos queden entre 1 y 5 \n",
    "Y_en = Y_ent.argmax(1) + 1 # Sumamos 1 para que las clases nos queden entre 1 y 5 \n",
    "\n",
    "\n",
    "print('---Reporte para el modelo construido---')\n",
    "print(classification_report(Y_en, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6bf764d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_2 = confusion_matrix(Y_en, y_pred_2)\n",
    "disp_2 = ConfusionMatrixDisplay(confusion_matrix=cm_2, display_labels= np.arange(1,6))\n",
    "disp_2.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e0c5be",
   "metadata": {},
   "source": [
    "A diferencia del modelo anterior, este modelo tiene un rango de precisiones más variado. Notamos que la clasificación de la clase 1 es la mejor, mientras que la de la clase 3 está incluso por debajo del 50%. Por esta razón, y debido a que dado el contexto del problema queremos clasificar tan bien como se pueda de todas las clases, nos quedamos con el modelo en el que usamos BioSentVec.\n",
    "\n",
    "Inferimos que quizá el wordembedding que utilizamos como preentrenamiento tenía una dimensionalidad muy grande, para haber sido únicamente tan pocas palabras. Este modelo queda, entonces, descartado.\n",
    "\n",
    "Por lo tanto, como resultado de este notebook, nos quedamos con el modelo resultado de la validación cruzada 1, el cual se encuentra en el archivo ```model_94.h5``` para su validación con respecto a los otros modelos. Es importante anotar que decidimos también implementar un algoritmo con transfer learning, remítase a dicho cuaderno para visualizarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf497f",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "---\n",
    "[1] https://www.analyticsvidhya.com/blog/2021/06/lstm-for-text-classification/\n",
    "\n",
    "[2] https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n",
    "\n",
    "[3] Application of Long Short-Term Memory (LSTM) Neural Network for Flood Forecasting - Scientific Figure on ResearchGate. Available from: https://www.researchgate.net/figure/The-structure-of-the-Long-Short-Term-Memory-LSTM-neural-network-Reproduced-from-Yan_fig8_334268507 [accessed 28 Mar, 2022]\n",
    "\n",
    "[4] Zhang Y, Chen Q, Yang Z, Lin H, Lu Z. BioWordVec, improving biomedical word embeddings with subword information and MeSH. Scientific Data. 2019.\n",
    "\n",
    "[5] https://towardsdatascience.com/simplified-math-behind-dropout-in-deep-learning-6d50f3f47275\n",
    "\n",
    "[6] https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "\n",
    "[7] https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f74c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
