{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### María Sofía Álvarez - Brenda Barahona - Álvaro Plata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Proyecto 1: Analítica de textos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de librerías\n",
    "<b><font color='blue'>Importante:</font></b> Correr antes de ejecutar el notebook. Con una única vez que se corra, basta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stopwords in c:\\users\\brend\\anaconda3\\lib\\site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!pip install -U git+https://github.com/neomatrix369/nlp_profiler.git@master\n",
    "#!pip install wordcloud\n",
    "#!pip install contractions\n",
    "#!pip install nltk\n",
    "#!pip install inflect\n",
    "#!pip install unicode\n",
    "#!pip install stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías\n",
    "Importamos las librerías necesarias para el desarrollo de este proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\brend\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\brend\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\brend\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\brend\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ESAI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nlp_profiler.core import apply_text_profiling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Para resampling\n",
    "from sklearn.utils import resample \n",
    "import contractions\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import inflect\n",
    "import re\n",
    "import unicodedata\n",
    "import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las historias médicas describen las condiciones actuales de un paciente. Los médicos rutinariamente escanean docenas o cientos de historias clínicas en un solo día mientras hacen sus turnos en un hospital y deben resaltar la información relevante de ellos para poder determinar la enfermedad que padece un paciente. El objetivo de este proyecto es, a partir de dichas historias clínicas dadas por los médicos, crear una herramienta que ayude en la identificación del problema/enfermedad que un paciente padece. Se busca que las predicciones realizadas sean bastante precisas, pues los pacientes deben ser tratados acorde con la enfermedad que padecen. \n",
    "\n",
    "A continuación, se leerá el conjunto de datos correspondiente. Este incluye historias clínicas de varios pacientes, con la información más relevante de sus enfermedades reportada por los médicos. Asimismo, para cada paciente se tiene la enfermedad que padece. De acuerdo con el diccionario, esta puede ser cualquiera de las siguientes 5 categorías: \n",
    "1. Neoplasms (Neoplasias).\n",
    "2. Digestive system diseases (Enfermedades del sistema digestivo).\n",
    "3. Nervous system diseases (Enfermedades del sistema nervioso).\n",
    "4. Cardiovascular diseases (Enfermedades cardiovasculares).\n",
    "5. General pathological conditions (Condiciones patológicas generales).\n",
    "\n",
    "Es posible ver que se tiene un problema de clasificación multiclase. \n",
    "\n",
    "---\n",
    "## 1. Entendimiento del problema\n",
    "Lo primero que hacemos es cargar las librerías y el conjunto de datos, con el fin de entender las particularidades del problema que estamos enfrentando.\n",
    "### 1.1 Perfilamiento de los datos\n",
    "Procedemos, entonces, a ver los datos suministrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses =pd.read_csv('ApoyoDiagnosticoEstudiante/medical_text_clasificacion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de datos: 12000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_abstracts</th>\n",
       "      <th>problems_described</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>Thrombosis in a congenitally bifurcated superi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>Retrobulbar alcohol injection in blind painful...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>Giant cell versus lymphocytic myocarditis. A c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>Risk for colon adenomas in patients with recto...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8400</th>\n",
       "      <td>Visual recovery in patients with optic neuriti...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       medical_abstracts  problems_described\n",
       "6671   Thrombosis in a congenitally bifurcated superi...                   3\n",
       "3714   Retrobulbar alcohol injection in blind painful...                   5\n",
       "11382  Giant cell versus lymphocytic myocarditis. A c...                   5\n",
       "3286   Risk for colon adenomas in patients with recto...                   5\n",
       "8400   Visual recovery in patients with optic neuriti...                   3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tamaño del conjunto de datos:\", len(diagnoses))\n",
    "diagnoses.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, podemos ver una muestra de los datos. Aquí, nos damos cuenta que nuestro conjunto de datos consiste de dos columnas: \"medical_abstracts\", con las historias clínicas de los pacientes (escritas en inglés), y \"problems_described\", que es un número con la enfermedad padecida por el paciente, de acuerdo con lo descrito arriba y en concordancia con el diccionario.\n",
    "\n",
    "Asimismo, vemos que tenemos 12000 historias clínicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las categorías de las enfermedades son: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print('Las categorías de las enfermedades son: {}'.format(sorted(diagnoses['problems_described'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que podemos revisar es si hay algún problema que no se encuentre en las categorías 1-5 definidas para las enfermedades. Como vemos, en este caso todas las categorías concuerdan con las definidas por el negocio. Asimismo, nos damos cuenta que la clasificación es multiclase y no multietiqueta: cada historia clínica tiene una única enfermedad asociada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora queremos ver si nuestro conjunto de datos tiene entradas nulas. Para ello, revisamos si hay historias clínicas que correspondan con la cadena vacía \"\" o con un sólo espacio \" \". Se ve que no hay ninguna con estas características, pues obtenemos un <i>dataframe</i> vacío, como vemos en la celda a continuación. Podemos hacer también una revisión con el método <code>isna()</code> de <code>pandas</code>. Este indica si hay algún valor de los datos que tenga como valor <code>None</code> o <code>numpy.NaN</code>. Vemos entonces que nuestro conjunto de datos no tiene ni nulos, ni faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical_abstracts     0\n",
      "problems_described    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(diagnoses.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de de historias clínicas vacías es: 0\n"
     ]
    }
   ],
   "source": [
    "vacias = diagnoses[(diagnoses['medical_abstracts'] == \"\") | (diagnoses['medical_abstracts'] == \" \")]\n",
    "print('La cantidad de de historias clínicas vacías es: {}'.format(len(vacias)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo, confirmamos que no hay historias clínicas duplicadas en el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "duplicados = diagnoses[diagnoses.duplicated()]\n",
    "print('Número de registros duplicados: {}'.format(len(duplicados)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos entonces que la calidad de los datos, en el sentido de nulos y duplicados, es bastante buena.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos damos cuenta ahora de que sólo tenemos una variable explicativa (la historia clínica) y que la variable objetivo (target) es la enfermedad que padece el usuario. Así las cosas partimos el conjunto de datos entre los datos de entrenamiento y de test: esto es crucial, pues, tras entrenar el modelo, debemos validarlo con datos que este nunca había visto. De acuerdo con el libro de Géron <a href='#geron'>[1]</a>, una buena división entre datos de entrenamiento y test es 80% y 20%, respectivamente, y en consecuencia es la que usaremos para toda esta exploración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = diagnoses['medical_abstracts'], diagnoses['problems_described']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,stratify=Y,test_size=0.2, random_state=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, procedemos a hacer todo el entrenamiento sobre el conjunto de $X_{\\mathrm{train}},Y_{\\mathrm{train}}$ y guardamos el test en la \"caja fuerte\" hasta que sea el momento de la validación.\n",
    "\n",
    "Queremos ver la distribución de las clases de nuestro conjunto de datos. Para ello, consideremos el siguiente histograma y la distribución de los textos de acuerdo con sus clases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceo de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veamos la cantidad de datos en cada clase: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problems_described</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problems_described\n",
       "5                3194\n",
       "1                2103\n",
       "4                2029\n",
       "3                1280\n",
       "2                 994"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_counts_y = Y_train.value_counts()\n",
    "plt.bar(range(len(val_counts_y)), val_counts_y.values, align='center',color='skyblue')\n",
    "plt.xticks(range(len(val_counts_y)), val_counts_y.index.values, size='small')\n",
    "plt.title('División de las clases del conjunto de datos')\n",
    "plt.show()\n",
    "\n",
    "print('Veamos la cantidad de datos en cada clase: ')\n",
    "Y_train.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver claramente que las clases están notablemente desbalanceadas. Vemos que la clase con más datos es la 5, lo cual es consecuente con el hecho de que esta es la clase más amplia, al tratar condiciones patológicas generales. Debemos clasificar todas las clases igual de bien, pues nos interesa conocer con precisión qué enfermedad posee cada paciente particular. Por esta razón, debemos utilizar técnicas de balanceo de clases. Podemos abordar este problema desde el preprocesamiento, usando técnicas de oversampling como SMOTE, o en la implementación del algoritmo, diciéndole que estamos trabajando con clases desbalanceadas (aunque esto depende de los algoritmos a utilizar, los cuales se definirán más adelante). Quisiéramos ver ambos comportamientos, entonces intentaremos explorar ambas alternativas. Esto se realiza más adelante, en las secciones de preprocesamiento y modelado (respectivamente) de este documento.\n",
    "\n",
    "Realizaremos un balanceo de datos, en el que quitaremos datos de los problemas 1, 4 y 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problems_described</th>\n",
       "      <th>medical_abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>4</td>\n",
       "      <td>Placebo controlled trial of xamoterol versus d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>1</td>\n",
       "      <td>Significance of blasts in low-cell-count cereb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>5</td>\n",
       "      <td>Obstructive sleep apnea following topical orop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>5</td>\n",
       "      <td>Experience with the Sarns centrifugal pump as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>3</td>\n",
       "      <td>Fine surface structure of an intraspinal neure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>1</td>\n",
       "      <td>Chondrosarcoma of the soft tissues. Two differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11269</th>\n",
       "      <td>4</td>\n",
       "      <td>Prolongation of ventricular refractoriness by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>1</td>\n",
       "      <td>Regressing atypical histiocytosis. Aberrant pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440</th>\n",
       "      <td>2</td>\n",
       "      <td>The role of gastric resection in the managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>5</td>\n",
       "      <td>Sympathomimetics for acute severe asthma: shou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       problems_described                                  medical_abstracts\n",
       "5659                    4  Placebo controlled trial of xamoterol versus d...\n",
       "11557                   1  Significance of blasts in low-cell-count cereb...\n",
       "1509                    5  Obstructive sleep apnea following topical orop...\n",
       "6883                    5  Experience with the Sarns centrifugal pump as ...\n",
       "3844                    3  Fine surface structure of an intraspinal neure...\n",
       "...                   ...                                                ...\n",
       "5271                    1  Chondrosarcoma of the soft tissues. Two differ...\n",
       "11269                   4  Prolongation of ventricular refractoriness by ...\n",
       "2059                    1  Regressing atypical histiocytosis. Aberrant pr...\n",
       "8440                    2  The role of gastric resection in the managemen...\n",
       "3820                    5  Sympathomimetics for acute severe asthma: shou...\n",
       "\n",
       "[9600 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train= pd.concat( [Y_train, X_train], axis=1)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1600\n",
       "1    1600\n",
       "5    1600\n",
       "3    1280\n",
       "2     994\n",
       "Name: problems_described, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1 = data_train[data_train[\"problems_described\"] == 1]\n",
    "cat2 = data_train[data_train[\"problems_described\"] == 2]\n",
    "cat3 = data_train[data_train[\"problems_described\"] == 3]\n",
    "cat4 = data_train[data_train[\"problems_described\"] == 4]\n",
    "cat5 = data_train[data_train[\"problems_described\"] == 5]\n",
    "\n",
    "cat1 = resample(cat1, replace = False, n_samples = 1600, random_state = 0)\n",
    "cat4 = resample(cat4, replace = False, n_samples = 1600, random_state = 0)\n",
    "cat5 = resample(cat5, replace = False, n_samples = 1600, random_state = 0)\n",
    "\n",
    "data_train = pd.concat([cat1, cat2, cat3, cat4, cat5])\n",
    "#Se cuentan los valores de la variable target\n",
    "data_train[\"problems_described\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = data_train[['medical_abstracts']], data_train[['problems_described']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-92f63173aa9b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['medical_abstracts']=X_train['medical_abstracts'].apply(contractions.fix)\n"
     ]
    }
   ],
   "source": [
    "#pasa de you're a you are \n",
    "X_train['medical_abstracts']=X_train['medical_abstracts'].apply(contractions.fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea nueva columna con la lista de las palabras \n",
    "X_train[\"words\"]=X_train['medical_abstracts'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems + lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"words\"]=X_train[\"words\"].apply(stem_and_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_abstracts</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>Ovarian myxoma. A study of two cases with long...</td>\n",
       "      <td>[ov, myxom, ., a, study, of, two, cas, with, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>Intraperitoneal yttrium-90-labeled monoclonal ...</td>\n",
       "      <td>[intraperiton, yttrium-90-labeled, monoclon, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11595</th>\n",
       "      <td>Chemical carcinogenesis: too many rodent carci...</td>\n",
       "      <td>[chem, carcinogenes, :, too, many, rod, carcin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11019</th>\n",
       "      <td>Comparison of FRTL-5 cell growth in vitro with...</td>\n",
       "      <td>[comparison, of, frtl-5, cel, grow, in, vitro,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Invasive lobular carcinoma: mammographic findi...</td>\n",
       "      <td>[invas, lobul, carcinom, :, mammograph, find, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>Prospective comparison of a conventional and a...</td>\n",
       "      <td>[prospect, comparison, of, a, conv, and, an, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>Hippocampal sclerosis in temporal lobe epileps...</td>\n",
       "      <td>[hippocamp, sclerosis, in, temp, lob, epilepsy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6981</th>\n",
       "      <td>The prolonged burner syndrome. Over the course...</td>\n",
       "      <td>[the, prolong, burn, syndrom, ., ov, the, cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>Myosin expression in hypertrophied fast twitch...</td>\n",
       "      <td>[myosin, express, in, hypertroph, fast, twitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>Elevation of the petrous bone caused by hyperp...</td>\n",
       "      <td>[elev, of, the, pet, bon, caus, by, hyperplas,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7074 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       medical_abstracts  \\\n",
       "7103   Ovarian myxoma. A study of two cases with long...   \n",
       "2269   Intraperitoneal yttrium-90-labeled monoclonal ...   \n",
       "11595  Chemical carcinogenesis: too many rodent carci...   \n",
       "11019  Comparison of FRTL-5 cell growth in vitro with...   \n",
       "791    Invasive lobular carcinoma: mammographic findi...   \n",
       "...                                                  ...   \n",
       "10686  Prospective comparison of a conventional and a...   \n",
       "8416   Hippocampal sclerosis in temporal lobe epileps...   \n",
       "6981   The prolonged burner syndrome. Over the course...   \n",
       "2731   Myosin expression in hypertrophied fast twitch...   \n",
       "5375   Elevation of the petrous bone caused by hyperp...   \n",
       "\n",
       "                                                   words  \n",
       "7103   [ov, myxom, ., a, study, of, two, cas, with, l...  \n",
       "2269   [intraperiton, yttrium-90-labeled, monoclon, a...  \n",
       "11595  [chem, carcinogenes, :, too, many, rod, carcin...  \n",
       "11019  [comparison, of, frtl-5, cel, grow, in, vitro,...  \n",
       "791    [invas, lobul, carcinom, :, mammograph, find, ...  \n",
       "...                                                  ...  \n",
       "10686  [prospect, comparison, of, a, conv, and, an, a...  \n",
       "8416   [hippocamp, sclerosis, in, temp, lob, epilepsy...  \n",
       "6981   [the, prolong, burn, syndrom, ., ov, the, cour...  \n",
       "2731   [myosin, express, in, hypertroph, fast, twitch...  \n",
       "5375   [elev, of, the, pet, bon, caus, by, hyperplas,...  \n",
       "\n",
       "[7074 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de Ruido \n",
    "En esta sección se quitará o modificará todo lo que se considere como ruido:\n",
    "\n",
    "+ Caracteres no ascii\n",
    "+ Se pasará de mayusculas a minusculas\n",
    "+ Se eliminará la puntuación\n",
    "+ Se reemplazarán los números\n",
    "+ Se quitarán las palabras vacias (artículos, pronombres, preposiciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "    \n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def preprocessing(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_abstracts</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>Ovarian myxoma. A study of two cases with long...</td>\n",
       "      <td>[ov, myxom, study, two, cas, longterm, followu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>Intraperitoneal yttrium-90-labeled monoclonal ...</td>\n",
       "      <td>[intraperiton, yttrium90labeled, monoclon, ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11595</th>\n",
       "      <td>Chemical carcinogenesis: too many rodent carci...</td>\n",
       "      <td>[chem, carcinogenes, many, rod, carcinog, admi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11019</th>\n",
       "      <td>Comparison of FRTL-5 cell growth in vitro with...</td>\n",
       "      <td>[comparison, frtl5, cel, grow, vitro, xenotran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Invasive lobular carcinoma: mammographic findi...</td>\n",
       "      <td>[invas, lobul, carcinom, mammograph, find, 10y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>Prospective comparison of a conventional and a...</td>\n",
       "      <td>[prospect, comparison, conv, accel, protocol, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>Hippocampal sclerosis in temporal lobe epileps...</td>\n",
       "      <td>[hippocamp, sclerosis, temp, lob, epilepsy, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6981</th>\n",
       "      <td>The prolonged burner syndrome. Over the course...</td>\n",
       "      <td>[prolong, burn, syndrom, ov, cours, singl, foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>Myosin expression in hypertrophied fast twitch...</td>\n",
       "      <td>[myosin, express, hypertroph, fast, twitch, sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>Elevation of the petrous bone caused by hyperp...</td>\n",
       "      <td>[elev, pet, bon, caus, hyperplas, occipit, bon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7074 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       medical_abstracts  \\\n",
       "7103   Ovarian myxoma. A study of two cases with long...   \n",
       "2269   Intraperitoneal yttrium-90-labeled monoclonal ...   \n",
       "11595  Chemical carcinogenesis: too many rodent carci...   \n",
       "11019  Comparison of FRTL-5 cell growth in vitro with...   \n",
       "791    Invasive lobular carcinoma: mammographic findi...   \n",
       "...                                                  ...   \n",
       "10686  Prospective comparison of a conventional and a...   \n",
       "8416   Hippocampal sclerosis in temporal lobe epileps...   \n",
       "6981   The prolonged burner syndrome. Over the course...   \n",
       "2731   Myosin expression in hypertrophied fast twitch...   \n",
       "5375   Elevation of the petrous bone caused by hyperp...   \n",
       "\n",
       "                                                   words  \n",
       "7103   [ov, myxom, study, two, cas, longterm, followu...  \n",
       "2269   [intraperiton, yttrium90labeled, monoclon, ant...  \n",
       "11595  [chem, carcinogenes, many, rod, carcinog, admi...  \n",
       "11019  [comparison, frtl5, cel, grow, vitro, xenotran...  \n",
       "791    [invas, lobul, carcinom, mammograph, find, 10y...  \n",
       "...                                                  ...  \n",
       "10686  [prospect, comparison, conv, accel, protocol, ...  \n",
       "8416   [hippocamp, sclerosis, temp, lob, epilepsy, de...  \n",
       "6981   [prolong, burn, syndrom, ov, cours, singl, foo...  \n",
       "2731   [myosin, express, hypertroph, fast, twitch, sl...  \n",
       "5375   [elev, pet, bon, caus, hyperplas, occipit, bon...  \n",
       "\n",
       "[7074 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"words\"]=X_train[\"words\"].apply(preprocessing)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "banned = [\"and\"]\n",
    "\n",
    "def remove_banned(words):\n",
    "    \"\"\"Remove banned words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in banned:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "X_train['words'] = X_train['words'].apply(remove_banned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_abstracts</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>Ovarian myxoma. A study of two cases with long...</td>\n",
       "      <td>ov myxom study two cas longterm followup two c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>Intraperitoneal yttrium-90-labeled monoclonal ...</td>\n",
       "      <td>intraperiton yttrium90labeled monoclon antibod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11595</th>\n",
       "      <td>Chemical carcinogenesis: too many rodent carci...</td>\n",
       "      <td>chem carcinogenes many rod carcinog admin chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11019</th>\n",
       "      <td>Comparison of FRTL-5 cell growth in vitro with...</td>\n",
       "      <td>comparison frtl5 cel grow vitro xenotranspl ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Invasive lobular carcinoma: mammographic findi...</td>\n",
       "      <td>invas lobul carcinom mammograph find 10year ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       medical_abstracts  \\\n",
       "7103   Ovarian myxoma. A study of two cases with long...   \n",
       "2269   Intraperitoneal yttrium-90-labeled monoclonal ...   \n",
       "11595  Chemical carcinogenesis: too many rodent carci...   \n",
       "11019  Comparison of FRTL-5 cell growth in vitro with...   \n",
       "791    Invasive lobular carcinoma: mammographic findi...   \n",
       "\n",
       "                                                   words  \n",
       "7103   ov myxom study two cas longterm followup two c...  \n",
       "2269   intraperiton yttrium90labeled monoclon antibod...  \n",
       "11595  chem carcinogenes many rod carcinog admin chem...  \n",
       "11019  comparison frtl5 cel grow vitro xenotranspl ce...  \n",
       "791    invas lobul carcinom mammograph find 10year ex...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actualizacion de la columna words. se pone toda la lista a manera de str \n",
    "X_train['words'] = X_train['words'].apply(lambda x: ' '.join(map(str, x)))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problems_described</th>\n",
       "      <th>medical_abstracts</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>1</td>\n",
       "      <td>Ovarian myxoma. A study of two cases with long...</td>\n",
       "      <td>ov myxom study two cas longterm followup two c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>1</td>\n",
       "      <td>Intraperitoneal yttrium-90-labeled monoclonal ...</td>\n",
       "      <td>intraperiton yttrium90labeled monoclon antibod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11595</th>\n",
       "      <td>1</td>\n",
       "      <td>Chemical carcinogenesis: too many rodent carci...</td>\n",
       "      <td>chem carcinogenes many rod carcinog admin chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11019</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparison of FRTL-5 cell growth in vitro with...</td>\n",
       "      <td>comparison frtl5 cel grow vitro xenotranspl ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>1</td>\n",
       "      <td>Invasive lobular carcinoma: mammographic findi...</td>\n",
       "      <td>invas lobul carcinom mammograph find 10year ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>5</td>\n",
       "      <td>Prospective comparison of a conventional and a...</td>\n",
       "      <td>prospect comparison conv accel protocol progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>5</td>\n",
       "      <td>Hippocampal sclerosis in temporal lobe epileps...</td>\n",
       "      <td>hippocamp sclerosis temp lob epilepsy demonst ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6981</th>\n",
       "      <td>5</td>\n",
       "      <td>The prolonged burner syndrome. Over the course...</td>\n",
       "      <td>prolong burn syndrom ov cours singl footbal se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>5</td>\n",
       "      <td>Myosin expression in hypertrophied fast twitch...</td>\n",
       "      <td>myosin express hypertroph fast twitch slow ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>5</td>\n",
       "      <td>Elevation of the petrous bone caused by hyperp...</td>\n",
       "      <td>elev pet bon caus hyperplas occipit bon pres h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7074 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       problems_described                                  medical_abstracts  \\\n",
       "7103                    1  Ovarian myxoma. A study of two cases with long...   \n",
       "2269                    1  Intraperitoneal yttrium-90-labeled monoclonal ...   \n",
       "11595                   1  Chemical carcinogenesis: too many rodent carci...   \n",
       "11019                   1  Comparison of FRTL-5 cell growth in vitro with...   \n",
       "791                     1  Invasive lobular carcinoma: mammographic findi...   \n",
       "...                   ...                                                ...   \n",
       "10686                   5  Prospective comparison of a conventional and a...   \n",
       "8416                    5  Hippocampal sclerosis in temporal lobe epileps...   \n",
       "6981                    5  The prolonged burner syndrome. Over the course...   \n",
       "2731                    5  Myosin expression in hypertrophied fast twitch...   \n",
       "5375                    5  Elevation of the petrous bone caused by hyperp...   \n",
       "\n",
       "                                                   words  \n",
       "7103   ov myxom study two cas longterm followup two c...  \n",
       "2269   intraperiton yttrium90labeled monoclon antibod...  \n",
       "11595  chem carcinogenes many rod carcinog admin chem...  \n",
       "11019  comparison frtl5 cel grow vitro xenotranspl ce...  \n",
       "791    invas lobul carcinom mammograph find 10year ex...  \n",
       "...                                                  ...  \n",
       "10686  prospect comparison conv accel protocol progra...  \n",
       "8416   hippocamp sclerosis temp lob epilepsy demonst ...  \n",
       "6981   prolong burn syndrom ov cours singl footbal se...  \n",
       "2731   myosin express hypertroph fast twitch slow ton...  \n",
       "5375   elev pet bon caus hyperplas occipit bon pres h...  \n",
       "\n",
       "[7074 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train= pd.concat( [Y_train, X_train], axis=1)\n",
    "data_test= pd.concat( [Y_test, X_test], axis=1)\n",
    "data_train.to_csv(\"train_Data.csv\")\n",
    "data_test.to_csv(\"test_Data.csv\")\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#los tokens (palabras) para un determinado problems_described se junten\n",
    "#Junta todas las palabras con el problema #problems_described\n",
    "def generate_docx(df, problems_described):\n",
    "    \"\"\"Gets a string of all text of an emotion\"\"\"\n",
    "    mylist = df[df[\"problems_described\"] == problems_described][\"words\"].tolist()\n",
    "    mydocx = ''.join(mylist)\n",
    "    return mydocx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5=generate_docx(data_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Da los 50 tokens mas comunes \n",
    "def extract_keywords(text, num = 50):\n",
    "    \"\"\"Gets a dictionary with the # of ocurrences of a word\"\"\"\n",
    "    tokens = [token for token in text.split()]\n",
    "    most_common_tokens = Counter(tokens).most_common(num)\n",
    "    return dict(most_common_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6f46744f3fa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkey5\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'doc5' is not defined"
     ]
    }
   ],
   "source": [
    "key5= extract_keywords(doc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "def plot_most_common_words(mydict, problems_described):\n",
    "    df_01 = pd.DataFrame(mydict.items(),columns=[\"token\",\"count\"])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Plot of {}\".format(problems_described))\n",
    "    sns.barplot(x = 'token', y=\"count\", data = df_01)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cd787fb65ae0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_most_common_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'key5' is not defined"
     ]
    }
   ],
   "source": [
    "plot_most_common_words(key5,\"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7103     False\n",
       "2269     False\n",
       "11595    False\n",
       "11019    False\n",
       "791      False\n",
       "         ...  \n",
       "10686     True\n",
       "8416      True\n",
       "6981      True\n",
       "2731      True\n",
       "5375      True\n",
       "Name: problems_described, Length: 7074, dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"problems_described\"]==5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante notar que almacenaremos el resultado del perfilamiento en un archivo <code>csv</code> para fácil acceso cuando tenga que ejecutarse todo el proyecto; y, segundo, nos enfocaremos en analizar únicamente aquellas funcionalidades de <code>nlp profiler</code> que sean relevantes para este proyecto. Entonces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importante: ¡Esta celda tarda mucho en ejecutarse!\n",
    "#profile_data = apply_text_profiling(diagnoses, 'medical_abstracts')\n",
    "\n",
    "# Importante: No correr esta linea si no se ha corrido la anterior.\n",
    "#profile_data.to_csv('nlp_profiler_medical_abstracts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data = pd.read_csv('nlp_profiler_medical_abstracts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
